1929 or 1989?
PARIS – As the economic crisis deepens and widens, the world has been searching for historical analogies to help us understand what has been happening.
At the start of the crisis, many people likened it to 1982 or 1973, which was reassuring, because both dates refer to classical cyclical downturns.
Today, the mood is much grimmer, with references to 1929 and 1931 beginning to abound, even if some governments continue to behave as if the crisis was more classical than exceptional.
The tendency is either excessive restraint (Europe) or a diffusion of the effort (the United States).
Europe is being cautious in the name of avoiding debt and defending the euro, whereas the US has moved on many fronts in order not to waste an ideal opportunity to implement badly needed structural reforms.
For geo-strategists, however, the year that naturally comes to mind, in both politics and economics, is 1989.
Of course, the fall of the house of Lehman Brothers has nothing to do with the fall of the Berlin Wall.
Indeed, on the surface it seems to be its perfect antithesis: the collapse of a wall symbolizing oppression and artificial divisions versus the collapse of a seemingly indestructible and reassuring institution of financial capitalism.
Yet 2008-2009, like 1989, may very well correspond to an epochal change, whose unfolding consequences will be felt for decades.
The end of the East-West ideological divide and the end of absolute faith in markets are historical turning points.
And what happens in 2009 may jeopardize some of the positive results of 1989, including the peaceful reunification of Europe and the triumph of democratic principles over nationalist, if not xenophobic, tendencies.
In 1989, liberal democracy triumphed over the socialist ideology incarnated and promoted by the Soviet Bloc.
For many of his supporters, it was President Ronald Reagan who, with his deliberate escalation of the arms race, pushed the Soviet economy to the brink, thereby fully demonstrating the superiority of liberal societies and free markets.
Of course, there are obvious differences between 1989 and now.
First, and perhaps above all, the revolutions of 1989 and the subsequent collapse of the Soviet Union put an end to global bipolarity.
By contrast, 2009 is likely to pave the way to a new form of bipolarity, but with China substituting for the Soviet Union.
Second, whereas democracy and market capitalism appeared as clear – if more fragile than expected – winners in 1989, it is difficult in 2009, with the spread of the global crisis, to distinguish winners from losers.
Everyone seems to be a loser, even if some are more affected than others.
Yet, history is unfair, and the US, despite its greater responsibility for today’s global crisis, may emerge in better shape than most countries from the morass.
In better shape, but not alone.
As a visiting professor at Harvard and MIT, I am getting a good preview of what the world could look like when the crisis finally passes.
One senses something like the making of an American-Asian dominated universe.
From the incredible media lab at MIT to the mathematics and economics departments at Harvard, Asians – Chinese and Indians, in particular – are everywhere, like the Romans in Athens in the first century BC: full of admiration for those from whom they were learning so much, and whom they would overcome in the coming decades.
But before this new order appears, the world may be faced with spreading disorder, if not outright chaos.
What, for example, will happen to a country as central and vulnerable as Egypt when hundred of thousands of Egyptians working in the Gulf are forced to return to their homeland as a result of the crisis in the oil-producing countries?
When the rich get less rich, the poor get poorer.
And what about the foreign workers who have reached for the “European dream” and are now faced with potential explosions of xenophobia in Europe’s supposedly open countries?
The consequences of 1989 ended up being less enduring than many observers, including me, would have assumed.
We can only hope that, in the end, the consequences of 2009 similarly prove to be far less dramatic than we now – intuitively and in our historical reflexes – feel them to be.
One Hundred Years of Ineptitude
BERLIN – The global financial and economic crisis that began in 2008 was the greatest economic stress-test since the Great Depression, and the greatest challenge to social and political systems since World War II.
It not only put financial markets and currencies at risk; it also exposed serious regulatory and governance shortcomings that have yet to be fully addressed.
In fact, the 2008 crisis will most likely be remembered as a watershed moment, but not because it led to reforms that strengthened economic resilience and removed vulnerabilities.
On the contrary, leaders’ failure to discern, much less act on, the lessons of the Great Recession may open the way for a series of fresh crises, economic and otherwise, in the coming decades.
However serious those crises turn out to be, historians a century from now will likely despair at our shortsightedness.
They will note that analysts and regulators were narrowly focused on fixing the financial system by strengthening national oversight regimes.
While this was a worthy goal, historians will point out, it was far from the only imperative.
To prepare the world to confront the challenges posed by globalization and technological development in a way that supports sustainable and equitable growth, governance institutions and regulations at both the national and international levels must be drastically improved.
Yet not nearly enough has been invested in this effort.
Beyond regional bodies like the European Union, international financial governance has remained largely untouched.
Worse, because the partial fixes to the financial system will enable even more globalization, they will end up making matters worse, as strain on already-inadequate governance and regulatory frameworks increases, not only in finance, but also in other economic and technological fields.
Meanwhile, enormous financial investments focused on securing a higher rate of return are likely to fuel technological innovation, further stressing regulatory systems in finance and beyond.
Major technological advances fueled by cheap money can cause markets to change so fast that policy and institutional change cannot keep up.
And new markets can emerge that offer huge payoffs for early adopters or investors, who benefit from remaining several steps ahead of national and international regulators.
This is what happened in the run-up to the 2008 crisis.
New technology-enabled financial instruments created opportunities for some to make huge amounts of money.
But regulators were unable to keep up with the innovations, which ended up generating risks that affected the entire economy.
This points to a fundamental difference between global crises of the twenty-first century and, say, the Great Depression in the 1930s or, indeed, any past stock-market crashes.
Because of the financial sector’s growth, more actors benefit from under-regulation and weak governance in the short term, making today’s crises more difficult to prevent.
Complicating matters further, the systems affected by today’s crises extend well beyond any one regulatory body’s jurisdiction.
That makes crises far unrulier, and their consequences – including their long-term influence on societies and politics – more difficult to predict.
The next crises – made more likely by rising nationalism and a growing disregard for science and fact-based policymaking – may be financial, but they could also implicate realms as varied as migration, trade, cyberspace, pollution, and climate change.
In all of these areas, national and international governance institutions are weak or incomplete, and there are few independent actors, such as watchdog groups, demanding transparency and accountability.
This makes it harder not only to prevent crises – not least because it creates opportunities for actors to game the system and shirk responsibility – but also to respond to them.
The 2008 crisis cast a harsh spotlight on just how bad we are at responding quickly to disasters, especially those fueled by fragmented governance.
To be sure, as the Hertie School’s 2018 Governance Report shows, there have been some improvements in preparing for and managing crises.
But we must become more alert to how developments in a wide range of fields – from finance to digital technologies and climate change – can elude the governance capacities of national and international institutions.
We should be running crisis scenarios and preparing emergency plans for upheaval in all of these fields, and taking stronger steps to mitigate risks, including by managing debt levels, which today remain much higher in the advanced economies than they were before the 2008 crisis.
Moreover, we should ensure that we provide international institutions with the needed resources and responsibilities.
And by punishing those who exacerbate risks for the sake of their own interests, we would strengthen the legitimacy of global governance and the institutions that are meant to conduct it.
As it stands, inadequate cross-border coordination and enforcement of international agreements is a major impediment to crisis prevention and management.
Yet, far from addressing this weakness, the world is reviving an outdated model of national sovereignty that makes crises of various kinds more likely.
Unless we change course soon, the world of 2118 will have much reason to regard us with scorn.
What Failed in 2008?
BERKELEY – To solve a problem, it is not enough to know what to do.
You actually have to implement the solution – and be willing to change course if it turns out that you did not know quite as much as you thought.
That is the message of two recent books that, together, tell you everything you need to know about the 2008 financial crisis: what caused it, what can be done to prevent it from recurring, and why those things have yet to be done.
The first book is The Shifts and the Shocks, by the conservative British journalist Martin Wolf, who begins by cataloguing the major shifts that set the stage for the economic disaster that continues to shape the world today.
His starting point is the huge rise in wealth among the world’s richest 0.1% and 0.01% and the consequent pressure for people, governments, and companies to take on increasingly unsustainable levels of debt.
Meanwhile, policymakers were lulled into complacency by the widespread acceptance of economic theories such as the “efficient-market hypothesis,” which assumes that investors act rationally and use all available information when making their decisions.
As a result, markets were deregulated, making it easier to trade assets that were perceived to be safe, but were in fact not.
As a result, systemic risk proliferated beyond central bankers’ wildest imagination.
Untested – and ultimately incorrect – assumptions created a policymaking environment defined by what can only be called hubris.
Officials underestimated tail risks.
They set inflation targets at around 2% – leaving little room for maneuver when the water got choppy.
And, most audaciously of all, the European Union introduced the euro as a common currency.
Indeed, wrongheaded policymaking continued long after the crisis began.
Politicians responded to worsening economic conditions by hewing as closely as possible to failed prescriptions, making sure to do no more than absolutely necessary to address the biggest economic disaster since the Great Depression.
Wolf’s prescription for countering the crisis is simple, smart, and unassailable.
In the short term, he suggests that countries with reserve currencies spend more (especially to finance public-sector investments) and issue more debt.
Their central banks, he argues, should raise inflation targets to 3% or even 4% per year.
Over the medium term, according to Wolf, countries need to put in place regulatory measures that lower debt levels and discourage overleveraging.
The eurozone, too, must resolve its internal contradictions, either by disbanding or by introducing “a minimum set of institutions and policies” that allow the monetary union to function properly.
Wolf’s long-term solutions include tackling inequality, “more global regulation,” a greater degree of “freedom for individual countries to craft their own responses,” and economic analysis that is less in thrall to the free-market ideologues that led us into the crisis in the first place.
And yet, as recommendable as Wolf’s proposals may be, little has been done to implement them.
The reasons why are found in the second book: Hall of Mirrors, by my friend, teacher, and patron, Barry Eichengreen.
Eichengreen traces our tepid response to the crisis to the triumph of monetarist economists, the disciples of Milton Friedman, over their Keynesian and Minskyite peers – at least when it comes to interpretations of the causes and consequences of the Great Depression.
When the 2008 financial crisis erupted, policymakers tried to apply Friedman’s proposed solutions to the Great Depression.
Unfortunately, this turned out to be the wrong thing to do, as the monetarist interpretation of the Great Depression was, to put it bluntly, wrong in significant respects and radically incomplete.
The resulting policies were enough to prevent the post-2008 recession from developing into a full-blown depression; but that partial success turned out to be a Pyrrhic victory, for it allowed politicians to declare that the crisis had been overcome, and that it was time to embrace austerity and focus on structural reform.
The result is today’s stagnant economy, marked by anemic growth that threatens to become the new normal.
The United States and Europe are on track to have thrown away 10% of their potential wealth, while the failure to strengthen financial-sector regulation has left the world economy exposed to the risk of another major crisis.
Wolf and Eichengreen would agree that the main shortcomings that led to the 2008 financial crisis – and that continue to underpin our inadequate response to it – are intellectual.
Indeed, the only true lesson of the crisis so far seems to be that its lessons will never truly be learned.
A Comeback Strategy for Europe
STOCKHOLM/MADRID – When Pope Francis addressed the European Parliament last November, he compared the European Union to a grandmother – pleasant and rich with experience, but lacking the vitality and energy of the past.
It is high time, Francis argued, that EU leaders shed their dozy image, recognize the strategic challenges that Europe faces, and forge a clear policy for tackling them.
Admittedly, the pope’s characterization was alarmingly accurate in some respects.
But, despite its seeming lassitude, Europe retains significant strengths.
It is a hub of high-level thought and innovation; it is home to some of the world’s most competitive regions and industries; and, perhaps most impressive, it has built a community and market encompassing a half-billion people.
But the world is changing: the Asia-Pacific region is increasingly influencing global developments, economic and otherwise.
The Trans-Pacific Partnership – by which the United States and 11 other countries would create a mega-regional free-trade zone – would most likely accelerate this shift (all the more so if China eventually joins).
Though the TPP faces no shortage of hurdles to clear before an agreement is finalized, its potential to augment Asia’s economic power cannot be underestimated.
Europe must work to secure its position in the new world order – beginning by enhancing its own trade and investment ties with the US.
The problem is that, as the TPP negotiations progress, talks on the EU-US Transatlantic Trade and Investment Partnership (TTIP) have become so deeply mired in domestic controversies that the entire project may well be scuttled.
Business leaders on both sides of the Atlantic are convinced that a successful TTIP agreement would bring substantial economic benefits – a perception that many studies reinforce.
Yet trivial issues – for example, the use of chlorinated chicken and settlements of investor disputes – continue to dominate the debate.
The TTIP’s goal is to unleash the power of the transatlantic economy, which remains by far the world’s largest and wealthiest market, accounting for three-quarters of global financial activity and more than half of world trade.
(If the TTIP was opened to other economies – such as Turkey, Mexico, and Canada – the benefits would be even greater.)
Even more compelling than the benefits of achieving an agreement, though, are the potentially catastrophic consequences of failure.
For starters, a breakdown of TTIP talks would give considerable ammunition to those in the United Kingdom who advocate withdrawal from the EU; conversely, if the TTIP were implemented, the UK would be unwise – and thus unlikely – to leave.
Moreover, the perception that the EU’s internal squabbles had led it to squander a strategic opportunity would probably drive the US to accelerate its disengagement from the continent.
And Russian President Vladimir Putin would invariably regard the EU’s failure as a major opportunity to exert more influence over parts of Europe.
All of this contributes to a starkly fundamental strategic risk: If the TTIP stalls or collapses, while the TPP moves forward and succeeds, the global balance will tip strongly in Asia’s favor – and Europe will have few options, if any, for regaining its economic and geopolitical influence.
When the TTIP was first proposed, Europe seemed to recognize its value.
Indeed, it was the EU that pushed the US, which initially doubted Europe’s commitment, to launch the negotiation process in June 2013.
The ambition was to complete the negotiations on “one tank of gas.”
No one wanted to endure protracted talks – or the associated political pain.
But EU leaders essentially abandoned the project, seemingly confirming American fears.
Trade negotiators struggled to make headway, while anti-globalization groups seized control of the public discourse, presenting the TTIP as a threat to everything from Europe’s democracy to its health.
This is dangerously inaccurate talk, and EU leaders must prevent it from gaining any more traction by making the strategic case for the agreement.
And they must revive their commitment to conclude the talks successfully in 2015.
This is not to say that resolving the remaining issues in the TTIP negotiations will be simple.
But establishing a trade agreement, especially one that entails so many regulatory issues, is always difficult, as it must account for the complexity and changeability of modern economies.
The fact is that the challenges inherent in completing the TTIP are no more intractable than those that EU leaders have faced in the last few years of crisis.
When the TTIP negotiations resume next month, EU leaders must push for genuine progress, with the goal of completing a deal by the end of the year.
The good news is that the recent midterm elections in the US might have improved their chances.
President Barack Obama now might get so-called fast-track negotiating authority from Congress.
If he does, Congress would simply approve or reject any negotiated agreement, rather than picking it apart.
The US presidential election season is starting, and other issues in the new year could easily take over the EU agenda.
That is why Europe’s leaders have no time to waste.
They must seize economic opportunity – and avert strategic disaster.
The Year That Ended an Epoch?
MADRID – As 2016 comes to an end, the outlook for 2017 is shrouded in uncertainty.
Tensions in the Middle East are rising, and populist movements have appeared in Europe and the United States.
In the Middle East, the tragic conflict in Syria continues, despite several fruitless attempts at rapprochement, which were marred by the fundamental disagreement about Syrian President Bashar al-Assad’s future role in any peace process or political transition.
Meanwhile, over the past week, Syrian government troops, backed by Russia and Iran, have retaken almost all of Aleppo – once Syria’s largest city, now utterly devastated by the war.
The world’s priority for the coming year must be to achieve peace in Syria, which will require close regional and international cooperation.
On December 27, Iran, Russia, and Turkey will hold a tripartite meeting in Moscow to discuss a political solution for the Syria conflict.
That meeting, if it takes place, is likely to be overshadowed by the fallout from the assassination of Russia’s ambassador to Turkey.
But it is nothing if not surprising that these parties, and not the US and the European Union, would be negotiating such an agreement.
One positive development this year came in March, when the EU and Turkey signed an agreement to address the refugee crisis.
Turkey has now taken in some three million Syrian refugees since the beginning of the conflict.
Although EU-Turkey relations are currently not at their best, the dialogue between the two sides must continue in 2017, not least because of their common interests, which are based not only on economic interdependence, but also on the refugee crisis and the collective fight against terrorism.
European politics next year, meanwhile, will be consumed by the Brexit negotiations.
In March, the United Kingdom will likely invoke Article 50 of the Treaty of Lisbon, triggering the formal procedure for withdrawal from the EU.
The challenge will be to reach an agreement that guarantees the wellbeing of future EU-UK relations.
This will not be easy, and EU negotiators have already set a timeline of only 18 months.
While much remains uncertain, what is clear is that if the UK wants to retain access to the European single market, it will have to accept the EU’s four freedoms, including the free movement of workers.
In 2017, several European countries will hold general elections, and there is a risk that isolationist, anti-European populist movements will make a strong showing.
For the EU to lose a country as militarily and economically important as the UK is bad enough; but to lose a founding EU member state, such as France, would be tragic.
Fortunately, many Europeans’ views toward the EU actually improved in the aftermath of the Brexit referendum.
But this will not lessen the challenge for EU governments in the year ahead.
They must unite societies divided by powerful global forces, such as globalization and rapid technological innovation.
The Brexit referendum, followed by Donald Trump’s victory in the US presidential election, signaled the rise of populism in the West.
But now that Trump is filling his cabinet with oligarchs and former military men, we have reason to doubt that he will keep his promise to govern without the Washington “establishment.”
Trump’s incoming administration is full of unknowns, but there can be no doubt that his rejection of multilateral institutions will endanger international efforts to cooperate on solutions to the world’s biggest problems.
This holds peril for US-EU relations.
In previous years, the Paris climate agreement and the nuclear agreement with Iran were rays of light in a world closing itself off to multilateralism.
In the coming years, such rays may become scarcer still.
Now more than ever, we need the kind of dialogue that builds strategic trust between great powers.
And yet, Trump’s statements casting doubt on continued US adherence to a “One China” policy vis-à-vis Taiwan could severely damage relations between the world’s two largest economies.
Similarly, notwithstanding the pro-Russian leanings of some among Trump’s team, the US-Russian relationship also lacks strategic trust, owing to Russia’s military intervention in Syria, its invasion of eastern Ukraine, and its alleged interference in the US election.
The coming year will be particularly important for Europe.
Relations between the EU and the US must remain strong, rooted in mutual respect for democracy, freedom, and human rights.
After a turbulent 2016, and with little positive news in international politics, 2017 is shaping up to be a year of challenges and uncertainty.
But the biggest uncertainty of all is whether this is simply the end of another year, or the end of a geopolitical epoch.
Another Slow Year for the Global Economy
WASHINGTON, DC – Last April, the International Monetary Fund projected that the world economy would grow by 3.5% in 2015.
In the ensuing months, that forecast was steadily whittled down, reaching 3.1% in October.
But the IMF continues to insist – as it has, with almost banal predictability, for the last seven years – that next year will be better.
But it is almost certainly wrong yet again.
For starters, world trade is growing at an anemic annual rate of 2%, compared to 8% from 2003 to 2007.
Whereas trade growth during those heady years far exceeded that of world GDP, which averaged 4.5%, lately, trade and GDP growth rates have been about the same.
Even if GDP growth outstrips growth in trade this year, it will likely amount to no more than 2.7%.
The question is why.
According to Christina and David Romer of the University of California, Berkeley, the aftershocks of modern financial crises – that is, since World War II – fade after 2-3 years.
The Harvard economists Carmen Reinhart and Kenneth Rogoff say that it takes five years for a country to dig itself out of a financial crisis.
And, indeed, the financial dislocations of 2007-2008 have largely receded.
So what accounts for the sluggish economic recovery?
One popular explanation lies in the fuzzy notion of “secular stagnation”: long-term depressed demand for goods and services is undermining incentives to invest and hire.
But demand would remain weak only if people lacked confidence in the future.
The only logical explanation for this enduring lack of confidence, as Northwestern University’s Robert Gordon has painstakingly documented and argued, is slow productivity growth.
Before the crisis – and especially from 2003 to 2007 – slow productivity growth was being obscured by an illusory sense of prosperity in much of the world.
In some countries – notably, the United States, Spain, and Ireland – rising real-estate prices, speculative construction, and financial risk-taking were mutually reinforcing.
At the same time, countries were amplifying one another’s growth through trade.
Central to the global boom was China, the rising giant that flooded the world with cheap exports, putting a lid on global inflation.
Equally important, China imported a huge volume of commodities, thereby bolstering many African and Latin American economies, and purchased German cars and machines, enabling Europe’s largest economy to keep its regional supply chains humming.
This dynamic reversed around March 2008, when the US rescued its fifth-largest investment bank, Bear Sterns, from collapse.
With the eurozone banks also deeply implicated in the subprime mortgage mess and desperately short of US dollars, America and much of Europe began a remorseless slide into recession.
Whereas in the boom years, world trade had spread the bounty, it was now spreading the malaise.
As each country’s GDP growth slowed, so did its imports, causing its trading partners’ growth to slow as well.
The US economy began to emerge from its recession in the second half of 2009, thanks largely to aggressive monetary policy and steps to stabilize the financial system.
Eurozone policymakers, by contrast, rejected monetary stimulus and implemented fiscal austerity measures, while ignoring the deepening distress of their banks.
The eurozone thus pushed the world into a second global recession.
Just when that recession seemed to have run its course, emerging economies began to unravel.
For years, observers had been touting the governance and growth-enhancing reforms that these countries’ leaders had supposedly introduced.
In October 2012, the IMF celebrated emerging economies’ “resilience.”
As if on cue, that facade began to crumble, revealing an inconvenient truth: factors like high commodity prices and massive capital inflows had been concealing serious economic weaknesses, while legitimizing a culture of garish inequality and rampant corruption.
These problems are now being compounded by the growth slowdown in China, the fulcrum of global trade.
And the worst is yet to come.
China’s huge industrial overcapacity and property glut needs to be wound down; the hubris driving its global acquisitions must be reined in; and its corruption networks have to be dismantled.
In short, the factors that dragged down the global economy in 2015 will persist – and in some cases even intensify – in the new year.
Emerging economies will remain weak.
The eurozone, having enjoyed a temporary reprieve from austerity, will be constrained by listless global trade.
Rising interest rates on corporate bonds portend slower growth in the US.
China’s collapsing asset values could trigger financial turbulence.
And policymakers are adrift, with little political leverage to stem these trends.
The IMF should stop forecasting renewed growth and issue a warning that the global economy will remain weak and vulnerable unless world leaders act energetically to spur innovation and growth.
Such an effort is long overdue.
Trumpian Uncertainty
NEW YORK – Every January, I try to craft a forecast for the coming year.
Economic forecasting is notoriously difficult; but, notwithstanding the truth expressed in Harry Truman’s request for a one-armed economist (who wouldn’t be able to say “on the other hand”), my record has been credible.
In recent years, I correctly foresaw that, in the absence of stronger fiscal stimulus (which was not forthcoming in either Europe or the United States), recovery from the Great Recession of 2008 would be slow.
In making these forecasts, I have relied more on analysis of underlying economic forces than on complex econometric models.
For example, at the beginning of 2016, it seemed clear that the deficiencies of global aggregate demand that have been manifest for the last several years were unlikely to change dramatically.
Thus, I thought that forecasters of a stronger recovery were looking at the world through rose-tinted glasses. Economic developments unfolded much as I anticipated.
Not so the political events of 2016.
I had been writing for years that unless growing inequality – especially in the US, but also in many countries throughout the world – was addressed, there would be political consequences.
But inequality continued to worsen – with striking data showing that average life expectancy in the US was on the decline.
These results were foreshadowed by a study last year, by Anne Case and Angus Deaton, which showed that life expectancy was on the decline for large segments of the population – including America’s so-called angry men of the Rust Belt.
But, with the incomes of the bottom 90% having stagnated for close to a third of a century (and declining for a significant proportion), the health data simply confirmed that things were not going well for very large swaths of the country.
And while America might be at the extreme of this trend, things were little better elsewhere.
But, if it seemed clear that there would be political consequences, their form and timing were far less obvious.
Why did the backlash in the US come just when the economy seemed to be on the mend, rather than earlier?
And why did it manifest itself in a lurch to the right?
After all, it was the Republicans who had blocked assistance to those losing their jobs as a result of the globalization they pushed assiduously. It was the Republicans who, in 26 states, refused to allow the expansion of Medicaid, thereby denying health insurance to those at the bottom.
And why was the victor somebody who made his living from taking advantage of others, openly admitted not paying his fair share of taxes, and made tax avoidance a point of pride?
Donald Trump grasped the spirit of the time: things weren’t going well, and many voters wanted change.
Now they will get it: there will be no business as usual. But seldom has there been more uncertainty.
Which policies Trump will pursue remains unknown, to say nothing of which will succeed or what the consequences will be.
Trump seems hell-bent on having a trade war.
But how will China and Mexico respond?
Trump may well understand that what he proposes will violate World Trade Organization rules, but he may also know that it will take a long time for the WTO to rule against him.
And by then, America’s trade account may have been rebalanced.
But two can play that game: China can take similar actions, though its response is likely to be more subtle.
If a trade war were to break out, what would happen?
Trump may have reason to think he could win; after all, China is more dependent on exports to the US than the US is on exports to China, which gives the US an advantage.
But a trade war is not a zero-sum game. The US stands to lose as well.
China may be more effective in targeting its retaliation to cause acute political pain.
And the Chinese may be in a better position to respond to US attempts to inflict pain on them than the US is to respond to the pain that China might inflict on Americans.
It’s anybody’s guess who can stand the pain better.
Will it be the US, where ordinary citizens have already suffered for so long, or China, which, despite troubled times, has managed to generate growth in excess of 6%?
More broadly, the Republican/Trump agenda, with its tax cuts even more weighted toward the rich than the standard GOP recipe would imply, is based on the idea of trickle-down prosperity – a continuation of the Reagan era’s supply-side economics, which never actually worked.
Fire-breathing rhetoric, or raving three a.m. tweets, may assuage the anger of those left behind by the Reagan revolution, at least for a while.
But for how long?
And what happens then?
Trump might like to repeal the ordinary laws of economics, as he goes about his version of voodoo economics. But he can’t.
Still, as the world’s largest economy leads the way into uncharted political waters in 2017 and beyond, it would be foolhardy for a mere mortal to attempt a forecast, other than to state the obvious: the waters will almost certainly be choppy, and many – if not most – pundit ships will sink along the way.
9/11 and the New Authoritarianism
Five years after the attacks on the Twin Towers in New York and the Pentagon in Washington, “9/11” is no longer a mere date.
It has entered the history books as the beginning of something new, a new era perhaps, but in any case a time of change.
The terrorist bombings in Madrid and London and elsewhere will also be remembered; but it is “9/11” that has become the catchphrase, almost like “August 1914.”
But was it really a war that started on September 11, 2001?
Not all are happy about this American notion.
During the heyday of Irish terrorism in the UK, successive British governments went out of their way not to concede to the IRA the notion that a war was being waged.
“War” would have meant acceptance of the terrorists as legitimate enemies, in a sense as equals in a bloody contest for which there are accepted rules of engagement.
This is neither a correct description nor a useful terminology for terrorist acts, which are more correctly described as criminal.
By calling them war – and naming an opponent, usually al-Qaeda and its leader, Osama bin Laden – the United States government has justified domestic changes that, before the 9/11 attacks, would have been unacceptable in any free country.
Most of these changes were embodied in the so-called “USA Patriot Act.”
Though some of the changes simply involved administrative regulations, the Patriot Act’s overall effect was to erode the great pillars of liberty, such as habeas corpus , the right to recourse to an independent court whenever the state deprives an individual of his freedom.
From an early date, the prison camp at Guantánamo Bay in Cuba became the symbol of something unheard of: the arrest without trial of “illegal combatants” who are deprived of all human rights.
The world now wonders how many more of these non-human humans are there in how many places.
For everyone else, a kind of state of emergency was proclaimed that has allowed state interference in essential civil rights.
Controls at borders have become an ordeal for many, and police persecution now burdens quite a few.
A climate of fear has made life hard for anyone who looks suspicious or acts suspiciously, notably for Muslims.
Such restrictions on freedom did not meet with much public opposition when they were adopted.
On the contrary, by and large it was the critics, not the supporters, of these measures who found themselves in trouble.
In Britain, where Prime Minister Tony Blair supported the US attitude entirely, the government introduced similar measures and even offered a new theory.
Blair was the first to argue that security is the first freedom.
In other words, liberty is not the right of individuals to define their own lives, but the right of the state to restrict individual freedom in the name of a security that only the state can define.
This is the beginning of a new authoritarianism.
The problem exists in all countries affected by the threat of terrorism, though in many it has not become quite as specific.
In most countries of continental Europe, “9/11” has remained an American date.
There is even a debate – and indeed some evidence – concerning the question of whether involvement in the “war against terrorism” has actually increased the threat of terrorist acts.
Germans certainly use this argument to stay out of the action wherever possible.
This stance, however, has not prevented the spread of something for which a German word is used in other languages, too: Angst .
A diffuse anxiety is gaining ground.
People feel uneasy and worried, especially when traveling.
Any train accident or airplane crash is now at first suspected of being an act of terrorism.
Thus, 9/11 has meant, directly or indirectly, a great shock, both psychologically and to our political systems.
While terrorism is fought in the name of democracy, the fight has in fact led to a distinct weakening of democracy, owing to official legislation and popular angst.
One of the worrying features of the 9/11 attacks is that it is hard to see their purpose beyond the perpetrators’ resentment of the West and its ways.
But the West’s key features, democracy and the rule of law, have taken a far more severe battering at the hands of their defenders than by their attackers.
Two steps, above all, are needed to restore confidence in liberty within the democracies affected by the legacy of 9/11.
First, we must make certain that the relevant legislation to meet the challenge of terrorism is strictly temporary.
Some of today’s restrictions on habeas corpus and civil liberties have sunset clauses restricting their validity; all such rules should be re-examined by parliaments regularly.
Second, and more importantly, our leaders must seek to calm, rather than exploit, public anxiety.
The terrorists with whom we are currently at “war” cannot win, because their dark vision will never gain broad popular legitimacy.
That is all the more reason for democrats to stand tall in defending our values – first and foremost by acting in accordance with them.
9/11 in Perspective
NEW YORK – It was a decade ago that 19 terrorists took control of four planes, flew two into the twin towers of the World Trade Center, hit the Pentagon with a third, and crashed the fourth in a field in Pennsylvania after passengers resisted and made it impossible for the terrorists to complete their malevolent mission.
In a matter of hours, more than 3,000 innocent people, mostly Americans, but also people from 115 other countries, had their lives suddenly and violently taken from them.
September 11, 2001, was a terrible tragedy by any measure, but it was not a historical turning point.
It did not herald a new era of international relations in which terrorists with a global agenda prevailed, or in which such spectacular terrorist attacks became commonplace. On the contrary, 9/11 has not been replicated.
Despite the attention devoted to the “Global War on Terrorism,” the most important developments of the last ten years have been the introduction and spread of innovative information technologies, globalization, the wars in Iraq and Afghanistan, and the political upheavals in the Middle East.
As for the future, it is much more likely to be defined by the United States’ need to put its economic house in order; China’s trajectory within and beyond its borders; and the ability of the world’s governments to cooperate on restoring economic growth, stemming the spread of nuclear weapons, and meeting energy and environmental challenges.
It is and would be wrong to make opposition to terrorism the centerpiece of what responsible governments do in the world.
Terrorists continue to be outliers with limited appeal at best.
They can destroy but not create.
It is worth noting that the people who went into the streets of Cairo and Damascus calling for change were not shouting the slogans of Al Qaeda or supporting its agenda.
Moreover, measures have been implemented to push back, successfully, against terrorists.
Intelligence assets have been redirected. Borders have been made more secure and societies more resilient.
International cooperation has increased markedly, in part because governments that cannot agree on many things can agree on the need to cooperate in this area.
Military force has played a role as well.
Al Qaeda lost its base in Afghanistan when the Taliban government that had provided it sanctuary was ousted from power.
Osama bin-Laden was finally found and killed by US Special Forces in the suburbs of Islamabad.
Drones – unmanned aircraft that are remotely steered – have proven to be effective in killing a significant number of terrorists, including many of the most important leaders.
Weak governments can be made stronger; governments that tolerate or support terrorism must be held accountable.
But progress is not to be confused with victory.
Terrorists and terrorism cannot be eliminated any more than we can rid the world of disease.
There will always be those who will resort to force against innocent men, women, and children in pursuit of political goals.
Indeed, terrorists are advancing in some areas.
Pakistan remains a sanctuary for Al Qaeda and some of the world’s other most dangerous terrorists.
A mixture of instability, government weakness, and ideology in countries such as Yemen, Libya, Somalia, and Nigeria are providing fertile territory for terrorists to organize, train, and mount operations – much as they did in Afghanistan did a decade ago.
New groups constantly emerge from the ruins of old ones.
There is also a growing danger of homegrown terrorism.
We have seen it in Great Britain and the US.
The Internet, one of the great inventions of the modern Western world, has shown itself to be a weapon that can be used to incite and train those who wish to cause harm to that world.
The question raised in October 2003 by then US Secretary of Defense Donald Rumsfeld is no less relevant today: “Are we capturing, killing, or deterring and dissuading more terrorists every day than the madrassas and the radical clerics are recruiting, training, and deploying against us?”
All things being equal, we probably are.
But even small terrorist successes are costly in terms of lives, money, and making open societies less so.
What is to be done?
Alas, there is no single or silver bullet.
The establishment of a Palestinian state will not be enough for those terrorists who want to see the elimination of the Jewish state, any more than reaching a compromise over Kashmir will satisfy those Pakistan-based terrorists with bigger agendas vis-à-vis India.
Reducing unemployment is desirable, of course, but many terrorists do not come from poverty.
Helping to make societies in the Middle East and elsewhere more democratic might reduce the alienation that can lead to radicalism and worse, but this is easier said than done.
Of course, we want to continue to find ways to make ourselves less vulnerable and terrorists more so.
But what may be most important, particularly in the Arab and Islamic communities, is to end any acceptance of terrorism.
The Nigerian father who warned the US embassy in Lagos that he feared what his own son might do – before that same young man attempted to detonate a bomb aboard a flight to Detroit on Christmas Day 2009 – is an example of just this.
Only when more parents, teachers, and community leaders behave likewise will recruitment of terrorists dry up and law-enforcement authorities receive full cooperation from the populations they police.
Terrorism must lose its legitimacy among those who have historically supported or tolerated it before it will lose its potency.
Transatlantic Trade for All
WASHINGTON, DC – The negotiations to create a Transatlantic Trade and Investment Partnership between the European Union and the United States are being widely welcomed.
British Prime Minister David Cameron has called the TTIP a “once-in-a-generation prize,” citing potential gains of £80 billion ($125.5 billion) each for the EU and the US and £85 billion for the rest of the world.
For a world weary of waiting for the World Trade Organization’s interminable Doha trade round to conclude, even a bilateral trade initiative may seem like a boon, especially when, as a recent Financial Times editorial pointed out, “bilateral” covers half of the world’s economy.
But there is a serious downside: The deal could hurt developing-country exporters, unless the EU and the US make a concerted effort to protect these actors’ interests.
The feature of the proposed pact that elicits the most excitement – its focus on regulatory barriers like mandatory product standards – should actually incite the greatest concern.
Given low tariffs in the EU and the US – less than 5%, on average – further preferential reductions will not seriously handicap outsiders.
But, when it comes to standards – such as those governing safety, health, and the environment – the market-access requirements are brutal and binary: either you meet the established standard or you do not sell.
As a result, third-country firms’ options will depend on how TTIP standards are established: through harmonization (adoption of a common standard) or mutual recognition (acceptance of goods that meet one another’s established standards).
The first option would enable producers everywhere to take advantage of economies of scale.
But, in some cases, the harmonized standard could be more stringent than some countries’ original standards.
Even though new standards would apply to suppliers from all exporting countries, compliance costs usually vary, meaning that those less equipped to meet higher standards could suffer.
In the late 1990’s, when the EU decided to harmonize standards for aflatoxins (a group of toxic compounds produced by certain molds), eight member states – including Italy, the Netherlands, and Spain – raised their national standards substantially, which is likely to have caused African exports of cereals, dried fruits, and nuts to Europe to decline by as much as $670 million.
With mutual recognition, the EU and the US would accept each other’s standards or conformity-assessment procedures, allowing firms to adhere to the less stringent requirements in each area.
If the policy were extended to third-country firms, it would have a powerful liberalizing impact.
For example, Malaysian television producers could choose to comply with, say, America’s easier-to-meet safety standards, then sell the same product in both markets, reaping the benefits of economies of scale while lowering compliance costs.
If, however, the TTIP excluded third-country firms from the mutual recognition policy, their competitiveness vis-à-vis European and American companies would diminish substantially.
Indeed, our research shows that when mutual-recognition agreements include restrictive rules of origin, intra-regional trade increases – at the expense of trade with other countries – and that developing countries tend to suffer most.
In fact, excessively constraining rules of origin have proved problematic for some of the EU’s previous recognition agreements, such as those governing professional-services standards.
While a Brazilian orange admitted for sale in Portugal can be sold throughout the EU, a Brazilian engineer or accountant licensed in Portugal must fulfill separate licensing requirements to work elsewhere in the EU, hampering much-needed labor mobility by forcing non-European workers to endure costly and inefficient bureaucratic procedures.
Furthermore, when it comes to tariffs and standards, WTO rules are not created equal.
While they protect countries excluded from bilateral or regional tariff agreements, thereby ensuring that integrated markets do not receive additional advantages, few safeguards exist to shield third countries from the fallout of agreements on mandatory standards.
Even in the absence of international rules, the EU and the US could take two actions to ensure that the TTIP does not have adverse consequences for developing economies.
First, they could allow all countries to reap the benefits of a bilateral mutual-recognition deal by agreeing not to impose restrictive rules of origin.
Second, where they do consider harmonization, they could favor the less stringent of the original standards, unless there is credible evidence that it would not support the relevant regulatory objective.
This is akin to a WTO test for departures from established international standards.
If the EU and the US made these two commitments, the rest of the world could follow the TTIP negotiations with hope, rather than trepidation.
A Balanced Look at Sino-American Imbalances
BEIJING – Before July 2007, most economists agreed that global imbalances were the most important threat to global growth.
It was argued that the United States’ rising net foreign debt-to-GDP ratio – the result of chronic current-account deficits – would put a sharp brake on capital inflows, in turn weakening the dollar, driving up interest rates, and plunging the US economy into crisis.
But this scenario failed to materialize. Instead, the crisis stemmed from the US sub-prime debacle, which quickly dragged the global economy into its deepest recession since the 1930’s.
Most economists failed to foresee the economic dynamics that actually led to the crisis, because they failed to pay enough attention to the rapid increase in US total debt.
Instead, they focused exclusively on US foreign debt, ignoring household debt (mortgage and consumer debt), public debt, business debt, and financial debt.
In particular, they should have paid greater attention to the sustainability of US mortgage and consumer debt.
In 2007, the mortgage and consumer debt-to-GDP ratio was more than 90%, compared to 24% for net foreign debt.
Of course, the various components of debt differ considerably in their character and sources of financing – and thus in their sustainability.
But all parts of a country’s total debt and how it is financed are interconnected.
This means two things. First, funds from different sources of finance are interchangeable to a certain degree: deficiency of funds for one component of total debt can be supplemented by surplus funds originally aimed at financing other components.
Second, troubles in any single component of total debt will have an impact on all the other components.
After the subprime crisis erupted, mortgage and consumer debt was paid down by households either with their savings or by default.
The fall in US total debt, and the narrowing of the financing gap between total debt and domestic funds, led to a significant improvement in the US current-account deficit in 2008-2009, disproving US Federal Reserve Board Chairman Ben Bernanke’s claim that the deficit was caused by a global “saving glut.”
Indeed, America’s current-account position strengthened despite the dollar’s appreciation in the face of safe-haven demand.
Unfortunately, as a result of the private-sector deleveraging and an increase in household savings, the US economy, driven by debt and consumption, slid into recession.
To offset the negative impact of private-sector deleveraging on growth, the US government has maintained expansionary fiscal and monetary policies.
Now, with household debt sustained on a knife-edge after feverish government intervention, the fiscal position has deteriorated dramatically and the current-account balance has worsened again.
Sustainability of public debt has replaced sustainability of private debt as the biggest threat to financial stability, and the focus of debate about the US current account has shifted from the sustainability of foreign debt to the impact of reducing the external deficit on growth and employment.
The dilemma facing US policymakers is how to stimulate growth while lowering the level of total debt.
The most important way to achieve both objectives is to increase exports by strengthening US competitiveness.
But where will increased competitiveness come from?
Devaluation of the dollar could improve US competitiveness in the short run, but it is not a solution.
Because rapid fiscal deterioration now has investors worrying about capital losses on US government securities, devaluation would make foreigners more hesitant to finance America’s budget deficit.
If foreign financing is not forthcoming, yields on US government debt will rise and the US economy will fall back into recession.
In the long run, America’s growth pattern must undergo a structural shift from reliance on debt and consumption one based on Americans vaunted capacity for creativity and innovation.
Only then will America improve its competitiveness enough to allow the government to reduce both private and public debt to sustainable levels while maintaining a respectable growth rate.
But neither improved competitiveness, nor reduction of total debt, can be achieved overnight.
In the short run, the US current-account deficit will remain, regardless of which country runs bilateral surpluses.
Thus, China’s continued reinvestment of its current-account surplus in US government securities is of utmost important for US growth and financial stability.
Given that America benefits mightily from China’s purchases of US government securities, it is difficult to understand why the US government and Congress have been complaining so much about the bilateral current-account deficit.
It is also difficult to grasp why China is so reluctant to reduce its bilateral surplus, given meager returns on its massive holdings of US government securities and a sustained risk of large capital losses in the future.
The good news is that, following President Hu Jintao’s recent visit to Washington, both America and China have been taking positive steps to resolve their differences over the bilateral current-account balance.
That augurs well for a more rational and constructive Sino-American dialogue on global imbalances, which would certainly benefit the global economy.
A Banking Union Baby Step
BRUSSELS – At the beginning of the financial crisis, it was said that banks were, in Charles Goodhart’s crisp phrase, “international in life, but national in death.”
At the time (2008-2009), large international banks had to be rescued by their home countries’ governments when they ran into trouble.
But the problem now in Europe is the opposite: banks are “national in life, but European in death.”
In Spain, for example, local savings banks (cajas) financed an outsize real-estate boom.
As the boom turned to bust, the losses threatened to overwhelm the capacity of the Spanish state, and the problem became European, because it threatened the very survival of the euro.
The Spanish case is symptomatic of a larger problem.
National supervisors always tend to minimize problems at home.
Their instinct (and their bureaucratic interest) is to defend their countries’ “national champion” bank(s) abroad.
But their resistance to recognizing problems at home runs even deeper.
Until recently, the Spanish authorities maintained that the problems in their country’s real-estate sector were temporary.
To acknowledge the truth would have meant admitting that for years they had overlooked the build-up of an unsustainable construction boom that now threatens to bankrupt the entire country.
In the case of Ireland, the situation was initially not much different.
When problems started to surface, the finance minister at the time initially claimed that the country would carry out “the cheapest bank rescue ever.”
Given national supervisors’ predictable tendency not to recognize problems at home, it seemed natural that the cost of cleaning up insolvent banks should also be borne at the national level.
It thus seemed to make sense that even in the eurozone, banking supervision remained largely national.
The recently created European Banking Authority has only limited powers over national supervisors, whose daily work is guided mainly by national considerations.
But reality has shown that this approach is not tenable.
Problems might originate at the national level, but, owing to monetary union, they quickly threaten the stability of the entire eurozone banking system.
At their June summit, Europe’s leaders finally recognized the need to rectify this situation, transferring responsibility for banking supervision in the eurozone to the European Central Bank.
Given that financial integration is particularly strong within the monetary union, putting the ECB in charge was an obvious choice.
Moreover, the ECB already bears de facto responsibility for the stability of the eurozone’s banking system.
But, until now, it had to lend massive amounts to banks without being able to judge their soundness, because all of that information was in the hands of national authorities who guarded it jealously and typically denied problems until it was too late.
Putting the ECB in charge should also help to stop the creeping disintegration process, which is not publicly visible, but is very real nonetheless.
Just ask any of the large international banking groups headquartered in financially stressed eurozone countries.
Consider the case of a bank headquartered in Italy, but with an important subsidiary in Germany.
The German operations naturally generate a surplus of funds (given that savings in Germany far exceed investment on average).
The parent bank would like to use these funds to reinforce the group’s liquidity.
But the German supervisory authorities consider Italy at risk and thus oppose any transfer of funds there.
The supervisor of the home country (Italy) has the opposite interest.
It would like to see the “internal capital market” operate as much as possible.
Here, too, it makes sense to have the ECB in charge as a neutral arbiter with respect to these opposing interests.
But, while putting the ECB in charge of banking supervision solves one problem, it creates another: can national authorities still be held responsible for saving banks that they no longer supervise?
Economic (and political) logic requires that the eurozone will soon also need a common bank rescue fund.
Officially, this has not yet been acknowledged.
But that is often the way that European integration proceeds: an incomplete step in one area later requires further steps in related areas.
This incremental approach has worked well in the past; indeed, today’s European Union resulted from it.
But a financial crisis does not give policymakers the time that they once had to explain to voters why one step required another.
They will have to walk much more quickly to save the euro.
The Renewed Promise of Abenomics
TOKYO – Japan’s Liberal Democratic Party scored a decisive victory in the December 14 parliamentary election, with Japanese voters demonstrating their overwhelming approval of Prime Minister Shinzo Abe’s macroeconomic policy agenda.
Though voter turnout was relatively low, owing largely to the somewhat technical nature of the issues, the election’s message was clear: most Japanese abhor the prospect of a return to the grim economic trajectory that prevailed in Japan before “Abenomics.”
When the first “arrow” of Abenomics – a fiscal stimulus program – was launched nearly two years ago, asset markets' immediate response was positive.
The second arrow of Abenomics – monetary easing – intensified these effects.
In the last two years, Japan’s stock market has almost doubled in value, increasing the wealth of Japanese consumers.
Moreover, the yen has fallen by nearly one-third against the US dollar, from around ¥80 to nearly ¥120 per dollar, invigorating Japan’s export industries.
Even more encouraging are developments in the labor market, which, unlike those in asset markets, reflect outcomes, not expectations.
Here, too, the news is good.
The labor market has tightened, with unemployment standing at 3.5% and the job-to-applicant ratio above parity.
To be sure, there have been some setbacks: Japan’s GDP shrank in the second and third quarters of 2014.
But the downturn, which resulted from April’s consumption-tax hike – from 5% to 8% – cannot be blamed on Abenomics.
Indeed, Abe was honoring a law enacted by the previous government, led by the Democratic Party of Japan.
The first two arrows of Abenomics were aimed at stimulating demand – and they were extremely effective.
The consumption-tax hike was needed to sustain them in flight. Unfortunately, the hike was too large to keep them aloft.
The good news is that the tax hike’s impact is temporary. Soon, it will begin to taper off, and industrial output will approach full capacity.
When demand begins to exceed supply, demand-side stimulus policies will become increasingly ineffective, and it will be time to launch the third arrow of Abenomics: growth-enhancing structural reforms.
Such reforms are essential to raise productivity growth and improve the Japanese economy’s competitiveness.
Four imperatives stand out.
The first task should be to eliminate – or, at least, reduce – the thicket of government regulations that is stifling economic dynamism.
The current system is so convoluted and complex that it took more than three decades to open a new medical school in Tokyo.
Likewise, flights to Haneda airport, a convenient connection to the Tokyo city area, have been rationed.
This is no formula for long-term economic success.
Furthermore, Japan’s government should push to complete negotiations for the Trans-Pacific Partnership, which is currently being negotiated among 12 countries, from Mexico to the United States to Vietnam.
The TPP would improve Japan’s trade prospects considerably, including in sensitive sectors like agriculture, where exports of fast-moving consumer goods like flowers and vegetables would benefit.
Japan’s leaders must also work to expand the workforce, which faces severe constraints, owing largely to the country’s rapidly aging population.
In the absence of large-scale immigration, to which Japanese remain unamenable, one relatively simple solution would be to integrate more women into the labor force.
A 10% increase in Japan’s female labor-force participation rate – an entirely attainable goal – would translate into an almost 5% gain in total labor-force participation.
Finally, Abe’s government must reduce the corporate-tax rate to align it more closely with international standards.
Amid increasingly intense international competition to attract foreign investment, reducing the corporate tax would actually increase Japan’s tax revenues, by spurring companies to invest their vast cash stockpiles in more productive activities.
Now that Abe’s government has a renewed mandate from Japanese voters, it must deliver on its promises – and that means decisive and comprehensive implementation of structural reforms.
Of course, this will require some sacrifices.
Indeed, households have already endured some hardship, brought about by the consumption-tax hike.
The next step is for Abe’s government to use its political capital to overcome vested interests, both in the bureaucracy and the business community.
This means compelling businesses to give up some of the special tax benefits they now enjoy.
For their part, politicians must participate in the taxpayer identification system.
And bureaucrats must forego some of the power that excessive regulation affords them.
If all of these groups join the Japanese public in accepting reasonable sacrifices, Abe’s government can fulfill its promise and build a thriving economy.
For the sake of all Japanese – not to mention a world economy in need of a new source of dynamism – that promise deserves to be met.
The Missing Arrow of Abenomics
TOKYO – In his drive to kick-start the Japanese economy, Prime Minister Shinzo Abe, shortly after taking office in 2012, introduced a large fiscal stimulus and put in place a bold program of monetary easing.
Since then, Japanese policymakers have been working to launch what Abe calls the third “arrow” of his agenda: arduous reforms of key industries and the demolition of structural barriers to growth.
But the focus on public policy has left a “fourth arrow” – the private sector – untouched and seemingly ignored.
This is unfortunate, because the government cannot fix Japan’s ills on its own.
Annual productivity growth has been stubbornly sluggish, rarely rising above 2% for much of the past two decades, reflecting both missed opportunities and declining cost competitiveness.
Japan’s productivity slump permeates the entire economy; labor and capital productivity gains have nearly stalled in almost every sector – even in Japan’s signature advanced manufacturing industries.
Labor productivity in the transport-equipment sector, for example, is barely half that of Germany.
This trend puts annual GDP growth on course to average only 1.3% through 2025, implying a third consecutive decade of stagnation.
Such an outcome would coincide with – and exacerbate the effects of – an adverse demographic shift that will constrain fiscal revenues and drive up costs for universal health care and pension benefits.
Japan’s ability to alter its trajectory depends on individual companies making decisions to invest, change workplace policies, deploy new technologies, and test untried business models.
Abe’s structural reforms will take time and political will to enact, but Japanese companies cannot afford to sit still.
They can and must act, without waiting for the government to change its policies.
In many cases, the economy’s bottlenecks are not regulatory in nature, but stem from entrenched ways of doing business.
New research by the McKinsey Global Institute examines Japan’s advanced manufacturing, retail, financial services, and health-care industries in detail – and finds substantial untapped productivity potential in every area.
For starters, Japanese firms must become more globally integrated.
Exporting to the fastest-growing overseas markets is one obvious route to overcoming sluggish demand growth at home.
But, rather than just selling products abroad, Japanese enterprises need to expand operations beyond their borders and cast a wider net for international talent.
Japanese companies have formidable R&D operations, but most will need to reconfigure them to obtain better returns and impact.
The process must start with an understanding of what the customer wants and a determination to deliver solutions accordingly.
Closed and tightly managed R&D operations must be transformed into more fluid, open processes involving collaboration with customers and suppliers.
Japanese companies will also need to improve their capabilities in areas such as marketing, pricing, and talent development.
While there are some pockets of excellence, most Japanese firms are severely lacking in these areas.
To compete in global markets, they will need to achieve the same consistency in these areas that they have in their traditional areas of strength.
Many Japanese companies have yet to digitize paper-based processes and replace outdated information-technology systems.
Others would benefit from moving beyond basic digitization to next-generation technologies, such as big-data analytics.
Companies can also head off looming labor shortages with intelligent software systems and robotics.
Manufacturers can augment or replace their assembly lines with technologies such as the Internet of Things and 3D printing.
More broadly, Japanese companies have to organize for performance and discipline.
As policy changes unleash market forces, businesses will face greater competition.
Some may need to reorganize or exit unprofitable markets; others may have to undertake mergers and acquisitions to achieve economies of scale.
Finally, shareholders and senior executives should tie performance goals to incentives.
Some of Japan’s corporate giants have already begun shifting from traditional seniority-based advancement toward merit-based pay structures.
Others should follow their lead.
Promoting younger and more diverse talent can create agile organizations with fresh ideas.
If Japan’s private sector rises to the challenge, it can move the economy onto a path of faster growth.
Innovations in one company would cascade across its entire industry by forcing competitors to raise their game.
In the 1950s and 1960s, for example, Toyota introduced more efficient production processes that were eventually adopted by the entire automobile industry.
Instead of settling for a future of 1.3% annual GDP growth, Japan could attain roughly 3% annual growth through 2025.
Doing so would require the growth rate of labor productivity to more than double, but this is an attainable goal.
More than half of this growth increment can be met by adopting best practices that companies around the world already use, while technology can close much of the remaining gap.
Japanese business leaders need to combine big thinking with a focused attention to detail.
They will need to create innovative products, penetrate new markets, and make bold investments in equipment, technology, and talent, while simultaneously scrutinizing every aspect of their operations for inefficiency and waste.
Traditional ways of doing business may have to be abandoned.
But there is ample scope to make progress and spur faster economic growth.
Immense trade flows, the rise of billions of new consumers in the emerging world, and technology breakthroughs are rapidly transforming the global economy.
Japan can shift its current trajectory by turning this wave of disruption into opportunity.
From Russia With Unrequited Love
NEW DELHI – Japanese Prime Minister Shinzo Abe has assiduously courted Russian President Vladimir Putin, meeting with him more than a dozen times in four years.
This month he hosted Putin in Tokyo and in his hometown of Nagato (famed for its onsen, or natural hot springs).
But Abe’s courtship has so far yielded little for Japan, and much for Russia.
Abe’s diplomatic overtures to Putin are integral to his broader strategy to position Japan as a counterweight to China, and to rebalance power in Asia, where Japan, Russia, China, and India form a strategic quadrangle.
Abe has already built a close relationship with India, and he sees improved relations with Russia – with which Japan never formally made peace after World War II – as the missing ingredient for a regional power equilibrium.
But Abe’s trust-building efforts with Russia are not aimed only at checking Chinese aggression.
He also wants Russia to return its southernmost Kuril Islands – a resource-rich area known as the Northern Territories in Japan – which the Soviet Union seized just after the United States dropped nuclear bombs on Hiroshima and Nagasaki in August 1945.
In exchange, Abe has offered economic aid, investments in Russia’s neglected Far East, and major energy deals.
Abe has, however, encountered several obstacles.
For starters, Japan is a participant in the US-led sanctions that were imposed on Russia after it annexed Crimea in March 2014.
These sanctions have pushed Russia closer to its traditional rival, China; and Putin has publicly identified the sanctions as a hindrance to concluding a peace treaty with Japan.
In response to Abe’s overtures, Putin has doggedly tried to drive a hard bargain.
Russia has bolstered its defenses on the four disputed islands, and, just prior to this month’s summit, he told the Japanese media that the current territorial arrangement suits Russian interests.
“We think that we have no territorial problems,” he said. “It’s Japan that thinks that it has a territorial problem with Russia.”
The US-led sanctions regime and low oil prices have battered the Russian economy, which is expected to contract by 0.8% in 2016.
Thus, Putin is more reluctant than ever to offer territorial concessions, lest it tarnish his domestic image as a staunch defender of Russian national interests.
Against this backdrop, it is not surprising that Abe left the recent “onsen summit” with dashed hopes of resolving the territorial dispute, while Putin returned home with 68 new commercial accords.
Many of the new agreements are symbolic, but some are substantive, including deals worth $2.5 billion and an agreement to set up a $1 billion bilateral-investment fund.
Under the latter agreement, Japan and Russia are supposed create a “special framework” for joint economic activities on the disputed islands.
But the plan has already run into trouble.
Peter Shelakhaev, a senior Russian official who leads the government’s Far East Investment and Export Agency, has indicated that there are legal hurdles to establishing such a framework, and that Japanese firms doing business on the Kurils would have to pay taxes to Russia.
If Japan did that, however, it would effectively be recognizing Russia’s jurisdiction over the islands.
Abe has thus been denied the legacy that he sought, while Putin has succeeded in easing Russia’s international isolation.
Abe was the first G7 leader to hold a summit with Putin after Russia annexed Crimea, and now Russia has won Japan’s economic cooperation, too.
Japan is the only G7 country that has a territorial dispute with Russia, and it is clearly more eager to reach a deal than the Kremlin is.
But this has only strengthened Russia’s hand.
While Japan has softened its position, and signaled that it may accept only a partial return of the islands, Russia has grown only more intransigent.
After the recent summit, Abe revealed that Putin now seems to be reneging on a 1956 agreement between Japan and the Soviet Union, which stipulates that the smaller two of the four islands will be returned to Japan after a peace treaty is signed.
As it happens, this year marks the 60th anniversary of that joint declaration, which was widely viewed as a breakthrough at the time.
The Kremlin is now suggesting that its commitment to fulfilling the declaration was conditional on Japan not joining any security alliance against Russia.
And Putin has expressed concerns that the 1960 Japan-US Security Treaty would extend to the disputed islands if they were returned, thus allowing the US to establish a military presence there.
Japan is in no position to address Russia’s concerns.
It cannot opt out of the US-led sanctions regime; and it cannot exempt the disputed Kurils from its security treaty with the US, especially now that it has been urging the US to provide an explicit commitment to defend the Japanese-controlled Senkaku Islands, over which China claims sovereignty.
Putin, for his part, appears smugly content with his negotiating position.
Not only did he arrive almost three hours late to the onsen summit, in keeping with his habit of leaving foreign leaders waiting; he also declined a Japanese government gift – a male companion for his native Japanese Akita dog, which Japan gave him in 2012.
There is little hope now that Abe will see tangible returns on the political capital he has invested in cultivating Putin.
And Japan’s dilemma will only deepen.
US President-elect Donald Trump’s desire to improve relations with Russia may give Abe leeway to continue wooing Putin; but if Russia gets the US in its corner, it won’t need Japan anymore.
A Berlin Consensus?
HONG KONG – A recent trip to Berlin brought back memories of an earlier visit in the summer of 1967, when I was a poor student who marveled at the Wall that would divide and devastate an entire society for another two decades.
Berlin today is vibrant and rejuvenated, rebuilt by the German peoples' hard work and sacrifice to unify the country, and an apt setting for the conference of the Institute for New Economic Thinking (INET), which I was there to attend.
The conference’s theme was “Paradigm Lost,” with more than 300 economists, political scientists, systems analysts, and ecologists gathering to rethink economic and political theory for the challenges and uncertainty posed by growing inequality, rising unemployment, global financial disarray, and climate change.
Almost everyone agreed that the old paradigm of neoclassical economics was broken, but there was no agreement on what can replace it.
Nobel laureate Amartya Sen attributed the European crisis to four failures – political, economic, social, and intellectual.
The global financial crisis, which began in 2007 as a crisis of US subprime lending and has broadened into a European sovereign-debt (and banking) crisis, has raised questions that we cannot answer, owing to over-specialization and fragmentation of knowledge.
And yet there is no denying that the world has become too intricate for any simple, overarching theory to explain complex economic, technological, demographic, and environmental shifts.
In particular, the rise of emerging markets has challenged traditional Western deductive and inductive logic.
Deductive inference enables us to predict effects if we know the principles (the rule) and the cause.
By inductive reasoning, if we know the cause and effects, we can infer the principles.
Eastern thinking, by contrast, has been abductive, moving from pragmatism to guessing the next steps.
Abductive inference is pragmatic, looking only at outcomes, guessing at the rule, and identifying the cause.
Like history, social-scientific theory is written by the victors and shaped by the context and challenges of its time.
Free-market thinking evolved from Anglo-Saxon theorists (many from Scotland), who migrated and colonized territories, allowing fortunate individuals to assume that there were no limits to consumption.
European continental thinking, responding to urbanization and the need for social order, emphasized institutional analysis of political economy.
Thus, the emergence of neoclassical economics in the nineteenth century was very much influenced by Newtonian and Cartesian physics, moving from qualitative analysis to quantifying human behavior by assuming rational behavior and excluding uncertainty.
This “predetermined equilibrium” thinking – reflected in the view that markets always self-correct – led to policy paralysis until the Great Depression, when John Maynard Keynes’s argument for government intervention to address unemployment and output gaps gained traction.
By the 1970’s, the neoclassical general-equilibrium school captured Keynesian economics through real-sector models that assumed that “finance is a veil,” thereby becoming blind to financial markets’ destabilizing effects.
Economists like Hyman Minsky, who tried to correct this, were largely ignored as Milton Friedman and others led the profession’s push for free markets and minimal government intervention.
But then technology, demographics, and globalization brought dramatic new challenges that the neoclassical approach could not foresee.
Even as the world’s advanced countries over-consumed through leveraging from derivative finance, four billion of the world’s seven billion people began moving to middle-income status, making huge demands on global resources and raising the issue of ecological sustainability.
New thinking is required to manage these massive and systemic changes, as well as the integration of giants like China and India into the modern world.
A change of mindset is needed not just in the West, but also in the East.
In 1987, the historian Ray Huang explained it for China:
“As the world enters the modern era, most countries under internal and external pressure need to reconstruct themselves by substituting the mode of governance rooted in agrarian experience with a new set of rules based on commerce.…This is easier said than done.
The renewal process could affect the top and bottom layers, and inevitably it is necessary to recondition the institutional links between them.
Comprehensive destruction is often the order; and it may take decades to bring the work to completion.”
Using this macro-historical framework, we can see Japanese deflation, European debt, and even the Arab Spring as phases of systemic changes within complex structures that are interacting with one another in a new, multipolar global system.
We are witnessing simultaneous global convergence (the narrowing of income, wealth, and knowledge gaps between countries) and local divergence (widening income, wealth, and knowledge gaps within countries).
Adaptive systems struggle with order and creativity as they evolve.
As the philosopher Bertrand Russell presciently put it: “Security and justice require centralized governmental control, which must extend to the creation of a world government if it is to be effective.
Progress, on the contrary, requires the utmost scope for personal initiative that is compatible with social order.”
A new wave of what the economist Joseph Schumpeter famously called “creative destruction” is under way: even as central banks struggle to maintain stability by flooding markets with liquidity, credit to business and households is shrinking.
We live in an age of simultaneous fear of inflation and deflation; of unprecedented prosperity amid growing inequality; and of technological advancement and resource depletion.
Meanwhile, existing political systems promise good jobs, sound governance, a sustainable environment, and social harmony without sacrifice – a paradise of self-interested free riders that can be sustained only by sacrificing the natural environment and the welfare of future generations.
We cannot postpone the pain of adjustment forever by printing money.
Sustainability can be achieved only when the haves become willing to sacrifice for the have-nots.
The Washington Consensus of free-market reforms for developing countries ended more than two decades ago.
The INET conference in Berlin showed the need for a new one – a consensus that supports sacrifice in the interest of unity.
Europe could use it.
Accepting Japan at Its Word
TOKYO – In recent years, the number of tourists visiting Japan has been increasing rapidly, reaching a record 13.4 million last year, a 29% increase from 2013.
Japan seems to be making great strides toward its goal of recapturing the position as an Asian cultural center that it held a century ago, when the Indian Nobel laureate poet Rabindranath Tagore lived in Tokyo.
Chinese revolutionary leaders Sun Yat-sen and Chiang Kai-shek, along with many other prominent Asians, moved there as well.
Anyone visiting Japan today would do well to learn two key words: domo, meaning “hello,” “thanks,” or “well,” and sumimasen, which can carry any of the meanings of domo, as well as “sorry” or “excuse me.”
Ordinary Japanese say sumimasen countless times each day, to apologize to friends or strangers for even the most trivial accident or mistake.
But, as Japan’s leaders have experienced firsthand since World War II, expressing regret to other countries is not so simple.
Yet that is precisely what Prime Minister Shinzo Abe must do in his upcoming statement marking the 70th anniversary of the end of the war.
The statement will be based on consultations with many of Japan’s, and the world’s, leading WWII historians, as well as – and more important – with himself, his conscience, and his heart, because he understands the significance of his words on this highly fraught topic.
Of course, Abe is far from the first Japanese leader to confront this challenge.
His statement will follow a long line of declarations by prime ministers and chief cabinet secretaries expressing sincere remorse over the events of WWII.
Twenty years ago, Prime Minister Tomiichi Murayama, the head of the Socialist Party, acknowledged that “Japan, through its colonial rule and aggression, caused tremendous damage and suffering to the people of many countries,” particularly in Asia.
He went on to express “feelings of deep remorse” and offer a “heartfelt apology” to the victims.
Ten years later, Prime Minister Junichiro Koizumi reiterated Murayama’s words, adding that since the war, Japan had been “manifesting its remorse for the war through actions,” especially development assistance and humanitarian activities.
Koizumi also pledged that “Japan, as a peace-loving nation, will work to achieve peace and prosperity for all humankind with all its resources.”
Despite these straightforward declarations of regret, some governments and citizens continue to demand more, giving the impression that nothing a Japanese leader says or does will convince them of the country’s remorse.
This intractability is, in some cases, understandable; the pain of survivors and their descendants remains acute.
But in many other cases, the unwillingness to move beyond history is driven by political interests.
Indeed, political motivations are behind claims that Abe does not agree with past official apologies, despite his repeated assurances that he does, as well as suggestions that he is seeking to revise history, even though he has never denied Japan’s colonial aggression.
Moreover, some have produced portrayals of Japan, as a whole, as an unrepentant country – or, worse, as one that is hell-bent on remilitarization.
Such depictions are breathtaking in their audacity, given Japan’s seven-decade record as a peaceful and constructive member of the international community.
This is not lost on those in Japan who ask for how long their country will have to apologize, with some even suggesting that after 70 years, a “tweet” on the subject should amount to adequate acknowledgement by Abe.
The prime minister, however, remains committed to issuing a strong and sincere statement on the subject.
Early this year, Abe announced his intention to use the 70th anniversary statement to communicate Japan’s remorse for the war, describe the progress the country has made in upholding peace, and describe the contributions that Japan can make to Asia and the rest of the world in the coming decades.
In fact, it is the third component of the announcement that inspires fear in some observers: By helping to build a strong security architecture in the Asia-Pacific region, Japan could undermine the ability of some actors to advance their own interests.
That is why they launched a whisper campaign against Abe’s statement months before he even began to write it.
But, of course, Asian security and prosperity is in everyone’s interest.
Given this, not even the language of Abe’s statement is particularly important; what matters is the determination he expresses, and the actions he takes to follow through – with appropriate humility – on his pledges.
And it seems that Abe is, indeed, determined to make real contributions to peace, based on effective cooperation with Japan’s friends and allies.
But if Asia is to move beyond its past, the victims of Japan’s wartime aggression must recognize that the Japan of 2015 is not the Japan of 1931, 1941, or even 1945, and that, as many Asian leaders have realized over the years, forgiveness benefits everyone.
In 1998, South Korean President Kim Dae-jung responded positively to a statement by former Japanese Prime Minister Keizo Obuchi.
The governments of Indonesia, the Philippines, Vietnam, and other countries have done the same, and now welcome Japan’s commitment to act with its allies to protect regional security.
These countries’ openness to reconciliation have enabled Japan to recast itself as a key arbiter of regional peace and prosperity, not to mention an increasingly dynamic cultural hub.
It is time for the rest of the region to follow suit, accepting at face value Japan’s sincere apologies and working with the country to build a better future.
At a time when Asia is facing serious security challenges, this stance could not be more urgent.
A Big Chance for Small Farmers
NEW YORK – The G-8’s $20 billion initiative on smallholder agriculture, launched at the group’s recent summit in L’Aquila, Italy, is a potentially historic breakthrough in the fight against hunger and extreme poverty.
With serious management of the new funds, food production in Africa will soar.
Indeed, the new initiative, combined with others in health, education, and infrastructure, could be the greatest step so far toward achieving the Millennium Development Goals, the internationally agreed effort to reduce extreme poverty, disease, and hunger by half by 2015 .
During 2002-2006, I led the United Nations Millennium Project, which aimed to achieve the Millennium Development Goals, for then-UN Secretary General Kofi Annan.
One cornerstone of the project was “smallholder farmers,” meaning peasant farm families in Africa, Latin America, and Asia – working farms of around one hectare (2.5 acres) or less.
These are some of the poorest households in the world, and, ironically, some of the hungriest as well, despite being food producers.
They are hungry because they lack the ability to buy high-yield seeds, fertilizer, irrigation equipment, and other tools needed to increase productivity.
As a result, their output is meager and insufficient for their subsistence.
Their poverty causes low farm productivity, and low farm productivity reinforces their poverty.
It’s a vicious circle, technically known as a poverty trap.
The UN Millennium Project’s Hunger Task Force, led by two world-leading scientists, M. S. Swaminathan and Pedro Sanchez, examined how to break this vicious circle.
The Hunger Task Force determined that Africa could substantially increase its food production if help was given to smallholder farmers, in the form of agricultural inputs.  The Millennium Project recommended a big increase in global funding for this purpose.  Drawing on that work and related scientific findings, Annan launched a call in 2004 for an African Green Revolution, based on an expanded partnership between Africa and donor countries.
Many of us, notably current UN Secretary General Ban Ki-moon, have worked hard to make this possible, with Ban repeatedly emphasizing the special emergency arising from the global food, financial, and energy crises of the past two years.
The G-8 announcement reflects these years of effort, and of course the boost from the leadership of US President Barack Obama, Spanish Prime Minister Jose Luis Zapatero, Australian Prime Minister Kevin Rudd, World Bank President Robert Zoellick, European Commissioner Louis Michel, European Parliamentarian Thijs Berman, and others.
Now the key is to make this effort work.
The lessons of history are clear.
Getting seed and fertilizer to smallholder farmers at highly subsidized prices (or even free in some cases) will make a lasting difference.
Not only will food yields rise in the short term, but farm households will use their higher incomes and better health to accumulate all sorts of assets: cash balances, soil nutrients, farm animals, and their children’s health and education.
That boost in assets will, in turn, enable local credit markets, such as micro-finance, to begin operating.
Farmers will be able to buy inputs, either out of their own cash, or by borrowing against their improved creditworthiness.
A consensus has now been reached on the need to assist smallholders, but obstacles remain.
Perhaps the main risk is that the “aid bureaucracies” now trip over each other to try to get their hands on the $20 billion, so that much of it gets taken up by meetings, expert consultations, overhead, reports, and further meetings.
“Partnerships” of donors can become an expensive end in themselves, merely delaying real action.
If donor governments really want results, they should take the money out of the hands of thirty or more separate aid bureaucracies and pool it in one or two places, the most logical being the World Bank in Washington and the International Fund for Agricultural Development (IFAD) in Rome.
One or both of these agencies would then have an account with several billion dollars.
Governments in hunger-stricken regions, especially Africa, would then submit national action plans that would provide details on how they would use the donor funds to get high-yield seeds, fertilizer, irrigation, farm tools, storage silos, and local advice to impoverished farmers.
An independent expert panel would review the national plans to verify their scientific and managerial coherence.
Assuming that a plan passes muster, the money to support it would quickly be disbursed.
Afterward, each national program would be monitored, audited, and evaluated.
This approach is straightforward, efficient, accountable, and scientifically sound.
Two major recent success stories in aid have used this approach: the Global Alliance on Vaccines and Immunizations, which successfully gets immunizations to young children, and the Global Fund to Fight AIDS, TB, and Malaria, which supports national action plans to battle these killer diseases.
Both have saved millions of lives during the past decade, and have paved the way to a new more efficient and scientifically sound method of development assistance.
Not surprisingly, many UN agencies and aid agencies in rich countries fight this approach.
All too often, the fight is about turf, rather than about the most effective way to speed help to the poor.
Obama, Rudd, Zapatero, and other forward-thinking leaders can therefore make a huge difference by following up on their pledges at the G-8 and insisting that the aid really works.
The bureaucracies must be bypassed to get help to where it is needed: in the soil tilled by the world’s poorest farm families.
A Black and White Question
NEW YORK – In the afternoon of July 16 two men appeared to be breaking into a fine house in an expensive area of Cambridge, Massachusetts.
Alerted by a telephone call, a policeman arrived smartly on the scene.
He saw one black male standing inside the house and asked him to come out.
The man refused.
He was then told to identify himself.
The man, still refusing to step out, said he was a Harvard professor, showed his ID, and warned the cop not to mess with him.
He said something about black men in America being singled out, and asked the cop, who was white, for his name and identification.
The cop, joined by several colleagues, arrested the professor for disorderly conduct.
We now know that the professor had broken into his own home, with the help of his chauffeur, because the door was jammed.
What was unusual here was not the cop’s heavy-handedness.
Most people in the US know that if you talk back to the police, they will get nasty very fast.
The fact that the man was black might or might not have made the cop go for his handcuffs even sooner than he might normally have done.
That, too, would not have been unusual.
What made this case special was that Henry Louis “Skip” Gates is one of the most celebrated professors in the country, famous for his books, his articles, and numerous television appearances.
He is a grandee, a mover and shaker in the academic and media world, a friend of President Barack Obama.
That is why he warned the cop, Sgt. James Crowley, a veteran of the Cambridge police force, not to mess with him.
Class and race overlap in the US.
In this instance, it is impossible to pry them apart.
Gates, deeply conscious, indeed a specialist of the terrible history of race relations in his country, instinctively assumed that he was a victim of prejudice.
From his words it appears that he was equally conscious of not getting the proper respect due to a distinguished Harvard professor and media celebrity.
As he put it to his daughter in an interview published online: “[Crowley] should have gotten out of there and said, ‘I’m sorry, sir, good luck.
Loved your [television] series—check with you later!’”
Alas, Sgt.Crowley had never heard of Professor Gates.
A local man whose brothers all serve in the police force, a sports fan, and an amateur basketball coach, Crowley does not move in the same social circles as Gates.
As it happens, the charges were duly dropped, and there the case might have rested if President Obama, tired and frustrated after weeks of fighting for his healthcare bill, had not weighed in on behalf of his “friend” Gates, and called the police “stupid.”
Both he and Gates then spoke of “learning” from the incident.
Gates might even be planning a television documentary on racial profiling.
One thing to be learned, if we didn’t know this already, is how close racial sensitivities are to the surface of US life, despite the election of a black president.
The complexities of black anger, white guilt, and of black, and white fear, are so vexed that most Americans prefer not to talk about race at all.
The field is too full of mines.
One of Obama’s great achievements is that he made it into a serious topic through the brilliance and subtlety of his rhetoric.
And there remains plenty to talk about: the grotesquely disproportionate number of black men in US prisons; the lack of educational opportunities in poor, mostly black areas; the appalling healthcare system; and the very real brutality used by police officers against blacks, who don’t have the privilege of a Harvard ID.
It is probably true that many white policemen, even if they are trained to avoid racial profiling, as Sgt. Crowley was, need to be convinced that a black man can be at home in one of the finer houses of Cambridge, or any other American city.
But is the Gates affair the right way to enter into this discussion?
One might argue that it was.
If not Professor Gates, then who?
Precisely because he is a grandee, he is in the position to draw national attention to a serious issue.
If the same thing had happened to an unknown man in Harlem, or some other poor, or predominantly black district, no one would ever have heard about it.
The fact that it happened to a professor in Cambridge makes everyone sit up and take notice.
There is, however, a danger that it will have an adverse affect on the necessary national discussion about race.
By having made such a big issue out of what was in fact a relatively minor event Gates could be accused of trivializing much worse instances of abuse.
Indeed, we don’t even know for certain whether this was such an instance.
Crowley never mentioned the color of Gates’ skin. There was no question of violence.
There were just very raw nerves and hypersensitivity to hints of disrespect, on the part of the professor, and of the cop.
Outrage about a professor who is not to be messed with is not the best way to discuss the plight of countless, poor, anonymous people, whom most of us find it too easy to ignore.
A Bollywood Bride for Sarkozy?
PARIS -- Ever since French President Nicolas Sarkozy took himself off his country’s most-eligible-bachelor list by publicly acknowledging his affair with supermodel-turned-pop-musician Carla Bruni during a romantic trip to Euro Disney, he’s run into trouble.
His ratings have dipped below 50% for the first time.
Older French citizens don’t find the public spectacle of their leader in love very amusing.
Abroad, Egyptian lawmakers were so exercised over the prospect of the French head of state sharing a bed with his girlfriend that several vented their disapproval on the floor of the parliament.
Likewise, India is all in a quandary over how to handle protocol during Sarkozy’s impending visit to the subcontinent as the guest of honor at the country’s Republic Day celebrations on January 26.
Should the First Girlfriend have her own motorcade, as a first lady would?
Meanwhile, the same hard-right Hindu groups that protest Valentine’s Day as a decadent Western holiday have warned that if Sarkozy arrives with his girlfriend in tow, they’ll be out in the streets to welcome him.
This controversy has threatened to cast a pall over a much-heralded summit between two of the world’s great democracies.
With lucrative deals at stake for the big-ticket products that drive the French economy – military hardware, nuclear power plants, and Airbus planes – France has a strong interest in a successful summit in India.
So, as rumors fly of secret marriage ceremonies either already concluded or in the works, could the trouble brewing in India over the French president’s very public love life be behind the rush to have the couple legally wed?
The news in Sarkozy’s favored media outlet Journal du Dimanche that the couple plan to marry touched off a flurry of fevered speculation on when the happy event might occur.
The couple exchanged significant tokens of their mutual affection: he offered her a heart-shaped pink diamond ring by Dior, she offered him a Swiss watch.
It’s “serious,” the smitten president admitted.
But he refused, even under direct questioning by reporters, to reveal an exact date.
“You’ll probably find out after it’s happened,” he taunted.
Rumor has it the couple has set February 8 or 9 for the wedding.   Others say that Sarkozy has already outsmarted the media by secretly marrying in the Elysee Palace, even as he was dodging wedding questions.
If that is true, then Sarkozy missed the romantic opportunity of a lifetime.
If the couple sizzled for cameras with Luxor and Petra as the backdrop, just imagine how hot things could get at the most romantic spot on Earth, the Taj Mahal.
And, given the current rage for all things Bollywood in France, a lavish Indian wedding would be fitting.
Bruni’s own life path closely resembles any number of Bollywood stars who have made the transition from model to actress.
A comely brunette who sings is perfect for a Bollywood makeover.
The Indian government will be nothing if not relieved to see the first girlfriend made a wife.
As one of India’s leading daily newspapers, the Indian Express, spelled it out, lest anyone be confused, “a girlfriend is not a wife or spouse.”
Once wed, all protocol worries about the French delegation would simply disappear.
Despite the sometimes downright pornographic on-screen writhing of Bollywood starlets, India is still a deeply conservative society.
Divorce is anathema. (Sarkozy is now twice divorced.)
And, while mistresses abound among the privileged classes, they do not strut publicly by their power-mates’ sides.
Kissing and fondling in public, even by spouses, is taboo.
In this respect, India more resembles the France with which Sarkozy wants to make a clean break than the current one.
Most Indians, as it seems many French, would prefer not to shed the “hypocrisy” Sarkozy laments on the part of his predecessors (read: former French President François Mitterrand, who had a child with his mistress about whom the public knew nothing until the man’s funeral).
Sarkozy, of all people, should know that a large part of the gravitas of office derives from pomp and circumstance.
Statecraft is a realm where appearances are meant to be deceiving.
When Sarkozy, who otherwise has such finely tuned media instincts, protests that he’s no different from any other man, he comes dangerously close to confusing the office and the person of the president.
Most French people could only dream of an exotic wedding in India.
Sarkozy could make that dream come true.
If he really is as head-over-heels in love with Bruni as he claims, and plans to marry her imminently, why not take advantage of his upcoming trip to India and make this a wedding to remember?
He could meet his bride seated majestically on the caparison of an elaborately decorated elephant, and she would look ravishing swathed and bejeweled in Indian finery.
The “bling-bling” president, as Sarkozy has been dubbed, can wear all the gold he wants and heap yet more diamonds on his bride.
The cameras would roll, Indians would smile, and France would be treated to a Bollywood spectacle beyond its wildest dreams.
And if it’s too late for the wedding, there’s always the reception.
A Born-Again CAP
WAGENINGEN, NETHERLANDS – Born in 1957, the Common Agricultural Policy (CAP) is now more than 50 years old, and the European Commission is proposing what it calls a health check for its middle-aged child.
But superficial repairs will not meet the European Union’s future needs. The CAP must be born again.
Work on its renewal is due to start now, with the completed project ready in 2013. But a much more profound re-think is needed.
The CAP’s original aim was to provide a secure source of food for the six original member states of the Union, which were importers of food and sought a degree of self-sufficiency.
Good, healthy, and cheap food had to be accessible for all citizens. Improved agricultural productivity would benefit rural areas and give farmers a comparative share in the Union’s growing wealth.
Instruments to achieve those objectives were developed, and food security was achieved.
The CAP quickly came to be seen as the jewel in the crown of the European project.
As the EU has evolved and expanded, food systems have become more complex, involving production, processing, supply-chain organization, and wholesale and retail distribution, with all of these involving new issues like health and the environment. The use of land is also receiving more serious scrutiny.
A 1991 study by the Netherlands Scientific Council for Governmental Policy, entitled Ground for Choices, demonstrated that the EU’s food supply could be met with 50% less cultivated land, 80% less pesticides, and at 50% less cost.
Pollution would be reduced by 70% as a result of fewer nitrates in the surface water, and greenhouse gases would be cut.
Those figures were for an EU of 15 countries, so with today’s 27 members the possibilities are even greater.
A Dutch analysis of land use has shown that by employing the best technical and ecological means on the best available land, substantial gains could be made in food production.
So it is not surprising that the number of farmers needed has fallen substantially.
Viewed from the standpoint of food security and the wealth of rural areas, there is now an urgent need to revisit the CAP’s main instruments so that a new policy formula can be introduced.
Perverse subsidies must be removed and recent new ones favoring products such as bio-fuels reconsidered.
The status quo clearly has to be changed.
Rural policy in the EU is too often reduced to income guarantees for the farming community. But that attitude is undermining change.
Competition must be encouraged, as more rural entrepreneurship will strengthen the farming community, with fewer farmers but better farms.
A simplified CAP would encourage cleaner, more productive, and efficient agriculture.
A side benefit for the EU’s standing in the world could be that the World Trade Organization’s stalled Doha negotiations could be restarted once farmers in developing countries are assured of getting a fair deal from Europe.
Moreover, the CAP’s role as a motor of political and social integration in Europe could be restored once renewed policies are in place.
But renewal of this sort cannot be left to global market forces, as the results might not necessarily benefit European agriculture and society.
If the market “misbehaves,” farmers could be reduced to poverty, leading to the neglect of large areas of Europe.
That is a real enough danger to which policymakers must give serious thought as they reform the CAP on the basis of the following five pillars.
1.      The EU needs a knowledge and innovation policy that strengthens European agriculture’s competitiveness.
Such a policy has been successful in the Netherlands, substantially contributing to the development and power of the country’s agribusiness.
Ten of 21 branches of Dutch agribusiness, including horticultural seeds, ornamentals, seed potatoes, and veal, are among the top contributors to the national economy and the country’s trade balance.
In the EU as a whole, a policy directed toward research programs stimulating scientific excellence and greater coherence in the European knowledge system would greatly strengthen agriculture’s competitiveness and contribute to food security and sustainable development.
2.      Europe also needs a restructuring policy for land use.
Many structural improvement programs have been financed at the European level, but agricultural production and land use are not among them.
The development of an Agricultural Main Structure would compliment the European Ecological Main Structure.
Reforestation and the repair of natural ecosystems should also be part of a land use policy.
3.      A policy for European food systems would treat production, processing, distribution, logistics, and retailing in combination.
Consumption patterns and preferences are an integral part of such systems.
Preliminary studies by the European Science Foundation’s “Forward Look on European Food Systems” could prove useful in devising an EU-wide policy.
4.      Metropolitan agriculture in a rapidly urbanizing world can provide high-quality produce on small amounts of land.
It offers an answer to rising demand for healthy food with minimal environmental side effects.
5.      A new CAP should include a policy to safeguard Europe’s landscapes.
But a cultural heritage should not be maintained everywhere, nor should it ignore cost.
And it should not be a defensive policy of the sort that tends to concentrate on poor-quality land.
These five pillars involve drastic choices, but they will probably require less money from Europe’s taxpayers, not more.
They could make a real contribution to cleaner, more productive, and efficient farming and land use, while addressing social needs.
A Breakthrough Against Hunger
NEW YORK – Today’s world hunger crisis is unprecedentedly severe and requires urgent measures.
Nearly one billion people are trapped in chronic hunger – perhaps 100 million more than two years ago.
Spain is taking global leadership in combating hunger by inviting world leaders to Madrid in late January to move beyond words to action.
With Spain’s leadership and United Nations Secretary General Ban Ki-moon’s partnership, several donor governments are proposing to pool their financial resources so that the world’s poorest farmers can grow more food and escape the poverty trap.
The benefits of some donor help can be remarkable.
Peasant farmers in Africa, Haiti, and other impoverished regions currently plant their crops without the benefit of high-yield seed varieties and fertilizers.
The result is a grain yield (for example, maize) that is roughly one-third less than what could be achieved with better farm inputs.
African farmers produce roughly one ton of grain per hectare, compared with more than four tons per hectare in China, where farmers use fertilizers heavily.
African farmers know that they need fertilizer; they just can’t afford it.
With donor help, they can.
Not only do these farmers then feed their families, but they also can begin to earn market income and to save for the future.
By building up savings over a few years, the farmers eventually become creditworthy, or have enough cash to purchase vitally necessary inputs on their own.
There is now widespread agreement on the need for increased donor financing for small farmers (those with two hectares or less of land, or impoverished pastoralists), which is especially urgent in Africa.
The UN Secretary General led a steering group last year that determined that African agriculture needs around $8 billion per year in donor financing – roughly four times the current total – with a heavy emphasis on improved seeds, fertilizer, irrigation systems, and extension training.
In addition to direct help for small farms, donors should provide more help for the research and development needed to identify new high-yielding seed varieties, especially to breed plants that can withstand temporary flooding, excess nitrogen, salty soils, crop pests, and other challenges to sustainable food production.
Helping the poor with today’s technologies, while investing in future improved technologies, is the optimum division of labor.
This investment pays off wonderfully, with research centers such as the International Rice Research Institute and the International Maize and Wheat Improvement Centre providing the high-yield seeds and innovative farming strategies that together triggered the Asian Green Revolution.
These centers are not household names, but they deserve to be.
Their scientific breakthroughs have helped to feed the world, and we’ll need more of them.
Dozens of low-income, food-deficit countries, perhaps as many as 40-50, have elaborated urgent programs for increased food production by small farms, but are currently held back by the lack of donor funding.
These countries have appealed to the World Bank for financing, and the Bank made a valiant effort in 2008 to help through its new Global Food Crisis Response Program (GFCRP).
But the Bank does not yet have sufficient funds to meet these countries’ urgent needs, and has had to ration assistance to a small fraction of the flows that could be effectively and reliably used.
Hundreds of millions of people, in the meantime, remain trapped in hunger.
Many individual donor countries have declared that they are now prepared to increase their financial support for smallholder agriculture, but are searching for the appropriate mechanisms to do so.
The current aid structures are inadequate.
The more than 20 bilateral and multilateral donor agencies for agriculture are highly fragmented and of insufficient scale individually and collectively.
Despite the dedicated efforts of many professionals, the response to the hunger crisis remains utterly inadequate.
The 2008 planting seasons came and went with much too little additional help for impoverished small farmers.
African countries search endlessly, and mostly fruitlessly, for the small amounts of funding needed for their purchases of fertilizer and improved seeds.
My colleagues and I, serving on an advisory committee for the Spanish initiative, have recommended that donors pool their funds into a single international account, which we call the Financial Coordination Mechanism (FCM).
These pooled funds would enable farmers in poor countries to obtain the fertilizer, improved seed varieties, and small-scale irrigation equipment that they urgently need.
Poor countries would receive prompt and predictable financing for agricultural inputs from a single account, rather than from dozens of distinct and fragmented donors.
By pooling financial resources into a single-donor FCM, aid programs’ administrative costs could be kept low, the availability of aid flows could be assured, and poor countries would not have to negotiate 25 times in order to receive help.
The time for business as usual is over.
The donors promised to double aid to Africa by 2010, but are still far off track.
Indeed, during the past 20 years, they actually cut aid for agriculture programs, and only now are reversing course.
Meanwhile, a billion people go hungry each day.
We need a breakthrough that is demonstrable, public, clear, and convincing, that can mobilize the public’s hearts and minds, and that can demonstrate success.
History can be made in Madrid at the end of January, when the world’s richest and poorest countries converge to seek solutions to the global hunger crisis.
The lives of the billion poorest people depend on it.
A Breakthrough Opportunity for Global Health
NEW YORK – Every year, millions of people die from preventable and treatable diseases, especially in poor countries.
In many cases, lifesaving medicines can be cheaply mass-produced, but are sold at prices that block access to those who need them.
And many die simply because there are no cures or vaccines, because so little of the world’s valuable research talent and limited resources is devoted to addressing the diseases of the poor.
This state of affairs represents a failure of economics and law that urgently needs to be corrected.
The good news is that there are now opportunities for change, most promisingly through an international effort headed by the World Health Organization that would begin to fix the broken intellectual-property regime that is holding back the development and availability of cheap drugs.
Two main problems limit the availability of medicines today.
One is that they are very costly; or, more accurately, the price charged for them is very high, though the cost of producing them is but a fraction of that amount.
Second, drug development is geared toward maximizing profit, not social benefit, which skews efforts directed at the creation of medicines that are essential to human welfare.
Because the poor have so little money to spend, drug companies, under current arrangements, have little incentive to do research on the diseases that afflict them.
It doesn’t have to be this way.
Drug companies argue that high prices are necessary to fund research and development.
But, in the United States, it is actually the government that finances most health-related research and development – directly, through public support (National Institutes of Health, National Science Foundation), and indirectly, through public purchases of medicine, both in the Medicare and Medicaid programs.
Even the part that is not government-financed is not a conventional market; most individuals’ purchases of prescription medicines are covered by insurance.
Government finances health-care research because improved medicines are a public good.
The resulting knowledge benefits everyone by stopping epidemics and limiting the economic and human toll of widespread illness.
Efficiency requires sharing research as widely as possible as soon as it is available.
Thomas Jefferson compared knowledge to candles: when one is used to light another, it does not diminish the light of the first.
On the contrary, everything becomes brighter.
Yet, in America and most of the world, drug prices are still exorbitant and the spread of knowledge is tightly limited.
That is because we have created a patent system that gives innovators a temporary monopoly over what they create, which encourages them to hoard their knowledge, lest they help a competitor.
While this system does provide incentives for certain kinds of research by making innovation profitable, it allows drug companies to drive up prices, and the incentives do not necessarily correspond to social returns.
In the health-care sector, it may be more profitable to devote research to a “me-too” drug than to the development of a treatment that really makes a difference.
The patent system may even have adverse effects on innovation, because, while the most important input into any research is prior ideas, the patent system encourages secrecy.
A solution to both high prices and misdirected research is to replace the current model with a government-supported prize fund.
With a prize system, innovators are rewarded for new knowledge, but they do not retain a monopoly on its use.
That way, the power of competitive markets can ensure that, once a drug is developed, it is made available at the lowest possible price – not at an inflated monopoly price.
Fortunately, some US lawmakers are taking a strong interest in this approach.
The Prize Fund for HIV/AIDS Act, a congressional bill introduced by Senator Bernie Sanders, is just such an initiative.
His bill also contains an important provision aimed at encouraging open-source research, which would move the current research model away from secrecy toward sharing.
But, globally, our innovation system needs much bigger changes.
The WHO’s efforts to encourage broad reforms at the international level are crucial.
This spring, the WHO released a report that recommends solutions similar to those proposed in the US Senate bill, but on a global level.
Importantly, the report, “Research and Development to Meet Health Needs in Developing Countries,” recommends a comprehensive approach, including mandatory funding contributions from governments for research on developing countries’ health needs; international coordination of health-care priorities and implementation; and a global observatory that would monitor where needs are greatest.
In late May, the international community will have a chance to begin implementing these ideas at the WHO World Health Assembly – a moment of hope for public health around the world.
Reforming our innovation system is not just a matter of economics.
It is, in many cases, a matter of life and death.
It is therefore essential to de-link R&D incentives from drug prices, and to promote greater sharing of scientific knowledge.
For America, the Sanders bill marks important progress.
For the world, the WHO’s recommendations represent a once-in-a-generation opportunity to remedy a long-standing and egregious inequity in health care, and, more broadly, to set a model for governance of global public goods befitting an era of globalization.
We cannot afford to let this opportunity pass us by.
India’s Change of Guard
SINGAPORE – In August, Raghuram Rajan was appointed Governor of the Reserve Bank of India.
On one level, this was a routine announcement that many had anticipated – after all, Rajan is arguably the best-known Indian economist of his generation.
On another level, however, his appointment can be seen as part of a broader generational shift.
Rajan, just 50, will be the first RBI governor born after India became a republic in 1950.
Similar changes are taking place in all walks of Indian life, including politics, the arts, sports, and social development.
And India will be better for it.
Although the country is one of the youngest in the world, with an average age of just 26 years, until recently aging stalwarts incongruously dominated most fields, from politics to the arts and even business and sports.
But now younger entrants are rising everywhere, bringing with them energy and new ideas.
In politics, as the country prepares for next year’s general election, the leading contenders to replace 81-year-old Prime Minister Manmohan Singh are the Bharatiya Janata Party’s Narendra Modi, 62, and Rahul Gandhi, who is just 43.
Either man would be the first prime minister who was not born in the British Raj.
The arts were one of the first areas to witness this generational change.
For a long time, Indian literature, especially in English, was dominated by a clique who wrote mainly for a niche audience and literary recognition.
Then, a few years ago, a group of young writers – such as Chetan Bhagat and Amish Tripathi, both former bankers – changed the rules of the game by writing for the mass market.
Rather than write for literary critics, they began to use a simpler language, including Indian turns of phrase.
They also chose new themes: Tripathi dipped into ancient mythology to write a trilogy about the god Shiva, while Bhagat began to write about the lives of India’s young, upwardly mobile middle class.
Predictably, the purists pounced and the critics ridiculed.
But people have bought their books in the millions, and film deals have followed.
As a result, the market for books has dramatically expanded and publishers have been forced to change their entire business strategies.
Something similar has happened in the music industry. Previously dominated by a small cabal of singers and music directors, the market has been transformed by TV talent contests, similar to American Idol, which provide a national showcase for the wealth of India’s talent.
The shows have made participants, some drawn from remote towns, into overnight stars, and many of them have gone on to sign lucrative careers.
Thanks partly to this parade of new talent, the Indian music industry is experiencing a period of extraordinary innovation and expansion.
The output of the US and European music industries sounds stale in comparison, owing to a dearth of innovation over the last two decades.
Generational change has even come to India’s most popular sport – cricket.
Such was the adulation once heaped upon its aging stars that many of them remained on the national team long past their peak.
But a mere two years after winning the World Cup in 2011, several members of that victorious team have been replaced – a decision that until recently would have seemed unthinkable.
India’s social sector has also been transformed.
Development policy used to be dominated by career activists wedded to socialist-era thinking.
But the arrival of new faces from the world of business, such as Ashish Dhawan, Jayant Sinha, and Ramesh and Swati Ramanathan, has meant that development issues are at last being assessed according to the problem-solving approach of social entrepreneurs, rather than through the ideological lens of activists.
Ironically, it is the world of business that remains slow to change.
The growth of the IT sector in the 1990’s seemed to promise that change would be rapid and far-reaching, but the old business families still dominate.
There is hope, though.
Entrepreneurs like Manish Sabharwal of Teamlease, and Binny and Sachin Bansal of Flipkart, an online retailer, are fundamentally changing the way India does business.
Similarly, Indian academia may be moribund, but new public intellectuals like Pratap Bhanu Mehta have emerged from outside the mainstream.
Yes, India’s economy has slowed sharply, the rupee has plunged, and scandals and protests dominate the headlines.
But, behind the gloom, a new generation is taking over, bringing with it fresh ideas and visions for India.
Absent-Minded Killers
As a species, human beings have a major self-control problem.
We humans are now so aggressively fishing, hunting, logging, and growing crops in all parts of the world that we are literally chasing other species off the planet.
Our intense desire to take all that we can from nature leaves precious little for other forms of life.
In 1992, when the world’s governments first promised to address man-made global warming, they also vowed to head off the human-induced extinction of other species.
The Convention on Biological Diversity, agreed at the Rio Earth Summit, established that “biological diversity is a common concern of humanity.”
The signatories agreed to conserve biological diversity, by saving species and their habitats, and to use biological resources (e.g., forests) in a sustainable manner.
In 2002, the treaty’s signatories went further, committing to “a significant reduction in the current rate of biodiversity loss” by 2010.
Unfortunately, like so many other international agreements, the Convention on Biological Diversity remains essentially unknown, un-championed, and unfulfilled.
That neglect is a human tragedy.
For a very low cash outlay – and perhaps none at all on balance – we could conserve nature and thus protect the basis of our own lives and livelihoods.
We kill other species not because we must, but because we are too negligent to do otherwise.
Consider a couple of notorious examples.
Some rich countries, such as Spain, Portugal, Australia, and New Zealand, have fishing fleets that engage in so-called “bottom trawling.”
Bottom trawlers drag heavy nets over the ocean bottom, destroying magnificent, unexplored, and endangered marine species in the process.
Complex and unique ecologies, most notably underground volcanoes known as seamounts, are ripped to shreds, because bottom trawling is the “low cost” way to catch a few deep sea fish species.
One of these species, orange roughy, has been caught commercially for only around a quarter-century, but already is being fished to the point of collapse.
Likewise, in many parts of the world, tropical rainforest is being cleared for pasture land and food crops.
The result is massive loss of habitat and destruction of species, yielding a tiny economic benefit at a huge social cost.
After cutting down a swath of rainforest, soils are often quickly leached of their nutrients so that they cannot sustain crops or nutritious grasses for livestock.
As a result, the new pasture land or farmland is soon abandoned, with no prospect for regeneration of the original forest and its unique ecosystems.
Because these activities’ costs are so high and their benefits so low, stopping them would be easy.
Bottom trawling should simply be outlawed; it would be simple and inexpensive to compensate the fishing industry during a transition to other activities.
Forest clearing, on the other hand, is probably best stopped by economic incentives, perhaps combined with regulatory limits.
Simply restricting the practice of land clearing probably would not work, since farm families and communities would face a strong temptation to evade legal limits.
On the other hand, financial incentives would probably succeed, because cutting down forest to create pastureland is not profitable enough to induce farmers to forego payments for protecting the land.
Many rainforest countries have united in recent years to suggest the establishment of a rainforest conservation fund by the rich countries, to pay impoverished small farmers a small amount of money to preserve the forest.
A well-designed fund would slow or stop deforestation, preserve biodiversity, and reduce emissions of carbon dioxide the burning of cleared forests.
At the same time, small farmers would receive a steady flow of income, which they could use for micro-investments to improve their household’s wealth, education, and health.
Aside from banning bottom trawling and establishing a global fund for avoided deforestation, we should designate a global network of protected marine areas, in which fishing, boating, polluting, dredging, drilling, and other damaging activities would be prohibited.
Such areas not only permit the regeneration of species, but also provide ecological benefits that spill over to neighboring unprotected areas.
We also need a regular scientific process to present the world with the evidence on species abundance and extinction, just as we now have such a process for climate change.
Politicians don’t listen very well to individual scientists, but they are forced to listen when hundreds of scientists speak with a united voice.
Finally, the world should negotiate a new framework no later than 2010 to slow human-induced climate change.
There can be little doubt that climate change poses one of the greatest risks to species’ viability.
As the planet warms, and rain and storm patterns change dramatically, many species will find themselves in climate zones that no longer support their survival.
Some can migrate, but others (such as polar bears) are likely to be driven to extinction unless we take decisive action to head off climate change.
These measures are achievable by 2010.
They are affordable, and in each case would ultimately deliver large net benefits.
Most importantly, they would allow us to follow through on a global promise.
It is too painful to believe that humanity would destroy millions of other species – and jeopardize our own future – in a fit of absent-mindedness.
Making Do With More
BERKELEY – In the United States, just three out of ten workers are needed to produce and deliver the goods we consume.
Everything we extract, grow, design, build, make, engineer, and transport – down to brewing a cup of coffee in a restaurant kitchen and carrying it to a customer's table – is done by roughly 30% of the country's workforce.
The rest of us spend our time planning what to make, deciding where to install the things we have made, performing personal services, talking to each other, and keeping track of what is being done, so that we can figure out what needs to be done next.
And yet, despite our obvious ability to produce much more than we need, we do not seem to be blessed with an embarrassment of riches.
One of the great paradoxes of our time is that workers and middle-class households continue to struggle in a time of unparalleled plenty.
We in the developed countries have more than enough to cover our basic needs.
We have enough organic carbon-hydrogen bonds to break to provide us with calories; enough vitamins and other nutrients to keep us healthy; enough shelter to keep us dry; enough clothing to keep us warm; enough capital to keep us, at least potentially, productive; and enough entertainment to keep us from being bored.
And we produce all of it for an average of less than two hours a day of work outside the home.
John Maynard Keynes was not off by much when he famously predicted in 1930 that the human race's “economic problem, the struggle for subsistence," was likely to be “solved, or be at least within sight of solution, within a hundred years."
It will take another generation, perhaps, before robots have completely taken over manufacturing, kitchen work, and construction; and the developing world looks to be 50 years behind. But Keynes would have been spot on had he targeted his essay at his readers' great-great-great-great grandchildren.
And yet there are few signs that working- and middle-class Americans are living any better than they did 35 years ago.
Even stranger, productivity growth does not seem to be soaring, as one would expect; in fact, it seems to be decelerating, according to research by John Fernald and Bing Wang, economists in the Economic Research Department of the Federal Reserve Bank of San Francisco.
Growth prospects are even worse, as innovation hits gale-force headwinds.
One way to reconcile the changes in the job market with our lived experience and statistics like these is to note that much of what we are producing is very different from what we have made in the past.
For most of human experience, the bulk of what we produced could not be easily shared or used without permission.
The goods we made were what economists call “rival" and “excludible" commodities.
Being “rival" means that two people cannot use the same product at the same time.
Being “excludible" means that the owner of a product can easily prevent others from using it.
These two traits put a great deal of bargaining power in the hands of those who control production and distribution, making them ideal for a market economy based on private property.
Money naturally flows to where utility and value are being provided – and those flows are easy to track in national accounts.
But much of what we are producing in the information age is neither rival nor excludible – and this changes the entire picture.
The creation of information-age goods is difficult to incentivize; their distribution is hard to monetize; and we lack the tools to track them easily in national accounts.
The result is an ever-growing discrepancy between what people would be willing to pay for a given service and growth as measured in national statistics.
In other words, we are producing and consuming much more than our economic indicators suggest – and the creators of many of those products are not being adequately compensated.
This produces a set of unique problems.
To ensure that the workers of today and tomorrow are able to capture the benefits of the information age will require us to redesign our economic system to stimulate the creation of these new types of commodities.
In addition to developing ways to account for this new type of wealth, we will have to develop channels through which demand for a product contributes to the income of its creator.
Only by finding ways to put true value on the goods we produce will we be able to sustain a middle-class society, rather than one of techno-plutocrats and their service-sector serfs.
Making Academia Matter Again
CAMBRIDGE – Academic freedom is a precious commodity, critical to ensure that discovery of the truth is not encumbered by political or ideological forces.
But this does not mean that intellectuals should hide in academic bunkers that, by protecting us from criticism by “non-experts,” allow ego to flourish and enable a focus on questions that are not actually relevant to anyone else.
We experts should have to explain ourselves.
This means, first and foremost, that researchers should be communicating their results in a way that supports accountability and confirms that public funds and education benefits are being used in ways that are in taxpayers’ interests.
The duty to communicate findings also ensures that the public is educated, not only about the topic itself, but also about the way research actually works.
Scholarly books and journals often give the impression that the truth is revealed through a neat, orderly, and logical process.
But research is far from being a pristine landscape; in fact, it resembles a battlefield, littered with miscalculations, failed experiments, and discarded assumptions.
The path to truth is often convoluted, and those who travel along it often must navigate fierce competition and professional intrigue.
Some argue that it is better to hide this reality from the public, in order to maintain credibility.
For example, in 2014, physicists collaborating on a project known as BICEP2 thought that they had detected gravitational waves from the beginning of the universe.
It was later realized that the signal they had detected could be entirely attributed to interstellar dust.
Some of my colleagues worried that this revelation would undermine faith in other scientific predictions, such as those involving climate change.
But would hiding the truth from the public really do more for scientific and academic credibility than cultivating a culture of transparency?
Probably not.
In fact, being honest about the realities of research might enhance trust and create more space for innovation, with an informed public accepting that risk is the unavoidable and worthwhile cost of groundbreaking and broadly beneficial discoveries.
Another way to ensure that academia continues to innovate in useful and relevant ways is to blur the traditional boundaries among disciplines – the frontiers where invention so often happens.
To that end, universities should update their organizational structure, moving away from clearly delineated departments in order to create a kind of continuum across the arts, humanities, and sciences.
Students should be encouraged to take courses in multiple disciplines, so that they can weave those lessons and experiences into new patterns of knowledge.
To make this process sustainable, universities should ensure that the courses and curricula they offer help students to develop the skills that a fast-changing labor market demands.
This means not just creating new curricula today, but also updating them every few years, in order to account for new trends and discoveries in areas ranging from artificial intelligence and Big Data to alternative energy sources and genome editing.
Professors, for their part, should approach their job as mentors of future leaders in science, technology, the arts, and humanities, rather than attempting to mold students in their own intellectual image.
Of course, the latter approach can be useful if the goal is to advance the popularity of one’s own research program and to ensure that one’s own ideas and perspective endure.
But that is not the fundamental mission of academia.
The louder the consensus in the echo chambers of academia become, the greater the ego boost for those who inhabit those chambers.
But history shows that progress is sometimes advocated by a soft voice in the background, like that of Albert Einstein during his early career.
Truth and consensus are not always the same.
Diversity of opinion – which implies diversity of gender, ethnicity, and background – is vital to support creativity, discovery, and progress.
That is why it is so important for prizes and professional associations to be used not to reinforce mainstream perspectives, but rather to encourage independent thought and reward innovation.
This does not mean that all opinions should be considered equal, but rather that alternative views should be debated and vetted on merit alone.
We in academia cannot continue to pat ourselves on the back, celebrating our own privileges and failing to look at the world in new and relevant ways.
If we are to defend the freedom of our enterprise, we must restore dialogue with the broader public and ensure that the relevance of our work is well understood – including by us.
The Closing of the Academic Mind
LONDON – I would wager that I have been Chancellor of more universities than anyone alive today.
This is partly because when I was Governor of Hong Kong, I was made Chancellor of every university in the city.
I protested that it would surely be better for the universities to choose their own constitutional heads.
But the universities would not allow me to resign gracefully.
So for five years I enjoyed the experience of giving tens of thousands of students their degrees and watching what this rite of passage meant for them and their families.
When I came back to Britain in 1997, I was asked to become Chancellor of Newcastle University.
Then, in 2003, I was elected Chancellor by the graduates of Oxford University, one of the world’s greatest institutions of learning.
So it should not be surprising that I have strong views about what it means to be a university and to teach, do research, or study at one.
Universities should be bastions of freedom in any society.
They should be free from government interference in their primary purposes of research and teaching; and they should control their own academic governance.
I do not believe it is possible for a university to become or remain a world-class institution if these conditions do not exist.
The role of a university is to promote the clash of ideas, to test the results of research with other scholars, and to impart new knowledge to students.
Freedom of speech is thus fundamental to what universities are, enabling them to sustain a sense of common humanity and uphold the mutual tolerance and understanding that underpin any free society.
That, of course, makes universities dangerous to authoritarian governments, which seek to stifle the ability to raise and attempt to answer difficult questions.
But if any denial of academic liberty is a blow struck against the meaning of a university, the irony today is that some of the most worrying attacks on these values have been coming from inside universities.
In the United States and the United Kingdom, some students and teachers now seek to constrain argument and debate.
They contend that people should not be exposed to ideas with which they strongly disagree.
Moreover, they argue that history should be rewritten to expunge the names (though not the endowments) of those who fail to pass today’s tests of political correctness.
Thomas Jefferson and Cecil Rhodes, among others, have been targeted.
And how would Churchill and Washington fare if the same tests were applied to them?
Some people are being denied the chance to speak as well – so-called “no platforming”, in the awful jargon of some clearly not very literate campuses.
There are calls for “safe spaces” where students can be protected from anything that assaults their sense of what is moral and appropriate.
This reflects and inevitably nurtures a harmful politics of victimization – defining one’s own identity (and thus one’s interests) in opposition to others.
When I was a student 50 years ago, my principal teacher was a leading Marxist historian and former member of the Communist Party.
The British security services were deeply suspicious of him.
He was a great historian and teacher, but these days I might be encouraged to think that he had threatened my “safe space.”
In fact, he made me a great deal better informed, more open to discussion of ideas that challenged my own, more capable of distinguishing between an argument and a quarrel, and more prepared to think for myself.
Of course, some ideas – incitement of racial hatred, gender hostility, or political violence – are anathema in every free society.
Liberty requires some limits (decided freely by democratic argument under the rule of law) in order to exist.
Universities should be trusted to exercise that degree of control themselves.
But intolerance of debate, of discussion, and of particular branches of scholarship should never be tolerated.
As the great political philosopher Karl Popper taught us, the only thing we should be intolerant of is intolerance itself.
That is especially true at universities.
Yet some American and British academics and students are themselves undermining freedom; paradoxically, they have the liberty to do so.
Meanwhile, universities in China and Hong Kong are faced with threats to their autonomy and freedom, not from within, but from an authoritarian government.
In Hong Kong, the autonomy of universities and free speech itself, guaranteed in the city’s Basic Law and the 50-year treaty between Britain and China on the city’s status, are under threat.
The rationale seems to be that, because students strongly supported the pro-democracy protests in 2014, the universities where they study should be brought to heel.
So the city’s government blunders away, stirring up trouble, clearly on the orders of the government in Beijing.
Indeed, the Chinese authorities only recently showed what they think of treaty obligations and of the “golden age” of Sino-British relations (much advertised by British ministers), by abducting a British citizen (and four other Hong Kong residents) on the city’s streets.
The five were publishing books that exposed some of the dirty secrets of China’s leaders.
On the mainland, the Chinese Communist Party has launched the biggest crackdown on universities since the aftermath of the killings in Tiananmen Square in 1989.
There is to be no discussion of so-called Western values in China’s universities. Only Marxism can be taught.
Did no one tell President Xi Jinping and his Politburo colleagues where Karl Marx came from?
The trouble these days is precisely that they know little about Marx but a lot about Lenin.
Westerners should take a closer interest in what is happening in China’s universities and what that tells us about the real values underpinning scholarship, teaching, and the academy.
Compare and contrast, as students are asked to do.
Do you want universities where the government decides what it is allegedly safe for you to learn and discuss?
Or do you want universities that regard the idea of a “safe space” – in terms of closing down debate in case it offends someone – as an oxymoron in an academic setting?
Western students should think occasionally about their counterparts in Hong Kong and China who must fight for freedoms that they take for granted – and too often abuse.
The New Brain Drain in Science
DUBAI – In December 2013, the Nobel laureate physicist Peter Higgs told The Guardian that if he were seeking a job in academia today, “I don’t think I would be regarded as productive enough.”
Having published fewer than ten papers since his groundbreaking work in 1964, Higgs believes that no university would employ him nowadays.
Academics are well acquainted with the notion of “publish or perish.”
They must publish their work in peer-reviewed journals increasingly often to climb the career ladder, protect their jobs, and secure funding for their institutions.
But what happens to scientists and other scholars, such as those in the Middle East, who have different research concerns from – and scant connections to – the professional journals that can make or break an academic/scientific career?
Scholars and institutions with high publishing rates in the established journals receive better productivity scores, which translate into bigger rewards, in terms of enhanced careers and greater research funding.
Whether the work they are publishing has a measurable impact on their field of study is, sadly, too often a secondary concern.
The incentives they face mean that quantity often comes before quality.
Academic journals determine the various disciplinary rankings that academic institutions are compelled to climb, which leads institutions to hire and retain only those scholars who can produce at high rates.
This has given rise to a deeper, twofold problem: academic journals have become disproportionately influential, and they have placed a premium on empirical research.
With respect to the first problem, journals are gradually replacing institutions as the arbiters of quality within academic communities.
Scholars in almost any discipline seeking jobs at “A-level” institutions must publish in a select few A-level journals that are seen as gateways.
These journals’ editorial boards increasingly privilege positivist theoretical work – meaning research that is based on empirical data analysis.
Qualitative research – such as ethnographies, participatory surveys, and case studies – is often designated as suitable only for B- and C-level journals.
Academics conducting empirical research have a big advantage over those carrying out qualitative work, because they can use efficient software and powerful computers to test their hypotheses quickly and account for different variables in data sets.
This kind of work can be cheaper, too, because a single data set can generate multiple journal articles.
To be sure, there is nothing wrong with scientific practices evolving along with technology, or with academics using richer data sets and better software.
But adoption of this quantitative approach should not be the single most important criterion for assessing scientific excellence and deciding career trajectories.
After all, knowledge is acquired in different ways, and empirical positivism is only one method in a larger epistemological inventory.
The positivist trend in science today is particularly problematic for developing countries, where data sets are scarce and often of poor quality.
Thus, scientists working in developing countries face a dilemma: either work on rich-world problems for which there is abundant data, or risk career advancement by conducting qualitative work that will not make it into A-level journals.
Academics who move from data-rich countries in Europe and North America to data-poor countries in the Middle East and elsewhere often face this problem.
As researchers at my institution in Abu Dhabi know, conducting surveys for qualitative research is feasible; but generating rich data from scratch for theory-building research is extremely difficult.
At the International Conference on Science and Technology Indicators this year, a French academic researching soil in Africa reported that only 5% of the published work in his field has originated from African researchers.
When he dug deeper into his own research, he found that 50% of what he had learned about African soil came from African researchers, who have not or could not publish their work in international academic journals.
Countries where English is not the lingua franca are particularly disadvantaged in science, not because they lack academic excellence, but because English-language journals call the shots.
Non-English academic journals simply do not command the same attention in the science community.
As a result, the scope of research topics that many countries can undertake is limited, and they must struggle to retain scientific talent.
This is particularly true in the Middle East, where governments are struggling to diversify their economies, in order to make them more resilient.
As English-language empirical-research journals consolidate their hold on the channels that determine whether or not a scientist will have a successful career, developing countries will have to invest heavily in their own data infrastructure to place domestic researchers on a more competitive footing.
But even – or especially – if developing countries do make such investments, much will be lost to science.
With (mostly) United States-based academic journals reigning over global science, no one has to move to become part of a new brain drain, whereby scientists’ research priorities, problems, and methods gravitate to the dominant positivist epistemology, at the expense of all alternatives.
Closing the Financial Services’ Accessibility Gap
KAMPALA – Last month, the United Kingdom hosted the first-ever Global Disability Summit to help focus the world’s attention on the needs of people with disabilities.
The agenda was packed with topics like building equitable education, ending discrimination, and bringing technology to disabled communities – especially poor countries in the Global South.
But one challenge that did not receive the attention it deserved is an often-overlooked component of development policy: access to financial services.
This was a missed opportunity – not only for the world’s one billion disabled people, but also for the institutions that should be serving them.
Increasing the accessibility of financial services is good for business and economic growth.
According to research by Barclays, when customers with disabilities are able to manage their money, economic vulnerability declines and overall economic health improves.
Moreover, with more than $1 trillion in disposable income, the so-called disability market is among the biggest potential client bases in the world. In other words, financial-service providers have every reason to cater to people with disabilities.
Why, then, are most businesses doing just the opposite?
One reason is a lack of awareness.
Because people with disabilities typically have less income than their nondisabled peers, service providers have often lacked an incentive to extend support to them.
But, with more attention being paid to total market potential, financial institutions are starting to adjust their product lines accordingly.
As they do, four issues must be addressed to maximize the benefits for customers with accessibility challenges.
First, financial-services companies must work harder to understand the needs of current and future clients.
For example, with better data, a bank in a particular market could improve the accessibility of its mobile-banking platforms.
This is essentially what happened at Standard Chartered Bank in India last year, when employees developed a voice-assisted system to help visually impaired customers access their accounts online.
Good data are also essential to the effectiveness of advocacy groups as they push providers to improve their services.
Second, engagement must not stop with innovative products; it must also be extended to the labor market.
Simply put, the financial-services industry should hire more people with disabilities by investing in assistive technologies like braille readers and alternative and augmentative communication devices.
The need to diversify the workforce is particularly acute in the United States, where one in five people has a disability.
Third, people with disabilities must always be included in discussions about how to expand and strengthen financial independence.
In 2013, when the Lloyds Banking Group convened a focus group to examine the effects of dementia on customer behavior, engagement with clients led to the charter on Dementia-friendly Financial Services.
This innovative document codified how banks should tailor products to clients with cognitive impairments.
Future initiatives should follow this collaborative model to ensure that decision-making at all levels is facilitated by human-centered design.
And, lastly, governments must commit to addressing this issue, by emulating the action of countries like the UK, which has linked services for the disabled to development funding.
With the right support, progress on these complex challenges can be sweeping; for example, at Financial Sector Deepening Uganda, where I work, we are using British aid money to extend financial services to the disabled in rural communities.
Our vision is to encourage the emergence of similar programs in many other countries around the world.
With 91 countries having already ratified the Optional Protocol to the Convention on the Rights of Persons with Disabilities, it is clear that there is plenty of political support for these initiatives.
The challenge now is to turn pledges into action.
In the coming decades, the world’s disabled population will grow as medical advances allow people to live longer, healthier, fuller lives.
Providing the disabled with access to financial services and products is among the best ways to guard against discrimination and nurture long-term empowerment.
Full financial inclusion will come slowly for a community often referred to as the “fastest-growing minority group in the world.”
The task for activists, advocates, enlightened business leaders, and policymakers is to highlight the social and economic benefits of success.
Surgery for All
BOSTON – On a recent trip to India, I hailed a rickshaw that was pedaled, I soon noticed, by a man with a lame leg.
It turns out that a few weeks earlier, the driver had been hit by a car while navigating the busy streets of New Delhi.
Although he had managed to obtain medication from a local pharmacy for the agonizing pain – probably because his leg was broken – he could spare neither the time nor the money to see a surgeon.
This type of tragic calculus is strikingly common.
The Lancet Commission on Global Surgery estimates that some five billion people – almost 70% of the world’s population – lack access to safe, affordable surgical and anesthetic care, while 33 million people are saddled with unbearably high health expenses.
Not surprisingly, the global poor suffer disproportionately: while low-income countries are home to close to 35% of humanity, they account for just 3.5% of all surgical procedures.
One of the biggest obstacles to achieving universal health coverage – which the United Nations has declared a global goal – is financing.
And, paradoxical as it may sound, one of the best ways that governments can get the money they need to expand coverage is by making surgery more widely available.
Time-sensitive health problems – such as injuries from traffic accidents and pregnancy-related complications – are among the leading causes of death and disability in low- and middle-income countries.
But untreated or undertreated conditions requiring surgery also hurt economic productivity.
For example, the Lancet study estimated that the failure to improve surgical care in developing countries would translate into $12.3 trillion of lost economic output by 2030.
Failure to maintain strong surgical capacity could even undercut economic gains made by middle-income countries, reducing total GDP growth by approximately 2% annually.
For many leaders, the common perception is that provision of surgical care is not sustainable or cost-effective.
When faced with tough budget choices, governments often favor programs that combat infectious and chronic diseases, leaving people like my rickshaw driver in the lurch.
But a growing body of evidence suggests that these views are misplaced.
When researchers at the Harvard Medical School analyzed surgical interventions in low- and middle-income countries, they found a remarkable disconnect between economic assumptions and reality.
For example, they calculated that money spent on cesarean sections and joint surgeries yields higher returns than spending on the management of HIV or heart disease.
To be sure, chronic and infectious diseases need our attention, too; we cannot restructure health systems overnight, nor should we turn our backs on those being treated for non-surgical illnesses.
But reforms that focus more attention on the importance of surgery would boost economic productivity and help create more equitable health care for everyone.
For starters, health ministries and physician organizations should formally recognize that surgical and anesthetic care are an essential part of universal health coverage.
To make this case, health-care providers will need to improve their collection and analysis of data on surgical outcomes, which would increase transparency on mortality and morbidity and strengthen overall accountability.
Decisions about how to expand services could be guided by the Lancet commission’s core indicators on “preparedness,” “delivery,” and “impact” of surgical care.
Second, to pool risk and guard against cost overruns, countries that are considering universal coverage policies should put surgical care under publicly financed plans.
While some funding for expanding surgical services could come from taxation, health-care providers should also explore innovative financing options – such as “social justice models,” whereby people pay according to their means.
Finally, to streamline resources and increase surgical capacity, hospitals should explore task-sharing, whereby non-emergency cases are referred to licensed nurses and physician assistants.
Longer-term strategies include investing more in medical education to bolster the ranks of doctors and surgeons.
The tremendous economic progress that many developing countries have made in recent decades has been largely driven by vibrant, young, and ambitious populations.
One of the most effective ways to maintain this growth and development is to ensure access to safe and affordable healthcare – including surgery.
While the cost of providing it may be high, the cost of not providing it is even higher.
Polluters Must Pay
NEW YORK – When BP and its drilling partners caused the Deepwater Horizon oil spill in the Gulf of Mexico in 2010, the United States government demanded that BP finance the cleanup, compensate those who suffered damages, and pay criminal penalties for the violations that led to the disaster.
BP has already committed more than $20 billion in remediation and penalties.
Based on a settlement last week, BP will now pay the largest criminal penalty in US history – $4.5 billion.
The same standards for environmental cleanup need to be applied to global companies operating in poorer countries, where their power has typically been so great relative to that of governments that many act with impunity, wreaking havoc on the environment with little or no accountability.
As we enter a new era of sustainable development, impunity must turn to responsibility.
Polluters must pay, whether in rich or poor countries.
Major companies need to accept responsibility for their actions.
Nigeria has been Exhibit A of corporate environmental impunity.
For decades, major oil companies, including Shell, ExxonMobil, and Chevron, have been producing oil in the Niger Delta, an ecologically fragile environment of freshwater swamp forests, mangroves, lowland rainforests, and coastal barrier islands.
This rich habitat supports remarkable biodiversity – or did before the oil companies got there – and more than 30 million local inhabitants, who depend on the local ecosystems for their health and livelihoods.
Twenty years ago, the International Union for Conservation of Nature and Natural Resources classified the Niger Delta as a region of high biodiversity of marine and coastal flora and fauna – tree species, fish, birds, and mammals, among other forms of life – and therefore rated it as a very high priority for conservation.
Yet it also noted that the region’s biodiversity was under massive threat, with little or no protection.
The global companies operating in the delta have spilled oil and flared natural gas for decades, without regard for the natural environment and the communities impoverished and poisoned by their actions.
One estimate puts the cumulative spills over the past 50 years at approximately 10 million barrels – twice the size of the BP spill.
The data are uncertain: there have been many thousands of spills during this period – often poorly documented and their magnitude hidden or simply unmeasured by either the companies or the government.
Indeed, just as BP was being hit with new criminal penalties, ExxonMobil announced yet another pipeline leak in the Niger Delta.
The environmental destruction of the delta is part of a larger saga: corrupt companies operating hand in hand with corrupt government officials.
The companies routinely bribe officials to gain oil leases, lie about output, evade taxes, and dodge responsibility for the environmental damage that they cause.
Nigerian officials have become fabulously wealthy, owing to decades of payoffs by international companies that have plundered the delta’s natural wealth.
Shell, the largest foreign operator in the Niger Delta, has been criticized repeatedly for its egregious practices and its unwillingness to be held to account.
Meanwhile, the local population has remained impoverished and beset by diseases caused by unsafe air, poisoned drinking water, and pollution in the food chain.
Local lawlessness has led to gang warfare and persistent illegal tapping into the pipelines to steal oil, leading to further massive oil spills and frequent explosions that kill dozens, including innocent bystanders.
In the colonial era, it was the official purpose of imperial power to extract wealth from the administered territories.
In the post-colonial period, the methods are better disguised.
When oil companies misbehave in Nigeria or elsewhere, they are protected by the power of their home countries.
Don’t mess with the companies, they are told by the United States and Europe.
Indeed, one of the largest bribes (a reputed $180 million) paid in recent times in Nigeria was by Halliburton, a company tightly intertwined with US political power.
(Dick Cheney went from being Halliburton’s CEO to the US vice presidency.)
Last year, the United Nations Environment Program (UNEP) issued a remarkable report on Ogoniland, a major ethnic homeland in the Niger Delta that has been at the epicenter of conflict between local communities and international oil.
The report was as scathing as it was scientifically clear.
Despite many past promises of a cleanup, Ogoniland remains in environmental agony, impoverished and sickened by the oil industry.
UNEP also offered clear and detailed recommendations, including emergency measures to ensure safe drinking water; cleanup activities targeting the mangroves and soils; public-health studies to identify and counteract the consequences of pollution; and a new regulatory framework.
The world’s governments have recently agreed to move to a new framework for sustainable development, declaring their intention to adopt Sustainable Development Goals at the Rio+20 Summit in June.
The SDGs offer a critical opportunity for the world to set clear, compelling standards for government and corporate behavior.
Many major companies, including in the oil industry, have expressed their readiness to support sustainable development goals.
Cleaning up the Niger Delta would provide the strongest possible example of a new age of accountability.
Shell, Chevron, ExxonMobil, and other major oil companies should step forward and help to fund the necessary cleanup, ushering in a new era of responsibility.
The Nigerian government’s own accountability is on the line as well.
It is heartening that several Nigerian senators have recently been in the forefront of efforts to strengthen the rule of law in the oil sector.
The cleanup of the Niger Delta provides an ideal opportunity for Nigeria, the oil industry, and the international community to show convincingly that a new age has dawned.
From now on, sustainable development must not be a mere slogan, but rather an operational approach to global governance and well-being on a strained and crowded planet.
Saving Capitalism from Economics 101
WASHINGTON, DC – All across the United States, students are settling into college – and coming to grips with “Econ 101.”
This introductory course is typically taught with a broadly reassuring message: if markets are allowed to work, good outcomes – such as productivity growth, increasing wages, and generally shared prosperity – will surely follow.
Unfortunately, as my co-author James Kwak points out in his recent book, Economism: Bad Economics and the Rise of Inequality, Econ 101 is so far from being the whole story that it could actually be considered misleading – at least as a guide to sensible policymaking.
Markets can be good, but they are also profoundly susceptible to abusive practices, including by prominent private-sector people.
This is not a theoretical concern; it is central to our current policy debates, including important new US legislation that has just been put forward.
One core problem is that market incentives reward self-interested private behavior, without accounting for social benefits or costs.
We generally overlook our actions’ spillover effects on others, or “externalities.”
To be fair, Econ 101 textbooks do discuss this issue in some contexts, such as pollution, and it is widely accepted that environmental damage needs to be regulated if we are to have clean air, clean water, and limits on other pollutants.
Unfortunately, “widely accepted” does not include by President Donald Trump’s administration, which is busy rolling back environmental protections across a broad range of activities.
The New York Times counts 76 rollbacks in progress.
The thinking behind this policy is straight out of the first few weeks of Econ 101: get out of the way of the market.
As a result, there is a lot more pollution – including more emission of greenhouse gases – in America’s future.
There is also an even deeper problem.
There is a general presumption in Econ 101 that firms should maximize profits, and that this is best for their shareholders and for society.
But this notion of “firms” is just a shorthand for people organized in a particular form. People, not firms, make decisions.
To understand the nature and impact of these decisions, we need to look closely at the incentives of firms’ senior managers and board members.
Since the 1970s, the people who run firms have become much more focused on increasing their compensation, through bonuses, stock options, and the like.
There has been a significant rise in the value of shares, most of which are owned by the wealthiest 10% of Americans.
At the same time, median wages have barely increased – a dramatic change from the immediate post-World War II period, when productivity increases led to steady wage gains.
Today, it is top managers and members of boards of directors in whose interest firms are run.
Investors sometimes get a good ride, though there are plenty of instances where insiders take excessive advantage by awarding themselves overly generous compensation, taking on excessive risk, or engaging in other, more devious practices.
The idea that compensation committees insist on genuinely impressive performance, relative to relevant benchmarks, has become risible.
This is the context in which Senator Elizabeth Warren of Massachusetts is proposing a new Accountable Capitalism Act.
Very large companies would need to acquire a federal charter (as opposed to the current state charter arrangements), which would come with specific obligations – in particular, the need to consider the interests of all corporate stakeholders, including workers.
To make this more meaningful and generally improve transparency, ordinary (non-management) employees should get some representation on the board of directors.
This type of arrangement works well in Germany, a country where workers continue to be treated with respect.
Warren also supports a proposal that originated from John Bogle, founder of Vanguard (a mutual fund company), that would require super-majority support from shareholders and directors before a large company could engage in political expenditures.
The underlying legal theory behind these proposals is sound, and it is well articulated in a letter signed by Robert Hockett of Cornell Law School and other distinguished figures.
Large corporations are granted significant rights, including limited liability for individual executives, and facilitate the pooling of large amounts of capital from people who do not necessarily know one another (or the promoters of the company).
Originally, the purpose was to enable the private sector to carry out large-scale risky investments that had broader potential impact, such as building canals and railroads.
The US supposedly constrains the activities of large corporations, with the Department of Justice taking action if companies acquire monopoly power or otherwise behave in an anti-competitive manner.
Realistically, the enforcement of antitrust law has slipped a long way in recent years, under both Republican and Democratic administrations.
Warren is proposing a much broader rethink.
Large corporations can still do well, but they need to be held accountable in a much more transparent way.
Incentives for executives would be adjusted, and running these companies would no longer be so much about lining their own pockets.
Workers would no longer be treated so badly, and more people might even start to believe again in the American Dream of prosperity for all.
The legitimacy of capitalism – private ownership and reliance on market mechanisms – would be greatly strengthened under the Accountable Capitalism Act.
So, yes, like it or not, this will be on the final exam.
A Centerless Euro Cannot Hold
CAMBRIDGE – With youth unemployment touching 50% in eurozone countries such as Spain and Greece, is a generation being sacrificed for the sake of a single currency that encompasses too diverse a group of countries to be sustainable?
If so, does enlarging the euro’s membership really serve Europe’s apparent goal of maximizing economic integration without necessarily achieving full political union?
The good news is that economic research does have a few things to say about whether Europe should have a single currency.
The bad news is that it has become increasingly clear that, at least for large countries, currency areas will be highly unstable unless they follow national borders.
At a minimum, currency unions require a confederation with far more centralized power over taxation and other policies than European leaders envision for the eurozone.
What of Nobel Prize winner Robert Mundell’s famous 1961 conjecture that national and currency borders need not significantly overlap?
In his provocative American Economic Review paper “A Theory of Optimum Currency Areas,” Mundell argued that as long as workers could move within a currency region to where the jobs were, the region could afford to forgo the equilibrating mechanism of exchange-rate adjustment.
He credited another (future) Nobel Prize winner, James Meade, for having recognized the importance of labor mobility in earlier work, but criticized Meade for interpreting the idea too stringently, especially in the context of Europe’s nascent integration.
Mundell did not emphasize financial crises, but presumably labor mobility is more important today than ever.
Not surprisingly, workers are leaving the eurozone’s crisis countries, but not necessarily for its stronger northern region.
Instead, Portuguese workers are fleeing to booming former colonies such as Brazil and Macau.
Irish workers are leaving in droves to Canada, Australia, and the United States.
Spanish workers are streaming into Romania, which until recently had been a major source of agricultural labor in Spain.
Still, if intra-eurozone mobility were anything like Mundell’s ideal, today we would not be seeing 25% unemployment in Spain while Germany’s unemployment rate is below 7%.
Later writers came to recognize that there are other essential criteria for a successful currency union, which are difficult to achieve without deep political integration.
Peter Kenen argued in the late 1960’s that without exchange-rate movements as a shock absorber, a currency union requires fiscal transfers as a way to share risk.
For a normal country, the national income-tax system constitutes a huge automatic stabilizer across regions.
In the US, when oil prices go up, incomes in Texas and Montana rise, which means that these states then contribute more tax revenue to the federal budget, thereby helping out the rest of the country.
Europe, of course, has no significant centralized tax authority, so this key automatic stabilizer is essentially absent.
Some European academics tried to argue that there was no need for US-like fiscal transfers, because any desired degree of risk sharing can, in theory, be achieved through financial markets.
This claim was hugely misguided.
Financial markets can be fragile, and they provide little capacity for sharing risk related to labor income, which constitutes the largest part of income in any advanced economy.
Kenen was mainly concerned with short-term transfers to smooth out cyclical bumpiness.
But, in a currency union with huge differences in income and development levels, the short term can stretch out for a very long time.
Many Germans today rightly feel that any system of fiscal transfers will morph into a permanent feeding tube, much the way that northern Italy has been propping up southern Italy for the last century.
Indeed, more than 20 years on, Western Germans still see no end in sight for the bills from German unification.
Later, Maurice Obstfeld pointed out that, in addition to fiscal transfers, a currency union needs clearly defined rules for the lender of last resort.
Otherwise, bank runs and debt panics will be rampant.
Obstfeld had in mind a bailout mechanism for banks, but it is now abundantly clear that one also needs a lender of last resort and a bankruptcy mechanism for states and municipalities.
A logical corollary of the criteria set forth by Kenen and Obstfeld, and even of Mundell’s labor-mobility criterion, is that currency unions cannot survive without political legitimacy, most likely involving region-wide popular elections.
Europe’s leaders cannot carry out large transfers across countries indefinitely without a coherent European political framework.
European policymakers today often complain that, were it not for the US financial crisis, the eurozone would be doing just fine.
Perhaps they are right.
But any financial system must be able to withstand shocks, including big ones.
Europe may never be an “optimum” currency area by any standard.
But, without further profound political and economic integration – which may not end up including all current eurozone members – the euro may not make it even to the end of this decade.
Achieving a “Europe of Results”
BRUSSELS – The tsunami that has swept across financial markets is a global catastrophe.
If handled correctly, however, the crisis may yet raise the esteem of the European Union and its institutions.
The EU’s legitimacy problem has two different aspects: apathy, leading to a low turnout in the European parliamentary elections, and outright euro-skepticism.
The voter-turnout problem partly reflects frustration about the present state of the EU, and also people’s impression that they can exert little influence by voting one way or the other.
Euro-skepticism, on the other hand, and the looming threat of anti-European populism, is directly linked to the idea that the EU is not merely incapable of offering a solution to the crisis, but in fact is part of the problem.
So, although the EU represents our best hope of ensuring that Europe is internationally competitive in today’s increasingly difficult environment, it is actually being blamed for globalization.
Many people confuse these two aspects of the EU’s legitimacy problem, and believe that somehow turnout in European elections can be increased by pointing out to people how good and important the EU is.
But in most cases, this is not possible.
At first sight, the easiest answer to the problem of low voter turnout is to give more power to the European Parliament.
But if this was the solution, then we would not have had steadily declining turnouts since the high point of 63%, at the first elections to the European Parliament in 1979. After all, since then the EP’s influence and powers of joint decision-making have grown constantly.
The trouble is that, EP elections must be “about” something if voters are to be interested, which means they must involve a real choice.
And a real choice requires Europe-wide election campaigns by all parties. This would also involve making the choice of the European Commission’s president dependent on the outcome of the EP elections.
But, in fact, both of these conditions have already been met; in 2004, Portuguese Prime Minister José Manuel Durão Barroso was appointed President of the Commission because he came from the political organization with the strongest election result, the European People’s Party.
And this year’s elections saw a more intensive presence of party organizations at European level than ever before.
Instead, I believe that the most important way to reawaken voters’ interest in European elections will be to open up the election of the Commission’s President to them, and create a genuinely Europe-wide political debate during the next election campaign.
The Euro-skepticism problem can be tackled only if the Union itself starts to perform better, and is seen to be doing so.
That is why in the aftermath of the failed referenda four years ago in France and the Netherlands on the Constitutional treaty, the Commission tried to emphasize the idea of a “Europe of Results” that would seek to convince citizens of its worth through concrete achievements.
Given the gravity of the economic crisis, the time has come for the EU to demonstrate its strengths whenever possible.
The aim must be not only to win back the hearts of Europeans who have become skeptical, but also to convince them that the Union is indispensable to meeting the challenges Europeans face.
Europe’s citizens understand that the relatively small nation-states that make up the EU are no longer able to face these enormous challenges on their own.
In Ireland, last autumn’s financial crisis provoked a turnaround in public opinion about the EU, and even in Iceland, although it lies on the periphery of our continent, membership of the EU and the euro have become a priority.
European countries have become so interconnected that isolated national measures on issues like financial-market regulation are hopeless.
A changing world in which new powers like China and India play an increasingly important role will not wait for Europe to make up its mind.
The EU must instead show leadership through its efforts to solve the world’s current problems.
As for the European People’s Party, for us the economy is not an end in itself but should serve the people.
The economic crisis was caused by shortsightedness and a lack of control in the global financial system. Now we must redefine the role of regulators in financial markets and in the wider economy, for we cannot let the financial sector walk off with the profits and leave taxpayers bearing the losses.
That doesn’t mean that we are advocating a move to socialism; we want better and smarter regulation, not regulation for its own sake.
We see five keys to recovery:
A “Europe of Results” is achievable.
It can strengthen the EU’s legitimacy, though, only if policy recommendations such as these, and the successes that result from implementing them, are communicated clearly and effectively to the general public.
The Education Roadmap to 2030
LONDON – When I visited the Zaatari refugee camp in Jordan earlier this year, I met with children who told me what education means to them.
For Syrian youths who have been forced from their homes and have lost everything, education is about more than qualifications or test scores; it embodies their hope for the future.
Children like those in Zaatari, and millions of others around the world, are central to the work of the International Commission on Financing Global Education Opportunity, which I joined last September.
This commission is committed to the fourth United Nations Sustainable Development Goal, which aims, by 2030, to “ensure inclusive and equitable quality education and promote lifelong learning opportunities for all.”
This goal is still a distant prospect for far too many children.
With so many development issues demanding our attention, policymakers should bear in mind that education is not just a good in itself; it is also a catalyst for many other development gains.
As the old African proverb goes, if you educate a girl, you educate an entire nation.
Ensuring access to quality education for children, especially girls, will lead to fewer child marriages and less child labor and exploitation.
And education has long-term societal benefits: aside from increased political engagement, educated children contribute intellectual capital and pursue entrepreneurial opportunities when they grow up, boosting economic growth.
Tackling the education challenge needs to start from two principles embedded in the goal.
First, “for all” means that we must focus on the children who have been left behind.
Millions of children are out of school or are receiving a substandard education because of who they are or where they live.
According to the UN High Commissioner for Refugees, refugee children are five times more likely to be out of school than other children in the countries to which they’ve been displaced.
And in all but two African countries, girls remain less likely than boys to complete a primary education.
Getting these children into school will require new approaches that directly address their exclusion and make schooling genuinely accessible and relevant.
Second, “quality”: Education must be effective, so that children actually learn.
For the 61 million children who are out of primary school, formal education is beyond reach.
But, just as urgently, more than one-third of children of primary-school age – 250 million – are not learning the basics, according to the UNESCO Education for All Global Monitoring Report.
Half of these children have been in school for at least four years.
We must address the barriers to learning, both in the classroom and at home, by improving the quality of teaching and classroom conditions and teaching parents how they can support their children’s education.
Upholding these two principles will require increased investment.
Last year, UNESCO calculated that governments must double education spending as a share of national income to achieve the 2030 goals.
This will require increased revenue from taxation and stronger efforts to collect what’s owed.
Donors also need to live up to their aid commitments and target aid more effectively.
For example, less than one-third of education aid goes to Africa, even though the region accounts for almost two-thirds of out-of-school children.
Moreover, at the moment, education budgets are often regressive, with almost half of spending in the poorest countries allocated to the most educated 10% of the population.
Fixing education investment requires action in two key areas.
First, we need equitable financing, with more investment in early childhood care and development, where there is the biggest potential for returns.
Budgets must be focused on the most excluded children, and primary education must be free at the point of use, so that every child can learn.
We also urgently need more transparency and accountability, so that budgets are visible and communities have a say in school governance.
Second, we need to strengthen domestic education systems so that governments see themselves as the guarantor of accessible, quality schools for their citizens, rather than abdicating that role to outside development agencies.
In particular, we should push for partnerships between government and business to boost domestic resources for education, and eliminate illicit capital flows that deprive governments of the means to fund it, such as tax evasion and money laundering across national borders.
With these priorities in mind, the education commission will deliver its recommendations at the UN General Assembly on September 18, when the Secretary-General will receive and act on them.
The Education Commission will have succeeded if we are able to leverage the funding and political will to ensure that every child learns, regardless of their income, location, or social status.
Our work will not be complete until that happens.
Sustaining Progress in Transition Countries
NEW YORK – In the World Bank’s most recent “Doing Business” report, half of the Eastern European and Central Asian countries included in the global ranking were among the top 50.
As a measure of economic maturity, the report confirms what many in the international development community have long known: the region is ascendant.
Over the last decade, the economies of Eastern Europe and Central Asia have recorded spectacular gains, buttressed by ambitious market and public-sector reforms.
The question now is how to ensure that this progress – which has tripled the size of the middle class – is sustained.
Signs of the region’s social and economic prosperity are everywhere.
In Azerbaijan, incomes have increased dramatically in recent decades, and only 5% of the population now lives below the poverty line – down from nearly 50% in 2002.
Elsewhere, Estonia is the third country in Europe in startups per person and has one of the fastest Internet speeds anywhere.
And from Albania to Kyrgyzstan, e-government systems are allowing more people to connect with critical services through online and electronic portals.
But while it is tempting to assume that the region is destined for prosperity, structural bottlenecks continue to slow progress, especially in the Western Balkans, the southern Caucasus, and parts of Central Asia.
To maintain momentum in meeting the United Nations Sustainable Development Goals (SDGs) by 2030, leaders must address three key issues.
First, the region’s economies need to be strengthened to incentivize smarter, more sustainable growth.
For example, fossil-fuel subsidies should be reconsidered, because they discourage investment in energy-efficiency projects, and impede the development of renewable technologies.
Similarly, while public financing of pensions and welfare programs is dependent on taxing labor, much of the region currently suffers from high rates of unemployment; in the Western Balkans, there are nearly no jobs, or none at all.
Job creation is an urgent challenge for every state in the region.
Second, in many countries, the space for civil society is becoming narrower, posing a threat to pluralism and accountability.
To prevent conflict and give voice to the region’s marginalized groups, tolerance and respect for human rights must be made essential ingredients of governance.
Finally, the region must coordinate on strategies to address the changes that automation and artificial intelligence will bring to the labor market.
Leaders in some countries, particularly Belarus, are shifting economic output from heavy manufacturing to technology startups.
But authorities everywhere can do more to increase the resilience of their workforces.
Fortunately, governments, technology companies, civil-society groups, and journalists recognize the salience of these issues and are working together to build more transparent and accountable institutions.
In many countries, heads of government are using the SDGs to guide their national planning and efforts to legislate reforms.
The parliaments of several Central Asian countries have even endorsed the SDGs as a development roadmap.
Changes like these are helping to translate development ambition into action.
In Armenia, the government recently created the world’s first national SDG innovation laboratory, a collaborative effort designed to “accelerate” SDG implementation.
Initial research efforts will focus on increasing the country’s tax collection, improving its education system, and boosting its renewable-energy sector.
Meanwhile, planning officials in Moldova have used crowdfunding to raise millions of dollars from the diaspora to fund sustainable development projects at home.
Revitalization efforts have included the reconstruction of a public plaza in the capital, Chișinău, and the expansion of infrastructure in rural areas.
The region’s private sector is also participating actively in sustainable development efforts.
From Siemens’ green heating and air conditioning systems to Unilever’s “equal pay for equal work” policy, multinational firms operating in Eastern Europe and Central Asia are embracing sustainability and equality as viable business models.
In only a few decades, the people of Eastern Europe and Central Asia have witnessed profound political and economic changes.
To capitalize on the development progress already made, countries and organizations must learn from one another, adapting solutions to local conditions.
That will be the main topic at the Istanbul Development Dialogues, an annual global gathering organized by the UN Development Programme, this week.
As the new UNDP Strategic Plan for 2018-2021 argues, collaboration is a critical component to any sustainable-development strategy.
If the measure of a country can be calculated by how easily business is conducted within its borders, the states of Eastern Europe and Central Asia have a bright future.
With strong leadership that transforms the region’s economies and modernizes its institutions, the region’s recent gains will not be fleeting.
The Achilles’ Heel of Trumponomics
NEW HAVEN – Donald Trump’s economic strategy is severely flawed.
The US president-elect wants to restore growth via deficit spending in a country with a chronic shortfall of saving.
This points to a further compression in national saving, making a widening of an already outsize trade gap all but inevitable.
That dynamic unmasks the Achilles’ heel of Trumponomics: a blatant protectionist bias that collides head-on with America’s inescapable reliance on foreign saving and trade deficits to sustain economic growth.
The Trump administration will not inherit a strong and sound US economy.
The pace of recovery since the Great Recession has been running at half that of normal cyclical rebounds – all the more disturbing given the massive size of the contraction in 2008-09.
And savings, the seed corn of future prosperity, remain in woefully short supply.
The so-called net national saving rate – the depreciation-adjusted sum of business, household, and government saving – stood at just 2.4% of national income in mid-2016.
While that’s an improvement from the unprecedented negative saving position in 2008-2011, it remains far short of the 6.3% average that prevailed over the final three decades of the twentieth century.
This is important because it explains the pernicious trade deficits that Trump continues to rail against.
Lacking in saving and wanting to grow, the United States must import surplus saving from abroad.
And the only way to attract that foreign capital is by running massive current-account and trade deficits.
The numbers bear this out: since 2000, when national saving fell well below trend, the current-account deficit has widened to an average of 3.8% of GDP – nearly four times the 1% gap from 1970 to 1999.
Similarly, the net export deficit – the broadest measure of a country’s trade imbalance – has been 4% of GDP since 2000, versus an average of 1.1% over the final three decades of the twentieth century.
Trumponomics has the cause and effect behind this development backwards.
It fixates on country-specific sources of the trade deficit, like China and Mexico, but misses the fundamental point that these bilateral deficits are symptoms of America’s far deeper saving problem.
Presume for the moment that the US closes down trade with China and Mexico – the first and fourth largest components of the overall trade deficit – through a combination of tariffs and other protectionist measures (including the proposed renegotiation of NAFTA and a Mexican-funded border wall).
Without addressing America’s chronic saving shortage, the Chinese and Mexican components of the trade deficit would simply be redistributed to other countries – most likely to higher-cost producers.
The result would be the functional equivalent of a tax hike on beleaguered middle-class US families.
In short, there is no bilateral fix for a multilateral problem.
The US had trade deficits with 101 countries in 2015 – a multilateral problem stemming from a saving shortfall that cannot be effectively addressed through country-specific “remedies.”
That’s not to say that America’s trading partners should be let off the hook for unfair practices.
But it does mean that there is limited hope for resolving seemingly chronic trade deficits – and the related erosion of domestic hiring traceable to these imbalances – if the US doesn’t start saving again.
Alas, this plot is about to thicken.
Trumponomics seems likely to exacerbate America’s saving shortfall in the years ahead.
Analyses by the Tax Policy Center, the Tax Foundation, and Moody’s Analytics all indicate that federal budget deficits under Trump’s economic plan are headed back toward at least 7% of GDP over the next ten years.
Trump’s senior economic-policy advisers, Peter Navarro and Wilbur Ross (Trump's pick for commerce secretary), argued in a position paper in September that these estimates are flawed, because they don’t take into account “growth-inducing windfalls” from regulatory and energy reforms, or the added bonanza that should arise from a sharp narrowing of America’s trade deficit.
Indeed, the Navarro-Ross analysis attributes fully 73% of the growth-inducing revenue windfall of Trumponomics to a massive improvement in the overall trade balance over the next decade.
Yet, as stressed above, barring a miraculous surge in national saving, this is highly dubious.
Creative accounting, long a staple of supply-side economics, has never been more imaginative.
Therein lies one of the most glaring disconnects of Trumponomics.
Getting tough on trade at a time when national saving is about to come under ever-greater pressure simply doesn’t add up.
Even the most conservative estimates of the federal budget deficit suggest that the already-depressed net national saving rate could re-enter negative territory at some point in the 2018-2019 period.
That would put renewed pressure on the current-account and trade deficits, making it extremely difficult to reverse the loss of jobs and income that politicians are quick to blame on America’s trading partners.
Ironically, in the coming era of negative saving, the US will find itself increasingly dependent on surplus saving from abroad.
If the Trump administration takes aim at major foreign lenders – namely, China – its strategy could quickly backfire.
At a minimum, there could be an adverse impact on the terms by which America borrows from abroad; that could mean higher interest rates – hints of which are already evident – and ultimately downward pressure on the dollar.
And, of course, there is the worst-case scenario of an escalating global trade war.
Protectionism, anemic saving, and deficit spending make for an especially toxic cocktail.
Under Trumponomics, it will be exceedingly difficult to make America great again.
A Clarion Call for Emerging Markets
ITHACA – With 2012 underway, it is worth reflecting on how a decade of strong economic growth in emerging markets led to last year’s resounding political transformations.
From the dramatic events in the Middle East, to the groundswell of support for the anti-corruption crusader Anna Hazare in India, leaders in emerging markets are getting a clear message from the streets that growth is not everything.
They ignore this message at their peril.
Emerging-market economies delivered solid growth during the 2000’s, and even survived the global financial crisis without a growth collapse.
But the specter of rising corruption is compromising the legitimacy of their economic gains and eroding support for further reforms needed to sustain their growth momentum.
Corruption takes many forms, but, in emerging markets, a combination of factors has turned it into a cancer that ultimately topples regimes.
Relentless low-level corruption is a major irritant for poor people in many of these countries; indeed, it limits their access to the social services and basic government functions that they often depend upon for their very survival.
Another type of corruption involves siphoning enormous sums of money from large-scale projects.
In India, for example, the government lost as much as $30-40 billion of much-needed revenue when coveted band spectrum was sold through a rigged auction.
For ordinary people, large-scale corruption is less visible, because, while the sums involved are mind-boggling, the costs are not as directly felt as they are in the case of lower-level graft.
But the perception of this type of mega-corruption has changed as rapid growth has increased inequality.
In countries like China and India, rapid economic growth has lifted a huge number of people out of poverty.
But the fruits of globalization and rapid growth have not been evenly shared – the rich become super-rich, even as a large fraction of the population remains destitute.
Rising income inequality is hardly limited to emerging markets, but their combination of open corruption and pervasive inequities creates a toxic brew that is undermining support for reforms that would strengthen and consolidate their economic gains.
In many emerging markets, a lack of political freedom adds to the combustible mix.
The combination of corruption, inequality, and political repression builds up enormous pressure, and there are no institutional channels through which to release it.
But freer political regimes are not a panacea.
In a democracy like India’s, the politically well-connected benefit from skewed growth, thus increasing the resentment of those left behind.
The opportunity to “throw the rascals out” in each election cycle helps to let off some steam, but it does not resolve the problems that are generating it.
It is difficult to predict what triggers popular protest, but economic factors are key.
For example, rising food prices tend to hurt the poor, especially the urban poor, who spend a large share of their income on food; unlike agricultural workers, they receive none of the benefits of higher food prices.
With swelling urban populations, it will become increasingly difficult to keep a lid on these pressures.
Some governments have reacted to recent events with political repression, information blackouts, or a combination of authoritarian measures.
China, for example, blocked media coverage of the Egyptian protests.
The Arab Spring, however, reveals the fragility of repressive political regimes that try to maintain their legitimacy by limiting information flows.
The main lesson for dynamic emerging-market countries is that an exclusive focus on GDP growth may ultimately not be good for economic and political stability.
Even with rapid increases in national income, if these countries’ leaders do not distribute the benefits fairly, they will become vulnerable to popular discontent.
Tackling corruption is critical to improving long-term growth and maintaining social stability.
These economies need measures that help to keep the poor out of poverty traps, and that give them realistic opportunities to improve their economic well-being.
Such steps include broadening financial markets to give more people access to credit and investment, strengthening social safety nets to protect the economically vulnerable, and improving educational access and quality.
These lessons apply equally to advanced economies, which also suffer from rising inequality and subtle forms of corruption.
But, for those wealthy economies, restoring decent growth is now the major priority.
Emerging markets have a golden opportunity to build on their economic gains and lock in growth and stability by tackling deep-seated problems like corruption.
As the past year’s events have shown, the costs of inaction could be calamitous.
A Climate Deal is Not Enough
AMSTERDAM – During the COP15 climate summit in Copenhagen, world leaders have been negotiating the future of our planet. All the signs suggest that they are unlikely to sign a global climate treaty.
The politicians, civil servants, and other participants at the Copenhagen summit have mainly been bombarding each other with numbers.
Figures on how much various countries should reduce CO2 emissions, the amount of money they should put up in coming years, the exact nature of their responsibilities, how much temperature increase Earth will be able to endure, and how long we can continue to wait.
These are all very important issues.
But the mere figures are simply not enough. A different approach to the problem of climate change is needed.
The climate issue can only be solved on the basis of shared, deeply felt ethical principles.
Humanity has reached a critical moment in Earth’s history, at which peoples and nations will have to recognize their solidarity – with each other and with the Earth – and start acting upon it.
Similar to the way world leaders adopted the United Nations Millennium Declaration in September 2000, and embraced the resulting Millennium Development Goals, today’s climate negotiators will have to commit themselves to creating a basis of shared fundamental ethical principles.
Such a basis is not hard to find.
Its inspiration can be the Earth Charter, which, launched in 2000, was initiated by, among others, former USSR President Mikhail Gorbachev and Wangari Mathaai, who received the 2004 Nobel Peace Prize for her efforts in the Green Belt Movement, a pan-African tree-planting initiative.
The climate problem does not stop at borders.
In the next few decades, a low-lying country like the Netherlands will need to invest billions of euros to intensify its age-old struggle against rising water.
But in many other countries, the water is already flooding over the dikes, both literally and figuratively.
Climate change affects particularly those countries that lack the money needed to take adequate measures against rising sea levels, persistent droughts, or devastating storms, even though they had nothing to do with the primary cause of these problems – industrialization in the developed countries.
Apart from the necessary, often infrastructural adaptations to survive the effects of climate change, enormous efforts to prevent even worse things from happening are required.
Large investments in forestation, agriculture, and energy supply are called for.
In devising solutions, the role of women should be the main focus.
Women are often the first people who have to address the problem of gaining access to natural resources, and they are capable of playing a major role as pioneers in finding solutions to climate change and the way humankind should adapt to it.
In the short term, the world should become a sustainable global society of low CO2 emitters.
This is a mission for all humankind, in which patriotic feelings and thinking in terms of power blocs have no place.
The pursuit of a sustainable global society of low CO2 emitters requires a tremendous effort.
Precisely for this reason, it also requires a broadly shared ethical basis.
This would guide the negotiating parties in such a way that they look not only for solutions to a part of the problem, but first and foremost at a comprehensive solution to the entire problem.
The climate change issue is too important to be left in the care of politicians.
In Copenhagen, it is therefore imperative that not only nation states, but the business community and citizens combine their efforts to save our planet’s climate. That is not only a scientific necessity; it is an ethical imperative.
A Communist Party without Communism
PRINCETON – Russian President Vladimir Putin’s anointment of Alexander Medvedev to succeed him in what is supposed to be a democratic presidential election next March shows that Russia’s leaders have not changed a whit.
It looks increasingly likely that, as under Leonid Brezhnev, we will see the same names in the news for decades to come.
According to Gleb Pavlovsky, the Putin regime’s leading ideologist, the current Russian system is perfect in all respects but one: it doesn’t know its enemies.
Indeed, it seems as if everyone in the Kremlin is reading Carl Schmitt, the Nazi legal theorist who taught that naming your enemy is the central mission of politics.
In the spirit of Schmitt, Putin’s men designated a liberal party, the Union of Right Forces, as their ur-enemy.
Its public meetings were broken up by armed police; its leaders arrested and beaten; Putin called its supporters “coyotes.”
What is surprising is that this aggressive behavior occurred in response to no visible danger.
Oil prices are soaring, as are Putin’s approval ratings.
His appointees control everything that matters, from Gazprom to the Central Electoral Committee.
Since the pacification of Chechnya with violence and subsidies, the incarceration or emigration of a few financially viable opponents, and the massive “social investments” of recent years, which, under Medvedev’s personal supervision, have bribed the population, no credible force can seriously challenge Putin’s men.
Yet their regime is in crisis, and they know it.
Russia’s economy is more dependent on gas and oil than ever before.
Military reform has been reversed.
Despite increasing incomes, Russians are less educated and less healthy than they were when Putin came to power; they still die at a shockingly young age.
Russian involvement in world affairs is tainted by poison and corruption.
State monopolies undo what private businesses created.
With more money, ill-educated bureaucrats hire more ill-educated bureaucrats; as a result, the regime fails to rule the country.
The country is unruly, and its rulers know it.
So they panic.
Putin’s aim was to subject all power to the control of Russia’s security forces.
His generation of KGB officers watched the collapse of the Communist Party and all the governmental bodies that it “directed and controlled,” including the KGB.
Under Putin, the security service has had its revenge.
Its people have become powerful, arrogant, and enormously rich.
They have also become disobedient.
In 2004, General Viktor Cherkesov, then Putin’s representative in northwest Russia, published an essay that glorified the KGB as the only unspoiled authority in a corrupted country.
This essay, more than anything else, defined Putin’s second term.
In October 2007, Cherkesov (now chief of one of the most obscure and powerful services, the Federal Anti-Drug Administration) published another essay in which he lamented his colleagues’ degradation: warriors had turned into traders, he complained.
Earlier, generals from a competing service, the FSB, had arrested Cherkesov’s deputy for “illegal bugging.”
In a public gesture of despair, Cherkesov admitted the failure of Putin’s project to reanimate Russian governance by subordinating it to the security services.
Cherkesov’s deputy remains in prison.
Most believe that Putin is unable to intervene in his defense.
In the absence of Communist Party control, these security officers betrayed their corporate ethic and engaged in horse-trading, applying force when a trade did not go well.
That this happens to ordinary Russians is clear; what Cherkesov revealed was that Putin’s circle also confronts this situation.
What is to be done when ex-KGB warriors turn their swords and bugs against one another?
Cherkesov’s case exemplifies Putin’s nightmare.
But if your instincts betray you, you go back to even deeper ones.
Now that Putin’s people have left their predecessors’ neo-liberal ideas behind and feel disenchanted with the ex-KGB clique, the task is to recreate an omnipresent political party that controls the security services, the administration, business, and much else.
This party will be centralized under personal leadership and will reduce the state to a legal fiction.
Preaching nationalism, its managers will believe in their universal competence, as opposed to KGB-style professionalism and corporatism.
Boris Yeltsin forbade party cells in state-controlled institutions by decree.
Putin’s lawyers will reverse that decision; the party will have cells or committees in every factory, corporation, military unit, university department, etc.
Integrated by the leader’s charisma and party discipline, party members will direct and unify the desolated country.
This is Putin’s plan.
Like former Soviet leader Yuri Andropov, the only other KGB man to rule Russia, Putin will become the party’s general secretary.
As in the Soviet era, state and governmental officials will be reduced to party ciphers – the role that President Medvedev will play under General Secretary Putin.
And, of course, being General Secretary carries no constitutional term limit.
In the end, Putin has what history left him: not ideas, just a faction yearning to consolidate its grip on power.
Lenin and Trotsky needed a party to make their ideology a reality; Putin and Medvedev are devising an ideology to solidify their party.
It is a bizarre ideology.
Accusing warriors of being traders and traders of being thieves, it shuns its Marxist origins.
It will subordinate all who really do work – traders, warriors, journalists, and others – to party ideologues whose sole job is to search for enemies.
A Confederal Solution for Palestine
LONDON – Last month, while in New York City, I happened to be staying in the same hotel as Israeli Prime Minister Binyamin Netanyahu.
To accommodate his security needs, the hotel had been converted into a fortress, much like Israel itself.
Netanyahu was in the United States for yet another round of Middle East peace talks.
The US offered various sweeteners to induce Israel to freeze its West Bank settlement construction for another 90 days.
The Israelis refused; another impasse was reached.
What, then, might be the prospects of a negotiated peace between two peoples with claims to the same land?
The answer is: very poor.
All peace efforts since the Oslo accords of 1993 have been based on the “two-state solution,” according to which Israel is supposed to turn over the occupied territories to a Palestinian state, the Palestinians are supposed to renounce any claims on the Jewish state, and everyone is supposed to live happily ever after.
A negotiated “land for peace” solution still remains official Western doctrine.
As US Secretary of State Hillary Clinton put it in a recent speech, “a just, lasting, and comprehensive peace” has to be based on “two states for two peoples.”
Meanwhile, the two main parties to the dispute, Palestine and Israel, are searching for unilateral alternatives to the stymied “peace process.”
The Palestinians are pushing for international recognition of their statehood, while the Israelis are using their settlement policy to preempt a Palestinian state.
Palestinian President Mahmoud Abbas has said that, if the latest peace talks collapse, he will press for UN recognition of a Palestinian state based on the 1967 borders.
This month, Brazil and Argentina recognized “Palestine,” and a cascade of Latin American countries is expected to follow.
Abbas is now setting his sights on Europe, and would ask Turkey to serve as a go-between.
The game is to use international recognition of an independent Palestinian state to pressure the US to retreat from its almost unconditional support for Israeli policy.
Israel’s main concern continues to be security.
The official Western doctrine is that Israel’s long-term security depends on the success of the “peace process.”
In practice, Israel has been taking other measures to secure its future.
Media attention has been focused on the “security wall,” which has certainly succeeded in reducing the level of violence.
But, to the hawks who now control Israeli politics, the key to Israel’s security depends on depth of defense, for which expansion of the settlements is indispensable.
The hawks’ recipe for survival is threefold: continued military and economic support from the US, defensible frontiers through a strategic settlement program, and the carve-up of the Palestinian West Bank into disconnected bantustans, or subordinate authorities, incapable of concerted opposition to Israeli policy.
Thus, while Abbas seeks to create a new “fact on the ground” by drumming up international support for a Palestinian state, Israel aims to trump him by making such a state unviable.
The ideal alternative to both strategies is a peace process that aims not to create two states, but rather to establish the political and economic basis for a single confederal state.
Indeed, the two-state solution was always an illusion.
There was never enough land to satisfy the passionate possessiveness of all those with claims to it.
And, over time, Israeli settler disengagement from the West Bank and East Jerusalem has become just as impossible as any attempt by Israel to expel its remaining Arabs.
Israeli Jews are bound to stay in the West Bank and East Jerusalem, and Israeli Arabs are bound to stay in Israel proper.
These are the “facts on the ground” that doom Palestinian hopes for a sovereign Palestinian state no less than Israeli hopes for a wholly Jewish state.
Moreover, land for peace never made sense from an economic point of view.
If compensation for wrongs to the Palestinians was to be the guiding principle, there were always better ways of going about it than to found a rickety, poverty-ridden new country dependent on foreign aid.
Most people have forgotten that the Paris Protocols of April 1994 established a customs union between Israel and the occupied territories, with a joint Economic Council to adjudicate trade disputes.
The free movement of goods, labor, and capital between the two parts could have given a tremendous economic boost to Palestinian GDP.
It could also have been the basis of a confederal state, whose Palestinian part would have benefited from the West Bank settlers’ productivity and taxes.
But this benign prospect was undermined by the violence needed to maintain the Jewish state and enable the emergence of a Palestinian one.
The official view remains that only an internationally guaranteed two-state settlement will bring about the security needed for the economic revival of the Palestinian territories.
But it is just possible that unilateral Israeli policy, implicitly backed by the US, will create interim conditions of peace that are sufficient for economic growth to cool Palestinian nationalism.
The Palestinian cause is not the overriding preoccupation of even the Arab states, so Netanyahu’s strategy of defense in depth stands a better chance of success than Abbas’s pursuit of statehood through international recognition.
Netanyahu’s project is not moral.
But that doesn’t mean that it won’t work, at least for a time.
A Confederation for Kosovo
Time is running out in Kosovo.
If a United Nations-backed settlement is not reached by early December, the province’s majority Albanian population is likely to declare independence unilaterally – a move that the United States has announced it may support.
That would be a disastrous step.
Russia would be furious, because it fears that Kosovo’s secession – whether or not it is internationally recognized – might fuel separatist movements in the former Soviet empire.
Serbia is even more strongly opposed.
Dusan Prorokovic, Serbia’s state secretary for Kosovo, has said that his country might use force to maintain its sovereignty.
Even if the government hesitates, ultranationalist groups might push Prime Minister Vojislav Kostunica to send in troops: the current UN presence in Kosovo is very thin (only 40 “military observers” and 2,116 policemen) but the stationing of 15,000 NATO troops could make any armed clash very dangerous.
After eight years of international administration, Kosovo’s Albanian majority has tasted freedom and is eager for full independence.
But Serbia claims that the province remains an essential part of its historical and cultural tradition.
Moreover, independence would not be accepted by the Serbian public, which has already watched in dismay as “Great Serbia” has been gradually whittled away, most recently with the secession of Montenegro.
Serbia is prepared to concede only “enhanced autonomy” to Kosovo, and some capacity to enter into international agreements.
Yet, while the two parties now seem irreconcilable, it is not too late for compromise.
But this is possible only by resuscitating – and updating – an old institution of the international community: a confederation of states.
By means of a binding UN Security Council resolution, Kosovo could be granted full and exclusive authority over its citizens and territory, as well as limited capacity for action on the international scene.
It could be authorized to enter into trade agreements as well as agreements concerning individuals (for example, admission and circulation of foreigners, or extradition), plus the right to seek admission to the UN (which does not require full sovereignty and independence).
Kosovo would thus gain some essential trappings of statehood.
However, a decision-making body consisting of delegates from Kosovo, Serbia, and the European Union would be given full authority over major foreign policy issues (for example, alliances and relations with international economic institutions), defence, borders (in case Kosovo wished to join with Albania), and the treatment of Kosovo’s Serbian minority.
As a result, Kosovo and Serbia would constitute two distinct international subjects, bound by a confederation hinging on a common decision-making body.
Of course, this confederation would be asymmetrical, because the Serbian government’s sovereignty over the rest of Serbia would remain intact and unlimited, whereas the Kosovar government’s “sovereignty” over Kosovo would be restrained.
To avoid one of the two parties getting the upper hand and imposing arbitrary decisions, the common decision-making body should consist of four Serbian delegates, two Kosovar delegates, and three representatives of the EU, thus requiring both sides to gain the support of the European delegates.
In addition, the EU should create a small but effective military force (say, 5,000 troops) to back up the common body’s decisions.
As with any compromise, the contending parties would both gain and lose from this arrangement.
Serbia would save face, and would continue to have a say on crucial matters concerning Kosovo, including the treatment of the Serbian minority.
Kosovo would acquire limited independence, with its status rising from a province of a sovereign state to an international subject capable of entering into certain agreements with other states and even joining the UN.
The EU would benefit as well, by contributing to the stabilization of a highly volatile area.
Subsequently, the EU would monitor Kosovo and prevent any dispute that might turn violent.
A final advantage of this solution is that it would be temporary.
Historically, confederations sooner or later either become federations (as occurred in the US, Germany, and Switzerland) or, pushed by centrifugal forces, split up (as with the United Arab Republic, established in 1958, which split three years later into Egypt and Syria).
The confederation I advocate would thus constitute an intermediate stage (lasting five or ten years), at the end of which Kosovo is likely to become fully independent.
Delaying a final solution in this way would provide time to verify Kosovo’s prospects of joining the EU and thus eventually sharing “sovereign authority” with other independent states, which could deflate Kosovars’ dangerously robust nationalistic demands.
A Cool Calculus of Global Warming
The British government recently issued the most comprehensive study to date of the economic costs and risks of global warming, and of measures that might reduce greenhouse gas emissions, in the hope of averting some of the direst consequences.
Written under the leadership of Sir Nicholas Stern of the London School of Economics, who succeeded me as Chief Economist of the World Bank, the report makes clear that the question is no longer whether we can afford to do anything about global warming, but whether we can afford not to.
The report proposes an agenda whose cost would be equivalent to just 1% of annual consumption, but would save the world risk equivalent costs that are five times greater.
The reported costs of global warming are higher than in earlier studies because it takes into account the mounting evidence that the process of global warming is highly complex and non-linear, with a non-negligible chance that it may proceed much faster than had previously been thought and that the extent of warming may be much greater than had previously been thought.
Indeed, the study may actually significantly underestimate the costs: for instance, climate change may lead to more weather variability, a possible disappearance or major shift of the Gulf Stream – of particular concern to Europe – and a flourishing of disease.
When I served in 1995 on the Intergovernmental Panel on Climate Change, the scientific group that periodically assesses the science of global warming, there was overwhelming evidence that the concentration of greenhouse gases in the atmosphere had increased markedly since the beginning of the industrial revolution, that human activity had contributed significantly to those increases, and that they would have profound effects on climate and sea levels.
But few saw, for instance, the Artic ice cap melting as rapidly as now seems to be the case.
Still, some suggest that because we are not certain about how bad global warming will be, we should do little or nothing.
To me, uncertainty should make us act more resolutely today, not less.
As one scientist friend puts it: if you are driving on a mountain road, approaching a cliff, in a car whose brakes may fail, and a fog bank rolls in, should you drive more or less cautiously?
Global warming is one of those rare instances where the scientific community is more fearful of what may be happening than the population at large.
Scientists have glimpsed what the future may portend.
As the Stern report points out, as usual, the poor are the most vulnerable.
A third of Bangladesh will be underwater by the end of this century.
The Maldives and a host of Pacific Island states will disappear: our twenty-first-century Atlantis.
To an economist, the problem is obvious: polluters are not paying the full costs of the damage they cause.
Pollution is a global externality of enormous proportions.
The advanced countries might mean Bangladesh and the disappearing island states no harm, but no war could be more devastating.
A global externality can best be dealt with by a globally agreed tax rate.
This does not mean an increase in overall taxation, but simply a substitution in each country of a pollution (carbon) tax for some current taxes.
It makes much more sense to tax things that are bad, like pollution, than things that are good, like savings and work.
Although President George W. Bush says he believes in markets, in this case he has called for voluntary action.
But it makes far more sense to use the force of markets – the power of incentives – than to rely on goodwill, especially when it comes to oil companies that regard their sole objective as maximizing profits, regardless of the cost to others.
Exxon has reportedly been funding so-called think tanks to undermine confidence in the science of global warming, just as the tobacco industry funded “research” to question the validity of statistical findings showing the link between smoking and cancer.
Some companies even seem to celebrate the melting of the polar ice cap, because it will reduce the cost of extracting the oil that lies beneath the Arctic Ocean.
The good news is that there are many ways by which improved incentives could reduce emissions – partly by eliminating the myriad of subsidies for inefficient usages.
The US subsidizes corn-based ethanol, and imposes tariffs on sugar-based ethanol; hidden in the tax code are billions of dollars of subsidies to the oil and gas industries.
Most importantly, price signals that show the true social costs of energy derived from fossil fuels will encourage innovation and conservation.
Small changes in practices, when replicated by hundreds of millions of people, can make an enormous difference.
For example, simply changing the color of roofs in warm climates to reflect sunlight or planting trees around houses can lead to great savings on energy used for air conditioning.
We have but one planet, and should treasure it.
Global warming is a risk that we simply cannot afford to ignore anymore.
A Cool Head for the Hottest Issues
LONDON – Reading Barack Obama’s Dreams from My Father, the US president’s beautifully written reflections on his early life and identity, most people are struck by his cool and intellectual approach.
This is not to say that he is unemotional.
Obama can rage and weep.
But he rarely seems to act on the basis of raw sentiment or instinctive prejudice.
Pragmatic and highly intelligent, sooner or later every issue receives the full attention of his forensic curiosity.
Recalling Hillary Clinton’s famous Democratic primary television advertisement, Obama, it turns out, is exactly the sort of president that most of us would want to have in the post for that 3 a.m. phone call about an international crisis.
He would not be afraid to act, but he would be prepared to think first.
I do not think, therefore, that Obama will be too vexed by some of the criticism he faces at the end of his first year in office, though he will undoubtedly grimace at the defeat of the Democratic candidate in the special election in Massachusetts to fill Ted Kennedy’s old seat.
Obama was praised extravagantly a year ago; 12 months on, the criticism is over the top, too.
Obama inherited a terrible legacy – recession, financial meltdown, Iraq, Afghanistan. He has not solved all of these problems.
But it is difficult to see any really bad mistakes, except perhaps allowing himself to be pushed around by Israeli Prime Minister Netanyahu and giving China the impression that he was prepared for a bilateral relationship entirely on China’s terms.
That seems to be changing now.
Obama may have come to understand that when you are the leader of the world’s only superpower, you need to be feared just a little if you are to be respected.
The left in America criticizes Obama for not turning the economy around already.
The right angrily denounces him as a crypto-communist because he wants every American to have health care.
With a dispassionate eye on the long game, what will the president himself be thinking?
One issue that Obama is certain to have in his sights is a problem that shadowed the world for years.
When I was growing up in the 1950’s and 1960’s, world peace was based on the nuclear standoff between the US and the Soviet Union.
The main strategic assessment on both sides of the Berlin Wall was that if either side made a wrong move, all of us might end up consumed in the flames of a nuclear holocaust.
This was called, in the geostrategic jargon of the day, “mutually assured destruction,” or MAD. The acronym was entirely appropriate.
We have forgotten those days.
Yet there are still 23,000 nuclear warheads on our planet, with the explosive power of 150,000 Hiroshima bombs.
Terrorist groups would undoubtedly like to get their hands on one.
In all, there are eight nuclear-weapon states – the US, Russia, Britain, France, China, Israel, India, and Pakistan.
North Korea may also have a few bombs. Iran is believed by many to be trying to develop one.
Other states, which have their own civil nuclear capacity, have the potential to develop a weapon. The number of countries in this category is bound to increase as the number of nuclear power reactors doubles over the next 20 years.
The Nuclear Non-Proliferation Treaty (NPT) has contained the number of nuclear states.
A conference is to be held in May to renew and review it.
Obama clearly recognizes that the NPT needs to be strengthened in order to prevent countries from turning their civil nuclear-power capacity into weapons.
But Obama also knows that if the existing nuclear states want others to accept tougher restrictions, they will have to cut back their nuclear arsenals.
This is principally an issue for the US and Russia, which possess 95% of the world’s nuclear weapons.
In addition, it would help if the US could take a strong lead by ratifying the Comprehensive Nuclear-Test-Ban Treaty.
The nuclear issue is one of the biggest items on the Obama agenda. How it is handled will help to define his presidency.
Even before the talking gets serious in May, there will be the question of Iran to sort out.
Iran says that it seeks no more than its own ability to produce nuclear power.
Disbelief grows with every revelation of secret Iranian facilities and plans, and with every refusal by Iran to negotiate safeguards that would allow for civil use while preventing weaponization.
The US, the European Union, and Russia have tried to engage Iran on this issue, so far without success.
China seems likely to block effective sanctions on Iran because of its close energy relationship with the country.
How China eventually handles this will profoundly affect its standing in the US and Europe.
These are going to be some of the major questions for Obama over the next year and more.
If he gets them right, he can forget about his short-term critics.
Fortunately, he is smart enough to know this.
A Crisis in Full Flight
MUNICH – For a while, it looked as if the European Central Bank’s €1 trillion credit program to pump liquidity into Europe’s banking system had calmed global financial markets.
But now interest rates for Italian and Spanish government bonds are on the rise again, closing in on about 6%.
Of course, this may not be the breaking point beyond which the debt burden becomes unsustainable.
After all, interest rates in Southern Europe were well above 10% in the decade before the euro was introduced.
Even Germany at that time had to pay bondholders more than 6%.
Nevertheless, the markets are clearly signaling growing doubt about whether Spain and Italy will be willing to bear their debt burden.
The main problem is Spain, where private and public-sector foreign debt is larger than that of Greece, Portugal, Ireland, and Italy combined, and, as in Greece, is in the neighborhood of 100% of GDP (93% to be precise).
A quarter of the labor force and half of Spain’s youth are unemployed, reflecting the country’s loss of competitiveness in the wake of the real-estate bubble inflated by cheap euro credit in the pre-crisis period.
The current-account deficit remains at 3.5% of GDP, despite the recession-induced decline in imports, while economic contraction will cause Spain to miss its budget-deficit target again.
Moreover, Spain’s debt with the ECB’s TARGET settlement system rose by €55 billion ($72 billion) between February and March, because capital outflows of that amount had to be compensated.
Since July 2011, Spain’s TARGET debt has grown by €199 billion.
Capital is in full flight, more than offsetting the inflows from 2008-2010.
The cumulative total since the beginning of the first crisis year (2008) means that Spain has financed its entire current-account deficit via the printing press.
The picture is little better in Italy, where the current-account balance has swung from a surplus of around 2% of GDP to a 3%-of-GDP deficit over the last ten years.
The country’s TARGET debt grew by €76 billion from February to March, with the total since July 2011 reaching €276 billion.
Italy, too, is being drained of capital; in fact, the flight of investors accelerated after the ECB’s liquidity injection.
It is now clear that the ECB itself has caused a large part of the capital flight from countries like Spain and Italy, because the cheap credit that it offered drove away private capital.
The purpose of the ECB’s measures was to re-establish confidence and bring about a recovery of the inter-bank market.
In this, too, it has not really been successful, despite the huge amount of money that it put on the table.
Indeed, now the French are looking wobbly.
As capital fled the country between July 2011 and January 2012, France’s TARGET debt increased by €95 billion.
France, too, has become uncompetitive, owing to the cheap credit brought by the euro in its initial years.
According to a recent study by Goldman Sachs, the country’s price level must drop by an estimated 20% vis-à-vis the euro average – that is, depreciate in real terms – if the economy is to regain competitiveness within the eurozone.
Italy will have to depreciate by 10-15%, and Spain by roughly 20%.
While Greece and Portugal face the need for deflation totaling 30% and 35%, respectively, the figures for Spain and Italy are high enough to justify fears about the future development of the eurozone.
These imbalances can be redressed only with great effort, if at all, and only if one accepts a decade of stagnation.
For Greece and Portugal, staying in the eurozone will be a tight squeeze.
There are many who would solve the problem by routing more and more cheap credit through public channels – bailout funds, eurobonds, or the ECB – from the eurozone’s healthy core to the troubled South.
But this would unfairly force savers and taxpayers in the core countries to provide capital to the South on terms to which they would never voluntarily agree.
Already German, Dutch, and Finish savings amounting to €15,000, €17,000, and €21,000, respectively, per working person have been converted from marketable investments into mere equalization claims against the ECB.
No one knows what these claims will be worth in the event of a eurozone breakup.
Above all, however, the permanent public provision of cheap credit would ultimately lead to a lingering infirmity, if not to Europe’s economic collapse, because the eurozone would become a central management system with state control over investment.
Such systems cannot work, because they eliminate the capital market as the economic system’s main steering mechanism.
One cannot help but wonder how thoughtlessly Europe’s politicians have started down this slippery slope.
A Crisis in Two Narratives
CHICAGO – With the world’s industrial democracies in crisis, two competing narratives of its sources – and appropriate remedies – are emerging.
The first, better-known diagnosis is that demand has collapsed because of high debt accumulated prior to the crisis.
Households (and countries) that were most prone to spend cannot borrow any more.
To revive growth, others must be encouraged to spend – governments that can still borrow should run larger deficits, and rock-bottom interest rates should discourage thrifty households from saving.
Under these circumstances, budgetary recklessness is a virtue, at least in the short term.
In the medium term, once growth revives, debt can be paid down and the financial sector curbed so that it does not inflict another crisis on the world.
This narrative – the standard Keynesian line, modified for a debt crisis – is the one to which most government officials, central bankers, and Wall Street economists have subscribed, and needs little elaboration.
Its virtue is that it gives policymakers something clear to do, with promised returns that match the political cycle.
Unfortunately, despite past stimulus, growth is still tepid, and it is increasingly difficult to find sensible new spending that can pay off in the short run.
Attention is therefore shifting to the second narrative, which suggests that the advanced economies’ fundamental capacity to grow by making useful things has been declining for decades, a trend that was masked by debt-fueled spending.
More such spending will not return these countries to a sustainable growth path.
Instead, they must improve the environment for growth.
The second narrative starts with the 1950’s and 1960’s, an era of rapid growth in the West and Japan.
Several factors, including post-war reconstruction, the resurgence of trade after the protectionist 1930’s, the introduction of new technologies in power, transport, and communications across countries, and expansion of educational attainment, underpinned the long boom.
But, as Tyler Cowen has argued in his book The Great Stagnation, once these “low-hanging fruit” were plucked, it became much harder to propel growth from the 1970’s onward.
Meanwhile, as Wolfgang Streeck writes persuasively in New Left Review, democratic governments, facing what seemed, in the 1960’s, like an endless vista of innovation and growth, were quick to expand the welfare state.
But, when growth faltered, this meant that government spending expanded, even as its resources shrank.
For a while, central banks accommodated that spending.
The resulting high inflation created widespread discontent, especially because little growth resulted.
Faith in Keynesian stimulus diminished, though high inflation did reduce public-debt levels.
Central banks then began to focus on low and stable inflation as their primary objective, and became more independent from their political masters.
But deficit spending by governments continued apace, and public debt as a share of GDP in industrial countries climbed steadily from the late 1970’s, this time without inflation to reduce its real value.
Recognizing the need to find new sources of growth, towards the end of Jimmy Carter’s presidency, and then under Ronald Reagan, the United States deregulated industry and the financial sector, as did Margaret Thatcher in the United Kingdom.
Productivity growth increased substantially in these countries over time, which persuaded Continental Europe to adopt reforms of its own, often pushed by the European Commission.
Yet even this growth was not enough, given previous governments’ generous promises of health care and pensions – promises made even less tenable by rising life expectancy and falling birth rates.
Public debt continued to grow.
And the incomes of the moderately educated middle class failed to benefit from deregulation-led growth (though it improved their lot as consumers).
The most recent phase of the advanced economies’ frenzied search for growth took different forms.
In some countries, most notably the US, a private-sector credit boom created jobs in low-skilled industries like construction, and precipitated a consumption boom as people borrowed against overvalued houses.
In other countries, like Greece, as well as under regional administrations in Italy and Spain, a government-led hiring spree created secure jobs for the moderately educated.
In this “fundamental” narrative, the advanced countries’ pre-crisis GDP was unsustainable, bolstered by borrowing and unproductive make-work jobs.
More borrowed growth – the Keynesian formula – may create the illusion of normalcy, and may be useful in the immediate aftermath of a deep crisis to calm a panic, but it is no solution to a fundamental growth problem.
If this diagnosis is correct, advanced countries need to focus on reviving innovation and productivity growth over the medium term, and on realigning welfare promises with revenue capacity, while alleviating the pain of the truly destitute in the short run.
For example, Southern Europe’s growth potential may consist in deregulating service sectors and reducing employment protection to spur creation of more private-sector jobs for retrenched government workers and unemployed youth.
In the US, the imperative is to improve the match between potential jobs and worker skills.
People understand better than the government what they need and are acting accordingly.
Many women, for example, are leaving low-paying jobs to acquire skills that will open doors to higher-paying positions.
Too little government attention has been focused on such issues, partly because payoffs occur beyond electoral horizons, and partly because the effectiveness of government programs has been mixed.
Tax reform, however, can provide spur retraining and maintain incentives to work, even while fixing gaping fiscal holes.
Three powerful forces, one hopes, will help to create more productive jobs in the future: better use of information and communications technology (and new ways to make it pay), lower-cost energy as alternative sources are harnessed, and sharply rising demand in emerging markets for higher-value-added goods.
The advanced countries have a choice.
They can act as if all is well, except that their consumers are in a funk, and that “animal spirits” must be revived through stimulus.
Or they can treat the crisis as a wake-up call to fix what debt has papered over in the last few decades.
For better or worse, the narrative that persuades these countries’ governments and publics will determine their future – and that of the global economy.
Financing the Next Development Agenda
WASHINGTON, DC – As the 2015 target date for the Millennium Development Goals approaches, the United Nations is intensifying its efforts to foster debate about what comes next for promotion of development worldwide.
The outcome of these discussions will shape policies and investment aimed at spurring GDP growth, strengthening human capital, and promoting more inclusive prosperity.
With the global population expected to reach nine billion people by 2050 – a significant proportion of whom will reside in developing or underdeveloped countries – the international community must improve access to education, health care, and employment opportunities worldwide.
Meanwhile, the prospect of a rise in global temperature of more than 2°C (3.6°F) over pre-industrial levels by the end of this century (which would trigger global warming’s most damaging effects) calls for higher investment in sustainable urbanization, climate-smart agriculture, and social safety nets.
Both factors challenge us to define, in the longer term, more sustainable patterns of production and consumption.
Governments, civil society, and the private sector must rise to the challenge, cooperating to find and implement creative solutions.
But, first, they must anticipate the associated financing requirements, which will soon surpass the current capacities of governments and international donors, and take action now to activate new, reliable sources of financing.
To start, governments should design targeted, evidence-based policies and support the development of sound institutions.
This would make government services more effective, while helping to catalyze additional development aid from traditional donors and mobilize private-sector resources.
In many countries, there is considerable scope for domestic resource mobilization.
Broadening the tax base, improving tax administration, and closing gaps in the value-added tax could make a significant difference in lower-income countries, where tax revenues account for only about 10-14% of GDP, compared to 20-30% of GDP in high-income countries.
More equitable taxation would have a positive impact on governance, another important tool for mobilizing domestic resources.
With improved corporate and public governance and clear transfer-pricing policies, resource-rich countries could shore up their capacity to negotiate fair contracts with extractive industries, balance revenues and expenditures over time, and manage their natural endowments more transparently.
Progress in these areas would help governments to channel their spending more effectively toward those who would benefit the most.
For example, only 8% of the $409 billion spent on fossil-fuel subsidies in 2010 reached the poorest 20% of the population.
A targeted support program could increase substantially the efficiency of spending, freeing up resources for education, health, and poverty eradication.
Furthermore, promoting financial deepening and inclusiveness could accelerate private-sector growth, creating more opportunities.
Indeed, broader access to financial services would help the estimated 400 million micro, small, and medium-size enterprises in developing countries to prosper, while enabling the 2.5 billion people worldwide who currently lack access to such services to build their assets.
A deeper and more efficient financial sector would also reduce transaction costs and facilitate risk management.
Local-currency bond markets could help to develop domestic investor bases and mobilize domestic savings to support long-term investments.
At the same time, the international community should work to improve the availability and effectiveness of official development assistance.
The ODA target of 0.7% of GDP – agreed in 2002 at the International Conference on Financing for Development in Monterrey, Mexico – should motivate countries to increase their contributions.
They can also take steps to make ODA more predictable from year to year.
Donors should structure aid to ensure that it supports sound national development policies and programs, rather than their own narrow interests.
This is particularly relevant as emerging development partners, especially the BRICS (Brazil, Russia, India, China, and South Africa), offer new kinds of aid packages that incorporate investment and non-financial assistance.
Private charities, which have been instrumental in promoting innovation in fields such as health care, the environment, and education, could provide valuable insight into channeling aid more effectively.
More generally, improving coordination among donors would help to maximize the impact of aid on the ground.
While ODA remains an important source of financing for fragile and very-low-income countries, it represents only 7% of net financial flows to developing countries, where foreign direct investment, remittances, long-term debt, and portfolio investment have a larger impact.
Donors should leverage aid to “grow the pie” and to diversify financing sources for the world’s poorest countries by providing risk guarantees, innovative investment vehicles, debt syndication, and co-financing arrangements.
Attracting even a fraction of the assets held by institutional investors, sovereign-wealth funds, and public pension funds could boost development finance substantially.
Diaspora populations are another major potential source of development financing.
Reducing transfer costs, which average an estimated 9% of the value of transactions, would put more money into the hands of those who need it most.
Tailoring financial products for diaspora communities could attract resources for investment, while reinforcing migrants’ ties – economic and otherwise – to their home countries.
Finally, the international community bears a special responsibility for delivering global public goods.
The responsibility to preserve the environment, stem the spread of communicable diseases, strengthen the international financial architecture, enhance developing-country participation in the global trading system, and facilitate the exchange of knowledge lies at the intersection of national development priorities and global interests.
Duty-free, quota-free access to OECD markets, complemented by simpler, more transparent rules of origin, would raise GDP by 1% in the least-developed countries, lifting millions out of poverty.
Investment in statistical capacity would help governments and businesses worldwide to make better policy decisions, based on a more accurate accounting of the associated costs and benefits.
The challenge of the post-2015 development agenda lies in finding creative solutions to support prosperity, equality, and sustainability.
Together, governments, civil society, international organizations, and the private sector can improve the availability and quality of finance for development, and shape a better future for all.
A Czech Moment
PRAGUE – As I listened to what some Europeans were saying as my country prepared to take over the presidency of the European Union, I heard dim echoes of Neville Chamberlain’s infamous description of Czechoslovakia as “a faraway country of which we know little.”
I suppose that Donald Rumsfeld’s misguided bid a few years ago to incite a divide between “new and old” Europe contributed to the re-emergence of that disdainful attitude.
The reality is that there is no such thing as “old and new” Europe, and there never was.
The break with communism and reunification of Europe is now almost two decades old.
We Czechs are 100% European, and were even when the Iron Curtain cut us off from democratic Europe.
Indeed, our pro-EU sentiments may be all the stronger because our membership in the Union, like our freedom, is so comparatively new.
So no one in Europe needs to fear that the Czech Republic has some nostalgic or idiosyncratic agenda that it wants to impose on the Union.
On the contrary, events have imposed an agenda on Europe that we cannot escape and for which solidarity – true union – will be needed.
The primary, and most pressing, of the problems we face is the financial and economic crisis that is enveloping the EU.
Unfortunately, conditions across the Union will likely worsen before they begin to improve.
The type of social unrest recently witnessed in Greece may spread, because the downturn is likely to take a disproportionate toll on Europe’s young people, who are seeking jobs at a time when hard-pressed European businesses will be able to offer them very few.
It will fall to the Union, once again, to help transform despair into hope.
We Czechs know something about this, as the wrenching economic transition that we underwent in the 1990’s taught us much about how the right policies can break the grip of hopelessness.
To contain today’s financial and economic crisis, Europe will also need to continue the cooperation that it has shown up to this point.
The very existence of our Union, and particularly of the euro, has already helped to prevent the competitive devaluations and beggar-thy-neighbor policies that ravaged Europe during the 1930’s – the last time the continent faced so brutal an economic downturn.
But we cannot be complacent that the forces of national egoism will remain in check.
For now, EU governments’ coordinated fiscal stimulus has deprived populists of their usual charge that the EU is indifferent to the fate of individuals.
Even more policy coordination will be needed both to confront the crisis and to re-establish EU norms once the storm clouds begin to dissipate.
Although it is right that the Stability and Growth Pact has become more flexible in these extraordinary times, its rules did secure a successful first decade for the euro.
These rules must eventually be restored intact if Europe is to return to the path of sustainable growth, and a consensus will need to be forged now to make that happen.
The second key challenge that we will face during our European presidency is that of Russia.
A new Partnership and Cooperation Agreement (PCA) between the EU and the Russian Federation must be negotiated.
Those negotiations should have begun seriously last year, but the war in Georgia intervened to put them on hold.
Now those talks have resumed, but the background to the negotiations has changed dramatically.
Russia’s economy is now in far worse shape than that of EU members.
The collapse of world oil and gas prices has wounded Russia’s budget, and lack of investment in the country’s energy sector over the years is now causing the declining production that economists have long predicted.
Until now, Russia has cared less about a new PCA than the EU, because two-thirds of Russia’s exports to the Union comprise natural resources, which bring in cash even without the strong rules that a PCA provides.
Given the stark changes in economic conditions, however, it is now in Russia’s national interest to reassure international markets that it is a reliable place to do business, for which a new PCA would serve as an ideal signal.
Moreover, without a new PCA, individual European countries may feel it necessary to seek even more bilateral agreements with Russia.
Indeed, many EU members have been in a race with each other to see who will be Russia’s closest friend in the Union.
But the bilateral deals that have emerged from this race sometimes come at the expense of other Union members, and may unbalance relations within the Union as a whole.  Only a rules-based EU framework can provide a firm foundation for both bilateral and Union-wide relations with Russia.
Europe’s main strength in foreign policy is not its commitment to a rules-based multilateralism, important as that undoubtedly is, but its unity.
When the Georgia crisis erupted, Europe united around a single position on Russia’s withdrawal.
It is the Czech Republic’s task, and that of the Swedish EU presidency that will follow our own, to maintain this unity as the PCA negotiations move forward.
During the 1990’s, the US and Europe erred in treating Russia with benign neglect.  It would be a mistake for Russia to respond in kind today by seeking to prolong the PCA negotiations in the hope that a possibly more amenable EU president may one day offer softer terms.
We, like all EU presidencies, will be representing the wider Union interests when we negotiate.
In Praise of Fragmentation
LONDON – Emerging markets are back in the spotlight.
Investors and banks are suddenly unwilling to finance current-account deficits with short-term debt.
South Africa, for example, has had to increase interest rates, despite slow economic growth, to attract the funding it needs.
Turkey’s rate increase has been dramatic.
For these and other emerging countries, 2014 may prove to be a turbulent year.
If volatility becomes extreme, some countries may consider imposing constraints on capital outflows, which the International Monetary Fund now agrees might be useful in specific circumstances.
But the fundamental question is how to manage the impact of short-term capital inflows.
Until recently, economic orthodoxy considered that question invalid.
Financial liberalization was lauded because it enabled capital to flow to where it would be used most productively, increasing national and global growth.
But empirical support for the benefits of capital-account liberalization is weak.
The most successful development stories in economic history – Japan and South Korea – featured significant domestic financial repression and capital controls, which accompanied several decades of rapid growth.
Likewise, most cross-country studies have found no evidence that capital-account liberalization is good for growth.
As the economist Jagdish Bhagwati pointed out 16 years ago in his article “The Capital Myth,” there are fundamental differences between trade in widgets and trade in dollars.
The case for liberalizing trade in goods and services is strong; the case for complete capital-account liberalization is not.
One reason is that many modern financial flows do not play the useful role in capital allocation that economic theory assumes.
Before World War I, capital flowed in one direction: from rich countries with excess savings, such as the United Kingdom, to countries like Australia or Argentina, whose investment needs exceeded domestic savings.
But in today’s world, net capital flows are often from relatively poor countries to rich countries.
Huge two-way gross capital flows are driven by transient changes in perception, with carry-trade opportunities (borrowing in low-yielding currencies to finance lending in high-yielding ones) replacing long-term capital investment.
Moreover, capital inflows frequently finance consumption or unsustainable real-estate booms.
And yet, despite the growing evidence to the contrary, the assumption that all capital flows are beneficial has proved remarkably resilient.
That reflects the power not only of vested interests but also of established ideas.
Empirical falsification of a prevailing orthodoxy is disturbing.
Even economists who find no evidence that capital-account liberalization boosts growth often feel obliged to stress that “further analysis” might at last reveal the benefits that free-market theory suggests must exist.
It is time to stop looking for these non-existent benefits, and to distinguish among different categories of capital flows.
Some are valuable, but some are potentially harmful.
Foreign direct investment (FDI), for example, can aid growth, because it is long term, involves investment in the real economy, and is often accompanied by technology or skill transfers.
Equity portfolio investment may involve price volatility as ownership positions change, but at least it implies a permanent commitment of capital to a business enterprise.
Long-term debt finance of real capital investment can play a useful role as well.
By contrast, short-term capital flows, particularly if provided by banks that are themselves relying on short-term funding, can create instability risks, while bringing few benefits.
What is less clear is the best policy response.
Capital controls are invariably porous, and we cannot gain the benefits of free trade and FDI without creating some opportunities for short-term investor positioning.
China has not liberalized its capital account, but short-term inflows are now driving stronger upward pressure on the renminbi (and larger offsetting reserve accumulation by the People’s Bank of China) than can be explained by the current-account surplus and FDI flows.
A case can thus be made for capital-account liberalization that is based on the impossibility of effective control, not on any supposed benefits.
But while perfect policy is unattainable, partly effective controls can still play a useful role if targeted at the interface between short-term inflows and domestic credit cycles.
After all, capital inflows cause the greatest harm when they drive rapid increases in credit-financed consumption or real-estate speculation.
The required policy response should integrate domestic financial regulation with capital-account management.
Tax instruments and reserve requirements that put sand in the wheels of short-term capital inflows should be combined with strong countercyclical measures, such as additional capital requirements, to slow domestic credit creation.
The effectiveness of such measures can be undermined if global banks operate in emerging countries in branch form, providing domestic credit financed by global funding pools.
But this danger can be countered by requiring banks to operate as legally incorporated subsidiaries, with locally regulated capital and liquidity reserves, and strong regulatory limits on the maturity of their funding.
Such requirements would not prevent useful capital flows: global banking groups could invest equity in emerging markets and fund their subsidiaries’ balance sheets with long-term debt.
In banking, as in other sectors, investment that combines long-term commitment with skill transfer can be highly beneficial, which implies that foreign banks should be free to compete on the same basis as domestic banks.
Neither mandatory subsidiarization nor tax- or regulation-based capital controls will solve all of the problems.
But, taken together, they can stem the volatility implied by short-term flows and help to smooth out domestic credit cycles.
Much of the financial industry resists such measures, as do the many economists who remain wedded to the old orthodoxy.
Renewed capital controls, they claim, would “fragment” the global financial market, undermining its ability to allocate capital efficiently.
In the past, policymakers have been at pains to stress that no such fragmentation will be allowed.
But we need to be blunt: Free flows of short-term debt can result in capital misallocation and harmful instability.
When it comes to global capital markets, fragmentation can be a good thing.
The High-Tech, High-Touch Economy
LONDON – A recent report revealed that the five richest families in Britain are worth more than the country’s poorest 20% combined.
Some of the wealth comes from new business ventures; but two of the five are a duke and an earl whose ancestors owned the fields across which London expanded in the nineteenth century.
Urban land wealth is not just a London phenomenon.
As Thomas Piketty’s recent book Capital in the Twenty-First Century shows, accumulated wealth has grown rapidly relative to income across the advanced economies over the last 40 years.
In many countries, the majority of that wealth – and the lion’s share of the increase – is accounted for by housing and commercial real estate, and most of that wealth resides not in the value of the buildings, but in the value of the urban land on which it sits.
That might seem odd.
Though we live in the hi-tech virtual world of the Internet, the value of the most physical thing – land – is rising relentlessly.
But there is no contradiction: The price of land is rising because of rapid technological progress.
In an age of information and communication technology (ICT), it is inevitable that we value what an ICT-intensive economy cannot create.
ICT has already delivered remarkable new products and services; but, as MIT’s Erik Brynjolfsson and Andrew McAfee argue persuasively in their recent book The Second Machine Age, the really dramatic changes are yet to come, with robots and software bound to automate out of existence a huge number of jobs.
One consequence is the striking phenomenon of huge wealth creation with very little labor input.
Facebook has an equity valuation of $170 billion but employs only around 6,000 people.
The investment that went into building the software that runs it entailed no more than around 5,000 software engineer man-years.
This remarkable technology has helped to deliver increasing average incomes and will continue to do so.
But the distribution of that bounty has been very unequal.
The lion’s share of the growth has gone to the top half, the top 10%, or even the top 1% of the population.
As the better off become richer, however, much of their rising income will not be spent on ICT-intensive goods and services.
There is a limit to how many iPads and smart phones one can need, and their price continues to plummet.
Instead, an increasing share of consumer expenditure is devoted to buying goods and services that are rich in fashion, design, and subjective brand values, and to competing for ownership of location-specific real estate.
But if the land on which the desired houses and apartments sit is in limited supply, the inevitable consequence is rising prices.
Urban land is therefore rising in value – in London, New York, Shanghai, and many other cities – partly because of consumer demand.
But its rising value also makes it an attractive asset class for investors, because further price increases are expected.
Moreover, returns on real estate have been swollen by the dramatic fall in interest rates over the last 25 years, a decline that was far advanced even before the 2008 financial crisis.
The cause of those low interest rates is debated; but one probable factor is the reduced cost of business investment in hardware and software-based “machines.”
If you can build a $170 billion company with just 5,000 software engineer man-years, you don’t need to borrow much money.
The fact that technology is so powerful not only makes physical land more valuable; it also means that future employment growth will be concentrated among the jobs that cannot be automated, particularly in services, which have to be delivered physically.
The US Bureau of Labor Statistics estimates that among the most rapidly growing occupational categories over the next ten years will be “healthcare support occupations” (nursing aides, orderlies, and attendants) and “food preparation and serving workers” – that is, overwhelmingly low-wage jobs.
In short, ICT creates an economy that is both “hi-tech” and “hi-touch” – a world of robots and apps, but also of fashion, design, land, and face-to-face services.
This economy is the result of our remarkable ability to solve the problem of production and automate away the need for continual labor.
But it is an economy that is likely to suffer two adverse side effects.
First, it may be inherently unstable, because the more that wealth resides in real estate, the more the financial system will provide leverage to support real-estate speculation, which has been at the heart of all of the world’s worst financial crises.
Major changes in financial and monetary policy, going far beyond those introduced in response to the 2008 crisis, are required to contain this danger.
Second, unless we deliberately design policies that encourage and sustain inclusive growth, a highly unequal society is virtually inevitable, with rising land values and wealth magnifying the effects of the unequal income distribution that ICT produces directly.
Indeed, the modern economy may resemble that of the eighteenth century, when the land owned by the Duke of Westminster and the Earl of Cadogan was still just fields to the west of London, more than the middle-class societies in which most developed countries’ citizens’ grew up.
The Trade Delusion
LONDON – Since 2008, global trade has grown slightly more slowly than global GDP.
The Doha Round of World Trade Organization negotiations ended in failure.
Transatlantic and transpacific trade negotiations are progressing slowly, held back by the resistance of special interests.
But, though many experts fear that protectionism is undermining globalization, threatening to impede global economic growth, slower growth in global trade may be inevitable, and trade liberalization is decreasingly important.
To be sure, for 65 years, rapid trade growth has played a vital role in economic development, with average advanced-economy industrial tariffs plummeting from more than 30% to below 5%.
The creation of Europe’s single market facilitated increased intra-European trade.
Japan, South Korea, and Taiwan achieved rapid economic catch-up on the basis of export-led growth.
China has followed the same path over the last 30 years.
Trade grew about twice as fast as global output from 1990 to 2008.
But there is no reason why trade should grow faster than GDP forever.
Indeed, even if there were no trade barriers at all, trade might grow significantly more slowly than GDP in some periods.
Several factors make it possible that we are entering such a period.
For starters, there is the changing pattern of consumption in the advanced economies.
Richer people spend an increasing share of their income on services that are either impossible to trade (for example, restaurant meals) or difficult to trade (such as health services).
Non-tradable sectors tend to account for a growing share of employment and economic activity.
For several decades, that tendency has been offset by ever more intensive trading of tradable goods, often passing through many countries in complex supply chains.
In the future, however, the shift to non-tradable consumption may dominate.
Indeed, trade intensity may decline even for manufactured goods.
Trade is partly driven by differences in labor costs.
China’s dramatic manufacturing growth reflected low wages up to now.
But as real wages in China and other emerging economies grow, incentives for trade will decline.
The more that global incomes converge, the less trade there may be.
In addition, as the economists Erik Brynjolfsson and Andrew McAfee of MIT have argued in their book The Second Machine Age, rapid advances in information technology may enable increasingly extensive automation.
Some manufacturing activities, though few jobs, may well return to developed countries, as the advantages of proximity to customers and lower transport costs outweigh decreasingly important differences in labor costs.
Global trade as a share of GDP may therefore decline, but without adverse consequences for global economic growth.
Rising productivity does not require relentlessly increasing trade intensity.
Earth, after all, does not trade with other planets, yet its economy still grows.
Optimal trade intensity depends on many factors – such as relative labor costs, transport costs, productivity levels, and economy-of-scale effects.
Trends in these factors might make reduced trade intensity not only inevitable but desirable.
Even if that is true, international trade will still play a vital role, and preventing any reversal of past trade liberalization is essential.
But further trade liberalization is bound to be of declining importance to economic growth.
With industrial tariffs already dramatically reduced most potential benefits of trade liberalization have already been grasped.
Estimates of the benefits of further trade liberalization are often surprisingly low – no more than a few percentage points of global GDP.
That is small compared to the cost of the 2008 financial crisis, which has left output in several advanced economies 10-15% below pre-crisis trend levels.
It is small, too, compared to the difference in economic performance between successful catch-up countries – such as China – and other countries that have enjoyed the same access to global markets but have performed less well for other reasons.
The main reason for slow progress in trade negotiations is not increasing protectionism; it is the fact that further liberalization entails complex trade-offs no longer offset by very large potential benefits.
The Doha Round’s failure has been decried as a setback for developing countries. And some liberalization – say, of advanced economies’ cotton imports – would undoubtedly benefit some low-income economies.
But full trade liberalization would have a complex impact on the least developed economies, some of which would benefit only if compensated for the loss of the preferential access to advanced-economy markets that they currently enjoy.
This implies that further progress in trade liberalization will be slow.
But slow progress is a far less important challenge to growth prospects than the debt overhang in developed economies, or infrastructure and educational deficiencies in many developing economies.
That reality often goes unacknowledged.
The importance of past trade liberalization has left the global policy establishment with a bias toward assuming that further liberalization would bring similar benefits.
But while the potential global benefits of trade liberalization have declined, reduced trade intensity might still impede economic development in some countries.
Only a handful of economies over the last 60 years have fully caught up to advanced-economy living standards, and all relied on export-led growth to drive productivity and job creation in manufacturing.
Relying solely on that model will be more difficult in the future.
China is so big that it must develop domestic drivers of growth at an earlier stage of development than did Japan, Taiwan, or South Korea; as a result, its exports will inevitably decline (relative to GDP).
Meanwhile, for some low-income countries, increased manufacturing and service-sector automation of the sort described by Brynjolfsson and McAfee, whether within advanced economies or within China’s established industrial clusters, will make the path to middle- and high-income status more difficult to achieve.
That poses important challenges for development policy, which further trade liberalization can alleviate only marginally.
Rethinking the Monetization Taboo
LONDON – Now that the pace of the US Federal Reserve’s “tapering” of its asset-purchase program has been debated to death, attention will increasingly turn to prospects for interest-rate increases.
But another question looms: How will central banks achieve a final “exit” from unconventional monetary policy and return balance sheets swollen by unconventional monetary policy to “normal” levels?
To many, a larger issue needs to be addressed.
The Fed’s tapering merely slows the growth of its balance sheet.
The authorities would still have to sell $3 trillion of bonds to return to the pre-crisis status quo.
The rarely admitted truth, however, is that there is no need for central banks’ balance sheets to shrink.
They could stay permanently larger; and, for some countries, permanently bigger central-bank balance sheets will help reduce public-debt burdens.
As a recent IMF paper by Carmen Reinhart and Kenneth Rogoff illustrates, advanced economies face debt burdens that cannot be reduced simply through a mix of austerity, forbearance, and growth.
But if a central bank owns the debt of its own government, no net public liability exists.
The government owns the central bank, so the debt is to itself, and the interest expense comes back to the government as the central bank’s profit.
If central bank holdings of government debt were converted into non-interest-bearing perpetual obligations, nothing substantive would change, but it would become obvious that some previously issued public debt did not need to be repaid.
This amounts to “helicopter money” after the fact.
In 2003, then-Fed Chairman Ben Bernanke argued that Japan, facing deflation, should increase public expenditure or cut taxes, funding the operation by printing money rather than issuing bonds.
This, he argued, was bound to increase national income, because the direct stimulative effect would not be offset by concern about future debt burdens.
His advice was not followed; large Japanese deficits were in fact bond-financed.
But the debts held by the Bank of Japan (BoJ) could still be written off.
In Japan’s case, this would reduce government debt by an amount equal to more than 40% of GDP today, and around 60% if implemented after the bond purchases planned for 2014.
Objections focus on two risks: central-bank losses and excessive inflation.
But both of these outcomes can be avoided.
Central banks have bought government bonds with money on which they currently pay zero or very low interest rates.
So, as interest rates rise, central banks might face costs exceeding their income.
But central banks can choose to pay zero interest on a portion of the reserves that commercial banks hold with them, even when they increase the policy interest rate.
And they can require commercial banks to hold zero-interest reserves at the central bank equal to a defined proportion of their loans, thus preventing inflationary growth of private credit and money.
Permanent monetization of government debts is undoubtedly technically possible.
Whether it is desirable depends on the outlook for inflation.
Where inflation is returning to target levels, debt monetization could be unnecessarily and dangerously stimulative.
Central-bank bond sales, while certainly not inevitable, may be appropriate.
But if deflation is the danger, permanent monetization may be the best policy.
I predict that Japan will, in effect, permanently monetize some government debt.
After two decades of low growth and deflation, Japanese gross public debt is now above 240% of GDP (and above 140% of GDP on a net basis); and, with the fiscal deficit at 9.5% of GDP, the debt burden continues to increase.
According to the IMF, to reduce its net public debt to 80% of GDP by 2030, Japan would have to turn today’s 8.6% primary budget deficit (the balance excluding interest payments) into a 6.7% primary surplus by 2020 and maintain such surpluses continuously until 2030.
That will not happen, and any attempt to reach that target would drive Japan into a severe depression.
But the government does not need to repay the ¥140 trillion ($1.4 trillion) of its debt that the BoJ already owns.
The BoJ will continue to increase its balance sheet until it achieves its 2% inflation target.
Thereafter, its balance sheet may stabilize in absolute yen terms and fall slowly as a percentage of GDP, but its absolute size will probably never decrease – a likelihood that should cause no concern.
It is precisely what happened to the Fed’s balance sheet after its wartime and postwar buying of US government bonds came to an end in 1951.
Even as permanent monetization occurs, however, the truth may be obfuscated.
If government bond repayments to the BoJ continued, but were always offset by new BoJ bond purchases, and if the BoJ kept the interest rate on reserves at zero, the net effect would be the same as a debt write-off, but the fiction of “normal” central-bank operations could be maintained.
Central banks can monetize debt while pretending not to.
That pretense may reflect a useful taboo: if we overtly recognize that debt write-off/monetization is possible, politicians might want to do it all the time and in excess, not just in circumstances that make it appropriate.
The historical experience of Weimar Germany, or that of Zimbabwe today, illustrates the danger.
As a result, even when permanent monetization occurs – as it almost certainly will in Japan and possibly elsewhere – it may remain forever the policy that dare not speak its name.
Such reticence may serve a useful purpose.
But it must not blind central banks and governments to the full range of policy tools available to address today’s severe debt overhangs.
The Perils of Financial Freedom
LONDON – Back in 2007, China’s then-prime minister, Wen Jiabao, famously described his country’s economy as “unstable, unbalanced, uncoordinated, and unsustainable.”
Today, the imbalance remains, with the economy too focused on investment and too dependent on credit.
China’s current leadership is committed to building a more balanced model, and believes that the market must play a “decisive role” in achieving that.
But, while stronger market discipline is needed in some areas, Chinese officials should be under no illusion that free markets are a panacea for the financial sector.
Indeed, China’s current economic imbalances partly reflect the dangers created by competition in credit markets.
Even before the 2008 global financial crisis, China’s annual investment/GDP ratio was running at an exceptionally high 40%, and economists were calling for a transition to more consumption-led growth.
But the huge credit stimulus introduced in 2009 drove the economy further in the opposite direction.
The investment ratio rose to 47% by 2012, and construction now accounts for 30% of all output. Total credit has risen from 130% of GDP to 200%, with both bank loans and “shadow bank” credit expanding rapidly.
Both China and the global economy benefited from that stimulus, which helped prop up overall demand in dangerously deflationary times.
But it has led to significant wasted investment in heavy industry, real estate, and urban infrastructure, and leaves China facing the challenge of deleveraging and working out bad debts.
In many areas, improved market discipline does have an important role to play in addressing the structural causes of imbalance.
Wasteful construction investment is encouraged by the under-pricing of rural land.
The lack of a normal ownership relationship between the central government and state-owned enterprises (SOEs) allows the latter to pay minimal dividends and over-invest in business expansion.
Caps on interest rates on bank deposits result in household savers supplying a large subsidy to corporate borrowers.
And SOEs have better access to credit from state-owned banks than private companies do.
But the belief that financial liberalization will provide an easy route to a balanced and stable economy is a delusion, as Japan’s experience in the 1980’s illustrates.
As Joe Studwell argues persuasively in his book How Asia Works, neither Japan nor South Korea based its successful economic development on free markets in credit supply; instead, they relied on the deliberate direction of credit toward industrial development rather than real estate or consumption.
When Japan relaxed constraints on its banking system in the 1980’s, the result was an enormous real-estate boom and subsequent bust, followed by two decades of slow growth and deflation.
China’s per capita income is still only about a quarter of Japan’s in 1990; it would be a tragedy if it suffered a similar setback before completing the path to developed-country living standards.
One striking feature of the Chinese economy, however, is that real estate and urban infrastructure development – high-rise housing, grand transport projects, convention centers, sports stadiums, and museums – already play a far more important role than they did in Japan and South Korea at comparable stages of economic development.
This reflects the interaction of two distinctively Chinese factors and one inherent feature of all banking systems.
The first Chinese factor is the authorities’ focus on “urbanization” as an end in itself, rather than as a byproduct of industrialization.
The second is China’s decentralized approach to economic development, with strong competition between regions and cities often focusing on prestige urban infrastructure projects.
The universal feature in this mix is the fact that banks everywhere can create private credit, money, and purchasing power that did not previously exist, and they have a natural bias, if not constrained by public policy, to allocate it to fund real-estate developments, which drive rising land prices.
These factors will drive construction booms and busts even if obvious market distortions are removed and market discipline is tightened.
The pre-crisis Irish and Spanish banking systems proved just as capable as Chinese state-owned banks at funding excessive real-estate construction.
So, even as China introduces greater market discipline to a largely positive effect, it must plan to constrain credit creation with policy tools that were missing in the advanced economies before the 2008 crisis.
Caps on loan-to-value or loan-to-income ratios on real-estate loans should be used aggressively.
Capital requirements for banks should reflect higher risk weights for real-estate lending than banks’ private assessments of credit risks suggest are appropriate.
The People’s Bank of China should maintain reserve requirements for commercial banks to contain credit creation, rather than reject them as old-fashioned, as occurred in the advanced economies in the decades before 2008.
Credit provision by shadow banks needs to be tightly regulated.
The credit cycle is too important to be left to free markets.
China thus faces a difficult challenge.
It must undergo a transition not to the Western model that produced the 2008 crisis, but to an entirely new model that combines elements of market discipline with strong public-policy constraints.
How smoothly that transition occurs matters for the whole world.
By the early 2020’s, China’s GDP will be $20 trillion.
If the credit/GDP ratio reaches 250% by then, total loans and debt securities would equal $50 trillion, which is more than three times the total of US mortgage debt in 2008.
Today, much of that debt represents claims within the state sector – owed, for instance, by SOEs to state-owned banks.
But, as the private sector develops, SOEs are subjected to hard budget constraints, and the external capital account is opened, this huge credit mountain will create increasing global financial vulnerability.
One hopes that the Chinese authorities understand the dangers as well as the benefits of free financial markets better than advanced-economy policymakers did ahead of the 2008 crisis.
If not, another crisis – far more severe than the last – may become inevitable.
The Great Credit Mistake
LONDON – Before the financial crisis erupted in 2008, private credit in most developed economies grew faster than GDP.
Then credit growth collapsed.
Whether that fall reflected low demand for credit or constrained supply may seem like a technical issue.
But the answer holds important implications for policymaking and prospects for economic growth.
And the official answer is probably wrong.
The prevailing view has usually stressed supply constraints and the policies needed to fix them.
An impaired banking system, it is argued, starves businesses, particularly small and medium-size enterprises (SMEs), of the funds they need to expand.
In September 2008, US President George W. Bush wanted to “free up banks to resume the flow of credit to American families and businesses.”
The stress tests and recapitalizations of US banks in 2009 were subsequently hailed as crucial to the recovery of both the banking system and the economy.
By contrast, the European Central Bank’s inadequately tough stress tests in 2010 were widely panned for leaving eurozone banks too weak to provide adequate credit.
In the United Kingdom, banks have been criticized for not lending the reserves created by quantitative easing to the real economy, leading the Bank of England to introduce its “funding for lending” scheme in 2012.
In the eurozone, it is hoped that this year’s asset quality review (AQR) and stress tests will finally dispel concerns about bank solvency and free up credit supply.
A “credit crunch” – particularly in trade finance – was certainly a key reason why the financial crisis generated a real economy recession.
Taxpayer-funded bank rescues, higher bank capital requirements, and ultra-easy monetary policy have all been vital to overcome credit supply constraints.
But there is strong evidence that once the immediate crisis was over, lack of demand for credit played a far larger role than restricted supply in impeding economic growth.
That argument is persuasively made by Atif Mian and Amir Sufi in House of Debt, an important new book that analyzes US data on a county-by-county basis.
Mian and Sufi show that the recession was caused by a collapse of household consumption, and that consumption fell most in those counties where pre-crisis borrowing and post-crisis real-estate prices left households facing the largest relative losses in net wealth.
It was in those US counties, too, that local businesses cut employment most aggressively.
For SMEs, a shortage of customers, not a shortage of credit, constrained borrowing, employment, and output.
And the customers were absent because the pre-crisis credit boom had left them over-leveraged.
In the UK, many business surveys from 2009-2012 told the same story.
Poor customer demand was ranked well ahead of credit availability as a constraint on growth.
Economic growth can indeed continue to be severely depressed by a debt overhang even when credit supply is unrestricted and cheap.
Many Japanese companies were left overleveraged by the boom and bust in credit and real estate in the 1980s and early 1990s.
By the late 1990s, the Japanese banking system was offering companies loans at near-zero interest rates.
But, rather than borrow to invest, firms cut investment to pay down debt, driving two decades of stagnation and deflation.
Since 2011, the ECB’s analysis of weak eurozone growth has stressed the negative impact of an impaired and fragmented financial system, with high sovereign-bond yields and funding costs for banks resulting in prohibitive lending terms in the peripheral countries.
Major progress in fixing these problems has already been achieved.
The ECB’s latest Monthly Bulletin documents this, citing multiple indicators of improved credit availability and pricing.
Nonetheless, the rate of decline in private-sector loans has accelerated over the last year – from -0.6% to -2% – and low demand is acknowledged to be the main driver of depressed credit growth.
Simultaneous private deleveraging and fiscal consolidation are restricting eurozone growth far more than remaining restrictions on credit supply.
Despite the ECB’s own evidence, however, the policy focus remains on fixing the credit-supply problem, through the AQR and stress tests, and through the ECB’s own version of a funding for lending scheme, announced on June 5.
That reflects a recurring tendency in official policy debates, particularly in the eurozone, to concentrate on fixable problems to the exclusion of more difficult issues.
Fixing impaired banking systems after a crisis is both essential and achievable.
Moreover, even when public rescue costs are inevitable, they are typically small change compared to the economic harm wrought by the financial crisis and post-crisis recession.
By contrast, a large debt overhang may be intractable unless policy orthodoxies are challenged.
Japan offset private deleveraging in the 1990s by running massive public deficits.
The US has pulled out of recession faster than the eurozone, not only – or even primarily – because it fixed its banking system faster, but because it pursued more stimulative fiscal policies.
But fiscal stimulus is constrained within the eurozone, where member countries no longer issue their own currency and “sovereign” debt therefore carries a default risk.
Aggressive monetary expansion through quantitative easing is also far more complicated and politically contentious in a currency area with no federal debt for the central bank to buy.
To survive and thrive, the eurozone will need to become more centralized, with some common fiscal revenues, expenditures, and debts.
Of course, this scenario implies immensely difficult political choices.
But the starting point for debate must be realism about the nature and severity of the problems facing the eurozone.
If eurozone policy assumes that fixing the banks will fix the economy, the next ten years in Europe could look like the 1990s in Japan.
Inequality by the Click
LONDON – Pope Francis warned in November that “ideologies which defend the absolute autonomy of the marketplace” are driving rapid growth in inequality.
Is he right?
In one sense, Francis was clearly wrong: in many cases, inequality between countries is decreasing.
The average Chinese household, for example, is now catching up with the average American household (though still with a long way to go).
But such examples do not negate the importance of rising inequality within countries.
Both China and the United States are dramatically unequal societies – and are becoming more so.
In the US, the statistics are striking at both ends of the income distribution.
The bottom quarter of US households have received almost no increase in real (inflation-adjusted) income for the last 25 years.
They are no longer sharing the fruits of their country’s growth.
The top 1% of Americans, however, have seen their real incomes almost triple during this period, with their share of national income reaching 20%, a figure not seen since the 1920’s.
In many emerging countries, rapid economic growth has raised living standards to at least some degree for almost everyone, but the share of the rich and ultra-rich is increasing dramatically.
Once these countries approach the average income levels of developed economies, and their growth slows to typical rich-country rates, their future may look like America today.
Globalization explains some of the bottom-quarter income stagnation in the US and other developed economies.
Competition from lower-paid Chinese workers has driven down US wages.
But technological change may be a more fundamental factor – and one with consequences for all countries.
Technological change is the essence of economic growth.
We get richer because we figure out how to maintain or increase output with fewer employees, and because innovation creates new products and services.
Successful new technologies always cause job losses in some sectors, which are offset by new jobs elsewhere.
Tractors destroyed millions of agricultural jobs, for example, but tractor, truck, and car manufacturers created millions of new ones.
But new technologies come in subtly different forms, with inherently different economic consequences.
Today’s new technologies may have far more troubling distributional effects than those of the electromechanical age.
Imagine that 30 years ago, someone had discovered a set of magic words enabling us to speak to any friend anywhere in the world – “abracadabra John” and you were talking to John, wherever he was.
Provided she secured intellectual-property rights, the inventor would have become the richest person in the world; and her lawyers and those who provided her with luxury goods and services would have become pretty rich, too.
But, beyond that, no new jobs would have been created.
Information and communication technology is not costless magic; but it is closer to it than were the innovations of the electromechanical age.
The cost of computing hardware collapses over time in line with Moore’s law of relentlessly increasing processing power.
And once software has been developed, the marginal cost of copying it is effectively zero.
The consumer benefits of this technology are large relative to its price: the cost of each year’s latest computer, tablet, or smartphone is trivial compared to the cost of a new car in 1950.
But the number of jobs created is trivial, too.
In 1979, General Motors employed 850,000 workers.
Today, Microsoft employs only 100,000 people worldwide, Google employs 50,000, and Facebook employs just 5,000.
These are mere drops in the ocean of the global labor market, replacing very few of the jobs that information technology has automated away.
But increased unemployment is not inevitable.
There is no limit to the number of service jobs that we can create in retail, restaurants and catering, hotels, and an enormous variety of personal services.
Walmart, for example, employs two million people, and the US Bureau of Labor Statistics forecasts that more than one million additional jobs will be created in America’s leisure and hospitality sector in the next decade.
But the wages that the market will set for these jobs may result in yet greater inequality.
And there is no reason to believe that politicians’ all-purpose answer to the problem – “increase workforce skills” – will offset this tendency.
However many people learn superior IT skills, Facebook will never need more than a few thousand employees.
And access to high-paid jobs is likely to be determined not by absolute skill level, but by relative skill in a winner-take-all world.
At least, however, IT products and services are very cheap, so even the relatively poor can afford them.
That might make very unequal societies more stable than many fear.
In his recent book Average is Over, the economist Tyler Cowen makes the deliberately provocative argument that while new technology will produce extreme inequality, the relative losers, satiated by computer games and Internet entertainment, and provided with the basics of a minimally acceptable life, will be too docile to revolt.
Cowen may be right; the poor may not rebel.
But extreme inequality should still concern us.
Beyond a certain point, unequal outcomes inevitably fuel greater inequality of opportunity; and extreme inequality of either outcomes or opportunity can undermine the idea that we should all be equal as citizens, if not in material standard of living.
So Pope Francis was right: despite capitalism’s undoubted success as a system for generating economic growth, we cannot rely on market forces alone to generate desirable social outcomes.
All new technologies create opportunities, but free markets will distribute the fruits of some new technologies in dramatically unequal ways.
Offsetting such outcomes will be a greater challenge today than it has been in the past.
Protectionist Shadows over Solar Power
CAMBRIDGE – As July ended, a settlement was reached in the world’s largest anti-dumping dispute, with China agreeing to a minimum price for the solar panels that it exports to the European Union.
The solution is much less severe than what had been the imminent alternative: EU tariffs on Chinese solar panels were set to rise to 47.6%, as a result of the European Commission’s “finding” that China – whose market share now stands at 80% in Europe – had been “dumping.”
Nonetheless, the settlement is a bad outcome for consumers – and for the environment.
The China-EU dispute parallels a similar one between China and the United States.
Last fall, the US introduced tariffs of 24-36% against Chinese solar-panel imports, after the Commerce Department determined that China had been “dumping” – which is generally defined as selling at a price below cost – into the American market.
China, citing its own finding of US dumping of polysilicon – a key input in the production of solar panels – into its market, has already retaliated by imposing import tariffs that could exceed 50%.
The solar-panel disputes may sound narrow and esoteric, but they go to the heart of the long-running debate over globalization.
Anti-globalization activists’ most powerful argument is that even if free trade is good for economic progress overall, it might undermine important public goods such as environmental protection.
Under the well-known “race to the bottom” hypothesis, countries that are open to international trade are thought to adopt weaker environmental regulations than less open countries do.
But trade can also have beneficial environmental effects.
Specialization in each country allows people to obtain more of what they want, which, especially at higher income levels, includes cleaner air and water.
When trade brings down costs, it can benefit environmental goods just as much as it benefits other goods.
So, is trade globalization, on balance, better or worse for the environment?
Some empirical studies of cross-country data find net beneficial effects on indicators of environmental degradation like local sulfur-dioxide air pollution.
Provided that countries have effective governance institutions at the national level, trade and growth give them the means to clean their air.
But the evidence also suggests that trade and growth can exacerbate other forms of environmental degradation, particularly carbon-dioxide emissions, because CO2 is a global externality that cannot be addressed at the national level, owing to the free-rider problem.
The solar-power industry is a perfect example of how trade can benefit air quality.
Skeptics of solar power have long argued that its share in electricity generation cannot rise above a few percentage points without massive subsidies, because it is too costly compared to the alternatives.
Proponents, for their part, counter that temporary moderate subsidies would expand the industry, with economies of scale and learning-by-doing then bringing down costs sharply.
But proponents have focused too much on government subsidies and too little on the contribution of international trade, which in recent years has had a highly positive effect on the development of solar power, as the bonanza of Chinese panels held down costs.
The current embrace of protectionism threatens to reverse this progress.
With the loss of cheap solar panels from China, and with subsidies that helped to drive the European industry now reduced for fiscal reasons, the share of solar power in Europe will fall far short of environmentalists’ goals.
But “findings” of “dumping” into foreign markets surely warrant some response, no?
Actually, no.
For starters, even those who are generally sympathetic to trade and markets often have the impression that anti-dumping laws target “predatory pricing,” a practice in which a large producer sells below cost in order to drive its competitors into bankruptcy, at which point it can raise the price and reap monopoly profits.
But that is not even the way anti-dumping laws are usually written, let alone applied.
Simply put, anti-dumping measures, such as the US and EU tariffs against Chinese solar panels, are a means of reducing, not fostering, competition.
So, if predatory pricing is not the producers’ motive for selling below cost in these cases, what is?
The solar-panel industry worldwide – in China, Europe, and the US – is experiencing a glut of productive capacity.
As a result, global supply and demand are balanced at a market price that is below the long-term average cost per unit, which includes a share of the cost already incurred in building the factories.
But that market price is not below the short-term cost of keeping the factories running once they are built.
In other words, producers sell at prices that are “below cost,” because, having already built the factories, they would lose even more money if they charged above the competitive market price or shut down production altogether.
When the US or EU finds that China is “dumping” solar panels, or when China finds that the US is “dumping” polysilicon, they are using average cost rather than marginal cost.
By this criterion, dumping occurs every time a store has a clearance sale.
Some have compared the negotiated agreements to limit China’s solar-panel exports to past “voluntary export restraints” (VERs) or “orderly marketing arrangements” in the steel and consumer-electronic industries, especially those that Japan agreed to apply to its exports to the US in the 1980’s.
But a more revealing precedent is Japan’s VERs on exports of autos during this period.
American automakers had found it increasingly difficult to compete against smaller, more fuel-efficient Japanese imports.
When free trade was eventually restored, American wallets and air quality benefited (and the US auto industry was forced to become more efficient).
Free trade in automobiles was good for the environment 30 years ago.
The same is true of trade in solar equipment today.
Westerners should thank Chinese panel producers for their contribution to keeping solar power viable, not penalize them through protectionist anti-dumping measures.
The Russian Godfather
WARSAW – Russian President Vladimir Putin is behaving like a Mafia boss.
In invading, occupying, and finally annexing Crimea, he pointed Russia’s guns at Ukraine and said: your territorial sovereignty or your life.
So far, extortion has worked – and Putin knows it.
Indeed, in his speech announcing the annexation of Crimea, Putin spoke his mind: his regime fears no punishment and will do whatever it pleases.
Crimea is just the first step toward realizing his dream of revived Russian greatness.
His address in the Kremlin was a tissue of lies and manipulation, though a subtle analysis would be a waste of time.
The simple fact is that the president of one of the world’s most powerful countries has embarked on a path of confrontation with the entire international community.
His speech smacked of the fevered, paranoid world of Fyodor Dostoyevsky’s Demons, conjuring as it did a delusional alternative universe – a place that does not exist and has never existed.
What does Kosovo, where the Albanians suffered persecution and ethnic cleansing, have in common with the situation in Crimea, whose people have never been oppressed by Ukrainians?
What is the point in displaying open contempt for Ukraine’s government, parliament, and people?
Why label Ukrainian authorities “fascist and anti-Semitic”?
Crimean Tatars pay no heed to the fairy tales about fascists ruling Ukraine; they can still remember the brutal and murderous mass deportations of their parents and grandparents, ordered by Stalin and carried out by the NKVD.
In Putin’s mind, the whole world has discriminated against Russia for the last three centuries.
Russia’s bloody despots – Catherine II, Nicholas I, or Stalin – apparently never discriminated against anyone.
Putin also warns that “you and we – the Russians and the Ukrainians – could lose Crimea completely.”
Yet he fails to specify who – perhaps Poles and Lithuanians again? – are setting their sights on Sevastopol.
Russia could not, according to Putin, leave the people of Crimea “alone in their predicament.”
These words prompt a sad smile; Leonid Brezhnev used precisely the same phrase in August 1968 to justify the Red Army’s intervention in Czechoslovakia to help beleaguered Communist hardliners there crush the Prague Spring reform movement.
“We want Ukraine to be a strong, sovereign, and independent country,” says Putin.
Stalin said the same thing about Poland in 1945.
Brave Russian democrats who have not yet been silenced have already remarked on the similarity between Putin’s appeal to ethnic solidarity in annexing Crimea and Hitler’s stance during the Anschluss and the Sudeten crisis in 1938.
This is the real end of history – the history of dreams about a world governed by democratic values and the market economy.
Unless the democratic world understands that now is not the time for faith in diplomatic compromise, and that it must respond strongly enough to stop Putin’s imperial designs, events could follow a logic that is too dreadful to contemplate.
It takes force to stop a thug, not sharp words or cosmetic sanctions.
I commend and take pride in Poland’s prudent and determined policy and the attitude of its public, which do us great credit.
But we must recognize that the best quarter-century in the last 400 years of Polish history is about to end before our very eyes.
A time of tectonic shifts has begun.
We must appreciate what we have managed to achieve – and learn to protect it.
Mafia bosses often meet an unhappy fate, and I do not think that Putin will fare much better in the end.
Unfortunately, many people are likely to be hurt in the meantime, not least those who now support him.
Living with Climate Change
ROTTERDAM – For anyone still undecided about the consequences of global warming, the summer of 2018, one of the hottest on record, should have tipped the scales.
Across far-flung longitudes and latitudes, regions are struggling with the fallout from large-scale climate-related events.
In the southern United States, cities and towns pummeled by Hurricane Florence in September were still drying out when Hurricane Michael brought more flooding in October.
In California, firefighters are battling the embers of the largest wildfire in state history.
And in parts of Latin America, Europe, Africa, and Asia, agricultural output is in freefall following months of stifling heat.
Cooler weather has done little to ease the suffering.
According to the National Oceanic and Atmospheric Administration, “moderate” to “exceptional” drought conditions cover 25.1% of the United States.
But “extreme” and “exceptional” drought – the worst categories – expanded to cover 6.3% of the country, up from 6% in mid-September.
Regions in Australia also are struggling with the worst drought in a generation.
In fact, for a growing number of people around the world, floods, landslides, and heatwaves – Japan’s summer in a nutshell – is the new normal.
A recent study in the journal PLOS Medicine projects a fivefold increase in heat-related deaths in the US by 2080; the outlook for poorer countries is even worse.
The climate debate is no longer about causes; fossil fuels and human activity are the culprits.
Rather, the question is how billions of at-risk people and businesses can rapidly adapt and ensure their communities are as resilient as possible.
Even if the world meets the Paris climate agreement’s target of limiting the increase in global temperature to 2º Celsius relative to pre-industrial levels, adaptation will still be critical, because climate extremes are now the new normal.
Some communities have already recognized this, and local adaptation is well under way.
In Melbourne, Australia, for example, planners are working to double the city’s tree canopy by 2040, an approach that will lower temperatures and reduce heat-related deaths.
Similarly, in Ahmedabad, a city of over seven million people in Western India, authorities have launched a major initiative to cover roofs in reflective paint to lower temperatures on “heat islands,” urban areas that trap the sun’s warmth and make city living unbearable, even at night.
These are just two of the many infrastructural responses that communities around the world have undertaken.
But adapting to climate change will also mean managing the long-term economic fallout of extreme weather, and this is a requirement that countries are only beginning to take seriously.
Consider water scarcity.
According to a 2016 World Bank analysis, drought-related water crises in Africa and the Middle East could reduce GDP in these regions by as much as 6% by 2050.
That would be painful anywhere, but it would be devastating in regions already rife with political turmoil and humanitarian crises.
At the same time, rising sea levels will cause severe damage to coastal areas.
The decline in property values will have far-reaching implications not only for individual wealth, but also for the tax bases of communities and the industries that serve them.
A related concern is that homes and businesses around the world will eventually become under-insured or even uninsurable, owing to the frequency of weather-related catastrophes.
ClimateWise, a global network of insurance industry organizations, has already warned that the world is facing a $100 billion annual climate risk “protection gap”.
No single international organization or authority has all the answers to the cascade of challenges that climate change has triggered.
But some are taking key leadership roles and pushing governments and local communities to act with more urgency.
One of the more promising initiatives to accelerate solutions, launched just this week, is the Global Commission on Adaptation, chaired by former UN Secretary-General Ban Ki-moon, Microsoft co-founder Bill Gates, and World Bank CEO Kristalina Georgieva.
Over the next 15 years, the world will need to invest some $90 trillion in infrastructure improvements.
How these projects proceed, and whether they are designed with low-carbon features, could lead the world toward a more-climate resilient future – or they could undermine food, water, and security for decades to come.
A Daughter of Dictatorship and Democracy
SEOUL – It is something of a cliché question in South Korea nowadays: Who would be the country’s next president if the election were held tomorrow, rather than in December 2012?
Numerous opinion polls show Park Geun-hye of the ruling Grand National Party (GNP) to be the leading candidate.
If elected, she would be South Korea’s first woman president, and, for her rivals, her dominant position in the race is an uncomfortable but unassailable fact.
South Korean voters of all ages and regions have welcomed Park as a candidate for their country’s leadership.
Her political style is both refreshing and relevant, because she comes across as sincere and forthright at a time when the public is hungry for moral leadership.
And she has an astonishing talent for simplifying complicated issues accurately, which she likely learned – along with how to interpret and manipulate the political connotations of every issue – from her father, former President Park Chung-hee.
Acclaimed as a national hero among radical right-wingers, the iron-fisted Park Chung-hee ruled South Korea from 1963 to 1979, in the wake of the 1961 military coup, only to be assassinated by his intelligence chief.
His daughter is proud of his legacy, which marked the beginning of South Korea’s economic boom.
Indeed, as a pillar of export-oriented modernity, Park Chung-hee was once lionized as the archetype of a modernizing political leadership in military-authoritarian states.
At home, he still ranks first in popularity among the country’s heads of state, kindling nostalgia like a popular old record – a corollary to people’s frustration and anger at the current government of President Lee Myung-bak.
Park, who lost her first bid for the GNP’s nomination to Lee in 2007, needs to ensure that no rupture with her erstwhile rival knocks her off the path to victory in 2012.
An astute politician, Park did not hesitate to campaign wholeheartedly for Lee the last time around – a move that, as part of long-term political strategy, made perfect sense.
To many South Koreans, the election is now Park’s to lose.
No candidate on the horizon seems able to stop her.
If she wins, it will be the result of her seriousness and tenacity, not her political heritage.
No one in South Korea’s conservative movement doubts that Park is one of them.
And, as an icon of the right, she is well aware that she cannot afford to betray her status.
Despite her charisma, Park is neither a Sarah Palin nor an Eva Peron.
Indeed, she looks more like a Korean Margaret Thatcher – a lady not for turning, in Thatcher’s famous phrase, and with clearly thought-through political principles animating her actions.
In any case, she seems destined to establish a new South Korea focusing on her landmark pledge ‘jul pu se,’ literally meaning ‘reduce-loosen-strengthen tax-cuts,’ deregulation, and law and order, not just to add another chapter to her father’s old book.
Her administration would mark a fresh departure from the country’s troubled recent past.
Left-leaning pundits claim that the dictator’s daughter has the same autocratic vision as her father, though Park invariably prefers incremental change to radical measures, and cut her political teeth in the tough-minded politics of the GNP.
Others take a flagrantly sexist stance, arguing that a woman president would be a non-starter as long as the North Korean regime continues to threaten national security.
Although these criticisms don’t seem to bother the electorate very much, Park’s path to victory may yet prove narrower than her supporters expect.
She has been called the “Queen of Elections,” in particular since she won a campaign in 2006 after being slashed with a box cutter by a deranged man.
But she must convincingly outline practical strategies to resolve South Korea’s most serious problems, including high unemployment, worsening educational performance, and North Korea’s nuclear weapons program.
Ms. Park once pledged to provide loans for working-class families from elementary school to college years, while contending that local universities should be empowered to have more autonomy.
She favors engagement policy and the six-party talks so as to resolve the nuclear troubles.
Come presidential election-day in 2012, South Korean voters will pick the candidate who embodies pragmatism and centrism over a partisan or ideologue.
Park’s success will depend, in the end, on the effectiveness of her campaign in further defining her character along those lines.
Unlike former Peruvian dictator Alberto Fujimori’s daughter, who lost her presidential bid in Peru last month, Park is likely to defy her family’s tragic history.
If she does, she will be Asia’s most powerful woman, perhaps the most powerful in the world, at the end of next year.
A Day for Planetary Justice
PRINCETON – What we are doing to our planet, to our children and grandchildren, and to the poor, by our heedless production of greenhouse gases, is one of the great moral wrongs of our age.
On October 24, you can stand up against this injustice.
October 24 is 350 Day.
The name comes from the number of parts per million of carbon dioxide in the atmosphere that, according to Jim Hansen, perhaps the world’s leading climate scientist, we should not exceed if we are to avoid potentially catastrophic climate change.
It is a measure of the seriousness of our problem that CO2 is already at 386 ppm, and is rising by two ppm each year.
The need to cut greenhouse gases has become increasingly clear as predictions of global warming – denounced as “alarmist” when they were first made just a few years ago – have repeatedly turned out to have been too conservative.
We are approaching a point of no return, at which feedback loops will kick in and continue to warm the planet, no matter what we do.
The melting of arctic ice is one example.
Four hundred years ago, explorers sought the legendary “Northeast Passage” across the north of Europe and Russia to China.
They found the arctic ice impenetrable, and soon gave up their quest.
This year, commercial vessels successfully navigated the Northeast Passage.
That is one of many recent dramatic signs that our climate is changing and that our planet is warmer than it has been for a very long time.
But ice-free arctic waters are more than a symptom of global warming. They are themselves a cause of further warming: ice and snow reflect the sun’s rays.
An ice-free surface absorbs more warmth from the sun than one covered in snow or ice.  In other words, our greenhouse gas emissions have, by causing enough warming to melt the arctic ice, created a feedback loop that will generate more warming, and melt more ice, even if we were to stop emitting all greenhouse gases tomorrow.
Other feedback loops pose a similar danger.
In Siberia, vast quantities of methane, an extremely potent greenhouse gas, are locked up in what used to be called “permafrost” – regions in which it was assumed that the ground was permanently frozen.
But areas that used to be frozen are now thawing, releasing methane and thus contributing to further warming – and to further thawing, which releases more methane.
Developing nations are grasping just how outrageous the current distribution of greenhouse-gas emissions really is.
At the United Nations Summit on Climate Change in September, President Paul Kagame of Rwanda pointed out that, while developed nations outside Africa are almost entirely responsible for the problem, its greatest impact will probably be on Africa, which has few resources to cope with the challenge.
Kagame then suggested giving every country an annual per capita quota for CO2 emissions, and allowing developing countries that are below the quota to trade their excess quota with countries that are above theirs.
The money that developing countries would receive for this would not be aid, but rather a recognition that the rich nations must pay for something that in the past they simply appropriated: far more than their fair share of our atmosphere’s capacity to absorb our waste gases.
Sri Lanka took a similar stance, using studies from the UN Intergovernmental Panel on Climate Change to calculate that in 2008, environmentally permissible carbon emissions totaled no more than 2,172 kilograms per person.
In fact, the world’s per capita emissions were 4,700 kilograms, or more than double the permissible limit.
But, while emissions in the rich nations were far above the permissible limit, Sri Lankan emissions were, at 660 kilograms, well below it.
As Sri Lanka’s government pointed out, “That means low-emitting countries like us could not emit more because our space has already been exploited by developed or global heavy polluting countries without our consent.”
This situation is an injustice of vast proportions, reminiscent of – and arguably much worse than – the now-repudiated colonialism of the Western powers in the nineteenth century.
The task of remedying it must begin at the meeting on climate change that will be held in Copenhagen in December.
Many political leaders have expressed support for strong action on climate change, but what most of them regard as “strong action” will not be enough to get us back below 350 ppm.
In some countries, including the United States, there are major political obstacles to taking even modest steps.
On October 24, people in nearly every country will be taking action to raise awareness of the need for an international treaty to bring our atmosphere back to 350 ppm of CO2.
There will be climbers hanging banners high in the Himalayas, where the glaciers are melting, and scuba divers at Australia’s Great Barrier Reef, which is threatened by climate change.
Churches will ring bells 350 times, 350 cyclists will circle towns, and, in many places, 350 trees will be planted.
At www.350.org you can find out what is happening near you and join in, or put your own idea online.
But don’t just sit back and hope that others will do enough to make an impact.
One day your grandchildren will ask you: what did you do to meet the greatest moral challenge of your time?
A Day of Liberation
When I was seven years old, in 1960, my grandmother Angelica opened my eyes to the meaning of 8 May 1945, the day when Nazi Germany surrendered and World War II ended in Europe.
We were spending our summer holidays in Normandy where the liberation of Europe from Nazism had started on D-Day, 6 June 1944.
One evening, I listened to my parents and my grandmother talking about the past.
I have forgotten the details of their conversation, but I can still hear my grandmother’s sigh of relief when she said “Thank God we lost that war!”
From a child’s perspective, it wasn’t self-evident that losing was a good thing.
But of course, my grandmother was right to equate defeat with liberation.
The more I have thought about the lesson she taught me 45 years ago, the clearer I have seen another, less obvious dimension in what she said: It is “we” who lost the war.
Collectively, the Germans had not been the innocent victims of a small gang of criminal outsiders called “Nazis” – Nazism had been an inside ideology supported by millions of Germans, and every German was liable for its atrocities whether or not he or she had adhered to it individually.
In today’s Germany, an overwhelming majority subscribes to the proposition that 8 May 1945 was a day of liberation – not only for Europe, but also for Germany itself.
Compared to public opinion in 1960, that’s certainly an enormous progress.
But paradoxically, it may also contain an element of forgetfulness, because it tends to conceal the fact that liberation required a military defeat.
To use my grandmother’s parlance, it is not “us” who were the liberators, but “them”.
The way people see the past tells us more about their present attitudes than about the past itself.
This is what the term “politics of memory” is meant to indicate. And this is why it doesn’t matter whether the relevant events happened 60 years ago (as World War II), 90 years (as in the case of the Armenian genocide) or even 600 years (such as the battle of Kosovo in 1389).
A violent conflict in the past may survive as a war of memories in the present, as can be observed in the current dispute between China and South Korea on one side, and Japan on the other.
A war of memories, in turn, may sometimes lead to a violent conflict in the future.
Former perpetrators often try to de-legitimize their former victims’ moral superiority by claiming they were victims themselves.
Therefore, the 60th anniversary of the firebombing of Dresden by Allied forces on 13 February 1945 has probably been a more crucial moment in terms of the German “politics of memory” than the 60th anniversary of 8 May 1945 is going to be.
Far-right groups infamously dubbed the attack by which at least 30,000 people were killed “Dresden’s Holocaust of bombs.”
Fortunately, their propaganda campaign has been a failure.
Although it is true that thousands of the civilians killed in Dresden and other German cities were innocent at an individual level, there can be no doubt it was morally imperative that Germany be defeated collectively.
On the left side of the German political spectrum, the proposition that 8 May 1945 was a day of liberation remains unchallenged.
However, it is sometimes repressed that the massive use of force had been necessary to achieve that result.
Left-wing pacifism tends to overlook this simple fact.
Its slogan “Never again war!” is only half the truth – the other half is “Never again appeasement!” 8 May 1945 was not “zero hour,” as a popular saying in Germany goes.
It had an antecedent, that is, a lack of pre-emptive resistance at home and abroad to the threat that built up in Nazi Germany during the 1930’s.
There is yet another lesson to be learned.
Yes, 8 May 1945 was a day of liberation to which the Soviet army contributed decisively.
But for millions of Central and East Europeans, liberation was followed by Stalin’s oppressive regime.
The current war of memories between the Baltic republics and Russia, with regard to the international celebration in Moscow on 9 May this year, reminds Germany of a special historic responsibility.
The German-Soviet non-aggression treaty, the so-called Hitler-Stalin pact, concluded in August 1939, had been supplemented by a secret appendix dividing the border states Finland, Estonia, Latvia, Lithuania, Poland and Romania into spheres of interest for the two parties.
But excusing Nazi atrocities by pointing to Stalinist crimes is an intellectually and morally unacceptable stratagem.
When Chancellor Schröder travels to Moscow for the Red Square celebrations, he should bear in mind Nazi Germany’s contribution to the Baltic tragedy.
On 8 May this year, public speakers will remind us how important it is not to forget.
They will stress that if the lessons of history are not learned, history is bound to repeat itself.
All this is perfectly true.
But personally, I will also remember my grandmother’s sentence “Thank God we lost that war!”
Thank God – and thanks to all those brave Allied soldiers who sacrificed their lives for the sake of Europe’s liberty.
Crashing the SDR
SANTA BARBARA – The Chinese government’s campaign to have its currency, the renminbi, included in the International Monetary Fund’s reserve asset appears to be on the brink of success.
Last week, IMF staff formally recommended adding the renminbi to the basket of currencies that determines the value of its so-called Special Drawing Rights (SDRs).
The addition of the renminbi to the basket, which currently includes the US dollar, the euro, the British pound, and the Japanese yen, would provide China with a boost to its prestige.
More important, it would advance the government’s efforts to internationalize the renminbi.
But it would also be a mistake.
The decision to recommend the renminbi’s inclusion, far from having been made on sound economic grounds, can only be understood as political.
As such, the long-term consequences are likely to be regrettable.
On a purely technical basis, the renminbi’s qualifications for inclusion in the SDR basket are questionable.
Traditionally, the IMF has insisted on two criteria: a currency’s issuing country must be among the world’s leading exporters, and the currency must be “freely usable” – widely used and traded.
As the world’s largest exporter, China clearly meets the first condition.
The second, however, is probably still beyond its reach.
The renminbi is by no means in the same league as the SDR basket’s four incumbent currencies.
In 2014, China’s currency ranked seventh in global central-bank reserves, eighth in international bond issuance, and 11th in global currency trading.
Moreover, the renminbi remains non-convertible for most capital transactions, China’s financial markets are primitive, and trading margins for the exchange rate are still set daily by the monetary authorities.
Indeed, as recently as August, the IMF was skeptical about adding the renminbi to the SDR basket, saying that “significant work” was still needed, and suggesting that a decision should be put off until 2016 in order to ensure a “smooth” transition.
So why did the IMF flip?
The answer is obvious: China mounted a full-court press to change minds.
In August, the currency’s exchange-rate regime was loosened slightly.
Renminbi-denominated government bonds were issued in London, and plans were laid to create new trading platforms for the currency in several European financial centers.
And Chinese policymakers made it abundantly clear how unhappy they would be with a negative decision.
Their pressure paid off.
One by one, Western governments fell in line behind the renminbi, despite its practical limitations.
The Fund got the message, and now the fix is in.
The recommendation to enlarge the SDR basket has been warmly backed by Christine Lagarde, the IMF’s managing director, and a final decision by the Fund’s executive board is expected at the end of the month.
Many would argue that this is a positive development.
Certainly, it mollifies China’s leaders, offering them a stronger incentive to continue to work within the existing international monetary regime.
Recent Chinese initiatives, especially the creation of the Asian Infrastructure Investment Bank, have given rise to fears that the country intends to build a new set of international institutions to compete with Western-dominated organizations like the IMF.
The decision to add the renminbi to the SDR basket may have put that danger into remission.
On the other hand, the move sets a worrying precedent, injecting politics into a policy area that had been governed by objective economic considerations.
Conceivably, over the longer term, China’s successful campaign could now open the door to lobbying by other governments to include their currencies as well.
Why not add the Swiss franc or the Canadian dollar?
Or, for that matter, why not include the Russian ruble or Indian rupee?
What was once the dignified preserve of obviously elite currencies could become the site of messy political battles for elevated status.
Of course, it can be argued that China’s recent economic trajectory means that it is only a matter of time before the renminbi does become a match for the SDR’s incumbents.
After all, international use of the currency has been growing exponentially.
But that optimistic assessment overestimates the renminbi’s prospects and illustrates the danger of linear extrapolation of the past into the future.
Likewise, use of the renminbi for the purpose of invoicing and settling trade with China is bound to continue growing.
But in terms of the all-important roles of a currency as an investment vehicle or reserve asset, the outlook for the renminbi is much less promising, owing to China’s still-tight capital controls and low level of financial development.
Nor is inclusion of the renminbi in the SDR basket likely to provide as big a boost to the currency’s internationalization as many believe.
Some central banks may decide to follow suit, adding renminbi-denominated assets to their reserves to match the composition of the basket.
But the increase will be marginal at best – some $40 billion in the next few years, according to the IMF’s calculations.
With global reserves now totaling more than $10 trillion, that is a mere drop in the proverbial bucket.
The political reasons for including the renminbi in the SDR are all too clear.
Unfortunately, the risks of doing so are no less obvious.
A Defeat for International Tax Cooperation
NEW YORK – Most of the world’s governments – eager to mobilize more tax revenues to finance development and curb pervasive tax-avoidance schemes, such as those revealed in the so-called Luxembourg Leaks scandal last year – have an interest in collaborating on taxation matters.
Yet at the Third International Conference on Financing for Development, held in Addis Ababa last month, the momentum toward strengthening international tax cooperation came to an abrupt halt.
Developed countries blocked a proposal at the conference to establish an intergovernmental tax body within the United Nations to replace the current UN Committee of Experts.
These countries insist that tax cooperation should take place exclusively under the leadership of the OECD, a body that they control.
The rest of the world should hope this will prove to be a pause rather than an end to progress on international tax cooperation, which began 13 years ago, at the first International Conference on Financing for Development in Monterrey, Mexico.
Two years later, in 2004, the United Nations Economic and Social Council (ECOSOC) upgraded its “ad hoc group” of tax experts to a regular committee.
This meant that the experts would meet regularly and have an expanded mandate that went beyond merely updating a model double-taxation treaty.
Four years later, at the Second Conference on Financing for Development, in Doha, Qatar, policymakers acknowledged that more needed to be done in tax matters, and asked ECOSOC to consider strengthening institutional arrangements.
And then, in the year leading up to the Addis Ababa conference, the UN Secretary-General endorsed the need for “an intergovernmental committee on tax cooperation, under the auspices of the United Nations.”
His endorsement, along with strong support from nongovernmental organizations and the Independent Commission for the Reform of International Corporate Taxation, gave greater force to the demand by developing countries, organized around the Group of 77 and China, for an equal voice in setting global tax norms.
Up until the 11th hour of negotiations in Addis Ababa, they stood firm in calling for an intergovernmental body with the mandate and resources to create a coherent global framework for international tax cooperation.
But to no avail: Developed countries, led by the United States and the United Kingdom –home to many of the multinational corporations implicated in the “Lux Leaks” – succeeded in blocking this much-needed advance in global governance.
In the end, the Addis Ababa Action Agenda provides that the current Committee of Experts will continue to function according to its 2004 mandate, with three additional meeting days per year, all funded through voluntary contributions.
That is a profoundly disappointing outcome.
The developed countries have an argument – but not a convincing one.
The OECD, whose members are essentially the world’s 34 richest countries, certainly has the capacity to set international standards on taxation.
Yet the domination of a select group of countries over tax norms has meant that, in reality, the global governance architecture for taxation has not kept pace with globalization.
The Monterrey Consensus reached in 2002 included a call to enhance “the voice and participation of developing countries in international economic decision-making and norms-setting.”
But although the OECD invites some developing countries to participate in its discussions to establish norms, it offers them no decision-making power.
The OECD is thus a weak surrogate for a globally representative intergovernmental forum.
Such a body must operate under the auspices of the United Nations, which bears the institutional legitimacy necessary to respond effectively to the challenges of globalization with coherent global standards to combat abusive tax practices and ensure fair taxation of corporate profits worldwide.
Despite the disappointment in Addis Ababa, the call for reform of the international tax system is not likely to be silenced.
Instead, it will grow louder on all sides, as the developed countries’ counter-productive resistance to any give and take on international cooperation results in a tsunami of unilateral tax measures beyond OECD control.
The Making of Euro-Jihadism
MADRID – The Belgian historian Henri Pirenne linked Europe’s birth as a Christian continent in the eighth century to its rupture with Islam.
Pirenne probably would never have expected a Muslim ghetto in Brussels to emerge, much less become a hub of jihadism, with marginalized and angry young Muslims revolting against Europe from within its own borders.
Divorce is not an option these days.
But nor is the kind of marriage that the Islam scholar Tariq Ramadan advocates.
Ramadan, a grandson of the founder of the Muslim Brotherhood in Egypt, is a Swiss citizen and a resident of the United Kingdom who argues that Islamic ethics and values should be injected into the European system.
Europe would then not just tolerate Islam, but actually embrace it as an integral part of itself.
The problem with Ramadan’s vision is that Europe is an overwhelmingly secular continent, with a profoundly forward-thinking approach to ethics.
Islamic societies, by contrast, are both deeply religious and deeply embedded in the past.
When Islamists speak of political or social reform, they are typically looking backward, hoping to resurrect a time when core European principles – from gender equality to gay marriage – were repudiated.
Even Muslims who support the modernization of Islam would typically stop well short of Europe’s ethical vision.
The flaws in Ramadan’s proposed solution to Euro-jihadism mirror the flaws in his explanation for the phenomenon, which he attributes largely to Europe’s involvement in the wars in the Middle East, its supposed collusion with Israel’s suppression of the Palestinians, and its support of Arab autocrats.
“We cannot,” he writes, “support dictatorships … be silent when civilians are massacred south of our borders, and hope that we will not receive a response to the injustice and humiliation we have provoked.”
But it is the United States that launched wars in Iraq and Afghanistan, offers unconditional support to Israel, and has repeatedly propped up Arab autocrats.
And it is Europe that has consistently criticized these policies – often harshly.
Yet America is not being subjected to a major surge of jihadist sentiment within its borders.
It might have helped that US President Barack Obama backed away from some of these policies.
When the Arab Spring uprisings began, for example, he was quick to cut support for Tunisian President Zine El Abidine Ben Ali and Egyptian President Hosni Mubarak, allowing protesters – inspired by the Western model of democracy – to secure regime change.
The return to autocracy in Egypt in 2013, via Abdel Fattah el-Sisi’s coup d’état, certainly was not aided by the US or Europe, both of which supported the democratically elected Muslim Brotherhood.
Europe has offered even more direct help to Arab countries in recent years.
If it were not for Europe’s military intervention, Libyans would still be living under the tyrannical Muammar el-Qaddafi.
True, Europe could have done more to prevent the ensuing chaos in Libya.
But the people of Libya surely must take responsibility for the proliferation of competing militias that refuse to unite to save their state from total collapse.
More broadly, though the West – especially the US – has made grave policy errors in the Arab world over the last 50 years, external powers cannot be blamed entirely for the region’s meltdown.
That is the result of a profound civilizational crisis – one that can be redressed only by the people of the Arab world.
If Europe’s foreign policy is not responsible for the Arab world’s current turmoil, it certainly cannot be the reason for the rise of jihadism within its own borders.
The real problem lies at home: a disastrous deficit of effective policies related to social justice, education, housing, and employment for young European Muslims.
Marginalization generates frustration, which is subsequently fed by growing Islamophobia and the rise of raucous right-wing movements throughout the continent.
This link is apparent in the fact that the majority of European jihadists come from underprivileged backgrounds.
Not particularly well versed in the true teachings of Islam, and lacking opportunities to improve their lives, they become easy prey for extremists.
Jihadism, with its absolute certainty and grand mission, offers a sense of purpose, pride, and identity – not to mention adventure – and an outlet for their anger against the “home” that has denied them those things.
The story of America’s Muslims is the measure of Europe’s failure.
Like most Americans, Muslims in the US maintain a certain amount of faith in the American dream.
They are mostly middle class, and, despite all the talk about rising economic inequality, they have not given up on the belief that, in the US, hard work and initiative are rewarded.
America is a country of immigrants, with a dynamic economy that has enabled newcomers, time and again, to achieve great success.
In Europe, by contrast, improving one’s social standing has always been very difficult; and, at a time of economic stagnation and staggeringly high unemployment, it is not getting any easier.
Socially, America also offers something to Muslims that Europe does not.
Its fundamentally religious culture enables Muslims to retain their identity to a far greater extent than in secular Europe.
Indeed, America’s core values – personal responsibility and constitutional patriotism – can be easier for Muslims to swallow than Europe’s more aggressively secular brand of liberalism.
As a result, integration and assimilation tend to be easier for Muslims in America.
All of this suggests that Europe must look inward to address homegrown jihadism effectively.
This does not mean that it should temper its secularism, much less its liberal values.
Rather, Europe must breathe life into its own “European dream,” ensuring that all people have access to real opportunities to improve their lives.
Otherwise, it will face a lost generation of millions of young Europeans – Muslim and otherwise.
The New Climate Economics
NEW YORK – This Friday, in its latest comprehensive assessment of the evidence on global warming, the United Nations Intergovernmental Panel on Climate Change will show that the world’s climate scientists are more certain than ever that human activity – largely combustion of fossil fuels – is causing temperatures and sea levels to rise.
In recent years, a series of extreme weather events – including Hurricane Sandy in New York and New Jersey, floods in China, and droughts in the American Midwest, Russia, and many developing countries – have caused immense damage.
Last week, Mexico experienced simultaneous hurricanes in the Pacific and in the Gulf of Mexico that devastated towns and cities in their path.
Climate change will be a major driver of such events, and we risk much worse.
This puts a new debate center stage: how to reconcile increased action to reduce greenhouse gas emissions with strong economic growth.
It is a debate that is already mired in controversy.
As most countries have started making serious investments in renewable energy, and many are implementing carbon prices and regulations, critics complain that such policies may undermine growth.
With the global economy still recovering from the 2008 financial crash, higher energy costs – not yet fully offset by greater energy efficiency – are worrying business and political leaders.
The advent of shale gas has confused the energy debate even more.
If gas is substituted for coal, it can be a useful bridge to a low-carbon future.
But astonishingly, it is coal, the dirtiest fuel, that is experiencing the sharpest increase in use.
Companies and investors are hedging their bets by taking a few resource-efficiency measures and investing in some low-carbon assets, but leaving their high-carbon portfolios and activities largely intact.
Policy vacillation in some countries has not helped.
Advocates of stronger action respond that low-carbon investments can generate much stronger, cleaner growth.
They point to the savings available from energy efficiency, and to the market opportunities generated by clean-energy technologies as the processes of learning and discovery take hold.
They seek to demonstrate the benefits that a more sustainable pattern of development can bring to the world’s cities, to people’s health (from the reduction in air pollution), to energy security, and to the ability of the world’s poor to access energy.
And they propose green bonds and public investment banks to finance new infrastructure and jobs at a time when world interest rates are low and demand is depressed in many countries.
These are serious economic debates, but too often they have become entangled in ideological disputes about the appropriate response to the economic crisis and the value of government intervention in markets.
That is regrettable.
Climate change is not a partisan issue, and climate policy is essentially market-based.
It is about correcting market failures so that markets and entrepreneurship can play their proper role of ensuring innovation and efficient resource allocation.
In order to escape this impasse, we have helped to launch the Global Commission on the Economy and Climate.
The Commission’s New Climate Economy project brings together seven leading policy research institutes from six continents, overseen by a panel of former heads of government and finance ministers and prominent business leaders, and advised by a panel of leading economists from across the world.
Its purpose is to provide authoritative new evidence concerning how governments and businesses can achieve stronger economic growth while simultaneously addressing climate risks.
Few governments or investors start from the standpoint of climate change.
They want to promote investment and economic growth, create jobs, stabilize public finances, expand markets, turn profits, ensure reliable energy and food supplies, produce goods and services, reduce poverty, and build cities.
So the primary question that we need to ask is not whether we can reduce emissions, but how public policy can help to achieve these core goals while reducing emissions and building a more climate-resilient economy.
There is now a lot of experience around the world in this area.
When the Stern Review on the economics of climate change was published seven years ago, the subject was largely theoretical.
Now countries at all stages of development are pursuing new patterns of economic growth that take climate into account.
Germany, for example, is planning the world’s most ambitious low-carbon energy transition, based on energy conservation and renewables.
South Korea has made “green growth” a central economic goal.
Mexico’s 2012 General Law on Climate Change has put it on course for a major increase in clean power.
China has placed the industrial development of green technologies at the top of its agenda.
Ethiopia is seeking to move to lower-carbon farming.
Brazil has significantly reduced the rate of deforestation in the Amazon.
Some major businesses are providing powerful examples of what is possible.
Unilever has committed to the sustainable sourcing of agricultural and forest products.
Coca-Cola is phasing out all use of climate-polluting hydrofluorocarbons.
The retail giant Wal-Mart is driving emissions reduction throughout its supply chain.
Meanwhile, the World Bank and the European Investment Bank have stopped lending to high-emission coal plants.
Yet genuine questions remain about how fast economies should move on to a low-carbon path, and the most effective way to do so.
Some low-carbon policies have clearly been expensive, while other, apparently cost-effective options, have not been pursued at all.
Any structural transformation involves costs, trade-offs, and uncertainties, and it is vital that we understand these properly.
Powerful interests will, of course, oppose any low-carbon transition, dismissing and often drowning out those who stand to benefit.
That makes it even more important to clarify the choices.
As science makes clear how imperative the climate question is, it is time for economists and policymakers to explain how it can be answered.
The Mouse Click that Roared
CAMBRIDGE – Until recently, cyber security has primarily interested computer geeks and cloak-and-dagger types.
The Internet’s creators, part of a small, enclosed community, were very comfortable with an open system in which security was not a primary concern.
But, with some three billion or so users on the Web nowadays, that very openness has become a serious vulnerability; indeed, it is endangering the vast economic opportunities that the Internet has opened for the world.
A “cyber attack” can take any number of forms, including simple probes, defacement of Web sites, denial-of-service attacks, espionage, and destruction of data.
And the term “cyber war,” though best defined as any hostile action in cyberspace that amplifies or is equivalent to major physical violence, remains equally protean, reflecting definitions of “war” that range from armed conflict to any concerted effort to solve a problem (for example, “war on poverty”).
Cyber war and cyber espionage are largely associated with states, while cyber crime and cyber terrorism are mostly associated with non-state actors.
The highest costs currently stem from espionage and crime; but, over the next decade or so, cyber war and cyber terrorism may become greater threats than they are today.
Moreover, as alliances and tactics evolve, the categories may increasingly overlap.
Terrorists might buy malware from criminals, and governments might find it useful to hide behind both.
Some people argue that deterrence does not work in cyberspace, owing to the difficulties of attribution.
But that is facile: inadequate attribution affects inter-state deterrence as well, yet it still operates.
Even when the source of an attack can be successfully disguised under a “false flag,” governments may find themselves sufficiently enmeshed in symmetrically interdependent relationships such that a major attack would be counterproductive.
China, for example, would lose from an attack that severely damaged the American economy, and vice versa.
An unknown attacker may also be deterred by cyber-security measures.
If firewalls are strong, or redundancy and resilience allow quick recovery, or the prospect of a self-enforcing response (“an electric fence”) seems possible, an attack becomes less attractive.
While accurate attribution of the ultimate source of a cyber attack is sometimes difficult, the determination does not have to be airtight.
To the extent that false flags are imperfect and rumors of the source of an attack are widely deemed credible (though not legally probative), reputational damage to an attacker’s soft power may contribute to deterrence.
Finally, a reputation for offensive capability and a declared policy that keeps open the means of retaliation can help to reinforce deterrence.
Of course, non-state actors are harder to deter, so improved defenses such as pre-emption and human intelligence become important in such cases.
But, among states, even nuclear deterrence was more complex than it first looked, and that is doubly true of deterrence in the cyber domain.
Given its global nature, the Internet requires a degree of international cooperation to be able to function.
Some people call for the cyber equivalent of formal arms-control treaties.
But differences in cultural norms and the difficulty of verification would make such treaties hard to negotiate or implement.
At the same time, it is important to pursue international efforts to develop rules of the road that can limit conflict.
The most promising areas for international cooperation today most likely concern problems posed for states by third parties such as criminals and terrorists.
Russia and China have sought to establish a treaty establishing broad international oversight of the Internet and “information security,” which would prohibit deception and embedding malicious code or circuitry that could be activated in the event of war.
But the US has argued that arms-control measures banning offensive capabilities could weaken defenses against attacks and would be impossible to verify or enforce.
Likewise, in terms of political values, the US has resisted agreements that could legitimize authoritarian governments’ censorship of the Internet – for example, by the “great firewall of China.”
Moreover, cultural differences impede any broad agreements on regulating online content.
Nonetheless, it may be possible to identify behaviors like cyber crime that are illegal in many domestic jurisdictions.
Trying to limit all intrusions would be impossible, but one could start with cyber crime and cyber terrorism involving non-state parties.
Here, major states would have an interest in limiting damage by agreeing to cooperate on forensics and controls.
The transnational cyber domain poses new questions about the meaning of national security.
Some of the most important responses must be national and unilateral, focused on hygiene, redundancy, and resilience.
It is likely, however, that major governments will soon discover that the insecurity created by non-state cyber actors will require closer cooperation among governments.
A Practical Agenda for Revolutionary Times
OXFORD – As the world’s financial leaders gather for the International Monetary Fund and World Bank spring meetings, many working people around the world are demanding radical change, because they sense that their voices are not being heard.
Those who are supposed to represent them should not ignore this anger and frustration any longer.
According to the 2017 Edelman Trust Barometer, the public’s confidence in the status quo has collapsed worldwide, owing to widely held concerns about globalization, innovation, immigration, the erosion of social values, and corruption.
At the same time, the response from elites who regard themselves as the guardians of economic growth has sometimes made matters worse.
If they think they can allay public concerns simply by explaining the benefits of the current global economic system and tweaking policies to compensate those left behind, they are in for a rude awakening.
Earlier this month, the IMF, World Bank, and World Trade Organization published a joint report extolling the benefits of trade as a driver of productivity growth, competition, and consumer choice.
The report’s argument in favor of free trade is not new, nor is its recommendation that “active labor-market policies” be used to cushion the blow of lost jobs and livelihoods.
What is new is that repeating these claims, without also addressing people’s deeper concerns, can now do more harm than good.
Global public opinion has changed dramatically in recent years.
A majority of people worldwide – and up to 72% of people in France and Italy – now believe that the system has failed them.
Moreover, only 29% of people across 28 countries now trust government leaders, while three-quarters of those surveyed say they trust reformers who would upend the status quo.
These findings suggest that those defending free trade have lost credibility with the people they hope to persuade.
World leaders need to recognize that today’s populist revolts are being fueled by a sense of lost dignity – a sentiment that does not factor into most policymakers’ prescription for economic growth and compensatory payments.
Working-class voters have lashed out because they feel not just economically abandoned, but also socially disdained and culturally marginalized.
Their vote is the only means they have left to hit back at the establishment.
To address the public’s concerns requires a three-part agenda.
The first order of business should be to reach out to those who feel voiceless and unrepresented.
During the US presidential campaign, Donald Trump tapped into this sentiment when he vowed to punish any company that moves jobs to China or Mexico.
As the filmmaker Michael Moore explained prior to the election, American working-class voters were desperate to hear someone promise to take on big business.
The fact that it took a populist plutocrat to do it underscores the extent to which the American labor movement has been extinguished.
Political parties that originally emerged from the labor movement have long since shifted to the “center.”
They now accept political contributions from big business, and have accordingly adopting the language of common prosperity and “consensus politics,” leaving the many working people who do not share in that prosperity and consensus feeling disregarded and displaced.
Second, the quality of work, and the status that it confers, must be improved.
In wealthy countries, precarious, poorly paid, and even dangerous forms of employment are becoming increasingly common.
A recent Bloomberg Businessweek story describes how temporary workers at auto-parts factories in Alabama are paid just $7.25 per hour, and must work in hazardous conditions with no safety training.
In 2010, these workers suffered work injuries at a 50% higher rate than unionized auto-parts workers elsewhere.
As the OECD has shown, “non-standard” work is proliferating globally.
This trend is contributing to deteriorating working conditions, making workers feel increasingly helpless and vulnerable.
Reversing it will require robust standards to ensure workplace safety, fair pay, and the right to enter into collective-bargaining arrangements.
Governments will have to intervene to set these standards, as they did during the nineteenth and twentieth centuries to improve abysmal conditions in factories.
Otherwise, businesses will not be able to behave decently, for fear of being undercut by unscrupulous competitors.
Finally, more opportunities must be created for the next generation – and not just economic opportunities.
Since the 2008 financial crisis, many governments have reduced their investments in health, education, housing, and other forms of human capital.
Many have also cut support for the unemployed, homeless, or indebted.
As a result, those who have fallen behind are deprived not just of resources, but, more important, the chance to pursue their aspirations.
As the IMF, World Bank, and WTO show in their report, free trade and globalization have certainly increased the size of the overall economic pie.
In theory, this should have expanded governments’ capacity to compensate those left behind and create the conditions for them to get ahead.
In fact, the opposite has happened, owing to government cutbacks since 2008.
The establishment’s agenda has been failing for too long.
And as elites continue to proclaim the benefits of free trade and globalization, they are merely widening the chasm of popular mistrust.
Over the past year, that mistrust has boiled over in many countries, with voters in one election after another rejecting the status quo.
Piecemeal curbs on globalization will not be enough to quell the revolt.
Instead, world leaders must leave their echo chamber, take ordinary people’s concerns seriously, diversify their views, and think about why so many have lost faith in the system.
The Development Costs of Homophobia
LONDON – As a gay man living in Nigeria, my biggest challenge was choosing between my sexuality and my job.
In 2004, I was at the start of my acting career.
I had just left university, and I was featured in “Roses and Thorns,” a prime-time soap opera on Galaxy Television, one of Nigeria’s most popular TV stations. I was playing the role of “Richard,” the only son of a rich family who was having an affair with the house maid.
Whispers were making the rounds about my private life, and I decided it was time to come out.
So I agreed to go on Nigeria’s most-watched television talk show to discuss my sexuality.
Almost immediately, my character was eliminated.
And when my job disappeared, so did my financial security.
Like many gay men and lesbians in Africa, my choice was between economic freedom and mental imprisonment.
This year, Nigeria and Uganda put in place draconian anti-gay laws, sparking a worldwide debate about human rights.
This debate has also started at the World Bank, whose president, Jim Yong Kim, recently declared that “institutionalized discrimination is bad for people and for societies.”
Kim’s statement has invited criticism and controversy.
Often, as in Uganda and Nigeria, we hear the claim that opposition to official discrimination against gay, lesbian, bisexual, and transgender (LGBT) people is simply a way to impose “Western” values on Africa.
But this assumes that homosexuality is “un-African.”
And, despite the absence of evidence that any given country or continent does not have LGBT people (and ample evidence to the contrary), it is an assumption that an increasing number of African leaders have embraced.
In 2006, President Olusegun Obasanjo, then Nigeria’s president, was among the first to do so.
Uganda’s President Yoweri Museveni followed suit when signing the anti-gay bill into law in 2014.
Other leaders, from Gambia’s President Yahya Jammeh to Zimbabwe’s Robert Mugabe, have spoken in the same vein.
These official attitudes have caused significant suffering for Africa’s gays and lesbians.
Indeed, the price of homophobia for gay people in many African countries is painfully clear: legal penalties, social ostracism, and mob justice.
But here is what Africa’s anti-gay leaders miss: legal protections are not only a human-rights issue, but also an economic issue.
Kim is exactly right, and research has started measuring the economic costs of homophobia by exploring links between anti-gay sentiment and poverty in countries where laws and social attitudes proscribe same-sex relationships.
M.V. Lee Badgett, an economist at the University of Massachusetts-Amherst, presented the initial findings of a study of the economic implications of homophobia in India at a World Bank meeting in March 2014.
Badgett estimated that the Indian economy may have lost up to $23.1 billion in 2012 in direct health costs alone, owing to depression, suicide, and HIV treatment disparities caused by anti-gay stigma and discrimination.
In addition to such concrete costs, being gay can bring violence, job loss, family rejection, harassment in schools, and pressure to marry.
As a result, many gay people have less education, lower productivity, lower earnings, poorer health, and a shorter life expectancy.
In Nigeria, I started the Independent Project for Equal Rights (TIERs) in 2005 to respond to the increasing number of people who were losing their jobs because of suspicions about their sexuality.
During our first year, we provided support for dozens of people.
One young man, “Olumide,” was given temporary housing after his family kicked him out for being gay.
Another, “Uche,” was fired from his job as a chef after his sexuality was revealed.
TIERs helped him with accommodation and capital to set up a catering business.
Though almost 10 years have passed, it is still not safe to use their real names.
Across Africa, the economic costs of discrimination are increasing, in line with growing pressure on employers, landlords, health-care providers, educational institutions, and others to exclude LGBT people.
Today, the World Bank and other development agencies are mapping out the global development priorities that will follow the Millennium Development Goals (MDGs), which officially end in 2015 and included specific targets for promoting gender equality and empowering women as a strategy for economic growth.
Looking ahead, the Bank should take the same approach to LGBT rights and make legal protections for sexual orientation and gender identity a condition for countries receiving loans.
Building recognition of women’s rights into the MDGs did not corrupt African cultures by imposing “Western” values; in fact, it strengthened many African countries, which now lead the world in the representation of women in government.
By pursuing similar protections for LGBT people, international investment and aid can improve economic performance and strengthen respect for basic human rights.
The World Bank, always wary of entangling itself in “political” questions, emphasizes that it is not a global human-rights enforcer.
But it also increasingly recognizes its own role as a facilitator in helping Bank members realize their human-rights obligations.
LGBT rights should be a test case.
Aid to governments that permit specific social groups to be ostracized can carry very real economic costs.
As new loans are considered, steps should be taken to ensure that the benefits are as inclusive as possible.
If the Bank – which currently lends Nigeria almost $5.5 billion and expects to commit an additional $2 billion in each of the next four years – moved in this direction, other funders might follow.
Africa’s LGBT people desperately need such powerful allies in their struggle for human and economic rights.
A Democratic Burma?
TOKYO – Historic transformations often happen when least expected.
Mikhail Gorbachev’s liberalizing policies of glasnost and perestroika in the Soviet Union emerged at one of the Cold War’s darkest hours, with US President Ronald Reagan pushing for strategic missile defense and the two sides fighting proxy wars in Afghanistan and elsewhere.
Deng Xiaoping’s economic opening followed China’s bloody – and failed – invasion of Vietnam in 1978.
And South Africa’s last apartheid leader, F. W. de Klerk, was initially perceived as just another apologist for the system – hardly the man to free Nelson Mandela and oversee the end of white minority rule.
Now the world is suddenly asking whether Burma (Myanmar), after six decades of military dictatorship, has embarked on a genuine political transition that could end the country’s pariah status.
Is Burma, like South Africa under de Klerk, truly poised to emerge from a half-century of self-imposed isolation?
And can Aung San Suu Kyi, the heroic opposition leader, and Thein Sein, Burma’s new president, engineer a political transition as skillfully and peacefully as Mandela and de Klerk did for South Africa in the early 1990’s?
Despite her two decades of house arrest and isolation, Suu Kyi possesses two of the gifts that enabled Mandela to carry out his great task: a reassuring serenity and an utter lack of vindictiveness.
As Burma’s authorities test reform, these gifts, together with her negotiating skills and, most of all, her vast moral authority, will be tested as never before.
Moreover, unlike Mandela during his 27-year imprisonment, Suu Kyi has had her hopes raised – and dashed – before.
In the mid-1990’s, and again in 2002-2003, reconciliation between Suu Kyi’s National League for Democracy (NLD) and the military junta seemed to be in the offing.
On both occasions, however, the regime’s hardliners gained the upper hand, crushing prospects for reform.
Yet Suu Kyi, and much of the Burmese opposition, is beginning to admit that today’s political liberalization might be the real thing.
Because Burma’s generals say almost nothing in public, it is difficult to fathom why they allowed elections that elevated Thein Sein to power, or to explain their willingness to embrace dialogue with the long-suppressed opposition.
Recent events suggest one possible explanation: Burma’s rulers have grown wary of China’s almost smothering embrace – a result of the country’s international isolation.
Indeed, public protests against China’s commercial exploitation of Burma’s natural resources became so widespread that the government called a halt to construction by Chinese investors on the huge and environmentally damaging Myitsone Dam on the Irrawaddy River.
Thein Sein’s decision to halt the project is clearly an important policy shift.
It is also a signal to the outside world that Burma’s new government may be much more willing than any of its predecessors to heed both public pressure and international opinion, both of which vehemently opposed the dam’s construction.
Almost simultaneously, Thein Sein offered even stronger signals that his was a very different Burmese administration: he freed political prisoners and invited Suu Kyi for direct talks with him.
Indeed, Suu Kyi now enjoys far greater freedom of movement than she has at any time since she received the Nobel Peace Prize 20 years ago, and the NLD recently announced that it will field candidates in the forthcoming by-elections to the country’s newly established parliament.
If Suu Kyi is permitted to campaign free of restraint, for both her own seat and to boost the electoral chances of her NLD colleagues, it will be clear that Thein Sein and his government are truly determined to bring their country in from the cold.
For both Suu Kyi and Thein Sein, every step from now on will be delicate, to be calibrated with the same care and deliberation that Mandela and de Klerk used in bridging their differences and leading their country out of isolation.
But the international community, too, must act with great care.
While Thein Sein would undoubtedly wish to see the myriad economic and political sanctions imposed on Burma quickly lifted, it is too soon for a general easing of such measures.
But the outside world should demonstrate that every clear move toward greater political openness will merit more international political and economic engagement.
The Japan Investment Bank’s decision to invest in port development in Burma – essential if the economy, too, is to be opened – is one positive sign that the world will keep pace with Thein Sein step for step.
And US President Barack Obama’s decision to send Secretary of State Hillary Clinton to Burma to meet Thein Sein is another clear sign that the world is ready to end the country’s isolation.
Closer to home, ASEAN’s recent decision to give Burma a chance to chair the organization in 2014 underscores its neighbors’ desire for the country’s full participation in Asia’s growing prosperity.
No one should rush to judgment yet, but Thein Sein’s decisions, at least so far, are beginning to resemble those of South Africa’s de Klerk when he initiated his country’s reform process.
Fortunately, Burma already has in Aung San Suu Kyi its very own Nelson Mandela.
A Devaluation Option for Southern Europe
CAMBRIDGE – This year is likely to mark a make-or-break ordeal for the euro.
The eurozone’s survival demands a credible solution to its long-running sovereign-debt crisis, which in turn requires addressing the two macroeconomic imbalances – external and fiscal – which are at the heart of that crisis.
The crisis has exposed the deep disparities in competitiveness that have developed within the eurozone.
From 1996 to 2010, unit labor costs in Germany increased by just 8%, and by 13% in France. Compare that to 24% in Portugal, 35% in Spain, 37% in Italy, and a whopping 59% in Greece.
The result has been large trade imbalances between eurozone countries, a problem compounded by large fiscal deficits and high levels of public debt in southern Europe (and France) – much of it owed to foreign creditors.
Does addressing these imbalances require breaking up the eurozone?
Suppose, for example, that Portugal were to leave and re-introduce the escudo. The ensuing exchange-rate devaluation would immediately lower the price of Portugal’s exports, raise its import prices, stimulate the economy, and bring about much-needed growth.
But a euro exit would be a messy affair. The resulting turmoil could very well trump any short-term gains in competitiveness from devaluation.
There is a remarkably simple alternative that does not require southern Europe’s troubled economies to abandon the euro and devalue their exchange rates.
It involves increasing the value-added tax while cutting payroll taxes.
Our recent research demonstrates that such a “fiscal devaluation” has very similar effects on the economy in terms of its impact on GDP, consumption, employment, and inflation.
A currency devaluation works by making imports more costly and exports cheaper. A VAT/payroll-tax swap would do exactly the same thing.
An increase in VAT raises the price of imported goods, as foreign firms face a higher tax.
To ensure that domestic firms do not have an incentive to raise prices, an increase in VAT needs to be accompanied by a cut in payroll taxes.
Moreover, since exports are exempt from VAT, the price of domestic exports will fall.
The desired competitiveness effects of exchange-rate devaluation can thus be had while staying in the euro.
This policy can also help on the fiscal front.
As is true of an exchange-rate devaluation, the positive impact on growth of an increase in competitiveness can strengthen the fiscal position by raising tax revenues.
Moreover, an important advantage of fiscal devaluations is that they generate additional revenues in proportion to the country’s trade deficit.
For countries that are suffering from weak competitiveness and, as a consequence, running trade deficits, this typically means more revenues, especially in the short run.
Like exchange-rate devaluations, fiscal devaluations create winners and losers.
Both act as a wealth levy: inflation means that bondholders suffer a real loss in proportion to their wealth and the size of the devaluation.
If taxes on capital are not adjusted, holders of domestic stocks suffer a comparable loss.
By contrast, many transfers, such as unemployment benefits, health benefits, and public pensions, are indexed to inflation, and thus maintain their real value.
The same is true of minimum wages.
These distributive effects play an important role in the politics of exchange-rate devaluations, and most of these effects appear in fiscal devaluations as well.
Fiscal devaluations already have some advocates.
Indeed, French President Nicolas Sarkozy’s government just announced one.
And concerns that a fiscal devaluation will conflict with euro rules can be met by simply pointing out that Germany’s government carried one out in 2007, though by another name, when it raised VAT from 16% to 19% and cut employers’ contribution to social insurance, from 6.5% to 4.2%.
In short, there are simple fiscal alternatives to exchange-rate devaluation that can address southern Europe’s short-term competitiveness problems.
To be sure, feasible fiscal devaluations would be limited in size.
But, together with debt restructuring, accommodative monetary policy, liquidity support from the European Central Bank, and much-required structural reforms, they can help to put these troubled economies on a sound footing without a euro breakup or a major austerity-induced recession.
A Dissident in China
TOKYO – 2009 was a good year for China. The Chinese economy still roared ahead in the midst of a worldwide recession.
American President Barack Obama visited China, more in the spirit of a supplicant to an imperial court than the leader of the world’s greatest superpower. Even the Copenhagen summit on climate change ended just the way China wanted: failure in its attempt to commit China, or any other industrial nation, to making significant cuts in carbon emissions, with the United States getting the blame.
The Chinese government, under the Communist Party, has every reason to feel confident.
So why did a gentle former literature professor named Liu Xiaobo have to be sentenced to 11 years in prison, just because he publicly advocated freedom of expression and an end to one-party rule?
Liu was co-author in 2008 of a petition, Charter 08, signed by thousands of Chinese, calling for basic rights to be respected.
Liu is not a violent rebel. His opinions, in articles published on the Internet, are entirely peaceful.
Yet he was jailed for “inciting subversion of state power.”
The notion that Liu might be capable of subverting the immense power of the Communist Party of China is patently absurd.
And yet the authorities clearly believe that they had to make an example of him, to prevent others from expressing similar views.
Why does a regime that appears to be so secure consider mere opinions, or even peaceful petitions, so dangerous?
Perhaps because the regime does not feel as secure as it looks.
Without legitimacy, no government can rule with any sense of confidence. There are many ways to legitimize political arrangements.
Hereditary monarchy, often backed by divine authority, has worked in the past. And some modern autocrats, such as Robert Mugabe, have been bolstered by their credentials as national freedom fighters.
China has changed a great deal in the last century, but it has remained the same in one respect: it is still ruled by a religious concept of politics.
Legitimacy is not based on the give and take, the necessary compromises, and the wheeling and dealing that form the basis of an economic concept of politics such as that which underpins liberal democracy.
Instead, the foundation of religious politics is a shared belief, imposed from above, in ideological orthodoxy.
In imperial China, this meant Confucian orthodoxy.
The ideal of the Confucian state is “harmony.”
If all people conform to a particular set of beliefs, including moral codes of behavior, conflicts will disappear.
The ruled, in this ideal system, will naturally obey their rulers, just as sons obey their fathers.
After the various revolutions in the early decades of the twentieth century, Confucianism was replaced by a Chinese version of Communism.
Marxism appealed to Chinese intellectuals, because it was bookish, introduced a modern moral orthodoxy, and was based, like Confucianism, on a promise of perfect harmony. Ultimately, in the Communist utopia, conflicts of interests would melt away.
Chairman Mao’s rule combined elements of the Chinese imperial system with Communist totalitarianism.
This orthodoxy, however, was also destined to fade away.
Few Chinese, even in the top ranks of the Communist Party, are convinced Marxists anymore.
This left an ideological vacuum, swiftly filled in the 1980’s by greed, cynicism, and corruption.
Out of this crisis came the demonstrations all over China, collectively known as “Tiananmen.”
Liu Xiaobo was an active spokesman in 1989 for the student protests against official corruption and in favor of greater freedom.
Soon after the bloody crackdown on Tiananmen, a new orthodoxy replaced Chinese Marxism: Chinese nationalism.
Only one-party rule would guarantee the continuing rise of China and put an end to centuries of national humiliation.
The Communist Party represented China’s destiny as a great power. To doubt this was not just mistaken, but unpatriotic, even “anti-Chinese.”
From this perspective, Liu Xiaobo’s critical views were indeed subversive.
They cast doubt on the official orthodoxy, and thus on the legitimacy of the state.
To wonder, as many have, why the Chinese regime refused to negotiate with the students in 1989 – or to find some accommodation with its critics today – is to misunderstand the nature of religious politics.
Negotiation, compromise, and accommodation are the marks of economic politics, where every deal has its price. By contrast, those who rule according to a shared belief cannot afford to negotiate, for that would undermine the belief itself.
This is not to say that the economic concept of politics is utterly strange to the Chinese – or, for that matter, that the religious notion of politics is unknown in the democratic West.
But the insistence on orthodoxy is still sufficiently strong in China to remain the default defense against political critics.
These things can change.
Other Confucian societies, such as South Korea, Taiwan, and Japan, now have thriving liberal democracies, and there is no reason to believe that such a transition is impossible in China.
But external pressure is unlikely to bring it about.
Many non-Chinese, including me, have signed a letter of protest against the jailing of Liu Xiaobo.
One hopes that this will lend comfort to him, and give a moral boost to Chinese who share his views. But it is unlikely to impress those who believe in the current orthodoxy of Chinese nationalism.
Until China is released from the grip of religious politics, Liu’s ideals are unlikely to take root.
This does not bode well for China, or, indeed, for the rest of the world.
A Drug War on Auto-Pilot
THE HAGUE – The war in Afghanistan, now approaching its tenth year, may seem to many to have no end in sight, but Latin America has endured an even longer fight, one that has recently become much more bloody: the “war” against drug trafficking.
So rote – and so violent – has that war become that many people in Latin America now wonder which side is suffering the more pathological addiction.
The new strategy that US Secretary of State Hillary Clinton has been promoting to staunch the upward trend of narco-trafficking-related murders – which leaked Mexican government reports put at more than 22,000 since late 2006 – is to build “stronger, more resilient communities.”
Ciudad Juárez, a sprawling Mexican border town that is now the homicide capital of the world, would have to be high on the list.
Four bridges and innumerable tunnels and drainage canals connect Ciudad Juárez and El Paso, Texas.
Rival cartels sparring for control of a plaza, the name given to any trafficking route, butcher each other and the security forces.
There is apparently no shortage of young, unemployed men willing to join the carnage.
Addressing the deep-seated social and economic problems of a city like Juárez, however, is a lot harder than flooding its streets with 8,000 soldiers carrying assault rifles.
Mexican President Felipe Calderón has, in this respect, remained faithful to the script written in previous theaters in the drug war, whether in Bolivia, Colombia, or Peru, where governments have used military force and extradition to placate the US and punish those with the least voice and influence.
But the language used by the Obama administration to describe the violence and state corruption that snakes from the Andes to the US border is starting to capture new thinking on narcotics.
Three former Latin American presidents, Mexico’s second richest man, Ricardo Salinas, and the Supreme Court of Argentina, among others, have criticized the war on drugs as a manifest failure that has lowered street prices, fueled production, and undermined weak states.
More strikingly, both Bolivia and Ecuador are governed by presidents who suffered directly from the collateral insensitivities of the war on drugs.
Bolivia’s Evo Morales rose to prominence as leader of the country’s coca growers during a brutal campaign to wipe out their crops, the so-called Dignity Plan.
Ecuadoran President Rafael Correa’s father was jailed for smuggling drugs to the US when the future leader was five years old.
These leaders’ profound ambivalence toward the goal of a world free of illegal drugs is shared by the European Union, where restrictions on narcotics consumption have slackened over the past decade.
The past three US presidents, furthermore, have all admitted to consuming – to one extent or another – illegal psychoactive substances, while seven million Americans, according to the United Nations, are regular cocaine users.
But the inertia of a bureaucratic drug-enforcement superstructure (worth approximately $40 billion each in the US and the EU), sustained by a deep-seated fear of the “threat” posed by drugs and cartels, appears to push policy repeatedly towards the familiar option of repressive auto-pilot.
For example, US support for Mexico’s campaign against the cartels looks set in stone, with Congress apparently ready to provide $300 million for another year of military and security upgrading.
In Colombia, seven new joint military installations are planned, and support for US private contractors who have cornered the market in crop fumigation presumably will not be interrupted.
Nevertheless, as the flaws in the four-decade-old edifice of counter-narcotics become more visible, it is increasingly difficult to regard the risks of drug use as being greater than the damage done by repression.
Prohibition hikes the mark-up on prices – an astounding 15,000% in the case of cocaine traveling to Europe from Andean processing facilities.
While the war on drugs focuses on bringing down cartels and their kingpins, it perversely aids the health of their markets, which nestle within legitimate trade flows and respond to price incentives.
Interviewed by the Mexican magazine Proceso this year, the second-in-command of the giant Sinaloa cartel, Ismael Zambada, made the point clearly: “The narco problem involves millions of people.
How do you control it?
The capos can be jailed, killed, or extradited, but their replacements are already wandering around.”
The emergence of Latin America’s powerful drug mafias cannot be traced to the radical evil of certain individuals.
These people emerged under conditions created in deeply inequitable societies by a misapplied, inconsistent, and bureaucratic war.
Indeed, the furies of the Zetas in Mexico originate in the counter-insurgency training provided in the 1990’s to a select group of special-forces soldiers, who later deserted.
The Zetas’ star recruits in recent years have come from the Guatemalan military’s special forces, whose infamous induction technique involved biting off the head of a live chicken.
Meanwhile, in Jamaica and across the rural outposts of Central America, drug lords have become benefactors and heroes to the poor.
It is time for serious reconsideration of the status and regulation of illegal drugs, pointing to selective legalization, as well as reclassification of the market as a public-health, rather than a criminal, concern.
For now, policymakers across the Americas are tiptoeing towards the obvious.
A Global "New Deal"?
ATHENS – The International Monetary Fund’s belated admission that it significantly underestimated the damage that austerity would do to European Union growth rates highlights the self-defeating character of “orthodox” recipes to address the causes of the debt crisis that followed the financial crash of 2008-2009.
Conventional theory suggests that a single country (or group of countries) consolidating its finances can expect lower interest rates, a weaker currency, and an improved trade position.
But, because this cannot happen for all major economies simultaneously – one country’s (or group of countries’) austerity implies less demand for other countries’ products – such policies eventually lead to beggar-thy-neighbor situations.
Indeed, it was this dynamic – against which John Maynard Keynes fought – that made the Great Depression of the 1930’s so grim.
Today’s problems are compounded by a lack of sufficient private demand – particularly household consumption – in the advanced economies to compensate for demand losses stemming from austerity.
During the last two decades, consumption drove these countries’ economic growth, reaching historically high GDP shares.
Moreover, major advanced economies, such as the United States, Germany, and Japan, face longer-term fiscal problems in the form of aging populations or oversize welfare states, limiting their capacity to contribute to demand management.
Recent moves to ease monetary policy have been a step in the right direction; but, so far, they have not proved to be a game changer.
For domestic demand to act as an engine of growth, policies should shift resources from investment to consumption.
While the magnitudes involved are huge, they must be attained if an extended period of low growth, high unemployment, and declining living standards among the world’s poorest is to be avoided.
International economic policy coordination should be significantly strengthened in order to deal effectively with changes on such a scale.
Start with Europe.
It is by now patently obvious that austerity and domestic reforms are not enough to pull the eurozone’s periphery out of deep recession.
Growing awareness of the failure of current policies is causing social discontent, civil disorder, and political instability, with the recently concluded Italian elections and the growing popular resistance to Greek reform efforts serving as a bellwether.
Returning the eurozone’s peripheral economies to the path of growth requires more than structural reforms and fiscal consolidation.
It also requires a substantial reform of the monetary union’s system of economic governance, aimed at restoring financial stability and lowering borrowing costs, together with a boost in external demand in order to compensate for the effects of austerity.
Reforming governance implies significant progress toward economic unification: centralizing European debt through Eurobonds, mobilizing sufficient rescue funds, allowing the European Central Bank to intervene in the primary bond markets, and establishing both a fiscal and a banking union.
This is a tall order, in view of the reluctance of most EU member states to cede competences to European institutions.
But Europe should move more decisively in this direction.
Otherwise, speculation on member states’ national debt will persist, keeping borrowing costs at levels that are inconsistent with the conditions required to sustain economic recovery.
Concerning external demand, intra-European help in the form of reflationary policies in stronger economies is unlikely to prove sufficient, owing primarily to the fiscal and political conditions prevailing in Germany.
Implementing a Marshall Plan-type initiative by mobilizing EU budget resources and additional lending by the European Investment Bank to finance investments in weaker countries could be an alternative, but it lacks political support.
On a global scale, neither the US nor Japan is in a position to provide significant external stimulus.
Only the emerging and developing economies of Asia could effectively contribute to lifting global demand through a coordinated effort aimed at boosting domestic consumption, which, in turn, would stimulate additional investment.
Recent IMF experience suggests that, through appropriate coordination, private funds could be mobilized for big private-public partnership projects linking demand expansion with infrastructure investment.
In other words, a global “New Deal” – combining policies designed to achieve an orderly realignment of consumption and investment worldwide – seems to be required.
The advanced economies should promote productivity-enhancing structural reforms with renewed vigor.
The eurozone should solidify its currency union.
And the emerging and developing economies should support domestic sources of growth.
For such a deal to become possible, certain preconditions must be met.
First, international policy coordination by the G-20 must be tightened by creating a permanent secretariat to make policy proposals and recommendations concerning macroeconomic and financial developments.
The secretariat should actively cooperate with the IMF to benefit from its analysis, notably regarding exchange rates.
Second, global financial reform must proceed at a faster pace.
The financial sector requires tougher regulation, strengthened supervision, and internationally consistent resolution mechanisms to address the problems posed by very large, global institutions that are considered too big (or too complex) to fail.
Such reform is essential if the international financial system is to mediate the sizeable resource transfers that will underpin the required changes in the structure of global demand.
Finally, a new trade pact – possibly, but not necessarily, within the Doha Round – is needed to ensure the major trading powers’ access to foreign markets.
This is critically important for inspiring confidence in Asian countries, which might be persuaded to favor domestic, as opposed to external, sources of demand.
Moreover, trade liberalization will also increase consumer confidence worldwide.
The time is right for a new global settlement that targets growth, addresses crisis conditions in certain parts of the world, and rebalances the global economy to set it back on a path of strong and steady growth.
The Other Financial Crisis
NEWPORT BEACH – Two variants of financial crisis continue to wreak havoc on Western economies, fueling joblessness and poverty: the one that we read about regularly in newspapers, involving governments around the world; and a less visible one at the level of small and medium-size businesses and households.
Until both are addressed properly, the West will remain burdened by sluggish growth, persistently high unemployment, and excessive income and wealth inequality.
The sovereign-debt crisis is well known.
In order to avert a likely depression, governments around the world engaged in fiscal and monetary stimulus in the midst of the global financial crisis.
They succeeded in offsetting nasty economic dislocations caused by private-sector deleveraging, but at the cost of encumbering their fiscal balances and their central banks’ balance sheets.
While sovereign credit quality has deteriorated virtually across the board, and will most probably continue to do so, the implications for individual countries vary.
Some Western countries – such as Greece – had fragile government accounts from the outset and tipped quickly into persistent crisis mode.
There they remain, still failing to provide citizens with a light at the end of what already has been a long tunnel.
Other countries had been fiscally responsible, but were overwhelmed by the liabilities that they had assumed from others (for example, Ireland’s irresponsible banks sank their budget).
Still others, including the United States, faced no immediate threat but failed to make progress on longer-term issues. A few, like Germany, had built deep economic and financial resilience through years of fiscal discipline and structural reforms.
It is not surprising that policy approaches have also varied.
Indeed, they have shared only one, albeit crucial (and disappointing) feature: the inability to rely on rapid growth as the “safest” way to deleverage an over-indebted economy.
Greece essentially defaulted on some obligations.
Ireland opted for austerity and reforms, as has the United Kingdom.
The US is gradually transferring resources from creditors to debtors through financial repression.
And Germany is slowly acquiescing to a prudent relative expansion in domestic demand.
So much for the sovereign-debt crisis, which, given its national, regional, and global impact, has been particularly well covered.
After all, sovereigns are called that because they have the power to impose taxes, regulations, and, at the extreme, confiscation.
But the other credit crisis is equally consequential, and receives much less attention, even as it erodes societies’ integrity, productive capabilities, and ability to maintain living standards (particularly for the least fortunate).
I know of very few Western countries where small and medium-size companies, as well as middle-income households and those of more limited means, have not experienced a significant decline in their access to credit – not just new financing, but also the ability to roll over old credit lines and loans.
The immediate causes are well known.
They range from subdued bank lending to unusually high risk aversion, and from discredited credit vehicles to the withdrawal of some institutions from credit intermediation altogether.
Such credit constraints are one reason why unemployment rates continue to rise in so many countries – often from already alarming levels, such as 25% in Greece and Spain (where youth unemployment is above 50%) – and why unemployment remains unusually high in countries like the US (albeit it at a much lower level).
This is not just a matter of lost capabilities and rising poverty; persistently high unemployment also leads to social unrest, erosion of trust in political leaders and institutions, and the mounting risk of a lost generation.
Indeed, unemployment data in many advanced countries are dominated by long-term joblessness (usually defined as six months or more).
Skill erosion becomes a problem for those with prior work experience, while unsuccessful first-time entrants into the labor force are not just unemployed, but risk becoming unemployable.
Governments are doing too little to address the private credit debacle.
Arguably, they must first sort out the sovereign side of the crisis; but it is not clear that most officials even have a comprehensive plan.
Policy asymmetry is greatest for the countries most acutely affected by the sovereign-debt crisis.
There, the private sector has essentially been left to fend for itself; and most households and companies are struggling, thus fueling continued economic implosion.
Other countries appear to have adopted a “Field of Dreams” – also known as “build it and they will come” – approach to private credit markets, In the US, for example, artificially low interest rates for home mortgages, resulting from the Federal Reserve’s policy activism, are supposed to kick-start prudent financing.
The European Central Bank is taking a similarly indirect approach.
In both places, other policymaking entities, with much better tools at their disposal, appear either unwilling or unable to play their part.
As such, action by central banks will repeatedly fail to gain sufficient traction.
In fact, only the UK is visibly opting for a more coordinated and direct way to counter the persistent shortfalls stemming from the private part of the credit crisis.
There, the “Funding for Lending Scheme,” jointly designed by the Bank of England and the Treasury, seeks “to boost the incentive for banks and building societies to lend to UK households and non-financial companies,” while holding them accountable for proper behavior.
The UK example is important; but, given the scope and scale of the challenges, the proposal is a relatively modest one.
The program may stimulate some productive credit intermediation, but it will not make a significant dent in what will remain one of the major obstacles to robust economic recovery.
Proper access to credit for productive segments is an integral part of a well-functioning economy.
Without it, growth falters, job creation is insufficient, and widening income and wealth inequality undermines the social fabric.
That is why any comprehensive approach to restoring the advanced countries’ economic and financial vibrancy must target the proper revival of private credit flows.
Toxic Politics Versus Better Economics
NEW YORK – The relationship between politics and economics is changing.
Advanced-country politicians are locked in bizarre, often toxic, conflicts, instead of acting on a growing economic consensus about how to escape a protracted period of low and unequal growth.
This trend must be reversed, before it structurally cripples the advanced world and sweeps up the emerging economies, too.
Obviously, political infighting is nothing new.
But, until recently, the expectation was that if professional economists achieved a technocratic consensus on a given policy approach, political leaders would listen.
Even when more radical political parties attempted to push a different agenda, powerful forces – whether moral suasion from G7 governments, private capital markets, or the conditionality attached to International Monetary Fund and World Bank lending – would almost always ensure that the consensus approach eventually won the day.
In the 1990s and 2000s, for example, the so-called Washington Consensus dominated policymaking in much of the world, with everyone from the United States to a multitude of emerging economies pursuing trade liberalization, privatization, greater use of price mechanisms, financial-sector deregulation, and fiscal and monetary reforms with a heavy supply-side emphasis.
The embrace of the Washington Consensus by multilateral institutions amplified its transmission, helping to drive forward the broader process of economic and financial globalization.
Incoming governments – particularly those led by non-traditional movements, which had risen to power on the back of domestic unease and frustration with mainstream parties – sometimes disagreed with the appropriateness and relevance of the Washington Consensus.
But, as Brazilian President Luiz Inácio Lula da Silva demonstrated with his famous policy pivot in 2002, that consensus tended largely to prevail. And it continued to hold sway as recently as almost two years ago, when Greek Prime Minister Alexis Tsipras executed an equally notable U-turn.
But after years of unusually sluggish and strikingly non-inclusive growth, the consensus is breaking down.
Advanced-country citizens are frustrated with an “establishment” – including economic “experts,” mainstream political leaders, and dominant multinational companies – which they increasingly blame for their economic travails.
Anti-establishment movements and figures have been quick to seize on this frustration, using inflammatory and even combative rhetoric to win support.
They do not even have to win elections to disrupt the transmission mechanism between economics and politics.
The United Kingdom proved that in June, with its Brexit vote – a decision that directly defied the broad economic consensus that remaining within the European Union was in Britain’s best interest.
The referendum happened for one reason: in 2013, then-Prime Minister David Cameron feared that he would be unable to secure sufficiently his Conservative Party base in the general election that year.
So he pandered to Euroskeptic voters with the promise of a referendum.
The source of Cameron’s fear?
The political disruption caused by the UK Independence Party – an anti-establishment party that ended up winning only one seat in Parliament and subsequently found itself leaderless and in turmoil.
Now, it seems, the floodgates have opened.
At the recent Conservative Party annual conference, speeches by Prime Minister Theresa May and members of her cabinet revealed an intention to pursue a “hard Brexit,” thereby dismantling trading arrangements that have served the economy well.
They also included attacks on “international elites” and criticism of Bank of England policies that were instrumental in stabilizing the British economy in the referendum’s immediate aftermath – thus giving May’s new government time to formulate a coherent Brexit strategy.
Several other advanced economies are experiencing analogous political developments.
In Germany, a surprisingly strong showing by the far-right Alternative für Deutschland in recent state elections already appears to be affecting the government’s behavior.
In the US, even if Donald Trump’s presidential campaign fails to put a Republican back in the White House (as appears increasingly likely, given that, in the latest twist of this highly unusual campaign, many Republican leaders have now renounced their party’s nominee), his candidacy will likely leave a lasting impact on American politics.
If not managed well, Italy’s constitutional referendum in December – a risky bid by Prime Minister Matteo Renzi to consolidate support – could backfire, just like Cameron’s referendum did, causing political disruption and undermining effective action to address the country’s economic challenges.
Make no mistake: solid and credible policy options are available.
After years of mediocre economic performance, there is widespread agreement that a shift away from excessive dependence on unconventional monetary policy is needed.
As IMF Managing Director Christine Lagarde put it, “central banks cannot be the only game in town.”
And yet they have been.
As I argue in The Only Game in Town, published in January, countries need a more comprehensive policy approach, involving pro-growth structural reforms, more balanced demand management (including higher fiscal spending on infrastructure), and better cross-border policy coordination and architecture.
There is also a need, highlighted by the protracted Greek crisis, to address pockets of severe over-indebtedness, which can have crushing impact extending well beyond the directly affected.
The emergence of a new consensus on these points is good news.
But, in the current political environment, translating that consensus into action is likely to happen too slowly, at best.
The risk is that, as bad politics crowds out good economics, popular anger and frustration will rise, making politics even more toxic.
One hopes that enlightened political leadership takes the reins in time to make the needed mid-course corrections voluntarily, before unambiguous signs of economic and financial crisis force policymakers to scramble to minimize the damage.
Another Lesson from Japan
NEW HAVEN – Yet another in a long string of negative inflation surprises is at hand.
In the United States, the so-called core CPI (consumer price index) – which excludes food and energy – has headed down just when it was supposed to be going up.
Over the three months ending in May, the core CPI was basically unchanged, holding, at just 1.7% above its year-earlier level.
For a US economy that is widely presumed to be nearing the hallowed ground of full employment, this comes as a rude awakening – particularly for the Federal Reserve, which has pulled out all the stops to get inflation back to its 2% target.
Halfway around the world, a similar story continues to play out in Japan.
But, for the deflation-prone Japanese economy, it’s a much tougher story.
Through April, Japan’s core CPI was basically flat relative to its year-earlier level, with a similar outcome evident in May for the Tokyo metropolitan area.
For the Bank of Japan (BoJ), which committed an unprecedented arsenal of unconventional policy weapons to arrest a 19-year stretch of 16.5% deflation lasting from 1994 to 2013, this is more than just a rude awakening. It is an embarrassment bordering on defeat.
This story is global in scope.
Yes, there are a few notable outliers – namely, the United Kingdom, where currency pressures and one-off holiday distortions are temporarily boosting core inflation to 2.4%, and Malaysia, where the removal of fuel subsidies has boosted headline inflation, yet left the core stable at around 2.5%.
But they are exceptions in an otherwise inflationless world.
The International Monetary Fund’s latest forecasts bear this out.
Notwithstanding a modest firming of global economic growth, inflation in the advanced economies is expected to average slightly less than 2% in 2017-2018.
The first chapter of this tale was written many years ago, in Japan.
From asset bubbles and excess leverage to currency suppression and productivity impairment, Japan’s experience – with lost decades now stretching to a quarter-century – is testament to all that can go wrong in large and wealthy economies.
But no lesson is more profound than that of a series of policy blunders made by the BoJ.
Not only did reckless monetary accommodation set the stage for Japan’s demise; the country’s central bank compounded the problem by taking policy rates to the zero bound (and even lower), embracing quantitative easing, and manipulating long-term interest rates in the hopes of reviving the economy.
This has created an unhealthy dependency from which there is no easy exit.
Though Japan’s experience since the early 1990s provides many lessons, the rest of the world has failed miserably at heeding them.
Volumes have been written, countless symposiums have been held, and famous promises have been made by the likes of former US Fed chairman Ben Bernanke never to repeat Japan’s mistakes.
Yet time and again, other major central banks – especially the Fed and the European Central Bank – have been quick to follow, with equally dire consequences.
The inflation surprise of 2017 offers three key insights.
First, the relationship between inflation and economic slack – the so-called Phillips curve – has broken down.
Courtesy of what the University of Geneva’s Richard Baldwin calls the “second unbundling” of globalization, the world is awash in the excess supply of increasingly fragmented global supply chains.
Outsourcing via these supply chains dramatically expands the elasticity of the global supply curve, fundamentally altering the concept of slack in labor and product markets, as well as the pressure such slack might put on inflation.
Second, today’s globalization is inherently asymmetric.
For a variety of reasons – hangovers from balance-sheet recessions in Japan and the US, fear-driven precautionary saving in China, and anemic consumption in productivity-constrained Europe – the demand side of most major economies remains severely impaired.
Juxtaposed against a backdrop of ever-expanding supply, the resulting imbalance is inherently deflationary.
Third, central banks are all but powerless to cope with the moving target of what can be called a non-stationary liquidity trap.
First observed by John Maynard Keynes during the Great Depression of the 1930s, the liquidity trap describes a situation in which policy interest rates, having reached the zero bound, are unable to stimulate chronically deficient aggregate demand.
Sound familiar?
The novel twist today is the ever-expanding global supply curve.
That makes today’s central banks even more impotent than they were in the 1930s.
This is not an incurable disease.
In a world of hyper-globalization – barring a protectionist relapse led by the America Firsters – treatment needs to be focused on the demand side of the equation.
The most important lesson from the 1930s, as well as from the modern-day Japanese experience, is that monetary policy provides no answer for a chronic deficiency of aggregate demand.
Addressing it is a task primarily for fiscal authorities. The idea that central banks should consider making a new promise to raise their inflation targets is hardly credible.
In the meantime, Fed Chair Janet Yellen is right (finally) to push the Fed to normalize policy, putting an end to a failed experiment that has long outlived its usefulness.
The danger all along has been that open-ended unconventional monetary easing would fail to achieve traction in the real economy, and would inject excess liquidity into US and global financial markets that could lead to asset bubbles, reckless risk taking, and the next crisis.
Moreover, because unconventional easing was a strategy designed for an emergency that no longer exists, it leaves the Fed with no ammunition to fight the inevitable next downturn and crisis.
We ignore history at great peril.
The latest disappointment for inflation-targeting central banks is really not a surprise after all. The same is true of the related drop in long-term interest rates.
There is much to be gained by studying carefully the lessons of Japan.
A Rest Stop for Europe
PRINCETON – Last week, in a highly anticipated speech, German President Joachim Gauck cautioned against the blind pursuit of an “ever-closer” European Union, acknowledging that the growing inequality among member states is generating “a sense of unease, even unmistakable anger,” and increasing the risk of national humiliation.
He pointed out that, in addition to the economic crisis, there is “a crisis of confidence in Europe as a political project.”
While Gauck made clear that he remains decidedly pro-Europe, he highlighted the need for closer reflection about Europe’s future – and especially that of the eurozone.
Standing on the verge of greater integration, Europeans are hesitant, “unsure whether we should really stride out on the onward journey.”
Addressing this hesitation, he declared, will require a thoughtful, nuanced understanding of what “more Europe” actually means.
Gauck may not have gone far enough: At this point, an ever-closer union may be a political mirage.
Any meaningful progress toward stabilizing the eurozone would require a significant – potentially open-ended – financial commitment, and the EU is not politically ready to cross that threshold.
Repeatedly pretending to move forward, then pulling back at the critical point, exacerbates political uncertainty and economic vulnerability.
Rather than indecisively pursuing more unity, this may be the moment to restore effective sovereignty to national authorities in eurozone countries.
Such a move would alleviate anxiety in the short term, thereby giving Europeans the opportunity to regroup in preparation for future steps toward a more integrated Europe and a more resilient euro.
To this end, eurozone leaders must take three key steps.
The dysfunctional system of European fiscal governance should be dismantled; fiscal responsibility should be returned to member states; and, to minimize the risk of excessive future lending, private lenders should be required to bear the losses implied by unsustainable sovereign debt.
The case against European fiscal governance is straightforward.
Before the crisis, the single-minded emphasis on reducing national budget deficits to less than 3% of GDP led to extensive abuse.
Either the target was openly flouted, as it was in leading economies like Germany and France, or the data were manipulated to obscure problems (a common practice throughout the eurozone, not just in Greece).
And the belief in economic growth as a fiscal panacea led to unrealistically optimistic GDP forecasts.
When the crisis struck, the 3% deficit target became the focal point for unrelenting austerity – a form of what anthropologist Clifford Geertz described as “involution,” which occurs when a process intensifies rather than changes in response to external or internal pressure.
In other words, EU leaders began to complicate fiscal governance, ultimately creating an inefficient, inescapable labyrinth of regulation and bureaucracy.
As fiscal metrics become increasingly intricate, monitoring efforts will become ever easier to undermine.
The case for returning fiscal responsibility to national authorities is also strong – and not only because centralized fiscal authority has proved to be so inefficient.
With citizens of distressed countries bearing the fiscal burden of the crisis, the enduring presumption that they will not act responsibly is patronizing, at best.
And the current strategy of exchanging goodies for good behavior encourages game-playing and dilutes responsibility.
While the risk that governments will succumb to fiscal temptation remains, citizens’ current suffering is likely to deter future excesses.
National fiscal sovereignty would facilitate the final crucial step: building a more mature relationship with private lenders.
The eurozone was founded on the “no bailout” principle: if member states could not repay their debts, lenders would bear the losses.
But lenders chose – correctly, as it turned out – to disregard that threat.
Instead of enforcing the no-bailout principle and establishing a precedent, debtor countries used official loans to repay private creditors.
As a result, these countries have condemned themselves to continued austerity, low growth, and high debt, while diminishing any future incentive for private lenders to impose fiscal discipline on sovereign borrowers.
Only by shifting the burden of responsibility back onto private lenders can debtor countries escape this quagmire.
In the United States, each state is responsible for its fiscal management, without being forced to comply with a single, overarching template.
The states are not regulated by the federal government; they are disciplined by the knowledge that no one will repay their debts for them.
And the system seems to work: entering the crisis, US states had significantly lower deficit and debt ratios than the eurozone’s vulnerable member states.
So far, European integration has largely been a process of “falling forward,” with each stumble serving as a lesson from which a stronger union emerges.
But, while this uncertain approach may suffice as a basis for declarations of good intentions, it does not inspire the confidence required for countries to make the profound financial commitment that is now needed.
Europeans should have the chance to regain their footing.
Transferring fiscal responsibility back to national authorities would not only mean the end of counterproductive efforts to manage fiscal affairs centrally; it would also diminish the sense of frustration and lack of control that is fueling Euro-skepticism.
In short, taking a step back would provide an opportunity to reset, to reflect, and to plot the best course toward a more stable, more integrated Europe.
For a fiscal union to function – however unlikely that outcome may be – a solid foundation is crucial.
As Gauck explained, Europeans “are pausing to… equip [themselves] both intellectually and emotionally for the next step, which will require [them] to enter uncharted territory.”
Giving Europeans the time and space to choose more Europe would reinforce the core values upon which integration has rested for more than six decades.
Continuing to stumble forward, however, would inevitably lead to a debilitating, if not fatal, fall.
A European Cure for Balkan Depression
VIENNA – European politics is mostly shaped by events and anniversaries.
But while events are often unforeseeable, anniversaries are not.
Five years from now, Europe will be reflecting on the 100th anniversary of the outbreak of World War 1, which led to a loss of life almost without parallel and set in motion a chain of events that led to the creation of Europe as we now know it.
World leaders may have already reserved some days in August 2014 to mark the occasion.
It is easy to predict that Sarajevo will be the place where they will meet to look back on Europe’s savage twentieth century.
But how will Sarajevo look in five years?
Will it still be the capital of a country whose citizens view the future bleakly and whose politicians have totally lost touch with the electorate?
Or is there a hope that European leaders will use the anniversary to announce the successful integration of the remaining Balkan countries into the European Union?
A Balkan Monitor survey recently conducted by Gallup Europe gives suggests the state of public opinion in Serbia, Montenegro, Macedonia, Albania, Croatia, Bosnia and Herzegovina, and Kosovo 20 years on from the fall of the Berlin Wall and a decade after the end of the Kosovo war.
The findings seem to indicate that the next five years will be a make-or-break period for the region’s future development.
While the overwhelming majority of citizens are convinced that further armed conflict in the region is unlikely, the public’s mood – with the exception of Kosovars and Albanians – is pessimistic.
The future promises peace without development.
Trust in political elites and in national and European institutions has been steadily declining.
The majority of citizens have experienced a decline in living standards in the last year, and there remains a perception that people have more opportunities outside their own countries.
Pessimism about employment is alarmingly high among young people, while corruption and government mismanagement are regarded as being widespread.
All those who have made it their job to praise the stability in the region should look at these figures.
Indeed, it is striking that the majority of citizens of Bosnia and Herzegovina believe that their leaders are not interested in their country joining the EU.
An absolute majority of citizens in each of the surveyed countries are convinced that their country is heading in the wrong direction.
Less than one in 10 Croats (whose country could be joining the EU in the near future) believes that their country is heading in the right direction.
There are now two options for the region: one is a “shock integration” program that takes all of the Western Balkan states into the EU; the other is a journey into the unknown. The hope that these countries can muddle through on their own is a dangerous illusion.
Stability alone can no longer be the EU’s only objective in the region.
The EU’s continuing presence as a colonial power in places like Bosnia and Herzegovina and Kosovo could cause even more problems in the future, especially if benefits are not forthcoming.
In particular, a delay in Serbia’s integration into the EU could bring Tito-inspired fantasies to the heart of the country’s foreign and security policy.
Thus, demoralization of Balkan society creates a dynamic of its own when the best and the brightest see their future outside of their own countries and where “stability” is just another name for political and economic stagnation.
If European leaders do plan to meet in 2014 in Sarajevo, they should act now.
The ratification of the Lisbon Treaty allows for an element of visionary realism in European politics, as there are no longer any institutional obstacles to the future enlargement of the EU.
Today, unlike a year ago, we know how many states are in the Balkans, and the Balkan Monitor results show that all of them want to join the Union.
What the EU has learned from the results of the last parliamentary elections in Bulgaria is that, contrary to conventional wisdom, the leverage of Brussels over new member states increases rather than diminishes after they join.
The EU’s decision to liberalize its visa regime for Serbia, Montenegro, and Macedonia – and the fact that George Papandreou, the major architect of the EU’s Balkan integration strategy, is back in power in Greece – is another source of optimism.
But it is now or never for the Balkans.
Visa liberalization can be a strategic step in the direction of “shock integration,” but if it is not followed by bold political action from the EU, it could merely become a re-packaging of the status quo.
In short, the moment has arrived for shaping events instead of simply marking anniversaries.
Closing Europe’s Strategy Gap
MADRID – The ongoing crisis in Ukraine has been a hot topic of analysis for almost a year.
But one question has largely escaped thorough examination: what Russia’s annexation of Crimea and invasion of eastern Ukraine indicates about the European Union’s foreign policy.
During the early stages of the crisis, Germany, which had bet heavily on Russia’s modernization, was averse to taking any consequential action.
But, as the crisis deepened, German Chancellor Angela Merkel worked to persuade her European counterparts to implement a broad and biting sanctions regime.
This certainly was a step in the right direction, but it did nothing to address the foreign-policy failings that helped spark the Ukrainian crisis and continue to undermine Europe’s response – namely, the EU’s misguided Neighborhood Policy (ENP) and its muddled approach to energy.
On both of these fronts, the EU’s lack of strategic vision has created the impression that Europe is repeatedly being outmaneuvered by Russian President Vladimir Putin.
It increasingly appears that Ukraine is becoming locked in a “frozen conflict” – Russia’s foreign-policy specialty.
Indeed, the situation in Ukraine represents a tactical victory for Russia, with the fragile but enduring ceasefire – and accompanying legislation that grants Donetsk and Luhansk considerable political autonomy – allowing Russia to entrench the conflict near the EU’s border.
Moreover, the delayed implementation of key elements of the EU’s association agreement with Ukraine is clear evidence that, at the moment, Russia dictates the terms of EU-Ukrainian engagement.
In Europe, the Kremlin has been able to pursue a successful divide-and-rule strategy, particularly in view of Hungary’s decision to suspend gas flows to Ukraine.
Prime Minister Viktor Orbán’s government, whose behavior in recent years has been at odds with the EU’s criteria for democracy, now openly approves of authoritarian regimes – and Putin’s, in particular – with serious potential consequences for European unity.
Nonetheless, the timing of the current ceasefire, which coincides with the installation of a new EU Commission, is advantageous, as is Putin’s shortsighted emphasis on tactical victories.
EU leaders should take advantage of the break in the fighting to stop reacting and start anticipating.
With a long-term strategic vision, the EU could overwhelm and ultimately undermine Putin’s short-term successes.
Such a vision must include a reconceptualization of the ENP.
The program’s mission – to help guide the political, social, and economic transitions of neighboring states – is not inherently problematic; the problem lies in the way that the mission has been interpreted and pursued.
For starters, the ENP assumes that all of the EU’s neighbors, both in the south and in the east, ultimately want to realize European values and structures in their own countries.
In other words, the ENP does not account for the developmental, cultural, and aspirational differences among the EU’s partner countries.
The ENP suffers operationally from its excessively technical approach and lack of strategic vision.
For example, before the Ukraine crisis, the European Commission was so focused on negotiating the technical features of the association agreement that it did not consider adequately the potential fallout of the process – such as, say, a response from Russia.
To be sure, the EU recognized its need for a coherent strategy, and attempted to resolve it by establishing the European External Action Service and the position of High Representative for Foreign Affairs.
But the EEAS ended up in a turf war with the European Commission, and outgoing High Representative Catherine Ashton did little to ease the tension, owing to her unwillingness to involve herself in intra-EU disagreements.
It is telling that Ashton has made progress exclusively in areas defined by ample consensus, such as the negotiations on Iran’s nuclear program and the pact between Kosovo and Serbia.
Further eroding Europe’s effectiveness is its fragmented approach to securing energy supplies.
With every country largely controlling its own energy policy, Europe’s energy market has become inefficient and excessively dependent on Russian supplies.
To the extent that there has been an EU-wide energy strategy, it has related to renewables, rather than the intersection of geopolitics and energy security.
But there is reason for hope.
The new Commission, which its president, Jean Claude Juncker, has restructured significantly, could provide Europe with the strategic leadership it so badly needs.
In fact, Juncker has already expressed a desire to integrate incoming High Representative Federica Mogherini into the Commission’s policy program.
The new structure – which tasks Mogherini with guiding and coordinating the work of multiple commissioners, including those responsible for trade, the ENP, and climate and energy – should strengthen the coherence and direction of EU policies, particularly after Mogherini completes her European Council-mandated assessment of the global strategic landscape.
But a restructured Commission is not enough to ensure a reset of Europe’s foreign-policy strategy.
For that to happen, Mogherini must assert herself as a leader, backed by Juncker and the new European Council president, Donald Tusk.
And, most important, all EU member states must recommit themselves to cooperation.
The Ukrainian people have demonstrated the power of Europe’s values.
Indeed, Europe has a large set of tools at its disposal; it just needs to figure out how to use them.
If it can, it will be better able to respond not only to the Russian challenge, but also to many of the other challenges that characterize today’s rapidly shifting global environment.
A Europe of Women?
PARIS – Are women in Europe on the verge of becoming an engine for political change?
In economic-development circles, experience and common sense suggest that progress, accountability, and hard work start with and depend on women.
Micro-credits, for example, are much more efficient when women receive and repay them.
Perhaps because they bear children and must find the means to feed them, women are now perceived as the best and most determined “agents of change.”
That seems to be as true now of European politics as it has been of economics in parts of Africa and Asia.
The results of Italy’s recent municipal elections could be a signal of an incipient electoral dynamic: it was women who voted Silvio Berlusconi’s party out of power in Milan, a city that he has long controlled (and the original seat of his power).
No direct link exists between that result and the dramatic Dominique Strauss-Kahn scandal in New York, but in the immediate aftermath of DSK’s arrest, Italian women and young voters decisively mobilized to defeat Berlusconi’s party (led in Milan, ironically, by a woman).
These voters could no longer stand the combination of machismo and vulgarity that had once served so well the man Italian humorists now call “Berlus-Kahn.”
When Berlusconi first came to power 17 years ago, he had the support of a majority of women.
They were not discouraged by his ambivalent perception of them (by turns celebrating their traditional domesticity and glorifying their sexual objectification).
But Italian society has changed: most women are now working, and they are no longer willing to accept Belusconi’s anachronistic and outrageous chauvinism.
Italian men may pity the aging, isolated leader, who looks increasingly like his wax effigy at Madame Tussaud’s.
But Italian women (indeed, women everywhere, it seems) feel only anger and humiliation over a man so obsessed with himself, his various criminal trials, and his vulgar pleasures that he appears to them to have no purpose left except to remain in power as long as possible.
Women, of course, are not alone in their opposition to Berlusconi, but they made the difference in Milan.
They are the incarnation of modernity, animated by a yearning for simple dignity and respect.
They are not alone in the vanguard of a new Europe of women.
As Iceland spiraled into bankruptcy, owing the irresponsible behavior of its mostly male political and financial elites, the people of Iceland decided that only a strong and responsible woman could redress the country’s problems.
So they elected one as President.
The depth and gravity of the current economic and social crisis in countries like Greece, Portugal, and Spain present women with a new opportunity.
Confronted with what many of them perceive as the equivalent of an “economic war,” women are playing an increasingly important role in maintaining their families’ financial security.
And the more widespread this becomes, the more women will seek a political role that reflects their economic clout.
Of course, women’s changing status may not translate immediately into growing political influence.
And the rest of Europe might never follow the example of Scandinavia, where gender equality has advanced much further than anywhere else.
But such a dynamic does now seem to be in motion.
Similarly, regardless of the outcome of DSK’s trial in New York, the case might represent a turning point in the treatment of women in Europe.
Public and private displays of atavistic machismo, one hopes, will no longer be considered acceptable.
In the Arab world, too, from Tunis to Cairo, young women have played an important role in the revolutionary process.
Their appetite for change – understandable, given the treatment of women in traditional Muslim societies – appears to be one of the main causes underlying the force of the revolutionary impulse in Tunisia and Egypt.
None of this is to argue that “women” are a universal force for positive change in Europe and around the world.
Consider, for example, Marine Le Pen, the new head of France’s National Front, Elena Ceaucescu, the sordid wife of the former Romanian dictator, or, more recently, Tunisian ex-President Zine El Abidine Ben Ali’s wife, Leila Trabelsi, who fled to Dubai with 1.5 tons of gold plundered from the central bank.
The point, simply, is that with so many people in so many countries demanding far-reaching change, the politics of gender is very much in play – in Europe and beyond.
The main question is whether the growing number of women in politics will deliver the different perspectives and modes of leadership that many voters (or protesters) now seem to crave.
A Euro Sabbatical
MUNICH – Under substantial external pressure, the eurozone’s crisis-hit countries are, at long last, bringing themselves to make painful cuts in their government budgets.
Salaries are being slashed and public employees sacked to reduce new borrowing to a tolerable level.
And yet, competitiveness in Greece and Portugal, in particular, is not improving.
The latest Eurostat figures on the evolution of the price index for self-produced goods (GDP deflator) show no tendency whatsoever in the crisis-stricken countries towards real devaluation. But real devaluation, achieved by lowering prices vis-à-vis their eurozone competitors, is the only way to re-establish these countries’ competitiveness.
A reduction in unit labor costs can also increase competitiveness only to the extent that it actually results in price reductions.
After all, it was price inflation in the crisis countries, fueled by massive inflows of cheap credit following the introduction of the euro, that resulted in their loss of competitiveness, ballooning current-account deficits, and accumulation of enormous foreign debt.
Now that capital markets are no longer willing to finance these deficits, prices should be going into reverse, but this, obviously, is not happening.
In 2010, inflation in some of the crisis countries lagged slightly behind that of their eurozone competitors.
The latest Eurostat figures for the third quarter of 2011, however, are already showing a different picture: the price level in Portugal and Greece has remained practically unchanged over the course of the year, and in Italy and Spain it even rose slightly (by 0.4% and 0.3%, respectively).
Only Ireland continued on a path of rapid deflation – as it has since the country’s real-estate bubble burst in 2006 – with a relative price decrease of 2.2%.
On the whole, Ireland has become cheaper relative to its eurozone competitors by a total of 15% over the course of the past five years.
This internal devaluation is paying off: while Ireland was still running a current-account deficit of 5.6% of GDP in 2008, the European Commission expects the outturn for 2011 to have been a 0.7%-of-GDP current-account surplus.
True, much of this is mere debt-service relief, given that Ireland was able to repay its foreign liabilities with self-printed money, for which it pays only 1% interest.
However, Ireland’s big trade surplus did improve further.
Ireland owes much of this turnaround to its efficient export sector, whose supporters were able to enforce a political U-turn.
Greece, on the other hand, is under the influence of a strong import lobby.
As the Greek economics minister, Michalis Chrysochoidis, has said, this is attributable to European Union subsidies, which drove entrepreneurs to follow the easy money into the import sector.
Now these importers form a powerful bulwark against any policy that causes deflation, even though lowering prices – and thereby redirecting Greek demand from foreign to domestic products and helping tourism – is the only way to put the Greek economy back on its feet.
Since Greece’s current-account deficit as a share of GDP was three times higher than Ireland’s, Greek prices would have to fall by about half to achieve the same kind of success.
It is inconceivable that Greece could manage that within the eurozone without widespread social unrest, if not conditions approaching those of civil war.
But it isn’t just importers who are blocking real devaluation. Unions, too, are resisting the necessary wage reductions, and public and private debtors fear the prospect of insolvency if their assets and revenues are assessed at a lower value, while their debts remain unchanged.
The situation is intractable.
Many people regard debt relief and socialization of debts as the only way out.
This help has been given.
The recent agreement gave Greece relief of €237 billion ($316 billion), about 30% more than Greece’s net national income of roughly €180 billion euros.But such help only entrenches the wrong prices – and thus the economy’s lack of competitiveness.
The debts will re-emerge like a tumor, growing year by year, while undermining the creditworthiness of stable eurozone countries.
If that happened, the euro would eventually collapse.
Only a price reduction would create current-account surpluses and enable the crisis countries to pay off their foreign debts.
It is time for Europe to come to terms with this remorseless truth.
Those crisis countries that do not want to take it upon themselves to lower their prices should be given the opportunity to leave the eurozone temporarily in order to devalue prices and debts.
In other words, they should take a kind of euro sabbatical – a proposal that has now also been taken up by American economist Kenneth Rogoff.
After the ensuing financial thunderstorm died down, the sun would come out again very quickly.
The creditor countries would have to shoulder big losses from write-downs, but they would still end up with more than they would have gotten had the crisis countries remained within the eurozone, because these countries’ new prosperity, gained by leaving, offers the only chance of recovering any assets at all.
A Fair Deal for Turkey
Turkey has been given what looks like an ultimatum from the EU Commission: open your ports for ships from Cyprus within a month, or you may risk a halt to the EU accession talks now underway.
At the same time, the Commission’s latest report on Turkey’s progress toward accession notes that political reforms have slowed down, further calling into question the country’s future EU membership.
The Commission’s progress report will be dealt with by the European Council next month.
At that meeting, European leaders should ask themselves the following questions: Has the EU given Turkey a fair deal in the case of Cyprus?
Has the EU’s behavior been consistent in supporting political reform in Turkey?
What are the EU’s long-term interests vis-à-vis Turkey?
If the answers to the first two questions are “no” – as I believe they are – the third question becomes vitally important.
True, Turkey has closed its ports to ships from (Greek) Cyprus, and this is a violation of agreements.
But it is also true that the northern Turkish part of Cyprus is denied access to free trade and other benefits from EU-membership.
This is because Cyprus remains a divided island.
It was assumed that Cyprus should be united when the country joined the EU in 2004.
A United Nations plan for unification was accepted by the Turkish part.
But the Greek Cypriots voted against the plan because their leaders did not live up to the implicit deal with the EU to support it.
Nevertheless, Cyprus became an EU member – but only the Greek part.
This was clearly a mistake, because it made the EU part of the conflict.
It gave Greek Cypriot leaders the possibility of blocking progress in negotiations between the EU and Turkey.
So how can Turkey under these conditions maintain confidence in the EU’s fairness?
Political and legal reforms in Turkey in recent years have been remarkably far-reaching, for they have clearly been spurred by Turks’ wish to move closer to the EU.
But Turkish public support for EU membership has fallen dramatically as Turks have grown to feel that they are not being given a fair deal.
This has given new strength to those who want Turkey to develop in another direction, towards a more Islamic society instead of a modern secular state.
Therefore, the recent lack of progress in Turkey’s reform process can to a large extent be explained by the EU’s behavior.
This leaves us with the third question: what kind of Turkey does the EU want?
There should be no doubt about the answer: it is clearly in the EU’s interest to see Turkey’s democracy and economy continue to strengthen.
More than 40 years ago, it was promised that once Turkey lives up to the preconditions for membership, it will be welcome in the EU.
It is high time that European leaders take this promise seriously.
It is a sad fact that a large majority of voters in the EU are against Turkish membership.
But they are reacting to the current situation.
When they are asked if they would like a reformed Turkey as a partner – a Turkey that lives up fully to the conditions for membership described in the Copenhagen Criteria (democracy, rule of law, respect for human rights, and an effective market economy) – many more are inclined to say yes.
European leaders must therefore take up two challenges.
First, they should say clearly to their own voters that the EU must live up to its promises to Turkey, and that this is in the larger interest of all Europeans.
Second, they should give Turkey a fair deal in the negotiations.
The first litmus test on European leadership concerns the practical problem of access to harbors.
Here the Finns, who chair the EU right now, have taken an initiative to implement a pragmatic solution that takes into consideration both sides in the conflict.
The Finnish initiative should be given strong support from all European leaders.
At the same time, a new effort should be made to bring life to the UN’s proposals regarding Cyprus.
If this means putting pressure on some actors within the EU’s own ranks, so be it.
A Farewell to (Glorious) War
In recent days, Italy’s government fell after losing a parliamentary vote on the country’s troop deployment in Afghanistan, while Britain and Denmark announced that they are to begin withdrawing their troops from Iraq.
Whereas the Bush administration is deploying an additional 21,000 American soldiers in Iraq, and is pushing for more allied troops in Afghanistan, America’s allies are rejecting its Middle East policy.
They are increasingly convinced that “victory” will be elusive in any asymmetric conflict between states, however powerful, and religiously driven armed insurgents.
Donald Rumsfeld’s dogma of military “transformation” – the technological upgrading of an army’s capacity to enable decisive victory with fewer troops – failed resoundingly in Iraq.
Nor could Israel, with its overwhelming technological advantage, defeat Hezbollah in Lebanon.
More rockets and missiles fell on northern Israel in 33 days than hit Britain during all of World War II.
So the Israelis now must reckon with an entirely new phenomenon: an asymmetric entity, Hezbollah, with nation-state firepower.
So the fierce debate over whether to increase the size of American ground forces in Iraq is beside the point.
Neither the Soviet experience in Afghanistan in the 1980’s nor NATO’s today vindicates the claim that troop numbers are what matter most on the modern battlefield.
When geo-strategic military front lines are non-existent, as in Kosovo, Afghanistan, and Iraq, mass no longer equals victory.
The great military thinker Carl von Clausewitz’s notion of “decisive battles” as the “center of gravity” of war is simply irrelevant to conflicts that have no visible “center of gravity.”
Indeed, while wars from the time of Hannibal’s defeat of the Romans in 216 B.C. to the Gulf War of 1991 had this center of gravity, with a massive concentration of force capable of bringing an enemy to its knees, such industrial inter-state wars have now become an historical anachronism.
Most states nowadays lie within borders that are widely accepted as legitimate, and they increasingly abide by international norms of behavior in times of war.
In fact, the obligation of states to abide by humanitarian rules of conduct while their enemies are free to barbarize warfare is what makes asymmetric wars especially insoluble.
Moreover, in an era of global media and international war crimes courts, the criteria for states’ use of military force have become more complex than ever.
Inter-state combat may still occur where strategic front lines can be found, such as Israel’s border with Syria, India’s border with Pakistan, and the border dividing the two Koreas.
In such cases, war, as the Egyptians showed in 1973, might still serve as an avenue to resolving a conflict.
The Syrians might be tempted to launch an offensive against Israel with the objective of breaking the deadlock over the future of the Golan Heights.
However, in the case of Kashmir, the asymmetric conflict currently fought by proxies and terrorist groups might not degenerate into all-out war precisely because India and Pakistan have mutual nuclear deterrence.Indeed, such asymmetric conflicts through proxies have become the new conventional way that states avoid the price of a general war.
This changing nature of the battlefield essentially means that war as a conclusive event in an international conflict has become obsolete.
The facile Clausewitzian wisdom that military action ultimately leads to a political solution is no longer convincing.
“Victory” cannot bring peace, simply because there will always be a war after the war.
Thus, for example, the conventional war in Kosovo lasted for two months, only to usher in a six-year asymmetric conflict.
Likewise, America’s three-week “shock and awe” campaign in Iraq in 2003 ended in “victory,” but opened the gates of hell for occupiers and ordinary Iraqis alike.
And six months after the merciless pounding of southern Lebanon, Hezbollah is as strong as it was before.
Nor does the return of the Taliban in Afghanistan six years after their overthrow now seen too far-fetched.
It is during the war after the war that the occupier’s inferiority is revealed, with constant reinforcements increasing the number of targets for the insurgents far more quickly than the occupier can adapt to the changing battlefield.
The insurgents in Iraq, as the British admit, were able in just three years to cope with their enemies’ technological superiority in a way that the IRA in Northern Ireland was unable to do in 30 years.
The Iraq war and Israel’s wars with Hamas and Hezbollah show the limits of what military power can achieve, as well as vindicate diplomacy and conflict resolution.
When it comes to tackling complex political and cultural conflicts, forging international and regional alliances around a legitimate objective is more important than sheer military capacity.
That said, it would be dangerously naïve to believe that the exercise of power and the capacity to intimidate are unnecessary.
But the objectives of the use of force need to be linked to the recognition that in today’s asymmetric conflicts, victory is no longer achieved on the battlefield.
Only better-informed foreign policies that can address the genuine anxieties of civilizations in crisis will yield more sustainable results.
A Farewell to Nuclear Arms
MOSCOW – Twenty-five years ago this month, I sat across from Ronald Reagan in Reykjavik, Iceland to negotiate a deal that would have reduced, and could have ultimately eliminated by 2000, the fearsome arsenals of nuclear weapons held by the United States and the Soviet Union.
For all our differences, Reagan and I shared the strong conviction that civilized countries should not make such barbaric weapons the linchpin of their security.
Even though we failed to achieve our highest aspirations in Reykjavik, the summit was nonetheless, in the words of my former counterpart, “a major turning point in the quest for a safer and secure world.”
The next few years may well determine if our shared dream of ridding the world of nuclear weapons will ever be realized.
Critics present nuclear disarmament as unrealistic at best, and a risky utopian dream at worst.
They point to the Cold War’s “long peace” as proof that nuclear deterrence is the only means of staving off a major war.
As someone who has commanded these weapons, I strongly disagree.
Nuclear deterrence has always been a hard and brittle guarantor of peace.
By failing to propose a compelling plan for nuclear disarmament, the US, Russia, and the remaining nuclear powers are promoting through inaction a future in which nuclear weapons will inevitably be used.
That catastrophe must be forestalled.
As I, along with George P. Shultz, William J. Perry, Henry A. Kissinger, Sam Nunn, and others, pointed out five years ago, nuclear deterrence becomes less reliable and more risky as the number of nuclear-armed states increases.
Barring preemptive war (which has proven counterproductive) or effective sanctions (which have thus far proven insufficient), only sincere steps toward nuclear disarmament can furnish the mutual security needed to forge tough compromises on arms control and nonproliferation matters.
The trust and understanding built at Reykjavik paved the way for two historic treaties.
The 1987 Intermediate-Range Nuclear Forces (INF) Treaty destroyed the feared quick-strike missiles then threatening Europe’s peace.
And, in 1991, the first Strategic Arms Reduction Treaty (START I) cut the bloated US and Soviet nuclear arsenals by 80% over a decade.
But prospects for progress on arms control and nonproliferation are darkening in the absence of a credible push for nuclear disarmament.
I learned during those two long days in Reykjavik that disarmament talks could be as constructive as they are arduous.
By linking an array of interrelated matters, Reagan and I built the trust and understanding needed to moderate a nuclear-arms race of which we had lost control.
In retrospect, the Cold War’s end heralded the coming of a messier arrangement of global power and persuasion.
The nuclear powers should adhere to the requirements of the 1968 Non-Proliferation Treaty and resume “good faith” negotiations for disarmament.
This would augment the diplomatic and moral capital available to diplomats as they strive to restrain nuclear proliferation in a world where more countries than ever have the wherewithal to construct a nuclear bomb.
Only a serious program of universal nuclear disarmament can provide the reassurance and the credibility needed to build a global consensus that nuclear deterrence is a dead doctrine.
We can no longer afford, politically or financially, the discriminatory nature of the current system of nuclear “haves” and “have-nots.”
Reykjavik proved that boldness is rewarded.
Conditions were far from favorable for a disarmament deal in 1986.
Before I became Soviet leader in 1985, relations between the Cold War superpowers had hit rock bottom.
Reagan and I were nonetheless able to create a reservoir of constructive spirit through constant outreach and face-to-face interaction.
What seem to be lacking today are leaders with the boldness and vision to build the trust needed to reintroduce nuclear disarmament as the centerpiece of a peaceful global order.
Economic constraints and the Chernobyl disaster helped spur us to action.
Why has the Great Recession and the disastrous meltdown at Fukushima Daiichi in Japan not elicited a similar response today?
A first step would be for the US finally to ratify the 1996 Comprehensive Test Ban Treaty (CTBT).
President Barack Obama has endorsed this treaty as a vital instrument to discourage proliferation and avert nuclear war.
It’s time for Obama to make good on commitments he made in Prague in 2009, take up Reagan’s mantle as Great Communicator, and persuade the US Senate to formalize America’s adherence to the CTBT.
This would compel the remaining holdouts – China, Egypt, India, Indonesia, Iran, Israel, North Korea, and Pakistan – to reconsider the CTBT as well.
That would bring us closer to a global ban on nuclear tests in any environment – the atmosphere, undersea, in outer space, or underground.
A second necessary step is for the US and Russia to follow up on the New START agreement and begin deeper weapons cuts, especially tactical and reserve weapons, which serve no purpose, waste funds, and threaten security.
This step must be related to limits on missile defense, one of the key issues that undermined the Reykjavik summit.
A fissile material cut-off treaty (FMCT), long stalled in multilateral talks in Geneva, and a successful second Nuclear Security Summit next year in Seoul, will help secure dangerous nuclear materials.
This will also require that the 2002 Global Partnership, dedicated to securing and eliminating all weapons of mass destruction – nuclear, chemical, and biological – is renewed and expanded when it convenes next year in the US.
Our world remains too militarized.
In today’s economic climate, nuclear weapons have become loathsome money pits.
If, as seems likely, economic troubles continue, the US, Russia, and other nuclear powers should seize the moment to launch multilateral arms reductions through new or existing channels such as the UN Conference on Disarmament.
These deliberations would yield greater security for less money.
But the buildup of conventional military forces – driven in large part by the enormous military might deployed globally by the US – must be addressed as well.
As we engage in furthering our Conventional Forces in Europe (CFE) agreement, we should seriously consider reducing the burden of military budgets and forces globally.
US President John F. Kennedy once warned that “every man, woman, and child lives under a nuclear sword of Damocles, hanging by the slenderest of threads, capable of being cut at any moment.”
For more than 50 years, humanity has warily eyed that lethal pendulum while statesmen debated how to mend its fraying cords.
The example of Reykjavik should remind us that palliative measures are not enough.
Our efforts 25 years ago can be vindicated only when the Bomb ends up beside the slave trader’s manacles and the Great War’s mustard gas in the museum of bygone savagery.
Affirmative Action for Europe
The violence in France, fueled by staggering unemployment and ruthless policing, reflects the utter failure of the French model of social integration.
But violence elsewhere in Europe, such as the London bombings of July and the brutal murder of Dutch filmmaker Theo van Gogh on the streets of Amsterdam in November 2004, had already made Europe’s failure to integrate its minorities painfully clear.
As the riots in France fade, French politicians are agonizing about how to proceed.
Forty years ago, after legal segregation of blacks and whites formally ended in America, the United States was confronted by similar problems.
America’s response shows, however, that integration cannot be viewed as a one-way street.
In addition to imposing demands and constraints on minorities to join the mainstream, society must be willing to demand of itself that it make room for all its citizens.
As a potential model to be followed, Europe should look at the so-called “affirmative action” policies that America enacted to provide opportunities to blacks.
Affirmative action, or “positive discrimination,” as some have called these policies, began with university admissions.
But, in the early 1970’s, President Richard M. Nixon expanded the scope of affirmative action.
As a result, ethnicity began to be weighed as a positive factor not only in university admissions, but also in public procurement decisions, credit facilities for small enterprises, and government hiring.
The rational for affirmative action in those early years was the fact that, after a long history of systemic injustice, merely outlawing discrimination based on race or gender would not ensure equal opportunity for all.
Such programs are often viewed as contradicting a basic American value, namely that admissions, lending, and hiring decisions should be based on the merits of the individual, not group distinctions.
But they remain in existence three decades later.
Indeed, leading American companies, like General Motors, General Electric, and Walmart, have created affirmative action programs for hiring and selecting suppliers at their own initiative.
Similarly, anchormen and anchorwomen from all ethnic backgrounds populate American television news programs.
In France, by contrast, the appointment of the black anchorwoman Audrey Pulvar was big news on its own, because most of her colleagues in France are white.
Affirmative action in the US has been effective in creating a large African-American middle class.
The percentage of black households earning over $50,000 a year (adjusted for inflation) has more than tripled over the last four decades, from 9.1% in 1967 to 27.8% in 2001.
Indeed, in the US, more people of color and women hold top jobs in the public and private sector than anywhere else in the world.
The fact that a large black underclass remains – something the recent floods in New Orleans revealed in a horrifically dramatic way – is mainly the result of failing school systems.
Affirmative action programs, of course, have always been vulnerable to attack by those who can’t benefit from them.
In 2003, a white student asked the US Supreme Court to declare that the use of race in the University of Michigan’s admission policies violated the Equal Protection Clause of the Fourteenth Amendment of the US Constitution.
The Supreme Court, however, ruled that the program was constitutional, citing a “compelling state interest” in racial diversity.
“Effective participation by members of all racial and ethnic groups in the civil life of our nation,” the court said, “is essential if the dream of one nation, indivisible, is to be realized.”
In reaching its decision, the Supreme Court took into account a legal brief submitted by 60 major American businesses, led by General Motors, asking that affirmative action be upheld.
They argued that the skills needed in today’s global marketplace can only be developed through exposure to a wide diversity of people.
Retired military officers and commanders told the court that affirmative action was essential to maintaining an integrated officer corps.
What America’s affirmative action programs may not do is set quotas for minorities, as this prevents competition between different groups.
But, in comparing groups, it is permitted to use an individual’s status as member of an under-represented minority in his or her favor.
As a result, a university may select a black student with a satisfactory score on the admissions test, even if there is a white student with a better score.
From the current French viewpoint, however, laws and regulations based on ethnicity are regarded as an unwelcome encroachment on the Republican ideal.
French President Jacques Chirac vehemently opposes quotas for immigrants, out of fear that such a policy would stigmatize groups.
And French businesses don’t see it as their role to solve the problems of the suburbs.
Moreover, French Interior Minister Nicolas Sarkozy hasn’t done much except hand out some special grants to the smartest immigrants from the suburbs.
France does have affirmative action programs, but they address poverty, not ethnicity.
If European politicians are serious about preventing a schism between population groups, affirmative action is essential – not only at the workplace, but also for small business loans, home loans, public procurement, and school admissions.
Tony Blair, who in July was faced with the shortcomings of integration in the UK, should take advantage of the country’s current presidency of the European Union to make affirmative action programs the top priority at next month’s summit of European government leaders in Brussels.
Affordable Green Energy
COPENHAGEN – Public skepticism about global warming may be growing, but the scientific consensus is as solid as ever: man-made climate change is real, and we ignore it at our peril.
But if that issue is settled (and it should be), there is an equally large and important question that remains wide open: what should we do about it?
One prescription that is bandied about with increasing frequency certainly sounds sensible: the world should drastically cut the amount of greenhouse gases that it pumps into the atmosphere each day.
Specifically, we are told, the goal should be a 50% reduction in global carbon-dioxide emissions by the middle of the century.
Even its backers concede that achieving this target won’t be easy – and they are right.
In fact, they are so right that they are wrong.
Allow me to explain.
Our dependency on carbon-emitting fuels is more than enormous. It is overwhelming.
For all the talk about solar, wind, and other hyped green-energy sources, they make up only 0.6% of global energy consumption. Renewable energy overwhelmingly comes from often-unsustainable burning of wood and biomass by people in the Third World.
Fossil fuels account for more than four-fifths of the world’s energy diet.
So, in order to cut global carbon emissions in half by the middle of the century, we would obviously have to start getting a lot more of our energy from sources that don’t emit carbon.
Can we do this?
According to the International Energy Agency, here’s what it would take to achieve the goal of cutting emissions by 50% between now and mid-century:
Now consider this: this list does not describe what we would have to build between now and 2050, but what we would have to build each and every year until then!
One more thing: even if we managed to do all this (which we obviously cannot), the impact on global temperatures would be hardly noticeable by 2050.
According to the best-known climate-economic model, this vast undertaking would likely wind up reducing global temperatures by just one-tenth of one degree centigrade (one-fifth of one degree Fahrenheit), while holding back sea-level rises by only one centimeter (less than half an inch).
That’s not a lot of bang for the buck.
Indeed, the projected costs of this approach – some $5 trillion annually by mid-century – are so much greater than its likely benefits that it makes no sense to call it a solution at all.
Fortunately, there is a better, smarter way to deal with global warming.
What if, instead of spending trillions of dollars trying to build an impossible number of power plants – or, more likely, condemning billions of people around the world to continued poverty by trying to make carbon-emitting fuels too expensive to use – we devoted ourselves to making green energy cheaper?
Right now, solar panels are so expensive – about 10 times more than fossil fuels in terms of cost per unit of energy output – that only well-heeled, well-meaning (and, usually, well-subsidized) Westerners can afford to install them.
But think where we’d be if we could improve the efficiency of solar cells by a factor of ten – in other words, if we could make them cheaper than fossil fuels.
We wouldn’t have to force (or subsidize) anyone to stop burning coal and oil.
Everyone, including the Chinese and the Indians, would shift to the cheaper and cleaner alternatives – and global emission targets would automatically be met.
Can we achieve this technological miracle over the next 20 to 40 years?
In a word, yes.
The price of solar energy has been dropping steadily for 30 years – by about 50% every decade – and we could likely accelerate that decline further with sufficiently large investments in research and development.
How large?
If we were willing to devote just 0.2% of global GDP (roughly $100 billion a year) to green-energy R&D, I believe that we could bring about game-changing breakthroughs not just for solar power, but also for a wide variety of other alternative-energy technologies.
This belief in the potential of technological progress strikes some climate activists as naïve or even delusional.
But is it really?
Consider one of the miracles of the modern age – the personal computer.
These devices didn’t become household items because governments subsidized purchases or forced up the price of typewriters and slide rules.
No, what happened is that, largely as a result of the space race, the United States government poured lots of money into R&D for solid-state physics and electronics engineering. The resulting breakthroughs not only got Neil Armstrong to the moon in 1969, but also made it possible for Apple to introduce the first Mac in 1976 and IBM to debut the first PC five years later.
We can do the same for clean energy.
Forget about subsidizing inefficient technologies or making fossil fuels too expensive to use. Instead, let’s fund the basic research that will make green energy too cheap and easy to resist.
Afghanistan Is Lost Without Better Governance
NEW YORK – President Obama's recent trip to Afghanistan highlighted the growing American and international perception that without better governance Afghanistan will fail.
As President Obama apparently made clear in his late night meeting with President Hamid Karzai, no matter what other progress is made, America and its allies cannot succeed in Afghanistan unless the Afghan government succeeds—and that government is moving in the wrong direction.
Until this changes, all other efforts will ultimately be in vain and current levels of international engagement with Afghanistan will become unjustifiable.
The United States and its Afghan and NATO allies have demonstrated unmistakable progress in Afghanistan this year.
The ongoing Marja campaign, the arrest of Mullah Abdul Ghani Baradar and two Taliban "shadow governors" in Pakistan, and the recent drone strike hitting top leaders of the Al Qaeda-affiliated Haqqani network are all clear steps in the right direction.
President Obama has defined America's goals in Afghanistan as denying Al Qaeda a safe haven, reversing the Taliban's momentum, and helping the country's security forces and government "take lead responsibility for Afghanistan’s future."
To this end, Obama launched an 18-month military "surge" with the backing of other NATO member countries, to be followed by the beginning of withdrawal.
To achieve these goals in such a short time, NATO and its Afghan partners must overcome three enormous obstacles.
First, they must fight far more successfully against the Taliban to create space for rebuilding and possible negotiation.
Second, they must convince Pakistan to begin actively opposing the Afghan Taliban and denying them the safe haven and support they currently receive in Pakistan.
Third, they must support the emergence of a legitimate Afghan government that is not, unlike the current government, seen as corrupt and ineffectual by its citizens.
Because the NATO strategy's success requires significant progress on each of these fronts, even the current preliminary signs of military progress and in Pakistan's relations with the Afghan Taliban will be for naught if Afghanistan's government cannot establish its legitimacy domestically.
Recent efforts by President Hamid Karzai’s administration to limit its public accountability demonstrate that the Afghan government in its current form lacks either the capacity or the willingness to do so.
For at least a year prior to the August 2009 elections, NATO officials recognized that ordinary Afghans' disgust with their government's massive corruption was among the Taliban's most effective recruitment tools.
At that time, these officials argued that the elections would give Afghanistan’s leaders a clear mandate for reform.
The deeply discredited elections put an end to those hopes.
The original flaw of the 2009 elections was structural. There was no voter list, and so it was nearly impossible to prevent ballot-stuffing.
The body empowered to conduct the vote, the Independent Election Commission, was run by commissioners all appointed by and partial to one candidate, Karzai.
One institution, the Electoral Complaints Commission—a hybrid Afghan-international oversight body with a majority vote controlled by United Nations-appointed commissioners—retained its credibility throughout the process.
Only the presence of the ECC, particularly its international commissioners, and the hope that it would ensure at least some fairness into the process prevented the electoral controversy from erupting into open conflict.
As flawed as the elections were and as contentious as the outcome ultimately was, the situation would have been far worse without the ECC.
After the election, many hoped that Karzai would recognize the need to build a more accountable government to help secure both Afghanistan's future and the future of international military and financial support.
In a high-profile speech in London this past January, Karzai pledged to make progress in fighting corruption and promoting government accountability.
Instead, the opposite appears to be happening.
Since his London speech, Karzai has actively opposed efforts to attack official corruption, sought to appoint warlords to his cabinet, failed to promote civil society, and weakened processes aimed at increasing the representation of women in parliament.
To make matters worse, Karzai issued a decree on February 13 permitting him to appoint all of the ECC's members, a measure clearly designed to strengthen the patronage system and weaken opposition movements’ prospects in future elections and a strong demonstration that his administration is not serious about establishing greater government accountability.
NATO and the international community must do everything possible to foster accountable government at all levels in Afghanistan.
Although Afghanistan's government does not need to be fully centralized, Afghanistan cannot succeed if the central government fails.
For this reason, unless the Karzai government changes course there is no justification for NATO member countries to risk the lives of their soldiers and commit other valuable resources to the struggle in Afghanistan if the Afghan government’s corruption and legitimacy deficit make current progress unsustainable and achievement of NATO’s goals impossible.
Karzai is free to lead his country as he pleases, but America and its allies cannot and should not maintain their current levels of commitment unless his government can establish itself as a viable partner.
The 18-month clock is ticking.
No Exit from Afghanistan
NEW DELHI – Despite frequent turmoil and repeated invasions, Afghanistan has remained virtually unchanged for centuries.
Nearly 120 years ago, Winston Churchill described the futility of warfare in the region: “Financially it is ruinous.
Morally it is wicked.
Militarily it is an open question, and politically it is a blunder.”
Churchill’s assessment undoubtedly rings true for many United States and NATO officials today, as they attempt to coordinate an exit from America’s longest overseas combat commitment in history.
While the war in Afghanistan may have resulted in fewer American deaths and injuries than previous US wars, the human cost remains substantial – especially after factoring in Afghan deaths and injuries.
Moreover, trillions of dollars have been wasted, with the few positive effects of the US-led military intervention already beginning to fade, and its many adverse consequences continuing to destabilize the region.
US President Barack Obama is now trying to negotiate a new “status of forces” agreement with the Afghan government in order to establish how many US troops will remain in Afghanistan and the terms of their deployment.
But the reality is that the US is scuttling from a conflict that it has lost, just as it did in Vietnam almost 40 years ago, leaving the beleaguered population to its own devices.
Rather than admit defeat, US officials are resorting to diversionary rhetoric.
For example, speaking recently in New Delhi, Secretary of State John Kerry said that the key to stabilizing Afghanistan is to build a “new silk road” connecting it with central Asia – a cynical contrivance apparently aimed at cloaking America’s failure in illusions of future commerce.
Kerry’s insistence that the US is not withdrawing, but “drawing down,” is a similarly transparent attempt at manipulation.
To be sure, America’s presence in Afghanistan has spawned important regional linkages; unfortunately, they are not the kind that support economic renewal.
The last decade of war and lawlessness has facilitated the Taliban’s proliferation across Pakistan and Afghanistan, leading the Taliban to consider itself an indefatigable force – a belief that could lead its leaders to undercut any progress toward stability.
In fact, the Taliban’s confidence already drove them to disrupt plans for peace talks with the Afghan government.
After agreeing to establish an office in Qatar exclusively to host the talks, in June the Taliban opened a quasi-embassy of the “Islamic Emirate of Afghanistan.”
The Afghan government responded by suspending talks with the Taliban, as well as the status-of-forces negotiations with the US.
Pakistan recommends seeking an alternate venue for the negotiations with the Taliban, rather than abandoning reconciliation efforts altogether.
This bodes well for the resumption of talks, given that Pakistan played a leading role in facilitating the Taliban’s emergence and is now home to the Afghan Taliban’s ruling council, including its leader, Mullah Omar, along with the Pakistani Taliban.
India’s former ambassador to Afghanistan, Vivek Katju, is confident that Afghan President Hamid Karzai’s anger at the Taliban’s gambit in Qatar will not delay negotiations for long.
(Indeed, Karzai has reportedly already met with Taliban representatives for secret talks aimed at restarting the stalled peace initiative.)
Katju attributes the talks’ inevitable resumption to America’s “strategic desperation,” which is so acute that the US would be unlikely even to follow through on Kerry’s pledge to call off the talks if any link to Al Qaeda were found.
After all, the US has already accepted the Taliban’s unrealistic assurances that it will not use Afghanistan as a base from which to “foment trouble” – that is, execute terrorist attacks – elsewhere.
Fortunately for the US, the Taliban is no longer a homogeneous group.
A decade of running and hiding from unrelenting surveillance and targeted drone attacks has caused the movement to splinter.
Yet, as the security expert Sajjan M. Gohel has observed, “the displaced and disillusioned Taliban youth of today” have “found solace and purpose in an extremely radical interpretation of Islam.”
The Taliban may no longer be a unified force, but they clearly remain a dangerous one.
All of these developments have put India in a difficult position.
In Afghanistan, America’s military was so tactically dependent on Pakistan that, on several occasions, the US encouraged India to curtail development projects, such as rebuilding Afghanistan’s infrastructure.
Following America’s military withdrawal, Afghanistan will most likely revert to pre-war conditions; Pakistan will revive state-sponsored terrorism against India; and extremism will spill into the Indian state of Jammu and Kashmir.
In order to make the best of a grim situation, India must be prepared to protect its own interests at all costs.
After all, as the US extricates itself from its Afghan quagmire, its own national interests will continue to trump all other considerations.
But China, Pakistan, and Iran also have their own important national-security interests in Afghanistan that each will now do their utmost to guarantee.
So, while US troops may be leaving Afghanistan, an end to the violence spawned by America’s war remains nothing more than a distant dream – especially for Afghanistan’s South Asian neighbors.
Afghanistan’s Customary Anguish
FARAH, AFGHANISTAN – When the problems riddling Afghan society are listed – violence, insecurity, corruption, religious fundamentalism – one dominating factor is usually left out: the influence of customary law.
In Afghanistan, there are three principal legal references:  constitutional law, the Koran, and the system of customary law known as Farhang, the most dominant and strictest version of which is called Pashtunwali (the way of the Pashtuns).
Originally an ancient honor code, Farhang ensures the dominance of the oldest male of any household, followed by married sons, unmarried sons, and grandsons, then wives (with the youngest at the bottom).
Collective decisions are taken by patriarchs in councils called jirgas, where all have to be in agreement.
This agreement includes including collaborating or not with the Taliban, cooperating with the Coalition forces, accepting or refusing poppy eradication in a village.
Everything else is left to patriarchal discretion.  Here, no one will intervene except to reinforce the application of  the patriarch's rights – say, in stoning a supposedly wayward girl, or turning a blind eye to so-called “honor killings” of women.
Every act of an Afghan male’s life is integrated in a form of reciprocity, in which nothing is free.
Melmastia, the basic tenet of hospitality means “I will give you shelter if you ask me to, even if you are a fugitive murderer; but, in exchange, you fight my battles.”
This sense of customary obligation is why so many of President Hamid Karzai’s cronies remain in place and Taliban leaders remain safe.
Women are excluded from collective decision-making, as they are mere objects.
Girls are literally sold upon marriage (the father is paid money for his daughter’s labor and reproductive capacity) and join their husband’s household.
The younger the girl, the higher the price.
Marriage, especially in the provinces, is routinely consummated on pre-pubescent bodies.
Yet women are precious in their own way.
A family’s principal “cultural capital” is its honor, which is ensured by denying women any opportunity to highlight male failings and therefore tarnish clan respectability.
As a result, women must be strictly secluded and made invisible when in public, for they are personally responsible for the desire that they could ignite in schools, hospitals, parks, or markets.
The all-covering burqa ensures sufficient anonymity to permit women a certain amount of freedom in public space.
Every female simultaneously carries her father’s and her husband’s honor, and will stoically submit to all forms of violence committed in its name.
This may mean dying in childbirth rather than risking the “dishonor” of giving birth in a public place, a hospital, in front of strangers.
Going to court is practically unheard of, as it would mean renouncing family practices.
From the male point of view, resorting to outside police or judicial intervention would signify an inability to fight one’s own battles – an admission of defeat and a symbolic castration.
This helps explain the intense corruption present in Afghan courts, where “honor” can be redeemed by bribing a judge to have a rapist or murderer released.
As violence is strictly a private matter, relinquishing justice to state institutions could be an unacceptable humiliation.
Customary law is not rigid in that it is made to fit round the demands of global economy.
It has become more rigorous in it s applications due to the influence ofmilitant Islam, which seeks to use religious texts to legitimize escalating brutality, especially against women.
However, Farhang and privatized violence are precisely what Mohammad sought to ban through Koranic law, which went beyond the personal domain and instituted a code that gave some rights to women.
For example, while the Koran allows for a measure of female inheritance, tribal custom does not authorize it, which explains the popularity of tribal councils to resolve inheritance problems and cheat women out of their rights.
Similarly, whereas the Koran requires four eyewitnesses as proof of adultery, mere suspicion of some unregulated, potentially sexual conduct by a woman warrants stoning under customary law.
Yet an awareness of alternatives is seeping in through the media, even in remote provinces.
Iranian films and the much loved Indian TV serials, not to mention the occasional American film, influence peoples' expectations.
Add to that the experience of having lived abroad as refugees in Pakistan and Iran.
Girls know that there are options to an unacceptable way of life: women are increasingly demanding more from life than what custom ordains.
This is especially true for those who have lived in Iran, a totally Muslim environment that allows women the freedom to study and work as well as access to adequate healthcare and family planning.
Once back in rural Afghanistan, forced into brutal marriages, many desperate women – especially returnees from Iran – resort to self-immolation.
Violence and murder of women are on the increase, perpetrated by men who feel that these alternatives pose a threat to their authority.
The West imagines that religion is the central issue in Afghanistan.
But the heart of the matter is the preservation of ancient patriarchal rights that go back to Biblical times, reformatted to fit the demands of globalized capitalism.
Governments and international aid organizations have failed to take into consideration the role of Farhang, perhaps because the power of unwritten law remains largely inconceivable in the West.
But Afghanistan cannot begin to solve its many problems until it criminalizes the privatized violence of this antiquated code.
Afghanistan’s Drug-Friendly Environment
Afghanistan’s President Hamid Karzai has stepped up international fundraising efforts in recent weeks, seeking a fresh package of military and reconstruction aid from the United States, together with stronger strategic guarantees.
But Karzai’s relationship with his sponsors has begun to sour, in part owing to charges that his government has failed to stop the resurgence of Afghanistan’s huge opium trade.
Underlying the opium trade issue is a security threat of another kind, one overlooked since the US-led invasion toppled the Taliban regime in 2001, despite the grave risk it poses to Afghanistan’s long-term stability, and that of the region.
In countries like Afghanistan, where 80% of the population lives on what they grow and many communities live far from any water source, environmental damage can be both economically devastating and politically momentous.
That lesson should have been absorbed and understood, not least by American strategists, long before the Taliban’s fall.
After all, desertification and deforestation helped fuel the rise, two decades earlier, of the Maoist guerilla group Sendero Luminoso (Shining Path) in Peru.
Sendero, which supplemented its income with drug production and timber smuggling, deliberately chose drought-weakened and deforested mountain villages as the stronghold of its insurgency.
Similarly, the Maoist insurgency in Nepal, which has claimed 10,000 lives, exploits the desperation of mountain villagers hit by flash floods – the result of deforestation higher up.
No Maoist group could ever gain a toehold in Afghanistan’s parched Pashtun south (these were, after all, people who, bare-knuckled, smashed the Soviets).
But the Taliban’s rapid rise in the 1990’s was inextricably linked to the failure of irrigation systems.
Villagers whose crops shriveled and whose livestock died in a prolonged drought saw joining the Taliban as an economic opportunity.
Had there been more irrigation, the Taliban’s gains might have been far less impressive.
The Taliban are now an increasingly spent force, but lack of water reinforced the logic of opium production across its former strongholds in the south.
Irrigation has failed or is inadequate in Helmand, Uruzgan, and Kandahar – three of the top five opium-producing provinces – where indebted farmers are hooked by the economics: opium brings in eight times as much cash as wheat and uses less water.
Without serious investment in irrigation, including construction of reservoirs to make use of the snowfall in the Hindu Kush, and in new cash crops such as saffron and rose oil, Afghanistan’s drift toward narco-statehood will continue, with all the instability that this implies.
Clear-cutting of old growth forests in the mountains bordering Pakistan may prove as problematic.
Agriculture there has been damaged by the cutting of walnut, apricot, and mulberry trees for winter fuel, and by a failure to replant poplar, willow, and tamarisk – the trees that hold fragile meadows in place.
These sorts of trees can be restored, given a concerted campaign and investment in nurseries to produce local varieties.
Loss of the ancient cedar, pine, fir, and oak forests on the slopes above is another matter.
This year’s snowmelt caused landslides and flooding – a warning of more soil erosion and destruction of arable land to come; hundreds died and thousands lost their livelihoods.
Forestry has always been a problem in Afghanistan.
In 1960, the United Nations Food and Agriculture Organization spoke of wasteful logging practices, such as “head-skidding” (in which a log is rolled downhill, ripping up plants and soil).
Aerial photographers were called in, and a large budget was set aside.
But, in 1976, the FAO admitted in a new plan that forest and watershed management activities had “turned out to be quite limited.”
The 1976 plan called for sustainable logging and basic forest-fire control, but war intervened, costing Afghanistan half its forest cover.
Up to 60% of the old growth forest in Nangahar, the second largest opium-producing province, may have been cut during the war years.
Mujahedin factions and later the Taliban exported stands of fine-grained cedar by the truckload from Nangahar and surrounding provinces to Pakistan, often in return for arms.
Illegal logging continues today, with only ineffectual efforts made to stop it.
At the current rate, Afghanistan’s old growth forest could vanish within a decade.
The UN acknowledges the problem but is (rightly) unwilling to risk sending forestry experts into a tribal region where American and allied troops venture only in armored convoys.
Safety concerns and cost also limit intervention by international conservation organizations.
A new initiative called the Green Corps includes 300 forest rangers charged with stopping illegal logging, and the ministry hopes to boost their numbers within a year. But the initiative is unlikely to have much effect.
Illegal logging crews number 200 or more.
They have chain saws and trucks. They are armed and work with the backing of drug and emerald smugglers – and often of local officials.
The price of plank cedar in Lahore is incentive enough to corrupt, or kill, any Green Corps men brave enough to stand in their way.
Environmental issues are of paramount importance in marginal countries because their impact on human survival is immediate and direct.
The inadequate response to pressing questions of natural resource management, whether of water or trees, merely strengthens the hands of opium dealers and malcontents in what is already the most disaffected and sensitive part of Afghanistan – the clear-cut mountain slopes where intelligence officers believe Osama bin Laden is most likely holed up.
Afghanistan’s Feminist Revolution
On April 16, more than 300 Afghani women – many of them students – marched together in Kabul in protest of a new law passed by Parliament that would impose a series of Taliban-like restrictions on women.
The law would permit marital rape, limit women’s movements – say, for work or study – without male permission, and even make it illegal for a woman to refuse to dress as her husband wishes.
The women, facing a crowd of furious men calling them “whores” and other epithets, marched two miles under a rain of abuse and delivered their petition against the law to legislators.
Both houses of Parliament had approved the law, and President Hamid Karzai signed it.
The law now affects only the Shia minority, but threatens to affect pending legislation that could restrict the rights of non-Shia women as well.
When Western media sought quotes from the women, they frequently heard a Western-style feminist refrain: “These laws would make women into a kind of property.”
In the West, the counterpoint to the notion of woman as property has been a highly individualistic demand for personal autonomy – decision-making based primarily on a woman’s own wishes, rather than as wife, mother, community member, or worshipper.
But, while some Western feminist insights may be useful to Afghani women and other women in the developing world as they resist certain forms of male oppression, we should not assume – as Western feminists often have – that our job is to proselytize “our” feminism.
On the contrary, the feminism expressed by women such as these Afghani heroines should educate us in the West about our own shortcomings.
The core theory with which emerging feminists in more traditional and religious societies are working is far different from that of Western feminism – and in some ways far more profound and humane.
In India, for example, feminists articulated to me a vision of women’s equality that was family-centered rather than self-centered, and that valued service to community rather than personal gratification.
They did not see their struggle as a cultural or ideological clash between men and women, but rather as a very practical effort to live free from violence and sexual assault, forced child marriage and bride-burning, and legal exclusion from parity.
The emerging consensus in India in support of greater rights and freedoms for women, while certainly causing some upheaval and adjustment (especially within the growing middle classes) has not yet – and might never – poison the basic trust and warmth between men and women.
Nor does it seem likely to emulate the splintered, individualized, solitary society – and the commodified sexual revolution – that Western, self-based feminism reflects.
This version of feminism – the notion that women can claim equality and still have a valued role in the home, prize family above all, and view rights in the context of community and spirituality – seems like a much-needed corrective to some of Western feminism’s shortcomings.
Ideally, men’s drive for progress in the developing world would also evolve, uniting the idea of the autonomous self with support for family, community, and other ties, and Western men would learn from this as well.
Moreover, intellectually, these women remind us that Western feminism did not have to evolve the way it did, and can still change and grow to embrace a more satisfying and humane definition of equality.
Simone de Beauvoir, whose seminal book The Second Sex laid the groundwork for post-war Western feminism, was an Existentialist who was neither a wife nor a mother nor a woman of faith.
So her work naturally posited female freedom in a secular, solitary, and individualistic context, in which “freedom” means pure autonomy rather than integration within a whole – comprising family, community, and even God – on equal terms.
The good news for all women, East and West, is that President Karzai, under intense international criticism – and not just Western criticism – changed the law less than one week after the march.
This global uproar is a testament to how three decades of Western feminist challenges to leadership have changed the world for the better.
But our (Western) moment of feminist leadership is over now – for good reasons.
We know by now what our problems are as women in the West, and we know the blueprint for solving them.
What we lack now is not analysis, but the organizational and political will to do so.
So the leadership role is shifting to women in the developing world.
Their agenda is more pressing, and their problems, frankly, far more serious than ours, which makes it much more urgent for them to develop theories appropriate to the challenges they face.
If one of those courageous Afghan women who marched in Kabul wrote – as I hope she or one of her sisters in the developing world is doing right now – the seminal text for the next 50 years on non-Western feminism, it would no doubt be equality-driven and practical.
And perhaps, in its likely view of the world as being more than the sum of consuming, competing autonomies, or gender warfare, it would be a valuable challenge to truisms that we Western feminists – and the men who love us – have thought we had to take for granted.
Afghanistan’s Opium War
When NATO leaders meet for their summit in Riga at the end of this month, there will be a ghost at the feast: Afghanistan’s opium.
Afghanistan is in danger of falling back into the hands of terrorists, insurgents, and criminals, and the multi-billion-dollar opium trade is at the heart of the country’s malaise.
Indeed, NATO’s top general, James Jones, has called drugs the “Achilles heel” of Afghanistan.
This year’s record harvest of 6,100 tons of opium will generate more than $3 billion in illicit revenue – equivalent to almost half of Afghanistan’s GDP.
Profits for drug traffickers downstream will be almost 20 times that amount.
Opium money is corrupting Afghan society from top to bottom.
High-level collusion enables thousands of tons of chemical precursors, needed to produce heroin, to be trucked into the country.
Armed convoys transport raw opium around the country unhindered.
Sometimes even army and police vehicles are involved.
Guns and bribes ensure that the trucks are waved through checkpoints.
Opiates flow freely across borders into Iran, Pakistan, and other Central Asian countries.
The opium fields of wealthy landowners are untouched, because local officials are paid off.
Major traffickers never come to trial because judges are bribed or intimidated.
Senior government officials take their cut of opium revenues or bribes in return for keeping quiet.
Perversely, some provincial governors and government officials are themselves major players in the drug trade.
As a result, the Afghan state is at risk of takeover by a malign coalition of extremists, criminals, and opportunists.
Opium is choking Afghan society.
Within Afghanistan, drug addiction is rising.
Neighbors that used to be transit states for drugs are now major consumers, owing to similar dramatic increases in opium and heroin addiction.
Intravenous drug use is spreading HIV/AIDS in Iran, Central Asia, and the former Soviet Union.
In traditional Western European markets, health officials should brace for a rise in the number of deaths from drug overdoses, as this year’s bumper opium crop will lead to higher-purity doses of heroin.
What can be done?
First, the veil of corruption in Afghanistan must be lifted.
Afghans are fed up with arrogant and well-armed tycoons who live in mansions and drive top-of-the range Mercedes limousines – this in a country where barely 13% of the population have electricity and most people must survive on less than $200 a year.
It is time for the Afghan government to name, shame, and sack corrupt officials, arrest major drug traffickers and opium landlords, and seize their assets.
Donors have trained police and prosecutors and built courts and detention centers.
Now it is up to the government to use the judicial system to impose the rule of law.
It will be difficult, but not impossible, to re-establish confidence in the central government.
Putting major drug traffickers behind bars at the new maximum-security prison at Pul-i-Charki, near Kabul, would be a good start.
Of course, Afghanistan does not bear sole responsibility for its plight.
The heroin trade would not be booming if Western governments were serious about combating drug consumption.
It is a bitter irony that the countries whose soldiers’ lives are on the line in Afghanistan are also the biggest markets for Afghan heroin.
Furthermore, Afghanistan’s neighbors must do more to stop insurgents, weapons, money, and chemical precursors from flowing across their borders into the country.
Coalition forces should take a more robust approach to the drug problem.
Counter-insurgency and counter-narcotics are two sides of the same coin.
Improving security and the rule of law must include destroying the opium trade.
Allowing opium traffickers to operate with impunity gives them a free hand to raise money to pay for the arms and fighters battling the Afghan army and NATO forces.
The United Nations Security Council has authorized the International Security Assistance Force to take all necessary measures to fulfill its mandate.
NATO troops should be given the green light to help the Afghan army fight opium – destroy the heroin labs, disband the opium bazaars, attack the opium convoys, and bring the big traders to justice.
And they should be given the tools and manpower to do the job.
There is no point in trying to win the hearts and minds of major drug traffickers.
Farmers are a different story.
Forced eradication risks pushing farmers into the hands of extremists, and thus will not lead to the sustainable reduction of opium fields.
Indeed, as we have seen in some Andean countries, it can be counter-productive.
Therefore, security and development must go hand in hand.
To achieve this, Afghanistan needs more development assistance.
International support so far has been generous, but it is still well below per capita equivalents for other post-conflict situations – and the need is much greater.
Farmers will be weaned off opium over the long term only if they have sustainable livelihoods.
At the moment, Afghanistan’s drug lords are prospering, and rural communities are suffering.
That situation needs to be reversed.
We must punish the traffickers and reward the farmers.
We cannot afford to fail in Afghanistan.
Recent history has given us graphic evidence of what would happen if we do.
But any solution in Afghanistan depends on eliminating its opium.
Afghanistan’s Terrorized Women
KABUL – Recently, the Afghan Independent Human Rights Commission (AIHRC) office in Kudoz province reported the rescue of a young woman who had been imprisoned in her in-laws’ dungeon for seven months.
Fifteen-year-old Sahar Gul was forced to marry an older man who serves in the Afghan army. She was then kept in the dungeon by her husband’s family and brutally tortured for months, because she refused to work as a prostitute.
Over the past ten years, the AIHRC has received more than 19,000 complaints related to violence against women.
Despite making some progress in investigating the complaints and referring them to the justice system, as well as in raising public awareness about the issue, the challenges remain huge.
Since 2002, many efforts have been made to improve women’s lives in Afghanistan.
The country has enacted several new laws and established a fairly advanced legal framework to end discrimination against women, including a new law that criminalizes any act that results in violence against women.
But laws and policies alone are not sufficient to protect women from horrific domestic abuse.
Indeed, the Gul case is hardly the only well-publicized case.
There was also Gulnaz, a young woman who was jailed for adultery after being raped by a relative (she was recently released after a presidential pardon, but may be forced to marry her attacker).
The husband of another young woman, Aisha, cut off her nose and ears when she ran away.
Violence against women in Afghanistan persists for many reasons. First, the country has inherited a patriarchal tribal tradition that assumes women’s inferiority.
Second, there is a strong political incentive to deprive women of their rights.
Radical groups receive immense support from the large share of the population that opposes women’s rights.
The Taliban, for example, have consistently used an anti-women policy to appeal to tribal and rural people.
Third, family pride and honor are deemed more important than a woman’s individual well-being and safety.
For example, if family members beat or abuse a woman, she has few options.
Often, her only choice is to remain silent or risk disgracing the family.
If she does report the matter to the authorities, the case will almost certainly never be properly investigated, nor the perpetrators ever prosecuted.
Gul, for example, complained to the police about her abusive in-laws, but she was returned to the family when some of their influential contacts intervened.
Fourth, laws are often arbitrarily applied, and sharia (Islamic law) frequently takes precedence over civil legislation, resulting in widespread impunity for crimes of violence against women.
For example, in October 2010, the Afghan Supreme Court ruled that women who run away from home can be charged with prostitution, unless they go to the police or an immediate relative's home. It is this mindset that led to Gul’s victimization.
Finally, while the Taliban lost power ten years ago, discrimination and violence against women has occurred in Afghan society for centuries.
Thus, despite some progress, public and official sensitivity to violence against women is only slowly emerging.
The Afghan government must take several steps to protect women fully.
Above all, perpetrators of violence against women should be prosecuted and tried under due process of law.
This will require strengthening the rule of law and ending the prevailing culture of impunity.
That, in turn, requires educating the public further about human rights and women’s rights through school textbooks, continuing education courses, and a vigorous media campaign.
It also requires persuading representatives and policymakers to develop policies and allocate budget revenues to combat violence against women, and training police and judges to handle cases of violence against women without deferring to claims of family honor.
Perhaps most importantly, non-constitutional justice systems, such as sharia, must be monitored and checked, if not prohibited altogether.
As for Sahar Gul, her case must be thoroughly investigated, and the police and judiciary must commit to bringing her torturers to justice.
Furthermore, Gul’s case, and others like it, should be studied in order to understand the roots of such crimes.
Until Afghanistan’s leaders begin to address this problem seriously, our country will continue to bear the scar of violence against women on its face.
A Flat World and a Round Ball
With the final stage of the World Cup approaching, now is a good opportunity for a mid-tournament appraisal.
This year’s Cup, unlike the previous one in Japan and South Korea in 2002, didn’t witness any real upsets in the first round.
Switzerland and Australia surprisingly reached the elimination round, and the Asian and African teams disappointed somewhat, with only Ghana advancing.
There have been just two ugly matches so far, full of fouls, nasty attacks, and unnecessary aggression, as well as numerous yellow and red cards: Italy vs. the US, and Portugal vs. the Netherlands.
Otherwise, we’re experiencing a wonderful Cup in Germany, in terms of both sportsmanship and the overall atmosphere.
As for Germany and the Germans, one hardly recognizes one’s own country and people.
Even Mother Nature has played along.
After a long winter and a non-existent spring, summer started promptly with the first kick-off – and virtually overnight, Germany has flaunted its sunniest and most delightful side.
The weather is Mediterranean, and all of a sudden, so are the people.
The Cup’s organization has been exceptional (as was to be expected), with excellent police work giving hooligans hardly a chance.
The whole of Germany has been celebrating a never-ending party with guests from all over the world (which was not expected).
And the German team has put on a wonderful display of heart warming and modern offensive soccer (which nobody could have expected!).
More importantly, not only in the German team, but also in the country as a whole, a young, cool, laid-back, and carefree Germany is raising its head – a Germany that is cosmopolitan, friendly, and good-humored.
Years of bad news appear to have passed the Germans by without a trace.
Doctors are on strike, taxes are on the rise, the parties in government are mauling each other, and Chancellor Angela Merkel herself proclaimed in a prominent speech that the country is in disastrous shape.
But the Germans, undaunted by it all, simply keep celebrating one great soccer party with their newfound friends from all over the world.
The black, red, and gold German tricolor adorns the entire country as never before, but almost nowhere are there nationalist undertones.
In fact, the flags of many nations fly alongside German.
In Berlin, as in other large German cities, taxis sport the flags of their drivers’ home countries – from Angola to Saudi Arabia.
Fans don not just their nations’ flags, but also fantastic costumes evocative of their home countries’ colors.
Flags are flown in hope of victory, but also serve to dry the tears of defeat.
In short, Germany during the World Cup is reminiscent of a Shakespearean midsummer night’s dream, with a touch of Woodstock to boot.
Outside the stadiums, public screenings of the games have become joyous mass “happenings.”
And how is the soccer?
This World Cup demonstrates three main developments that the sport has undergone.
First, Europe and South America are more dominant than four years ago and remain the unchallenged great powers of international soccer.
So we must hope that the World Cup in South Africa in 2010 will finally bring greater global parity.
Second, international soccer is witnessing the advent of a new generation.
Spain, Argentina, and Germany, to name but a few countries, have put forward very young teams that have played an impressive game.
On the French, English, and Portuguese teams, too, it is the young players that have shone – despite the continuing presence of Zidane, Beckham, and Figo.
Even the Brazilian squad is looking more aggressive and likely to score with young players like Robinho and Juninho than with their aging champions from 2002.
This generational change is accelerated by a third development.
At the top international level, soccer has become faster and more athletic, and the top teams can shrink space on the field more effectively.
A team that is unable to keep going at full speed for the full 90 (or more) minutes, switch from defense to offense quickly with the whole team, and maintain control of the ball to restrict their opponents' movements won’t stand much of a chance.
Here, soccer parallels today’s globalized markets, which make similar restructuring of national economies necessary.
Unlike economic globalization, however, it remains to be seen whether this new, fast-paced style of soccer will prevail (after all, the young blood of Spain lost to the Old Boys of France).
The sport and its fans will certainly profit if it does.
For now, we have a World Cup filled with soccer that is being shaped by a new, young generation both on and off the playing field – light-hearted, enthralling, and beautiful to watch.
Let’s hope that when the last whistle blows at the final in Berlin on July 9, we Germans retain as much of this positive spirit as possible.
Germany urgently needs this kind of optimism, because, unfortunately, two universal principles will continue to apply in the future: first, the winter will return, and, second, the ball is round and the next game is always the most difficult.
A Free Lunch for America
BERKELEY – Former US Treasury Secretary Lawrence Summers had a good line at the International Monetary Fund meetings this year: governments, he said, are trying to treat a broken ankle when the patient is facing organ failure.
Summers was criticizing Europe’s focus on the second-order issue of Greece while far graver imbalances – between the EU’s north and south, and between reckless banks’ creditors and governments that failed to regulate properly – worsen with each passing day.
But, on the other side of the Atlantic, Americans have no reason to feel smug.
Summers could have used the same metaphor to criticize the United States, where the continued focus on the long-run funding dilemmas of social insurance is sucking all of the oxygen out of efforts to deal with America’s macroeconomic and unemployment crisis.
The US government can currently borrow for 30 years at a real (inflation-adjusted) interest rate of 1% per year.
Suppose that the US government were to borrow an extra $500 billion over the next two years and spend it on infrastructure – even unproductively, on projects for which the social rate of return is a measly 25% per year.
Suppose that – as seems to be the case – the simple Keynesian government-expenditure multiplier on this spending is only two.
In that case, the $500 billion of extra federal infrastructure spending over the next two years would produce $1 trillion of extra output of goods and services, generate approximately seven million person-years of extra employment, and push down the unemployment rate by two percentage points in each of those years.
And, with tighter labor-force attachment on the part of those who have jobs, the unemployment rate thereafter would likely be about 0.1 percentage points lower in the indefinite future.
The impressive gains don’t stop there.
Better infrastructure would mean an extra $20 billion a year of income and social welfare.
A lower unemployment rate into the future would mean another $20 billion a year in higher production.
And half of the extra $1 trillion of goods and services would show up as consumption goods and services for American households.
In sum, on the benefits side of the equation: more jobs now, $500 billion of additional consumption of goods and services over the next two years, and then a $40 billion a year flow of higher incomes and production each year thereafter.
So, what are the likely costs of an extra $500 billion in infrastructure spending over the next two years?
For starters, the $500 billion of extra government spending would likely be offset by $300 billion of increased tax collections from higher economic activity.
So the net result would be a $200 billion increase in the national debt.
American taxpayers would then have to pay $2 billion a year in real interest on that extra national debt over the next 30 years, and then pay off or roll over the entire $200 billion.
The $40 billion a year of higher economic activity would, however, generate roughly $10 billion a year in additional tax revenue.
Using some of it to pay the real interest on the debt and saving the rest would mean that when the bill comes due, the tax-financed reserves generated by the healthier economy would be more than enough to pay off the additional national debt.
In other words, taxpayers win, because the benefits from the healthier economy would more than compensate for the costs of servicing the higher national debt, enabling the government to provide more services without raising tax rates.
Households win, too, because they get to buy more and nicer things with their incomes.
Companies win, because goods and workers get to use the improved infrastructure.
The unemployed win, because some of them get jobs. And even bond investors win, because they get their money back, with the interest for which they contracted.
So what is not to like?
Nothing.
How, you might ask, can I say this?
I am an economist – a professor of the Dismal Science, in which there are no free lunches, in which benefits are always balanced by costs, and in which stories that sound too good to be true almost inevitably are.
But there are two things different about today.
First, the US labor market is failing so badly that expanded government spending carries no resource cost to society as a whole.
Second, bond investors are being really stupid.
In a world in which the S&P 500 has a 7% annual earnings yield, nobody should be happy holding a US government 30-year inflation-adjusted bond that yields 1% per year.
That six-percentage-point difference in anticipated real yield is a measure of bond investors’ extraordinary and irrational panic.
They are willing to pay 6% per year for “safety.”
Right now, however, the US government can manufacture “safety” out of thin air merely by printing bonds.
The government, too, would then win by pocketing that 6% per year of value – though 30 years from now, bondholders who feel like winners now would most likely look at their portfolios’ extraordinarily poor performance of over 2011-2041 and rue their strategy.
A French Presidential Primer
The late British Prime Minister Harold Wilson used to quip that “a week is a long time in politics.”
So, in the 30 or so weeks between now and the next French presidential election, any prediction made today could be reversed, and reversed again, before the vote.
But two candidates have emerged as clear and constant favorites in opinion polls: Nicolas Sarkozy on the right and Ségolène Royal on the left.
In fact, they have more in common than meets the eye, for each speaks of a rupture with the past while incarnating a form of continuity.
For Sarkozy, “rupture” reflects both mundanely tactical and deeply personal choices.
The 12 years of Jacques Chirac‘s presidency, together with France’s tradition of alternation in power, suggests a victory for the left.
Positioning himself as the candidate who represents a sharp break with today’s unpopular politics is the only means to escape that fate.
This is reflected in Sarkozy’s openly pro-American stance – an act of political courage in a France where anti-Americanism is running high.
Sarkozy’s message is that Chirac and Villepin were right in substance to oppose America’s military adventure in Iraq, but that their style was disastrously wrong.
Thus, his deep admiration for “American values,” while sincere, implies no embrace of President George W. Bush.
It also reassures the French business community, which was shocked by Dominique de Villepin’s flamboyant opposition to the United States when he was Chirac’s foreign minister.
At home, Sarkozy has aimed his message particularly at the young, issuing a patriotic call to the values of work and discipline, a counter-revolutionary revolution.
The revolution that must be overcome is that of May 1968, whose leaders and supporters, according to Sarkozy, may have lost politically to de Gaulle, but deeply weakened France over the succeeding decades with their emphasis on “false values.”
By contrast, rebelling against one’s parents’ generation and rediscovering traditional moral stances will save France – a message that is highly applicable to issues, such as education and immigration, that may dominate the electoral campaign.
In the case of Royal, the meaning of “rupture” is both more obvious and more visible.
She is seeking to become the first woman President of the French Republic.
To achieve her goal, she prefers to emphasize her “essence,” thereby countering Sarkozy’s stress on his record as a “doer.”
Her appeal to voters is simple: “I am a woman, and you have never tried a woman, so be modern and try one now.”
Hiding behind the originality (in French presidential politics) of her gender, Royal has avoided specifying a detailed program.
When challenged by inquisitive journalists demanding greater precision about her policy agenda, her highly effective line of defense (so far!) has been: “You would not dare to ask me such a question if I were not a woman!”
Thus, Royal’s program is her popularity.
In foreign policy, one can only guess what her priorities would be.
As far as Europe is concerned, she seems as “agnostic” as Sarkozy, who, like her, incarnates a new generation of “post-European” leaders.
In terms of values, Royal, too, seems to represent a rupture with May 1968, with her emphasis on discipline and family.
According to public opinion polls, Royal is the clear favorite of the left and the only candidate able to defeat Sarkozy.
Her support is particularly strong among women voters.
For the Socialist Party, which is eager to return to power but has not yet recovered from the humiliating defeat of Lionel Jospin in the first round of the presidential election in 2002, the question is whether it can afford to resist the wave of favorable public opinion behind Royal.
In the opinion of Royal’s many opponents among Socialist leaders and militants, the dominance of the media in the political process is leading to mediocrity: the qualities required to be elected are becoming nearly incompatible with those needed to govern.
According to Royal’s Socialist critics, the “Hollywoodization” of politics from which she benefits entails a new approach in which leaders follow and followers lead.
But the same criticism can be directed at Sarkozy.
Moreover, both candidates embody continuity – with Chirac’s Gaullist side for Sarkozy and with François Mitterrand for Royal – as much as rupture.
Royal openly claims Mitterand’s legacy as she searches for legitimacy, while Sarkozy’s rejection of Chirac’s legacy has more to do with form than substance.
To a large extent, Sarkozy can be seen as Chirac with more, whereas Royal is clearly Mitterrand with less.
When the voters decide in the spring of 2007, their choice may depend more on negative than positive considerations, as it did in 2002, when Chirac faced the odious nationalist Jean-Marie Le Pen in the second round.
As in 2002, the winner next year will be whomever the electorate dislikes or fears less.
But one way or the other, personalities will prevail over programs.
A Fresh Start for China and Japan?
Edmonton – Chinese President Hu Jintao will make a high-profile visit to Japan from May 6-10, making him the second Chinese head of state ever to travel there.
The trip is being carefully managed by both countries, and is being watched closely around the world, with good reason: Sino-Japanese relations over the past decade have been turbulent, to say the least.
When Hu’s predecessor, Jiang Zemin, traveled to Japan ten years ago, bilateral relations were deteriorating: China was unhappy with the Japanese government’s refusal to extend the same apology offered to South Korea for past aggression; Japan was worried about a rising China and thus turning more confrontational.
The Japanese media’s coverage of the visit was overwhelmingly negative, and it was remembered as a public-relations disaster.
Hu succeeded Jiang in 2002, almost as former Prime Minister Junichiro Koizumi was coming to power in Japan, and encouraged “New Thinking” in China’s Japan policy, which would entail moving away from historical grievances and promoting better ties.
But, instead of accepting China’s olive branch, Koizumi implemented a more nationalistic agenda, including annual visits to the Yasukuni Shine, which is regarded as a symbol of Japanese militarism by Japan’s neighbors.
His hard-line approach isolated Japan and angered China, leading to an outburst of anti-Japanese demonstrations in China in 2005.
But both Japan and China recognize that further tension will serve neither country’s long-term interests.
Koizumi’s successors, Prime Ministers Shinzo Abe and Yasuo Fukuda, have sought to engage China over the past two years, with summits in Beijing and a successful visit by Chinese Premier Wen Jiabao to Japan last year.
Hu’s trip is likely follow the example set by Wen.
He will emphasize common strategic interests, highlight mutual economic benefits, generate positive public opinion, and promote further exchanges.
Japan is not only one of China’s largest trade and investment partners, it is also the most powerful neighbor with which China wants to be on good terms, partly to showcase that China’s rise is not a threat to Asia and the rest of the world.
Japan, whose economic recovery is attributable largely to its deepening ties with China in recent years, is also eager to demonstrate that it regards China not as a threat but as an opportunity, as least in economic terms.
It was 30 years ago that former Prime Minister Takeo Fukuda, the father of today’s prime minister, signed a Peace and Friendship Treaty with China.
The two governments will certainly use Hu’s visit to celebrate the anniversary with new programs designed to enhance bilateral understanding and friendship.
But, unlike three decades ago, when the Japanese regarded China as one of their most favored countries, public opinion in both countries nowadays registers more negative feelings than positive ones.
Behind the smiles, the polite interactions, and the cautiously worded diplomatic language, strong undercurrents of suspicion remain.
One problem is the disputed waters of the East China Sea.
Despite new joint projects in energy efficiency and environmental protection, areas in which China ranks Japan as the best performer among industrialized countries, the two sides remain in bitterly divided over these territorial waters, which contain huge potential oil, gas, and other mineral deposits. Even after many rounds of talks, no resolution is in sight, and Hu’s visit is not expected to produce any breakthroughs.
Then there are strategic suspicions.
Fukuda has dropped Abe’s talk about an “arch of freedom” – an effort to forge a bloc with the United States, Australia, and India.
But Japan remains concerned about China’s rapidly modernizing military, while China worries about a potential US-Japan containment strategy for China, especially in the case of a crisis in the Taiwan Straits.
So, although both sides endorse the idea of a “mutually beneficial strategic relationship,” and despite progress bilateral on military exchanges, mutual trust and confidence-building have a long way to go.
Moreover, today’s “warm politics, cool economics” trend is the reverse of the “cold politics, warm economics” pattern under Koizumi.
Last year, Japan’s committed investment projects in China fell 24% from 2006, while actual investment volume decreased by 25%, partly owing to regulatory changes in China regarding foreign investment.
Recent food safety issues, such as the “poisoned dumplings” cases, have clearly heightened the Japanese public’s sensitivity about Chinese exports.
Finally, historical issues could still resurface to cause new problems.
While Fukuda has made it clear that he will not visit the Yasukuni Shrine, 160 other parliamentarians paid homage at the site last month, an indication that conservative forces in Japan remain strong and that future prime ministers may not abstain from visiting Yasukuni.
And Japan has so far failed to live up to its treaty obligations to clean up between 700,000 and two million chemical weapons that were abandoned in China by the Japanese army at the end of World War II, another potential flash point if any of these weapons causes casualties in China.
A Fresh Start for Europe
As Europe’s leaders gather in Portugal to put the finishing touches on the new, slimmed down, Reform Treaty, it might be helpful if they all pretended that the last 50 years of European integration had never taken place.
Let’s then imagine what Europe needs to do to confront its most pressing challenges, especially if it were able to do so without the political constraints of 50 years of EU deal-making and ramshackle institution-building.
On top of that, let us make a major leap of imagination and suppose that even though this scenario of the EU at “Year Zero” means we would not have a half-century of intra-European cooperation to draw on, the nations that today make up the EU would nevertheless be keen to adopt far-reaching joint policies.
Let’s suspend our disbelief, then, and try to imagine what Europe could and should be doing to tackle some of the most far-reaching and obstinate policy challenges that will determine whether the next 50 years are as constructive as the last.
Or, to put it another way, let’s look at our problems in the light of the EU’s existing mechanisms and its potential for creating far-reaching new policies, and then let’s ask ourselves why the EU isn’t realizing its own potential and delivering the goods.
Broadly, we see three areas in which Europe’s policymakers at both the national and EU levels can do better: global challenges where Europe could show greater leadership, the creation and strengthening of human capital within the EU and worldwide, and improvement in the effectiveness of the EU’s own political machinery.
Europe needs a clearer and more recognizable global agenda.
It needs to build substantially on its leadership on climate change by adopting much tougher EU goals, and then use its international economic and trade clout to champion new global emissions standards that scientific opinion can accept as meaningful.
On conflict and security issues, Europe should be advancing to a new phase in which it takes much clearer and unambiguous positions on issues ranging from nuclear proliferation to sanctions against Burma’s military regime.
The purpose must be to establish Europe as a forceful and fair-minded player on the world stage, rather than as a “broad church” in which different viewpoints co-exist.
The aim should be that “soft power” instruments like EU development aid and economic partnerships would be linked with a growing sense of political and security outreach to ensure Europe is a global player to be reckoned with.
That means, of course, that the EU should seek to widen its transatlantic thinking so that the EU and the United States cooperate more closely on defining – and thus protecting – their common interests in a world where together they account for little more than 10% of the total population.
These points are far from a blanket criticism of the EU’s efforts to create a common foreign and security policy.
But they are intended to underline what many people in Europe know very well, which is that the speed with which problems concerning international development and conflict are growing easily outpaces the EU’s policy responses so far.
Building more human capital in Europe and worldwide is a crucially important element in future EU activities.
Education is by far the most profitable investment Europe can make, so it should be launching its most ambitious strategy ever to create a new knowledge dynamic and employment inside the EU while helping to expand greatly education in the world’s poorest countries.
Europe also must at last grasp the nettle of immigration policy – something that has persistently eluded generations of political leaders.
Agreed EU-wide immigration rules are needed to reconcile shrinking Europe’s hunger for imported labor with widespread fears of cultural tensions and social unrest.
It won’t be easy to create a fairer and more multi-cultural Europe, but failure to address this problem openly will carry an even heavier price.
By much the same token, Europe’s governments should be making a determined new effort to strengthen Europeans’ sense of a shared history and common values.
A stronger European identity is the soundest basis for creating the more multi-cultural society that demographers regard as inevitable.
Meanwhile, doubts still surround the political and institutional machinery the EU will need to realize these and other ambitious goals.
Sighs of relief greeted EU leaders’ mid-year agreement on a Reform Treaty aimed at overhauling the Union’s decision-making mechanisms, but it is still uncertain whether the new pact will survive the ratification process in 27 countries.
We believe, though, that the increased use of qualified majority voting by member governments embodied in the new treaty should also be applied to the ratification process itself.
That way, if a small minority of EU governments prove unable to ratify the treaty, it would not be torpedoed the way that its predecessor, the Constitutional Treaty, was in 2005.
How to Help the African Dust Bowl
SEATTLE – Picture a small farm under a blazing hot sky.
An intense drought is afflicting the surrounding region, prospects for the next harvest are bleak, and the financial system lacks the capacity to provide the loans farmers need to get by.
This scenario describes today’s southern Africa, which is in the grips of an epic drought.
As it happens, it also describes eastern Nebraska in the “Dust Bowl” years of the early 1930s – a period through which my own family lived.
My father, Ralph Raikes, was the first in his family to graduate from college.
After working for Standard Oil in California, he stopped by his parents’ farm on his way to Cambridge, Massachusetts, where he planned to pursue graduate studies at MIT.
He never made it.
He had to stay in Nebraska and help my grandfather save the family farm from the banks, which had already repossessed one-third of the land.
The most important change my father made was in his mindset: he came to think of the farm not as a subsistence operation, but as a family business.
He turned to the University of Nebraska, where he had received his undergraduate degree, and acquired hybrid corn and other improved seeds that the university was developing.
Then he tracked inputs and weather conditions, which was rarely done at that time.
My father realized that he couldn’t go it alone, and that he would need better access to financing.
So he helped guide – first as a customer, and later as an adviser and director – Farm Credit, a national banking cooperative network, in its efforts to help local farmers weather the Dust Bowl years.
He also helped found the Nebraska Farm Business Association, which aggregated the data that he and his peers collected, so that they could determine best practices.
And he worked together with my mother, Alice, who ran the family poultry business.
Farm Credit and the University of Nebraska’s labs and greenhouses emerged out of United States government programs that had been created to improve the agriculture sector’s performance.
That sector was under water in 1933; with one-quarter of the population living on farms at the time, more investment was needed.
That year, Congress passed the first “farm bill,” the Agricultural Adjustment Act, which boosted investment in the rural economy and helped lift farm income by 50% within two years.
Federal farm programs treated farming as a business enterprise, enabling businessmen like my father to prosper.
Eighty years later, African farmers need to make the same switch, by treating their subsistence operations as family-owned enterprises.
And, like my father during the Dust Bowl years, they have novel means at their disposal: a wide range of new seeds and other technologies have been developed for African family farms – those with 4-5 acres or less – to use in the field.
In October, a group of scientists received the World Food Prize for producing and disseminating a sweet potato variety that adds vitamin A to Sub-Saharan Africans’ diets, and other new seed varieties are helping farmers survive the harvest-crushing drought.
But, as a recent report from the Alliance for a Green Revolution in Africa (AGRA) makes clear, government investment must follow the science.
Agriculture comprises almost two-thirds of Sub-Saharan Africa’s workforce, and in 2003 the African Union called for countries to increase their investment in the sector to an ambitious 10% of all government spending.
Only 13 countries answered that call, but their investments – in research and development, services that help farmers take advantage of new research findings, credit and financing initiatives, commodity exchanges, and other marketing efforts – have already paid dividends.
Those 13 countries have experienced marked improvements in agricultural production, per capita GDP, and nutrition.
Government investment paves the way for private-sector investment, and it could be a game-changer for African farmers, who have operated at subsistence levels for far too long.
Only about 6% of rural households in Sub-Saharan Africa receive loans from financial institutions.
Moreover, almost two-thirds of African farmland soil is missing key nutrients, and many farmers lack the technical knowledge and resources to restore their land’s fertility, leaving them unable to take full advantage of new technologies.
African farmers growing new crop varieties are increasing their yields by only 28%, compared to 88% for farmers in Asia.
My parents made certain that all five of their children graduated from college.
Like them, farmers everywhere want to ensure that their children lead healthy, prosperous lives; and they all recognize the importance of education.
The farmers I have met around the world often just want to sell enough extra produce to pay their health bills and put their children through school.
They take advantage of opportunities when they arise, and they position their children to reap larger profits in the future.
One hopes that an American story of economic progress, like that of my family, will soon be an African story, too.
With so many new innovations becoming available, Africa’s family farmers need their governments to invest in their future.
If they do, that future will look much better than today’s dusty and desperate reality.
Africa at Risk
ADDIS ABABA – Climate change will hit Africa – a continent that has contributed virtually nothing to bring it about – first and hardest.
Aside from Antarctica, Africa is the only continent that has not industrialized.
Indeed, since 1980’s the industrialization that had taken place in Africa has by and large been reversed.
Africa has thus contributed nothing to the historical accumulation of greenhouse gases through carbon-based industrialization.
Moreover, its current contribution is also negligible, practically all of it coming from deforestation and degradation of forests and farmland.
Yet climate change will hit Africa hardest, because it will cripple the continent’s vulnerable agricultural sector, on which 70% of the population depends.
All estimates of the possible impact of global warming suggest that a large part of the continent will become drier, and that the continent as a whole will experience greater climatic variability.
We know what the impact of periodic droughts have been on the lives of tens of millions of Africans.
We can therefore imagine what the impact of a drier climate on agriculture is likely to be.
Conditions in this vital economic sector will become even more precarious than they currently are.
Africa will not only be hit hardest, but it will be hit first.
Indeed, the long dreaded impact of climate change is already upon us.
The current drought covering much of East Africa – far more severe than past droughts – has been directly associated with climate change.
The upcoming climate negotiations ought to address the specific problems of Africa and similarly vulnerable poor parts of the world.
This requires, first and most importantly, reducing global warming to the apparently inevitable increase of two degrees Celsius, beyond which lies an environmental catastrophe that could be unmanageable for poor and vulnerable countries.
Second, adequate resources should be made available to poor and vulnerable regions and countries to enable them to adapt to climate change.
Climate change, which was largely brought about by the activities of developed countries, has made it difficult for poor and vulnerable countries to fight poverty.
It has created a more hostile environment for development. No amount of money will undo the damage done.
But adequate investment in mitigating the damage could partly resolve the problem.
Developed countries are thus morally obliged to pay partial compensation to poor and vulnerable countries and regions to cover part of the cost of the investments needed to adapt to climate change.
Various estimates have been made of the scale of investment required by those countries.
One conservative estimate – which has a reasonable chance of being accepted precisely because it is conservative – calls for $50 billion per year as of 2015, increasing to $100 billion by 2020 and beyond.
A transitional financing arrangement would be put in place for the period 2010-2015.
Some argue that developed countries cannot come up with such sums, particularly given their current economic challenges.
But no one has so far argued that the cost of damage caused to the development prospects of poor countries and regions is less than the amount of compensation being offered to cover adjustment costs.
The reason is obvious: the damage caused is many times higher than the compensation being requested.
Nonetheless, it is argued, whatever the real cost of the damage, developed countries currently cannot afford to provide that kind of money.
But we all know that these countries and their national banks were able to spend trillions of dollars in a few months to bail out their bankers, who earned super-profits when the going was good.
When the good times ended, taxpayers and governments were prepared to rescue them and to ensure that they continued to receive their extraordinary bonuses.
If the developed world is able to pay trillions of dollars to clean up its bankers’ mess, how is it possible that it cannot afford to pay billions of dollars to clean up a mess that it created, and that is threatening the survival of whole continents?
Clearly this is not about the availability of resources. It is about the inappropriate priorities in how resources are allocated.
It is about moral values that make it appropriate to rescue bankers, who expect everyone but themselves to pay for the mess they created, and inappropriate to compensate the world’s poorest people, whose survival is threatened precisely because of the mess created by developed countries.
I cannot believe that people in developed counties, when informed about the issues, would support rescuing bankers and oppose partial compensation for poor countries and regions.
I cannot believe that they will let such an injustice occur.
If they are not expressing their outrage over the injustice of it all, it can only be because they are inadequately informed.
Three Humanitarian Challenges for Africa in 2018
NAIROBI – In mid-2017, when a cholera outbreak in Somalia threatened to overwhelm local hospitals, health experts feared the worst.
With crippling drought, malnutrition, and poverty already endemic, an outbreak of deadly diarrhea seemed destined to paralyze the fragile state. But, despite the dire predictions, institutional paralysis was avoided.
Although hundreds died and many more became sick, the collective response managed by governments, NGOs, and local communities, including the national Red Crescent Societies supported by the Red Cross movement, contained the disease.
Somalia’s experience gives me great hope for Africa’s future.
But it also serves as a reminder that local capacity is easily inundated during times of crisis.
While some parts of Africa have become self-sufficient in terms of public health, others continue to lean heavily on global aid.
For these areas, partnership is the best means of minimizing risks.
In particular, three key challenges this year are likely to pose the severest tests of Africa’s ability to manage humanitarian crises.
The first challenge is violence in the Democratic Republic of the Congo.
Last year, conflict in the DRC’s central Kasai region displaced some 1.4 million people, bringing the total displaced population to 4.1 million – the largest concentration of internal refugees anywhere in Africa.
The violence has exacerbated food insecurity, with more than three million people severely undernourished.
Unfortunately, the Kasai crisis is expected to worsen in 2018.
A recent assessment by the Red Cross Society of the DRC warns that the number of people displaced will continue to rise, and with a fast-spreading cholera outbreak threatening the region, a coordinated plan of action is urgently needed.
The second challenge this year is Somalia’s food insecurity, which, according to the Famine Early Warning Systems Network, is expected to intensify this year.
Below-average rainfall in 2017 stunted harvests, and most regions have not fully recovered.
As humanitarian aid is channeled to the country, efforts must be made to target long-term solutions, such as improving agricultural output, educational access, and economic opportunity.
Historically, most aid to the country has been earmarked for emergency relief; even the collective cholera response was narrowly focused on short-term health.
But Somalia desperately needs a more holistic, long-term development strategy.
Finally, the very scourge that Somalia contained last year will continue to rear its head elsewhere in the region.
Yemen’s cholera outbreak is now the largest in history, having already surpassed one million confirmed cases, and, despite years of international assistance, the threat continues to stalk Africa.
In the last four decades, African countries reported over three million suspected cholera cases to the World Health Organization and new cases are cropping up this year in Africa’s east-central and southern regions.
Fortunately, there is hope that Somalia’s containment success in 2017 can be replicated, provided that communities and individuals are well aware of the disease and related risks, and that local actors receive the needed resources.
The Global Task Force on Cholera Control, which seeks to build local and international support for improved health care and sanitation, has published a global roadmap for ending cholera by 2030.
Although that is an ambitious target, it is achievable if international organizations and local governments work together.
Natural and manmade crises will continue to plague Africa, but organizations like mine are working hard to bring about a brighter future through improved capacity building.
To succeed, however, local and international development partners must reorient their thinking; humanitarian aid alone will not solve Africa’s myriad challenges.
While money is clearly needed, it must be spent more strategically to improve structural weaknesses that perpetuate instability.
For example, if more funding were devoted to community-level health care projects, local organizations would be better positioned to lead when outbreaks threaten.
Put simply, the international development community must do more to invest in grassroots solutions, empowering Africans rather than treating them as subcontractors to their own suffering.
Not only are local organizations better positioned to navigate complex cultural and linguistic landscapes; they also have more to lose if they fail.
Last year was devastating for many Africans, as millions suffered from drought, hunger, and violence.
But in Somalia, a coordinated response to a serious health threat offered new hope for a more secure future.
When local ingenuity and international support align, the cycle of suffering can be broken. For many African countries, the ability to look confidently beyond the next crisis is the first step on the long road to self-reliance.
Africa, Climate Change, and the G-8 Summit
British Prime Minister Tony Blair has declared that the two issues at the center of the G-8 Summit this July will be African poverty and global climate change.
These may seem to be distinct issues. In fact, they are linked.
A trip I took to a village in the Tigre region in northern Ethiopia shows why.
One morning, I was taken to a dry riverbed at the village’s edge.
Farmers were digging a pit in the riverbed, down to the water table approximately two meters below ground level.
They explained that until recently this was a perennial river – one that flows throughout the year – but now the river stops flowing during the dry season.
Only when the annual rains begin in the summer does water reappear in the river bed.
Until then, water-starved communities dig for water, if they can find it and if they can afford to pump it out.
In northern Ethiopia, as in much of Africa, the rain cycle has changed markedly in recent years.
Ethiopian village life has long depended on two crops, one during a short rain in March and April, and the main crop during the long rain in the summer months.
In recent years, the short rains have failed entirely, and long rains have been erratic.
Hunger is omnipresent.
Perhaps half of the children are severely underweight.
Much of arid sub-Saharan Africa, notably in the Sahel (the region just south of the Sahara desert), has experienced a pronounced drop in rainfall over the past quarter-century.
This decline coincided with a rise in the surface temperature of the neighboring Indian Ocean, a hint that the decline in rainfall is in fact part of the longer-term process of man-made global warming.
Failures of rainfall contribute not only to famines and chronic hunger, but also to the onset of violence when hungry people clash over scarce food and water.
When violence erupts in water-starved regions such as Darfur, Sudan, political leaders tend to view the problems in narrow political terms.
If they act at all, they mobilize peacekeepers, international sanctions, and humanitarian aid.
But Darfur, like Tigre, needs a development strategy to fight hunger and drought even more than it needs peacekeepers. Soldiers cannot keep peace among desperately hungry people.
One course of action must be to help impoverished African regions to “adapt” to climate change and to escape the poverty trap.
Water-stressed regions like Ethiopia and Sudan can adapt, at least in part, through improved technologies such as “drip irrigation,” rainwater harvesting, improved water storage facilities, deep wells, and agro-forestry techniques that make best use of scarce rainfall. Better land-management practices (the re-planting of degraded forests, for example) can recharge underground water aquifers.
Poor countries cannot afford these technologies on their own.
Nor should they have to.
Help for poor countries in Africa and elsewhere to adapt to climate change should not be described as charity or aid, but rather as compensation for damages being imposed on the poorest people on the planet.
Greater help for these countries to escape from extreme poverty has been promised for decades but has not been delivered.
In addition to adapting to climate change, the world must also reduce future risks to the planet by cutting back on emissions of greenhouse gases, which are the source of man-made climate change.
While adaptation to climate change is necessary – because it is already occurring – this is not enough.
If the world fails to mitigate future climate change, the effects of rising temperatures, increasing droughts, more numerous and severe tropical storms, rising sea levels, and a spread of tropical diseases will pose huge threats to the entire planet.
The famines in Ethiopia and the violence in Darfur suggest what can lie ahead.
The best way to reduce long-term climate change is to reduce carbon emissions.
There are at least three options: shift to non-carbon energy sources such as solar or nuclear energy; capture and dispose of the carbon dioxide emitted at carbon-based power plants; economize on energy use, for example by shifting to hybrid automobiles and trucks.
Most likely, all three of these methods will have to play a role.
The effort to reduce greenhouse gases will require decades of action, but, given the long lead times in overhauling the world’s energy systems, we must start now.
Rich countries need to lead the way.
It is ironic that the United States, which portrays itself as a friend of democracy and impoverished countries, gives the smallest share of its GNP in aid among the rich countries, and also refuses to participate in global efforts to reduce greenhouse gas emissions.
This is especially ironic because African countries like Ethiopia stand steadfastly and bravely with the US in the fight for freedom and against terrorism, even as they struggle with hunger, disease, and famine.
Moreover, countries like Ethiopia are making valiant, indeed remarkable, efforts to overcome their problems, despite the lack of adequate, and long-promised, help from the world’s richest countries.
Africans suffering from hunger and drought, and indeed poor people everywhere, have a right to ask much more of the US and other rich countries.
Tony Blair is right to call on his rich-country colleagues to follow through on their unfulfilled promises.
Capitalizing on Africa’s Demographic Dividend
LOMÉ – Africa is home to the world’s youngest and fastest-growing population.
With as many as 20 million young people poised to join the workforce every year for the next three decades, the continent has an opportunity to shift the balance of local and global growth with a purpose: jobs.
But it is far from inevitable that it will do so.
For African countries to capitalize on this demographic dividend, the future workforce must be educated, trained, and have adequate employment opportunities.
Putting all the pieces in place will not be easy.
These are uncertain times for the global economy.
Trade tensions between the United States and China are threatening the integrity of global value chains, and Britain’s looming exit from the European Union has the potential to cause even more disruption.
The International Monetary Fund’s October forecast warns that as historic economic drivers stall, global growth this year and next could fall to 3.7%, a decline of 0.2 percentage points from previous estimates.
But as this slowdown gets priced in by stock markets around the world, new drivers of growth will emerge.
Africa is well positioned to become one of them.
According to the World Bank, six of the world’s ten fastest-growing economies are in Africa.
Intra-African trade might be the gateway to future local and global growth, with the continent’s burgeoning population forging new opportunities across borders.
Most significantly, Africa’s labor force is on the verge of a dramatic expansion.
Today, 60% of Africans are younger than 25, and 41% are under the age of 15.
By 2050, Africa’s youth population is expected to reach 840 million.
But this massive pool of potential talent is a double-edged sword.
Despite strong GDP growth over the last ten years, the majority of young people in Africa could not capture economic opportunities.
Furthermore, the African Union/OECD report Africa’s Development Dynamics 2018 highlights that if the underemployment trend continues, Africa’s young people will suffer the most.
Failing to employ Africa’s young people fully could marginalize an entire generation and lead them down a path of disruption for which we may not be prepared.
For countries to experience job-led long-term growth, the provision of quality opportunities in agriculture is vital.
If that does not happen, and quality jobs remain scarce, the economic expansion of which Africa is capable will not happen.
In other words, African governments are facing a deadline to match job growth with skills training.
Unfortunately, at the moment, few countries are addressing this challenge effectively.
According to the African Development Bank, the unemployment rate for young people in Africa is already double the rate for adults.
In fact, young people are being let down even before they start looking for work.
Too many primary schools suffer from crippling teacher shortages, for example, and gender discrimination prevents millions of girls from even attending high school.
To overcome these shortcomings will require significant investments of political and financial capital.
Some leaders are moving in this direction.
At the Paris Peace Forum (PPF), held earlier this month, African and global leaders gathered to discuss the powerful idea that international cooperation is the key to tackling global challenges and ensuring durable peace.
On the sidelines of the PPF, the focus fell on African youth.
The AU-EU Youth Cooperation Hub, one of 119 projects selected to participate in the Forum, attended the meeting to discuss the AU-EU Youth Agenda.
Striving to involve young people across Africa and Europe in decisions that impact them, now and in the future, this initiative aims to showcase strategies for bringing Africa and Europe together to address challenges such as the demographic dividend.
One approach to capitalizing on Africa’s demographic boom is to expand the availability of training initiatives that pair employers’ needs with African talent.
As a former fellow with the Ibrahim Leadership program, I can attest to the transformative power of top-tier educational schemes and their value as incubators for job-related skills.
Africa’s success relies on its ability to harness its demographic dividend by equipping its youth with technological and innovative skills, which will be a catalyst for economic growth.
This includes training and agriculture-focused programs to absorb skills along the value chains that connect raw materials to industries and markets across Africa.
By 2030, one in every five people on the planet will be African.
Because of its size alone, Africa’s labor force will have the potential to drive global growth for decades.
But to do so, Africans must implement the necessary reforms today.
As our demographic dividend matures, governments, institutions, and organizations must help position young people for success.
If African countries can meet this challenge, prolonged economic growth – at home and abroad – will be the reward.
Africa’s Path from Poverty
BEIJING – All low-income countries have the potential for dynamic economic growth.
We know this because we have seen it happen repeatedly: a poor, agrarian economy transforms itself into a middle- or even high-income urban economy in one or two generations.
The key is to capture the window of opportunity for industrialization arising from the relocation of light manufacturing from higher-income countries.
That was true in the nineteenth and twentieth centuries, and it remains true today.
Japan seized its opportunity in the years following World War II, using labor-intensive industries, such as textiles and simple electronics, to drive its economy until rising labor costs eroded its comparative advantage in those sectors.
That shift then allowed other low-income Asian economies – South Korea, Taiwan, Hong Kong, Singapore, and to some extent Malaysia and Thailand – to follow in Japan's footsteps.
China, of course, is the region's most recent traveler along this well-trodden path.
After more than three decades of breakneck economic growth, it has transformed itself from one of the poorest countries on earth to the world's largest economy.
And now that China, too, is beginning to lose its comparative advantage in labor-intensive industries, other developing countries – especially in Africa – are set to take its place.
Indeed, ever since the Industrial Revolution, the rise of light manufacturing has driven a dramatic rise in national income.
The United Kingdom's economic transformation started with textiles.
In Belgium, France, Sweden, Denmark, Italy, and Switzerland, light manufacturing led the way.
Similarly, in the United States, cities like Boston, Baltimore, and Philadelphia became centers for producing textiles, garments, and shoes.
Until recently, few believed that Africa, too, could become a center for modern manufacturing.
But, with the right policies, there is no reason why African countries could not follow a similar trajectory.
Consider land-locked Ethiopia, which only ten years ago seemed to be an especially bad bet.
But then the country built an industrial park near Addis Ababa and invited the Chinese shoemaker Huajian to open a factory there.
Huajian opened its doors in January 2012 with two production lines and some 600 workers.
By the end of the year, it had employed 2,000 Ethiopians and doubled the country's exports of leather shoes.
Today, the company has 3,500 workers in Ethiopia producing more than two million shoes a year.
In 2013, spurred by Huajian's success, the Ethiopian government created a new industrial park, with space for 22 factory units.
Within three months, all of them had been leased by export-oriented companies from Turkey, Korea, Taiwan, China, and elsewhere.
The World Bank has provided $250 million to support the continued construction of these industrial parks.
The Ethiopian success story is just the start.
As investors learn more about Africa, they will increasingly see what it has to offer.
Indeed, the cost of labor in Africa is competitive enough that Ethiopia could attract companies from countries as poor as Bangladesh.
Africa has a surplus of agricultural labor and too few other jobs.
As foreign firms launch operations in the labor-intensive sectors in which Africa has a comparative advantage, they will train the local workforce.
Some workers will become managers.
They will become familiar with the technology and learn how to maintain consistent quality in the production line.
They will establish contacts with international buyers and investors.
And, eventually, some of them will be able to raise capital and start firms of their own – export companies owned and operated by Africans.
Mauritius shows the path ahead.
In the 1970s, the government set up industrial parks to process textiles and garments for export.
At the time, most of the owners were from Taiwan or Hong Kong; today, more than 70% of the island's industrial companies are locally owned.
A carefully focused export strategy is crucial.
The international development community and many African governments want to work toward regional integration, linking the markets of 55 African countries.
This might have its advantages, but it should not be a priority.
Africa today accounts for just 1.9% of global GDP, compared to 21% for the United States and 23% for Europe.
Developing countries must use their limited resources in the most effective way, and there is no question where the most attractive opportunities in Africa are to be found.
For example, instead of investing heavily in the infrastructure needed for regional integration, a country like Ethiopia would be better off building industrial parks and linking them by road to ports in Djibouti.
With the right growth strategy, far-reaching change can come within a person's lifetime – sometimes more than once.
My native Taiwan is now a high-income economy.
But when I was born there, in 1952, the island was poorer than almost every country in Africa.
Then it happened to me again.
I moved to mainland China in 1979, when the country's per capita income was less than one-third of Sub-Saharan Africa's.
Today, China has become an upper-middle-income country, and it is on track to become a high-income country by 2020.
My hope is that I can witness a third economic transformation in my lifetime, this time in Ethiopia and other countries in Africa.
If they stay on the tried and tested path of those who have gone before, there is every chance that I will.
The Promise of Digital Health
BASEL – Africa has changed remarkably, and for the better, since I first worked as a young doctor in Angola some 20 years ago.
But no change has been more obvious than the way the continent has adopted mobile technology.
People in Africa – and, indeed, throughout low- and middle-income countries – are seizing the opportunities that technology provides, using mobile phones for everything from making payments to issuing birth certificates, to gaining access to health care.
The benefit of mobile technologies lies in access.
Barriers like geographical distance and low resources, which have long prevented billions of people from getting the care they need, are much easier to overcome in the digital age.
And, indeed, there are countless ways in which technology can be deployed to improve health-care access and delivery.
Of course, this is not new information, and a growing number of technology-based health initiatives have taken shape in recent years.
But only a few have reached scale, and achieved long-term sustainability; the majority of projects have not made it past the pilot phase.
The result is a highly fragmented landscape of digital solutions – one that, in some cases, can add extra strain to existing health systems.
The first step to addressing this problem is to identify which factors breed success – and which impede it.
Here, perhaps the most important observation relates to how the solution is linked to the reality on the ground.
After all, technology is an enabler for the innovation of health-care delivery, not an end in itself.
Solutions that focus on end-users, whether health practitioners or patients, have the best chance of succeeding.
Fundamental to this approach is the recognition that what users need are not necessarily the most advanced technologies, but rather solutions that are easy to use and implement.
In fact, seemingly outdated technologies like voice and text messages can be far more useful tools for the intended users than the latest apps or cutting-edge innovations in, say, nanotechnology.
Consider the Community-based Hypertension Improvement Project in Ghana, run by the Novartis Foundation, which I lead, and FHI 360.
The project supports patients in self-managing their condition through regular mobile medication reminders, as well as advice on necessary lifestyle changes.
This approach is successful because it is patient-centered and leverages information and communication technology (ICT) tools that are readily available and commonly used.
In a country where mobile penetration exceeds 80% but only a few people have smartphones, such simple solutions can have the greatest impact.
For health practitioners, digital solutions must be perceived as boosting efficiency, rather than adding to their already-heavy workload.
Co-creating solutions with people experienced in delivering health care in low-resource settings can help to ensure that the solutions are adopted at scale.
For example, the telemedicine network that the Novartis Foundation and its partners rolled out with the Ghana Health Service was a direct response to the need, expressed by health-care practitioners on the ground, to expand the reach of medical expertise.
The network connects frontline health workers with a simple phone call to consultation centers in referral hospitals several hours away, where doctors and specialists are available around-the-clock.
From the outset, the project was a response to an expressed need to expand the reach of medical expertise, and was fully operated on the ground by Ghana Health Service staff, which made this model sustainable at scale.
To realize the full potential of digital health, solutions need to be integrated into national health systems.
Only then can digital technology accelerate progress toward universal health coverage and address countries’ priority health needs.
Collaboration across the health and ICT sectors, both public and private, is essential.
Multidisciplinary partnerships driven by the sustained leadership of senior government officials must guide progress, beginning at the planning stage.
Intra-governmental collaboration, dedicated financing for digital health solutions, and effective governance mechanisms will also be vital to successful strategies.
Digital technologies offer huge opportunities to improve the way health care is delivered.
If we are to seize them, we must learn from past experience.
By remaining focused on the reality of end-users and on priority health needs, rather than being dazzled by the latest technology, we can fulfil the promise of digital health.
Confronting Africa’s Water Challenge
ABIDJAN – Water is essential for life, and yet it is scarce in many parts of the world.
Owing to the effects of climate change, Africa is experiencing its worst drought since 1945, especially in Southern Sudan, Somalia, Ethiopia, and Northern Nigeria.
These fragile areas now need the global community’s support.
We need to build resilient systems to ensure access to potable water for all people, and to improve water-delivery and sanitation provisions in Africa’s rapidly growing urban areas.
We should begin by expanding Africans’ capacity to harness wastewater.
With investment and proper management, wastewater can become a sustainable source of wealth for many Africans, with added benefits for human health, agricultural productivity, and environmental sustainability.
Over the past six years, the African Development Bank has invested $3.3 billion in projects to expand access to water and improve sanitation, with around $2.2 billion of that going to urban services that reach at least 17 million people.
The AfDB supports an integrated urban water-management model (IUWM) that, in keeping with United Nations Sustainable Development Goal 6, enables communities to derive a sustainable income from management of urban liquid and solid waste.
IUWM efforts require a significant initial investment, and come with steep capital and operational costs.
Only a few African cities collect and treat any more than 20% of the wastewater generated through centralized wastewater-management systems.
The remaining 80% constitutes a huge untapped source of potentially valuable liquid and solid waste.
With the right investment, foresight, and commitment, this underappreciated resource can create jobs and deliver sustainable growth.
Wastewater management is thus a central feature of the AfDB’s strategic priorities, known as the High 5s, which aim to improve Africans’ quality of life, boost public health, achieve gender equality, create jobs, and increase communities’ resilience to the effects of climate change.
Water will also play a key role in reaching the High 5s’ industrialization and sustainable-farming objectives.
In Yaoundé, Cameroon, the AfDB helped to protect some 300,000 people and their property by reducing the frequency of floods from 15 incidents per year to just three.
And with a $40 million sanitation project, the AfDB helped to lower the proportion of the city’s malaria-afflicted population from 16% to 12%.
In Abidjan, Côte d’Ivoire, the $23 million AfDB-funded Gourou Basin Integrated Watershed Management Project significantly reduced flooding throughout the Gourou Basin, and improved 2.8 million inhabitants’ livelihoods.
In Zimbabwe, after 4,300 people died in the 2008-2009 cholera pandemic, the AfDB and other donors supported the $43.6 million Urgent Water Supply and Sanitation Rehabilitation Project, which made emergency repairs to wastewater systems in urban areas, helping 2.5 million people.
All AfDB-supported wastewater-management systems follow sustainability strategies to ensure that they enhance economic gains, benefit local communities, and remain affordable.
These projects also help countries to harness and use waste flows, by converting sewage to biogas and fertilizer.
Meanwhile, the AfDB’s African Water Facility (AWF) complements its project-finance work by attracting downstream investments in water infrastructure.
In February, flooding and strong winds from Tropical Storm Dineo devastated the coast of Mozambique and had a severe impact on the local population.
But just a few weeks later, the AWF launched a feasibility study to improve livelihoods and climate-change resilience throughout Mozambique’s Inhambane Province, where the storm struck.
In collaboration with the Global Water Partnership, the AWF is implementing IUWM systems in five African cities, including Kinshasa in the Democratic Republic of Congo and Marondera in Zimbabwe.
In the DRC alone, IUWM systems can be expected to improve water delivery and sanitation for 17 million people by 2030.
The Bill & Melinda Gates Foundation is also tapping into the AfDB’s expertise, by providing an $18 million grant to fund Phase II of the AfDB’s Urban Sanitation Program.
This effort will help to develop business innovations for affordable and sustainable sanitation services in Africa, which could reach two million urban dwellers directly and another six million people through subsidiary projects.
Africa’s wastewater-management challenges are substantial and complex.
But the AfDB is determined to provide opportunities that pay dividends for African communities – in public health, improved sanitation, economic development, and environmental protection.
Improving the quality of life for all Africans will require political commitment, public-private partnerships, and robust public involvement.
With the High 5s framework, the AfDB is working to bring these three ingredients together.
All stakeholders – in Africa and internationally – must redouble our efforts to ensure clean, affordable water for all, and to support African countries suffering through a historic drought.
We have a moral obligation to do so.
After all, water means life.
Is Africa Still Rising?
WASHINGTON, DC – Between 2000 and 2014, Africa grew at a strong clip, fueling belief in the narrative of an “Africa rising.”
But, since 2015, growth across Sub-Saharan Africa has weakened, and the poor outlook for commodity prices has cast doubt on Africa’s economic promise, leading many to question the “Africa rising” narrative – and some to pronounce it dead.
Such skepticism is, to some extent, understandable.
The 2014 oil-price shock hit several African economies especially hard, and played a role in pushing aggregate growth down from 5-6% in 2004-2014 to just 2.5% in 2015-2017 – a rate that barely keeps up with population growth.
Moreover, the continent's three largest economies – Angola, Nigeria, and South Africa – have experienced major declines in performance.
Last year, Angola and South Africa’s economies stagnated, while the Nigerian economy actually contracted for the first time since 1991.
The latest projections suggest that these economies will experience tepid recoveries in the coming years.
But Africa’s skeptics have overlooked a number of important factors.
For starters, when one sets the three largest economies aside, Sub-Saharan Africa’s aggregate-growth rate for this year rises from 2.5% to almost 4%.
That is faster than the 3.5% rate at which the global economy is currently growing.
In fact, five of the ten fastest-growing economies in the world are in Africa.
And over the next five years, around half of all Sub-Saharan economies will expand at an average rate similar to or higher than that which prevailed during the “Africa rising” heyday.
Furthermore, high commodity prices were just one factor in the region’s strong economic performance between 2000 and 2014.
Many African countries have made vast improvements to macroeconomic management, governance, and the business environment, and entrepreneurship is on the rise.
Even with lower commodity prices, these developments will continue to bolster many African economies.
Today’s skepticism may reflect lasting memories from a darker period, and fears that Africa’s progress has not been sufficiently consolidated.
From the 1970s to the mid-1990s, dictators ruled in many African countries, and the institutions necessary for sustaining strong economic growth were fragile at best.
With civil wars constantly shredding the social fabric in many countries, the continent experienced decades of tepid economic growth.
By 2000, it had been reduced to what The Economist called “Hopeless Africa.”
But those days are gone.
Policymakers across the continent have sustained the 1990s-era reforms that set the stage for the subsequent period of high growth.
Although there is still much work to be done, the economic and business environment in many African countries has continued to improve, and institutions and governance have grown stronger.
Owing to new information and communication technologies, Africans, particularly young Africans, are better informed, more engaged in civil and political discourse, and increasingly capable of holding their leaders accountable.
ICTs have also unleashed a wave of innovation and entrepreneurship across the continent.
These positive trends are not likely to be reversed, and will continue to improve the economic conditions in Africa, even if commodity prices do not rebound.
After all, the region’s economic growth averaged 5.6% between 2000 and 2004, before commodity prices had begun their rapid ascent.
But that is not to say Africa will be spared from daunting challenges in the years ahead.
Globally, the economic environment will become less favorable for African economies.
In the major advanced economies, interest rates will soon rise, and the political backlash against globalization may force governments to abandon their past commitments to development assistance.
In light of all this uncertainty, African policymakers should look inward, by focusing on policies to mobilize national resources and finance their economic agendas.
Those agendas should include a number of key priorities.
African countries need to diversify their economies to withstand future shocks better, while also accelerating the pace of industrialization across the continent.
Governments will have to find a way to create decent jobs for the 11 million people now entering the region’s labor force every year.
And they will need to enact policies to reduce poverty, and ensure that prosperity is shared across all cohorts of society.
These are particularly important goals for Angola, Nigeria, and South Africa.
Angola and Nigeria need to become far less reliant on oil; and South Africa still needs to implement far-reaching reforms to address structural problems that have plagued it since the apartheid era.
Seeing these projects through will require competent political leaders who are committed to the principles of good governance.
Failure could result in an extended period of low growth.
But even if Africa’s three largest economies do end up in the doldrums, it will not necessarily seal the fate of the “Africa rising” story.
After all, “Africa rising” need not mean “all” of Africa.
From the 1960s to the 1990s, the “Asian Tigers” narrative referred only to Hong Kong, Singapore, South Korea, and Taiwan, excluding other developing countries in Asia, such as China.
Similarly, African economies are increasingly differentiating themselves, and should thus be evaluated individually, on the merits of their respective economic policies.
Africa Still Rising
JOHANNESBURG – Is the honeymoon over for African economies?
Less than a decade ago, it seemed that the continent’s economic dreams were beginning to come true, with many countries experiencing impressive GDP growth and development.
Now, as the harsh reality of the continent’s vulnerability to challenging external conditions has set in, sustaining that growth has proved difficult.
Encumbered by slowing growth in China, a collapse in commodity prices, and adverse spillover from numerous security crises, Africa’s overall annual GDP growth averaged just 3.3% in 2010-2015, barely keeping up with population growth – and down sharply from the 4.9% recorded from 2000 to 2008.
But a deeper look suggests that things may not be as bad as they seem, for two key reasons.
First, though average growth has declined, some African economies have thrived in recent years.
Indeed, aggregate GDP has been dragged down since 2010 by faltering growth among oil exporters and security-related crises in the Sahel and North Africa; but in the rest of Africa, GDP growth has accelerated, from 4.1% in 2000-2010 to 4.4% in 2010-2015.
Second, Africa is undergoing a profound long-term transformation, characterized by rapid digitization, urbanization, and growth in the working-age population, which will outnumber the labor force of China and India by 2034.
That demographic trend could unlock future growth by advancing economic diversification, spurring domestic consumption, and supporting industrialization.
In fact, today’s high-growth countries – including Côte d’Ivoire, Ethiopia, Kenya, and Tanzania – have made substantial progress in reducing their dependence on commodity exports, in favor of trade, investment, and domestic consumption.
And many lower-growth countries could head down a similar path.
New research by the McKinsey Global Institute (MGI) shows that spending by Africa’s consumers and businesses already totals $4 trillion.
By 2025, private spending could reach $5.6 trillion – $2.1 trillion by households, and $3.5 trillion by businesses.
This represents a huge opportunity for Africa���s manufacturers.
We believe that Africa can almost double its manufacturing output, to nearly $1 trillion, by 2025, with about 75% of that growth tied to production for local markets.
The question is whether manufacturers will manage to exploit the growth potential that lies in front of them.
African firms have not yet proved capable of meeting existing domestic demand.
Africa still imports about one-third of the food, beverages, and similar processed goods it consumes, whereas the Association of Southeast Asian Nations imports about 20%, and South America’s Mercosur trade bloc imports just 10%.
Africa even imports 15% of the cement it uses, despite having abundant raw materials to make it at home.
To be sure, African business has made great strides in recent years.
Today, 400 African companies have annual revenue of more than $1 billion, and 700 have annual revenue of more than $500 million.
On the whole, these large companies are growing faster – and generating higher profits – than their global peers.
But there is still a long way to go.
Large African (excluding South African) firms’ average annual revenue of $2 billion is half that of large firms in Brazil, India, Mexico, and Russia.
And Africa only has about 60% of the large firms it needs to put it at the same level as the emerging economies.
One key factor limiting firms’ growth is the fragmented nature of the African market, which currently comprises mostly small economies with only limited economic and political linkages.
There are eight partly overlapping regional trade zones, none of which includes more than half of Africa’s countries.
Only Egypt, Morocco, Nigeria, and South Africa rank in the top 100 of MGI’s Global Connectedness Index.
Beyond excessive trade barriers, Africa suffers from inadequate transport links and limits on the free movement of people.
Africans need visas to travel to more than half the countries on their own continent.
The recent launch of the African Union passport is a step in the right direction – but it is only one step.
A more integrated market would not only enable African companies to create the economies of scale they need to compete; it would also be far more appealing to institutional investors.
Building such a market must therefore be a top priority for African leaders, as they seek to unleash the continent’s economic potential.
Equally important, Africa’s leaders must work to improve the business environment.
Though some progress has been made on this front in the last two decades, non-tariff barriers remain high.
Indeed, regulatory issues are still cited as a serious deterrent to investment.
Many African businesses – nearly half of companies in Nigeria, and more than one-third in Angola and Egypt – highlight unreliable electricity supplies as a major challenge.
And almost 40% of firms surveyed by the World Bank lament the constraints imposed by competition from informal firms.
Some of these issues could be addressed relatively quickly.
Consider the strides Rwanda has made since 2007, when it established a development board to improve its business environment.
In less than a decade, that board has led the creation of a “one-stop center” to facilitate investment, has overseen streamlined issuance of construction permits, and has pressed successfully for a fixed fee for property registration, the extension of customs hours, and risk-based customs inspections.
As a result, Rwanda’s global ranking for the ease of doing business jumped from 143 in 2008 to 32 in 2014.
This success can surely be replicated elsewhere in Africa.
Despite the challenges some African countries face, the continent’s economic potential remains massive, thanks to favorable demographic dynamics, fast-growing cities, burgeoning domestic markets, and a digital revolution.
With the right policies, a relentless focus on execution, and a great deal of determination, Africa can still rise.
Africa’s Arrival
NEW YORK – The African Development Bank (AfDB) has just published its African Economic Outlook for 2018.
This year’s revamped publication – shorter than usual, analytically well-structured, and written in lucid prose, without hyperbole – in some ways mirrors Africa’s own transformation, as it raises hopes that we may at last be witnessing the continent’s long-promised economic arrival.
Africa’s rise has been a long time coming.
In the 1960s, hopes were high.
The remarkable leaders of the independence generation – such as Ghana’s Kwame Nkrumah and Kenya’s Jomo Kenyatta – received advice from the world’s top economists.
The Caribbean-born Nobel laureate Arthur Lewis became Nkrumah’s Chief Economic Adviser.
In India, we read about these leaders’ friendship with our own post-independence prime minister, Jawaharlal Nehru, and the hope for a new dawn for all emerging economies.
And many emerging economies did indeed take off.
In the late 1960s, some East Asian economies surged ahead.
Beginning in the early 1980s, China began its decades-long rise.
And, from the early 1990s, India’s economy also began to grow robustly, with annual rates reaching the 9% range by 2005.
But Africa remained stagnant, mired in poverty.
Ironically, it was the continent’s resource wealth that hampered economic progress, as it fueled conflicts among governments and insurgents eager to control it.
The resulting political instability attracted outsiders keen to exploit governments’ weakness.
As the Indian poet and Nobel laureate Rabindranath Tagore put it in his 1936 poem “Ode to Africa,” which played on perceptions about who is “civilized,” the continent fell prey to “civilization’s barbaric greed,” as the colonists “arrived, manacles in hand/Claws sharper by far than any of your wolves.”
Finally, at the turn of the twenty-first century, things began to change for Africa.
A few dynamic leaders, democratic stirrings, and emerging regional cooperation led to a decline in poverty and a pickup in growth.
Commodity exporters faced a setback around 2014, when prices plummeted.
But this turned out to be a blessing in disguise, because it forced countries to diversify their economies and increase production – factors that supported renewed growth.
According to the AfDB report, Africa’s 54 economies grew by 2.2% in 2016, on average, and 3.6% in 2017.
In 2018, the AfDB predicts, average growth will accelerate to 4.1%, while the World Bank expects Ghana to grow by 8.3%, Ethiopia by 8.2%, and Senegal by 6.9%, placing these countries among the world’s fastest-growing economies.
And these figures are not wishful thinking: in 2016, Ethiopia’s GDP grew by 7.6%.
Of course, serious challenges remain.
South Africa, the continent’s strongest economy, is now facing the difficult task of tackling its deep-rooted corruption.
Yet, with the African National Congress now apparently determined to replace President Jacob Zuma’s scandal-ridden administration with one led by the party’s new leader, Cyril Ramaphosa, there is reason for hope.
More broadly, many African countries need to find ways to create more employment – and fast.
The share of the working-age population is rising faster in Africa than in any other region.
This “demographic dividend” has immense potential.
But if job creation stalls, the unemployed or under-employed are likely to become frustrated – a recipe for conflict.
Consider the case of Tanzania.
Thanks to President John Magufuli’s effort to mobilize more domestic revenue to support increased development spending, the economy is doing well.
But, with roughly 800,000 individuals entering the labor force each year, Tanzania needs much more working capital, better infrastructure, and educational reform aimed at ensuring that workers have the skills, resources, and opportunities to secure decent jobs.
The same is true of Ethiopia.
In the last couple of decades, the country has made great strides in export-led growth, supported by a growing industrial sector and large investments from China.
Now, it is poised to take over as the economic powerhouse of East Africa.
Yet the urban youth unemployment rate stands at 23.3%. Left unchecked, this situation could easily end up fueling ethnic conflict and political turmoil.
Another, related challenge concerns resource mobilization: countries need funds to invest in infrastructure, human capital, and the creation of trade and digital links within and beyond Africa.
The AfDB report estimates that, for infrastructure investment alone, the continent needs some $170 billion per year, which is $100 billion more than is currently available.
As it stands, Africa receives a total of about $60 billion in foreign direct investment each year.
To close the gap, African governments must attract more money.
That will require establishing effective regulatory structures that facilitate long-term borrowing and repayment, while ensuring that lenders do not exploit borrowers, as has occurred everywhere from rural India to the United States mortgage market.
The challenges are daunting, to say the least.
But there are lessons that African countries can learn from one another.
For example, Ghana’s smooth transfer of power after the December 2016 election set a positive democratic example.
Nigeria’s Lagos State and Tanzania have done a good job of mobilizing internal resources for development.
Add to that the emergence of an indigenous intelligentsia in the region, exemplified by organizations like the AfDB, and it seems that Africa’s moment may have arrived at last.
Africa’s Schooling Without Learning
ACCRA – As the school year began this September, there was welcome news for Ghana’s nearly half-million students entering high school: President Nana Akufo-Addo had fulfilled his campaign promise of free secondary education for children nationwide.
He swore not only to do away with admissions fees, but also to provide free textbooks and meals, the cost of which had often remained a barrier for the poorest students.
Ghana had introduced free compulsory education at the primary and junior high school levels in 1995, but implementation had been painfully slow – and students’ educational dreams were often cut off before high school.
Even in 2014, only 37% of the nation’s students were enrolled in secondary school, owing to high fees.
The president’s move is thus an inspiring example that Ghana’s neighbors should follow.
Unfortunately, despite progressive reforms like these, students across Africa still face other steep barriers to a truly comprehensive education.
In Ghana, for example, poor and rural children are unlikely to reap the full benefits of their new access to secondary education.
The situation is arguably worse elsewhere on the continent.
The issue is not only lack of access to schools, but also lack of good schools.
The results of a staggering new report from the UNESCO Institute of Statistics show that six out of ten children and adolescents around the world – 600 million in total – are not achieving basic skills in mathematics and reading.
In Sub-Saharan Africa, it is estimated that 88% of children and teenagers will enter adulthood without basic literacy.
This constitutes a moral and development crisis that demands immediate action.
Having served as head of the department of Ga-Dangme education at the University of Education in Winneba, I know from first-hand experience that one of the main problems is lack of education and absenteeism among teachers themselves.
The World Bank, which similarly raised the issue of “schooling without learning” in a new report, has corroborated my view.
Addressing this issue requires investing more in teachers’ colleges, promoting teaching as the career of nation-builders, and encouraging the best and brightest students to aspire to a teaching career.
We cannot expect students to learn from poorly educated, poorly paid teachers.
We must also invest more in resources for schools and learning across the board, from scholarships for poor students to new libraries and classroom equipment.
With so many African governments already failing to provide equal, high-quality access to education for their citizens, this is not a challenge that they can take on alone.
As the continent’s population booms – half of the world’s population growth between 2017 and 2050 is expected to occur here – African heads of state will have to work closely with key allies and multilateral organizations to bring in funding and share know-how.
Fortunately, with the launch of the UNESCO report, several partners have already stepped up.
French President Emmanuel Macron is perhaps the most prominent of those who have promised to make investment in education in Africa a high priority.
As the UN’s main educational and cultural organization, UNESCO itself will play a key role in promoting initiatives to bring free, high-quality schooling to students across the continent.
And whoever takes over UNESCO, following the election of a new director-general next month, will have a make-or-break opportunity to craft the right agenda to meet this challenge.
Currently, the organization is mired in a financial crisis and internecine disputes, and it will need a leader who has the vision to solve both internal and external problems.
Notably, France’s candidate, former Minister of Culture and Communication Audrey Azoulay, has put both UNESCO’s internal crisis and education at the top of her agenda.
She has singled out the financial crisis as the biggest threat facing UNESCO and has stressed the need for greater dialogue with members in arrears, like the United States.
In her previous governmental roles, Azoulay helped launch a global plan for cultural diversity through books and introduced plans to protect cultural heritage in conflict zones.
Azoulay also has called for UNESCO to treat education as a catalyst for development and gender equality, and as the best way to help combat the “radicalization of the mind.”
If elected, she has promised to put Sustainable Development Goal 4 – universal quality education – at the heart of UNESCO’s mission, with a special focus on Africa.
The preamble to the Constitution of UNESCO declares, “Since wars begin in the minds of men, it is in the minds of men that the defenses of peace must be constructed.”
Unfortunately, in Africa, we know all too well what happens when efforts to construct the defenses of peace ultimately fail.
Islamist insurgents continue to pose a threat to Mali, where in 2013, they set fire to a library holding thousands of priceless historical manuscripts in the ancient cultural center of Timbuktu.
The incident was not only a devastating blow to world heritage; it was also a reminder of Africa’s history as a center for cultural exchange, literacy, and learning, and a call to action.
The stakes for Africa are high.
Our children are threatened not only by lack of access to schools, but also by lack of opportunities to learn, and by the loss of irreplaceable fragments of their rich history.
We must hope that more governments follow Ghana’s example, that more allies like France increase their support, and that the new director general will place a high priority on UNESCO’s missions in Africa, which are more critical than ever.
Africa’s Year of Opportunity
GENEVA – We are still near the start of 2018, and already it feels like tension and disorder will be the year’s defining characteristics.
From anti-immigration policies in the United States to flaring geopolitical hotspots in the Middle East and East Asia, disruption, upheaval, and uncertainty seem to be the order of the day.
But at least one metric offers reason for cautious optimism: economic growth.
The International Monetary Fund estimates that global growth will reach 3.7% this year, up from 3.6% in 2017.
As Christine Lagarde, the Fund’s managing director, put it in a speech in December, “The sun is shining through the clouds and helping most economies generate the strongest growth since the financial crisis.”
It was fitting that Lagarde made that observation in Addis Ababa, because it is in Africa where the rays of prosperity are shining brightest.
In fact, I predict that 2018 will be a breakout year for many – though not all – African economies, owing to gains in eight key areas.
For starters, Africa is poised for a modest, if fragmented, growth recovery.
Following three years of weak economic performance, overall growth is expected to accelerate to 3.5% this year, from 2.9% in 2017.
This year’s projected gains will come amid improved global conditions, increased oil output, and the easing of drought conditions in the east and south.
To be sure, growth will be uneven.
While nearly a third of African economies will grow by around 5%, slowdowns are likely in at least a dozen others.
Sharp increases in public debt, which has reached 50% of GDP in nearly half of Sub-Saharan countries, are particularly worrying.
But, overall, Africa is positioned for a positive year.
Second, Africa’s political landscape is liberalizing.
Some of Africa’s longest-serving presidents – including Zimbabwe’s Robert Mugabe, Angola’s José Eduardo dos Santos, and the Gambia’s Yahya Jammeh – exited in 2017.
In South Africa, Jacob Zuma’s resignation allowed Cyril Ramaphosa to become president.
In January, Liberians witnessed their country’s first peaceful transfer of power since 1944, when former soccer star George Weah was sworn into office.
All of these gains will be tested, however, as voters in 18 countries go to the polls this year.
Adding to Africa’s story of divergence will be continued political fragility in a number of states, including the Central African Republic, Burundi, Nigeria, South Sudan, and Somalia.
A third source of optimism is Africa’s agricultural sector, where the potential of smallholder farmers, the majority of whom are women, is finally being realized.
African agricultural output is forecast to reach $1 trillion by 2030.
This maturation could not have come at a more opportune time; roughly two-thirds of Africans depend on agriculture to make ends meet.
Large tracts of uncultivated land, a youthful workforce, and the emergence of tech-savvy “agropreneurs” – agricultural entrepreneurs – are lifting production and transforming entire economies.
Fourth, Africans are benefiting from technological disruption.
With more than 995 million mobile subscribers, Africa’s increasing connectivity is being used to power innovation.
Key sectors like farming, health, education, banking, and insurance are already being transformed, greatly enhancing the region’s business landscape.
Fifth, African leaders are getting serious about curbing illicit financial outflows from corrupt practices that rob African countries of some $50 billion annually, much of it in the oil and gas sector.
While US lawmakers are pushing to repeal portions of the 2010 Dodd-Frank financial reform legislation – which contains a provision requiring oil, gas, and mining companies to disclose payments they make to governments – the broader trend is toward greater transparency and accountability.
For example, the Panama Papers and the Paradise Papers pulled back the curtain on the murky system of tax havens and shell companies that shelter billions of dollars from some of the world’s poorest countries, including many in Africa.
And with the G20 and the OECD working to stop tax avoidance, Africa may soon benefit from global efforts to end shady accounting.
Sixth, Africa’s energy sector is set to thrive.
While 621 million Africans still lack reliable access to electricity, innovations like renewables, mini-grids, and smart metering are bringing power to more people than ever before.
In South Africa, renewable energy has taken off; the price of wind power is now competitive with coal.
Ethiopia, Kenya, Morocco, and Rwanda are also attracting large investments in renewable energy.
A seventh area showing signs of progress is education.
To be sure, Africa’s educational offerings remain dismal; more than 30 million children in Sub-Saharan Africa are not in school, and those who do attend are not learning as much as they could.
But many African leaders and publics have recognized these deficiencies; in some countries, such as Ghana, education has even become a deciding issue for voters.
As the Education Commission highlights, some countries are boosting investments in education.
This represents an opportunity to align learning outcomes with future employment needs.
But with over a billion young people living in Africa by 2050, greater investment in education is urgently needed.
Finally, greater attention is being paid to developing a pan-African identity, and African fashions, films, and foods are expanding to new markets.
As these cultural connections grow, Africa’s soft power will continue to rise and extend far beyond the continent.
In many corners of the world, 2018 is shaping up to be yet another disappointing year, as inequality and poverty continue to fuel anger and populism.
Africa will not be entirely immune from such developments.
Nonetheless, the continent’s inhabitants have at least eight good reasons – far more than most people elsewhere – to be optimistic.
Resetting the Africa-Europe Relationship
JOHANNESBURG – In October, the European Union announced a plan to invest €40 billion ($47.6 billion) in Africa, a “Marshall Plan” for the continent that would boost economic growth, create jobs, and, ultimately, slow the migration of young Africans to Europe.
“Words won’t convince migrants to stay at home,” European Parliament President Antonio Tajani said. “We must give them a chance to have a decent life.”
Tajani is right.
Unfortunately, his approach is not.
For almost 60 years, well-meaning foreign governments, many of them European, have poured huge sums of money into Africa, with little to show for it.
Lasting solutions to Africa’s development challenges require funding, to be sure, but they also demand a significant recalibration in relations with foreign partners.
And Africa’s relationship with Europe may require the biggest overhaul of all.
The problem goes much deeper than money; one might even say it’s philosophical.
Africa and Europe have a very old relationship, marked by complexity and pain.
Europe imposed its system of governance, values, and more recently, approaches to trade, long claiming that Africans need to be trained, to modernize, and to emphasize “capacity building.”
This patronizing partnership has run its course, and it is crucial that we change the dynamic.
Meetings like the fifth African Union-European Union summit, which wrapped up last week in Abidjan, Côte d’Ivoire, are a good start.
The meeting, which focused on “investing in youth,” put a spotlight on the complex links between the sides.
One conclusion was clear: the EU’s current answer to addressing migration from Africa is outdated.
If Europe’s strategy to solve its migration challenges relies on money alone, it will fail.
We are a long way from the lopsided dynamic that defined African-European relations during the colonial era.
Today, Europe may need Africa more than Africa needs Europe, especially if one considers human capital.
Over the next 15 years, some 440 million Africans will enter the job market, compared to 72 million in Europe.
Africa’s job seekers will need work, and Europe will have it.
An aging population is already putting a squeeze on Europe’s growth, and vacancies are forecast to multiply amid a shrinking labor pool.
There is even a strong possibility that, in the long run, it will be African young people who pay for the care of European pensioners.
These demographic differences underscore the potential benefits of rethinking economic and political relations.
Without migration, the redistributive policies on which European welfare states depend will be unable to withstand the current rate of aging.
Not only will finding the staff to care for an aging population become more difficult; obtaining sufficient revenue to fund social security systems will also become harder as the dependency ratio rises.
Migration policies that emphasize mobility are essential to support European industries, household consumption and, ultimately, the financing of social benefits.
Because strategic competitors like China and India have already identified the human-capital potential of Africa’s youth, Europe must move quickly to attract and retain – rather than repel – African professionals.
Of the 375,000 students from the continent who study abroad each year, many will establish businesses and find their own place in a globalized economy upon graduation.
There is already growing competition in the US, Canada, China, the Middle East, and Africa itself to attract these highly educated and mobile students.
Just as sixteenth-century Europe needed African gold, twenty-first-century Europe cannot do without the African diaspora.
Which other world region can offer similar market potential for European industries faced with declining demand and or subdued growth in both their domestic and traditional export markets?
That is why it is more important than ever that Europe not engage in an administrative bean-counting exercise, in which other economies will always appear stronger.
Instead, the EU should commit to mutually beneficial employment schemes that maximize the strengths of people and cultures on both continents, notably through skills transfer.
Europe’s recognition of its need for Africa is a necessary paradigm shift, leading, one hopes, to reasoned collaboration.
In an increasingly uncertain world, Africa and Europe can set the foundations for a smarter partnership by changing the basis of their cooperation.
Failure to do so will be costly.
But most of that cost will be borne by Europe.
With alternative partners already courting their talent, it is not Africa that will be hurt the most by the missed opportunity.
Gender Equity for Africa’s Scientists
KIGALI – A girl in Ethiopia could grow up to engineer a new method for improving agricultural yields, if only she could meet the right mentor.
A young woman in Malawi has ideas for new cancer treatments, but will never apply them if she is pushed out of school.
And a girl in Rwanda has all the skills to create a mathematical model to mitigate droughts; all she needs is a research grant to help her pay for college.
There is a global gender imbalance in science, technology, engineering, and mathematics – the so-called STEM disciplines.
But in Africa, this imbalance is doing more than threatening individual futures.
It is also depriving the continent of talents and contributions needed to drive development and progress.
A 2011 African Development Bank report finds that “getting women into science and technology ultimately promises to benefit society as a whole.”
Gender equity in STEM is achievable, and many African scholars are showing the world how to do it.
But they need help, and programs that offer scholarships and support are among the best ways to achieve parity in the sciences.
The causes of Africa’s STEM gender imbalance are often compared to a leaky pipe: girls start out with interest and aptitude, but drop out of the disciplines at various points in their education.
Early data from a Mastercard Foundation initiative aimed at reversing these trends show that a comprehensive approach to plugging the leaks can make a difference.
Success begins with acknowledging that gender equity in STEM matters.
“Science needs us” is how Armanda Kouassi, an industrial engineer and former Mastercard Foundation scholar, puts it.
“With different ideas and perspectives come better solutions and thinking that can move scientific innovations forward and benefit the whole of Africa.”
Kouassi is right.
Africa cannot afford to squander its young, female talent.
Sub-Saharan Africa faces a shortfall of some 2.5 million engineers, technologists, mathematicians, and scientists.
This dearth of expertise threatens a number of Sustainable Development Goals, such as food security, health care, clean water and sanitation, energy, and infrastructure.
Removing gender barriers to STEM requires African governments to make equity in the sciences a priority.
Nowhere is this happening more successfully than in Rwanda, where our collective experience has helped more than 1,250 girls and young women excel in STEM disciplines.
The African Institute for Mathematical Sciences (AIMS), in Rwanda’s capital, Kigali, is one of these agents of change.
The school believes that the next Einstein could be an African woman, an educational approach that informs its comprehensive strategy to plug leaks in the STEM development pipeline.
AIMS’s innovative approach includes helping governments train teachers, ensure that female students are not vastly outnumbered in their classrooms, support students who are mothers, and engage with industry leaders to help graduates succeed in their careers.
To attract more female students, 30% of the school’s scholarships are reserved for female applicants, and the school aspires to reach 50% in the near future.
Similarly, Carnegie Mellon University Africa (CMU-Africa), also in Kigali, is championing change by allocating 30% of its scholarships to young women.
These commitments will have a positive effect on the entire institution, as CMU-Africa seeks to increase dramatically enrollment of female scientists.
Finally, the Forum for African Women Educationalists (FAWE) in Rwanda has funded the education of 1,200 girls enrolled at the country’s top-performing secondary schools specializing in STEM subjects.
Of these students, an estimated 70% are expected to study science at the university level.
Despite these positive developments, quotas alone will not achieve parity.
To make lasting gains, opportunities outside the classroom are also needed.
At FAWE Rwanda, a program called Tuseme (a Swahili word meaning “let’s speak out”) offers girls leadership training through drama, song, and creative arts to teach presentation, negotiation, and decision-making skills.
FAWE Rwanda also works with teachers to develop gender-responsive pedagogical methods.
Likewise, at CMU-Africa, scholars are invited to participate in the university’s Meeting of the Minds Symposium, an annual global gathering for undergraduates to showcase their work to a wider audience of faculty, students, government officials, and industry representatives.
And, the Next Einstein Forum, a select program at AIMS that recognizes Africa’s best young scientists and technologists – of which 40% are women – provides emerging innovators with an opportunity to lead their own research while inspiring the next generation of scientific thinkers.
Inequalities faced by girls and young women in African education cannot be erased overnight.
As Rebecca, a Mastercard Foundation scholar from Uganda, remembers, “When I was at my school, the boys used to call us ‘half-men,’ because if you’re a lady and you go for sciences, you’re a half-man.”
But, Rebecca adds, “It was cool being a science student.”
Africa needs more women who share Rebecca’s enthusiasm for STEM.
To ensure that science remains appealing to girls, schools, governments, and industries must cooperate to educate teachers and mentors, and allocate funding to close the gender gap.
As Miranda, another Mastercard Foundation scholar, recently observed, “As we try to find new innovations and inventions to drive the economy, I believe that math and science is at the forefront of that progress.”
As professionals working to improve African education, we couldn’t agree more.
Liberal Democracy in Africa Can Wait
YAOUNDÉ – Africa’s policymakers understand that strong economic and political leadership is essential to growth and stability.
For years, African economies have fared better than expected, owing to a commitment to improving governance.
The question now is how to sustain the momentum.
Current strategies do not provide an adequate answer.
Although leaders at a recent African Economic Conference in Addis Ababa, Ethiopia, committed to keeping governance reforms at the top of Africa’s agenda, they offered no blueprint.
From my perspective, this void presents an opportunity to consider new governance paradigms, including those that borrow from two commonly discussed models: the “Washington Consensus” and the “Beijing Model.”
Development practitioners have long debated which model offers the best framework for reform.
Put simply, “governance” refers to a dynamic framework of rules, structures, and processes that help a government manage its economic, political, and administrative affairs.
But which principles a government focuses on varies by approach.
The model championed by the West places a premium on human rights and democracy, while the one advocated by China is more concerned with political stability and economic growth.
Since the election of President Donald Trump, the United States, which remains one of Africa’s top donors, has focused more on the principles China favors – like political stability, trade, and counterterrorism – than on human rights.
The rationale is that the Beijing Model is better for Africa in the short and medium term.
And, while it might not be popular to admit, Trump has a point.
Simply put, food, shelter, health, and good sanitation are more relevant for most Africans than the right to vote.
Moreover, only a moderately wealthy population, with a healthy middle class, can adequately demand the rights that democracy provides.
Paradoxically, the fastest way to build a strong middle class in Africa would be to move toward the hierarchy of principles that China’s model promotes.
For Africa to reorient its governance approach, and embrace a post-Washington Consensus, its leaders must commit to improving institutional effectiveness and economic management.
The first set of reforms would involve establishing clear lines of sovereignty with international partners.
Africa’s relationship with Western donors, for example, has historically placed individual rights over national rights.
But in my view, individual rights should not supersede sovereign ones.
Punishing entire countries for laws that affect a minority is counterproductive.
An example of such collective punishment occurred in Uganda in 2014, when the World Bank froze some $90 million in loans following the government’s enactment of legislation criminalizing homosexuality.
As a Ugandan government spokesman said at the time, the bank “should not blackmail its members” to adopt Western values.
Yet, when governance models are judged solely through the lens of the Washington Consensus, there is very little alternative.
Along the same lines, the second set of reforms pertains to prioritizing economic rights over political rights.
For example, politicians who manage an economy well should not be subject to term limits.
Neither Singapore nor China is a democracy; but leaders in both countries have used their political power to improve living standards.
Forcing leaders to step down in the middle of economic reforms seems counterproductive.
These are not far-fetched ideas.
Today, leaders in Rwanda, which is widely considered an African success story, have improved stability by moving away from the Washington Consensus approach to governance.
Politically, Rwanda is strong, disciplined, and organized, but it is not liberal.
The landslide reelection of President Paul Kagame last year had more to do with power than democracy.
Although Kagame remains popular, his government was criticized for stifling free speech and human rights in the run-up to the vote.
The conclusion I draw is not that human rights don’t matter, but that political discipline and imperfect forms of democracy are acceptable if the tradeoff is sustained progress in economic and institutional governance.
We should be intellectually honest and call a spade a spade.
Rwandans should not be ashamed to value economic and administrative strength more than fair elections.
The question for other African states seeking to reform their governance models, then, is how much of Rwanda’s approach to emulate.
Neither the Washington Consensus nor the Beijing Model has all the answers.
But, as Rwanda has demonstrated, if discipline and strong leadership are improving lives and delivering public goods, perhaps liberal democracy should be a long-term priority.
Health Coverage Must Not Ignore Africa’s Elderly
DAR ES SALAAM – My grandmother is 76, and my grandfather is 83.
They have lived fruitful lives together, cultivating crops and grazing cattle in a remote village in the hills of southwest Uganda.
But whenever I think of them, I am more in awe of their good health than their hard work.
Because of the remoteness of their community, anytime my grandparents need medical care, they must travel 25 miles to the nearest hospital on motorcycles known as boda-bodas, paying about 50,000 Ugandan shillings (about $13) for the round-trip journey.
Then, because they were recently dropped from their health-insurance plan due to age, they must cough up more money to foot the bill for treatment.
In other words, for my grandparents – and for many older Africans – a visit to the doctor is onerous, costly, and exceedingly rare.
Access to health care is an obsession for experts in international development.
In May, at the World Health Organization’s annual World Health Assembly, officials from dozens of countries discussed how to achieve universal health coverage through the United Nations Sustainable Development Goals.
And yet, most of the attention centered on mothers, newborns, and children; elderly populations in developing countries were largely ignored.
Failure to address this omission would leave an increasing share of the population without access to affordable health care.
According to the World Bank, life expectancy in Sub-Saharan Africa has risen steadily in recent decades, from just 40 years in 1960 to 60 years today.
If this trend continues, the number of Africans living past their 60th birthday will more than double by 2050.
This is of course good news; longevity is a key indicator of human development.
But Africa’s elder boom will be a disaster if living longer means living sicker because of inadequate health care.
In Uganda, many rural health-care centers lack the personnel, supplies, and infrastructure to meet the needs of older patients.
Small clinics typically refer their oldest patients to the closest big hospital, which is often many miles away.
Traveling by motorcycle over rough terrain can worsen health conditions; but with no other options, the frail must choose between a bumpy ride on the back of a bike and no treatment at all.
It’s hard to blame those who opt for the latter.
According to a 2010 survey by doctors at the Mulago National Referral Hospital in Kampala, boda-bodas are Uganda’s leading cause of road-related injuries.
During the survey period, motorcycle passengers accounted for 41% of the hospital’s 1,500 trauma cases, and riders’ injuries consumed 62.5% of the hospital’s surgery budget.
Given the dangers of travel, it is no wonder that my grandparents are reluctant to seek medical care.
Of course, the biggest obstacle to health care in Uganda – like everywhere else – is money.
In 2015, researchers at Makerere University found that household income is the main determinant of elderly people’s access to and use of health-care services.
The story is similar in the United States, where average annual health-care costs have been increasing for decades.
But while older patients in the US can turn to Medicare (which accounted for 15% of federal spending in 2017), the elderly in most African countries have less government support.
Still, a dearth of dedicated resources does not mean that Africa’s leaders must ignore their older constituents.
By combining elder-care services with existing programs, health benefits can be extended to underserved populations.
For example, single-sector initiatives, like HIV/AIDS treatment schemes, could include elderly-friendly health-care components.
Health-care workers who serve expectant and new mothers could also be trained to provide in-home care for the elderly in multigenerational households.
These types of initiatives would not require vast sums of money; rather, the most important factor in launching them is political support and effective program integration.
Developing countries have made considerable gains when it comes to improving health care for the young.
Now, we must do the same for the elderly.
In Uganda, the government’s national health-care strategy could easily be strengthened by adding seniors to the list of so-called vulnerable groups.
Integrating elder-care options into existing frameworks – such as the health extension program in Ethiopia, the community-based health program in Tanzania, and village health teams in my country – are other ways to extend coverage.
Finally, community health-insurance schemes must be overhauled to prevent the exclusion of poor older patients.
To maintain coverage and protect the elderly from financial ruin, reforms are needed to create plans that are financially sound and drawn from a larger pool of subscribers.
We all yearn to live long, healthy, productive lives – just as my grandparents have.
But without lifelong access to quality health care, longevity will be more luck than science.
The integrity of any society can be judged by how well it treats its youngest and oldest members.
That calculus applies to governments, too.
Africa’s Must-Do Decade
VIENNA – Since 2000, Africa has recorded impressive rates of economic growth, owing largely to development assistance and a prolonged commodity boom.
While the continent shows great diversity in the socioeconomic trajectories, growth rates have generally masked an underlying lack of structural transformation.
Many African countries have yet to undergo the kind of transformation that is necessary for socially inclusive and environmentally sustainable development over the long term: namely, industrialization.
Wherever industrialization has occurred, it has reliably improved economic diversification and helped to nurture, strengthen, and uphold the conditions for competitive growth and development.
In recent decades, some developing countries – mainly in Asia – have managed to industrialize.
But, despite repeated attempts, African countries have not.
In 2014, the Asia and Pacific region’s share of value added in global manufacturing was 44.6%, whereas Africa’s was just 1.6%.
With South Africa as its only industrialized country, Sub-Saharan Africa is the least industrialized region in the world.
For African countries to achieve sustainable development, they will have to increase substantially the share of industry – especially manufacturing – in their national investment, output, and trade.
And, to their credit, most African countries already recognize that such a transformation is necessary to address a wide range of interconnected challenges that they are now confronting.
One such challenge is population growth.
More than half of the continent’s 1.2 billion people are under the age of 19, and almost one in five are between the ages of 15 and 24.
Each year, 12 million new workers join the labor force, and they will need the tools and skills to ensure their future livelihoods.
Industrialization is the key to helping Africa’s fast-growing population realize a demographic dividend.
A related challenge is migration.
Many of Africa’s most ambitious and entrepreneurially minded young people are joining others in migrating north.
But no country, especially in Africa, can afford to lose so much talent and potential.
Industrialization alone cannot resolve the migration crisis, but it can address one root cause, by creating jobs in the countries of origin.
A third challenge is climate change, which weighs heavily on countries where agriculture is still the primary sector for employment.
To confront the threat, Africa will need to develop and adopt green technologies, while channeling more investment into resource efficiency and clean energy.
With the right investments, African countries can reduce the cost of delivering power to rural areas, and contribute to global efforts to reduce emissions and mitigate the effects of climate change.
In short, Africa must industrialize, and it must do so in a socially inclusive and environmentally sustainable manner.
Given that most previous efforts at sustainable development in Africa have failed, there is a clear need for a new approach: a broad-based, country-owned process that taps financial and non-financial resources, promotes regional integration, and fosters cooperation among Africa’s development partners.
As it happens, the United Nations General Assembly has declared 2016-2025 to be the Third Industrial Development Decade for Africa.
During IDDA III, the United Nations Industrial Development Organization, which I lead, will spearhead the new approach to sustainable development sketched above.
UNIDO has put its full support behind partnerships for mobilizing resources, and is offering a tested model for African countries to follow: the Programme for Country Partnership (PCP).
UNIDO’s PCP provides countries with technical assistance, policy advice, and investments to help them design and implement industrialization strategies.
The program was launched in 2014, and is already being successfully implemented in two African countries – Ethiopia and Senegal – and in Peru.
The PCP provides a multi-stakeholder partnership model that can be adapted to each country’s national development agenda.
It is designed to work in synergy with governments and their partners’ ongoing development efforts, while funneling additional funds and investments toward sectors that have high growth potential and are important to a particular government’s industrial-development agenda.
Priority sectors are typically chosen for their job-creation, investment, and export potential, and for their access to necessary raw materials.
The PCP approach is designed to maximize the impact of all partner programs and projects that are relevant to industrial development.
To that end, strategic partnerships with financial institutions and the business sector are particularly important.
With these in place, African countries can marshal additional resources for infrastructure, innovation, expertise, and new technologies.
UNIDO’s goal is to make the PCP model the mainstream approach for all African countries.
We stand ready to support Africa on its path to inclusive and sustainable industrial development – during IDDA III and beyond.
Africa’s Decade of Industrialization
VIENNA – In today’s interdependent global economy, Africa remains a weak link.
If the world is to achieve the Sustainable Development Goals, thereby completing the United Nations 2030 Agenda for Sustainable Development, it must help Africa accelerate its development by promoting rapid and responsible industrialization.
Africa is by no means destined to lag behind the rest of the world economy.
On the contrary, it could easily become a global economic powerhouse – and within the next decade.
But, to fulfill its economic potential, Africa must industrialize.
The importance of this has been stressed repeatedly at recent international forums, including last August’s Sixth Tokyo International Conference on African Development (TICAD VI), and the G20 summit in Hangzhou, China, the following month.
For the first time, the G20 placed industrialization in Africa – and all of the Least Developed Countries (LDCs) – on its agenda.
The African Union’s Agenda 2063 also supports this drive.
The recent UN General Assembly resolution declaring 2016-2025 the Third Industrial Development Decade for Africa is yet another push in this direction.
The organization that I represent, the UN Industrial Development Organization (UNIDO), has been tasked with operationalizing and leading the implementation of the concomitant program, including mobilizing the needed resources.
All of these declarations and commitments are an important first step.
But they will mean little unless they are translated into concrete and effective action that advances African industrialization, creates jobs, and fosters inclusive and sustainable economic growth and development.
The question is how.
The short answer is money and action.
We must challenge the international community and development partners to back their words with real financial commitments.
And we must build partnerships to operationalize programs that will enable Africa to become the world’s next main engine of economic growth.
Such programs must recognize and tackle the acute challenges the continent faces.
The economic growth experienced in recent decades has not been structurally driven, sustainable, or fully inclusive.
Indeed, growth rates vary widely across the continent, and not all Africans are benefiting.
Though the middle class in Africa has expanded markedly in recent years, generating a consumer boom and boosting domestic investment, many people still struggle to make a living.
Unemployment rates are high, especially for young people and women – a reality that drives many Africans to head north.
To keep them home, Africa’s economies must move beyond producing raw materials to build dynamic and competitive manufacturing sectors with higher value added.
Here, Africa must draw on the opportunities presented by participation in global and regional value chains.
New and innovative industrial-development strategies, as well as carefully tailored measures to attract foreign direct investment, must be introduced.
Of course, to develop such strategies and participate effectively in industrial value chains, Africans need knowledge.
Investment in education and skills training is imperative to facilitate successful and lasting industrialization.
By understanding and drawing on proven innovations from around the world, Africa could leapfrog more developed countries technologically, building the capacity to produce more sophisticated, higher-value goods.
Knowledge of other countries’ experiences will also help Africa to avoid the pitfalls of unbridled industrialization – particularly environmental damage.
Africa must ensure that its industrial-development strategy includes effective environmental safeguards.
Africa is well placed to industrialize.
Beyond its massive natural-resource endowments, the continent has a favorable demographic profile (its rapidly growing population means that it will soon have the world’s largest workforce) and high urbanization rates.
It also benefits from a highly educated diaspora.
But industrialization is never automatic.
Governments must step up to address market failures, while planning, implementing, and enforcing industrial policies that address the shortcomings of previous ineffective versions.
They must then institutionalize these new policies in national and regional development strategies.
To succeed, governments will need adequate capacity, competence, and legitimacy to mobilize and interact with all stakeholders, thereby creating an attractive investment climate.
The necessary reforms will open the way for public-private partnerships, which can provide investment for infrastructure development and maintenance.
They will also facilitate cooperation with international organizations and development finance institutions, which can provide additional funds, while helping countries to upgrade their productive capacity.
A recent report, prepared for the Hangzhou G20 Summit, features a number of recommendations for Africa.
It suggests support for agriculture and agribusiness development and linking them with other sectors, as well as measures to boost resilience to price shocks.
Furthermore, the report emphasizes the need to deepen, broaden, and update the local knowledge base, invest in energy- and material-resource efficiency, and promote green technologies and industries.
Other recommendations relate to trade and regional integration, leveraging domestic and external finance, and promoting what it calls the “New Industrial Revolution.”
My numerous meetings with African leaders and visits to dozens of countries across the continent have convinced me that Africa is committed to industrialization.
In fact, the process is already underway in many countries, including Ethiopia, Ghana, Rwanda, and Senegal.
By offering our commitment and support, we can enable these countries to realize inclusive and sustainable development for the benefit of everyone.
A Roadmap for African Industrialization
ABIDJAN – Africa is at a crossroads.
Six of the world’s ten fastest-growing economies are now located in the region, and the continent’s GDP is expected to grow at a rate of 4.1% this year, up from 3.6% in 2017.
Yet Africa’s economic growth has not been accompanied by a commensurate level of job creation, which has particularly negative implications for women and young people.
In fact, today’s jobless growth could even reverse the gains made in eradicating poverty in recent years.
The problem is that Africa’s growth, while impressive, has been volatile, because it has been driven mainly by high commodity prices, rather than by manufacturing.
The economic effects of this imbalance should not be underestimated.
Among other things, it explains why a region that produces about 75% of the world’s cocoa accounts for just 5% of the nearly $100 billion annual chocolate market.
Despite its vast natural resources, Africa will remain at the mercy of commodity prices and trade flows until it undertakes a profound structural transformation.
The time has come for Africa to unlock its true economic potential by following in the footsteps of every modern economy and undertaking the transition from agriculture to manufacturing.
Africa’s manufacturing sector is the weakest link in its ongoing integration into the global economy.
Today, primary products (raw materials) comprise 62% of Africa’s total exports, the highest share in the world.
At the same time, manufactured exports per capita in 2014 totaled just $218, which is among the lowest levels in the world, and far below other developing regions such as Asia ($883) and Latin America ($1,099).
Clearly, Africa must start catching up.
Fortunately, there is already a global consensus that industrialization matters, and that it is in everyone’s interest for Africa to become the global manufacturing power it ought to be.
With its “High 5 Agenda,” the African Development Bank (AfDB) has made industrialization a top priority.
Likewise, industrialization is a key component of the African Union’s “Agenda 2063.”
And, in 2016, the United Nations General Assembly declared 2016-2025 the “Third Industrial Development Decade for Africa.”
But such pronouncements are meaningless in the absence of concrete action.
To change the region’s economic trajectory, African policymakers must focus on three key areas: industrial policies, infrastructure financing, and leadership.
We now know that industrial policies can be effective in boosting growth.
The question is whether states possess the capacity to implement the policies they design.
If they do, they can channel resources toward industry and marshal available technologies to create synergy between the agriculture and manufacturing sectors.
A number of African countries have already moved in this direction.
Ethiopia, for example, has created special economic zones, where it has lowered production costs by investing in infrastructure.
As a result, the country has emerged as Africa’s largest hub for textile manufacturing, attracting major players like H&M and Primark.
Similarly, Rwanda’s Kigali Special Economic Zone, which exempts firms from taxes for ten years, has attracted a $20 million investment from Volkswagen for a new vehicle-assembly plant.
But industrialization cannot happen without power, roads, and railways, which is why infrastructure must be a key focus.
As of now, the AfDB pegs Africa’s infrastructure gap at $130–170 billion per year.
Closing it will require not just more financing, but also more innovative thinking, particularly concerning joint public-private efforts.
To that end, the AfDB has expanded its portfolio for financing new infrastructure projects in several countries.
As part of our “New Deal on Energy for Africa,” we have scaled up investment in renewable energy and put $265 million toward developing two solar-power plants in Morocco.
In Côte d’Ivoire, where demand for energy is surging by 8-9% annually, we are investing $60 million to bring a new 44-megawatt hydropower plant onstream.
African countries should make such investments now to reap the demographic dividend of the continent’s population bulge in the years ahead.
As manufacturing activities expand, they will need to be supported by more robust knowledge- and skill-based economies, which will require higher investment in education to boost technical and vocational skills and training.
No country has ever undergone economic modernization without industry.
But, more to the point, no functional industrial sector has ever emerged in the absence of strong, committed leadership.
Consider Mauritius, which in the 1970s was a low-income mono-crop economy with a per capita GDP of just under $250.
Today, Mauritius is an upper-middle-income country with a more diversified economy and a per capita GDP of around $9,600.
It is often cited as a model of economic success in Africa.
How did this come about?
As former Mauritian Prime Minister and President Anerood Jugnauth has put it, “There is no miracle.
It is due simply to hard work, discipline, and will.”
Leaders who want to develop a strong manufacturing base must have the political will to distribute resources fairly and pull the private sector along.
Mauritius experienced its fair share of challenges in moving from low-end manufacturing to technology-intensive goods and services.
But it now stands as an example of what committed leadership can accomplish.
Other African countries would do well to emulate it as they pursue their own economic transformations.
All told, Africa is well placed to seize many of the opportunities that the global economy offers emerging markets.
It already has the resources and the labor; now it needs committed leaders like Jugnauth who will implement the right policies.
Africa’s Alternative Path to Development
WASHINGTON, DC – Recent projections indicate that several Sub-Saharan African countries will experience robust economic growth over the next five years.
By 2023, around one-third of the region’s economies will have grown at an average annual rate of 5% or higher since 2000.
And yet, as The Economist observed last year, Africa’s development model “puzzles economists.”
After all, only four of the continent’s high-growth countries are natural-resource dependent.
Nor is overall performance due primarily to industrialization, as traditional development models would have predicted.
What, then, explains the strong economic performance?
New research by the Brookings Institution’s Africa Growth Initiative and the United Nations University World Institute for Development Economics Research (UNU-WIDER) might hold the key to answering that question.
According to the forthcoming book Industries Without Smokestacks: Industrialization in Africa Reconsidered, there is evidence to suggest that Sub-Saharan Africa is undergoing a more profound structural transformation than we think.
Africa owes this structural transformation not to traditional industries, but to new developments in tradable services and agro-industries that resemble traditional industrialization.
Aside from horticulture and agro-business, these new industries include information and communication technology-based services (ICT) and tourism.
This is a departure from the historical norm.
Traditionally, as Harvard University economist Dani Rodrik points out, economies that have sustained robust growth rates without relying on natural-resource booms, “typically do so through export-oriented industrialization.”
But in Africa, manufacturing as a share of total economic activity has stagnated at around 10%, with economic activity moving from agriculture to services.
And because the rate of productivity growth in services is only about half that of manufacturing, the aggregate productivity gains needed for sustained growth have fallen relatively short.
This process of premature deindustrialization is not unique to Africa.
But it is more consequential for the continent, given the scale of its development challenges.
Owing to its young, rapidly growing labor force, Africa now needs to create more than 11 million jobs in the formal economy every year.
But as Nobel laureate economist Joseph E. Stiglitz has warned, Africa cannot replicate East Asia’s manufacturing-led model, so the question is whether it can leverage modern services to achieve economic development.
According to Foresight Africa: Top Priorities for 2018, a Brookings Institution report previewing the results of Industries Without Smokestacks, services exports from Africa grew more than six times faster than merchandise exports between 1998 and 2015.
In Kenya, Rwanda, Senegal, and South Africa, the ICT sector is flourishing.
In Rwanda, tourism is now the single largest export activity, accounting for about 30% of total exports.
Ethiopia, Ghana, Kenya, and Senegal are all integrated into global horticultural value chains, and Ethiopia has become a leading player in global flower exports.
As these smokestack-less industries have grown, they have generated new patterns of structural change that are distinct from those of East Asia’s manufacturing-led transformation.
But, if properly stewarded, they could play the same role in Africa’s development as manufacturing did in East Asia.
First, manufacturing has higher productivity than agriculture, and it can absorb a large number of moderately skilled workers migrating out of the agriculture sector. Second, manufacturers benefit from technological transfers from abroad, so their productivity rises in line with global trends.
According to John Page, one of the editors of Industries Without Smokestacks, Africa’s growing service sectors share these same characteristics.
In addition to being tradable, they have higher productivity and can absorb large numbers of moderately skilled workers.
And like manufacturing, they also benefit from technological change and economies of scale and agglomeration.
Moreover, Africa’s smokestack-less service sectors have the added advantage of being less vulnerable to automation.
Notwithstanding automation’s many benefits, it presents challenges for countries where the overriding priority is to create a sufficient number of formal-sector jobs.
While economists have been increasingly confident that Africa’s development model will be different from that of East Asia, they have been less certain about what shape it will take.
An industries-without-smokestacks model offers one possible answer.
From a policy perspective, African leaders should explore more ways to support these industries’ growth, either through targeted reforms or by incorporating them into national industrialization strategies and broader development agendas.
The development of industries without smokestacks can occur alongside efforts to develop those with smokestacks, thus offering a multifaceted approach for Africa to achieve structural transformation.
Banking on African Infrastructure
JOHANNESBURG – As the US Federal Reserve embarks on the “great unwinding” of the stimulus program it began nearly a decade ago, emerging economies are growing anxious that a stronger dollar will adversely affect their ability to service dollar-denominated debt.
This is a particular concern for Africa, where, since the Seychelles issued its debut Eurobond in 2006, the total value of outstanding Eurobonds has grown to nearly $35 billion.
But if the Fed’s ongoing withdrawal of stimulus has frayed African nerves, it has also spurred recognition that there are smarter ways to finance development than borrowing in dollars.
Of the available options, one specific asset class stands out: infrastructure.
Africa, which by 2050 will be home to an estimated 2.6 billion people, is in dire need of funds to build and maintain roads, ports, power grids, and so on.
According to the World Bank, Africa must spend a staggering $93 billion annually to upgrade its current infrastructure; the vast majority of these funds – some 87% – are needed for improvements to basic services like energy, water, sanitation, and transportation.
Yet, if the recent past is any guide, the capital needed will be difficult to secure.
Between 2004 and 2013, African states closed just 158 financing deals for infrastructure or industrial projects, valued at $59 billion – just 5% of the total needed.
Given this track record, how will Africa fund even a fraction of the World Bank’s projected requirements?
The obvious source is institutional and foreign investment.
But, to date, many factors, including poor profit projections and political uncertainty, have limited such financing for infrastructure projects on the continent.
Investment in African infrastructure is perceived as simply being too risky.
Fortunately, with work, this perception can be overcome, as some investors – such as the African Development Bank, the Development Bank of Southern Africa, and the Trade & Development Bank – have already demonstrated.
Companies from the private sector are also profitably financing projects on the continent.
For example, Black Rhino, a fund set up by Blackstone, one of the world’s largest multinational private equity firms, focuses on the development and acquisition of energy projects, such as fuel storage, pipelines, and transmission networks.
But these are the exceptions, not the rule.
Fully funding Africa’s infrastructure shortfall will require attracting many more investors – and swiftly.
To succeed, Africa must develop a more coherent and coordinated approach to courting capital, while at the same time working to mitigate investors’ risk exposure.
Public-private sector collaborations are one possibility.
For example, in the energy sector, independent power producers are working with governments to provide electricity to 620 million Africans living off the grid.
Privately funded but government regulated, these producers operate through power purchase agreements, whereby public utilities and regulators agree to purchase electricity at a predetermined price.
There are approximately 130 such producers in Sub-Saharan Africa, valued at more than $8 billion.
In South Africa alone, 47 projects are underway, accounting for 7,000 megawatts of additional power production.
Similar private-public partnerships are emerging in other sectors, too, such as transportation.
Among the most promising are toll roads built with private money, a model that began in South Africa.
Not only are these projects, which are slowly appearing elsewhere on the continent, more profitable than most financial market investments; they are also literally paving the way for future growth.
Clearly, Africa needs more of these ventures to overcome its infrastructure challenges.
That is why I, along with other African business leaders and policymakers, have called on Africa’s institutional investors to commit 5% of their funds to local infrastructure.
We believe that with the right incentives, infrastructure can be an innovative and attractive asset class for those with long-term liabilities.
One sector that could lead the way on this commitment is the continent’s pension funds, which, together, possess a balance sheet of about $3 trillion.
The 5% Agenda campaign, launched in New York last month, underscores the belief that only a collaborative public-private approach can redress Africa’s infrastructure shortfall.
For years, a lack of bankable projects deterred international financing.
But in 2012, the African Union adopted the Program for Infrastructure Development in Africa, which kick-started more than 400 energy, transportation, water, and communications projects.
It was a solid start – one that the 5% Agenda seeks to build upon.
But some key reforms will be needed.
A high priority of the 5% Agenda is to assist in updating the national and regional regulatory frameworks that guide institutional investment in Africa.
Similarly, new financial products must be developed to give asset owners the ability to allocate capital directly to infrastructure projects.
Unlocking new pools of capital will help create jobs, encourage regional integration, and ensure that Africa has the facilities to accommodate the needs of future generations.
But all of this depends on persuading investors to put their money into African projects.
As business leaders and policymakers, we must ensure that the conditions for profitability and social impact are not mutually exclusive.
When development goals and profits align, everyone wins.
Freeing Africa’s Internet
WASHINGTON, DC – Much to the dismay of the government in Addis Ababa, “Zone 9” has become a household name in Ethiopia.
Since 2012, this small group of journalists-turned-online activists has used social media to campaign for political freedoms and civil liberties in their country.
The group’s success – measured, for example, by the flood of likes and comments on its Facebook page – has come in spite of government efforts to silence the writers, including the arrest of six members in 2014 on trumped-up terrorism charges.
Ethiopia’s government is not alone in seeking to consolidate political power by restricting what citizens say online.
Across Africa, governments are enacting legislation to restrict Internet access and outlaw criticism of elected officials.
Digital campaigners face myriad censorship tactics, including “Border Gateway Protocol” attacks, “HTTP throttling,” and “deep packet inspections.”
The irony, of course, is that censorship rarely quiets the disaffected.
Rather than quelling dissent, government intervention only inspires more people to take their grievances to WhatsApp, Facebook, Twitter, and other social media platforms, where Africans are increasingly challenging corrupt governments, exposing rigged elections, and demanding to be heard.
At the moment, however, few of Africa’s leaders are listening.
Leaders in nine of the 18 African countries that held elections in 2016 placed some level of restriction on the Internet to limit dissent.
Four days prior to Uganda’s presidential vote in February, President Yoweri Museveni cut access to mobile payment services and social media sites.
In August and September, Gabon’s president, Ali Bongo, seeking to project an atmosphere of calm to the international community, shut down Internet access overnight.
Then in December, officials in Democratic Republic of the Congo ordered an Internet shutdown the day before President Joseph Kabila was scheduled to leave office, thereby quashing online dissent when he refused to step down.
Internet blackouts like these violate people’s human rights and undermine democratic processes.
Last year, the United Nations Human Rights Council approved a resolution affirming that, “rights that people have offline must also be protected online, in particular freedom of expression.”
Most African governments try to justify Internet embargoes by arguing that the restrictions are necessary to ensure public safety and security.
Museveni, for example, claimed that blocking Internet access was the only way to protect visiting heads of state during his swearing-in ceremony.
But he presented no evidence linking social media accessibility and security in Uganda, or anywhere else.
According to Access Now, an international advocacy group for digital rights, people typically feel less secure without the Internet, because they cannot access information or connect with friends and family in times of uncertainty.
With several key African elections coming up, Internet shutdowns are again on the horizon.
In Zimbabwe, where President Robert Mugabe, who is 93, is expected to run for his eighth term in mid-2018, a government-led crackdown appears inevitable.
For decades, Mugabe has relied on intimidation and violence to stifle political dissent.
It is not surprising, then, that he has already begun taking a hostile approach to online activism.
Last year, his government shut down the Internet in the middle of political protests, and vowed to arrest anyone caught generating or sharing “abusive or subversive material on social media.”
But citizens are not helpless.
While governments issue orders to cut off Internet access, only telecommunications companies have the ability to hit the “kill switch.”
That is why Africa’s bloggers and online activists must work more closely with investors and shareholders of communications firms to convince them to stand up for democracy and human rights by resisting illiberal government directives.
Moreover, civil-society groups, the African Union, and the UN should do more to condemn national legislation that aims to normalize restrictive Internet policies.
Just as it launched a model law on access to information in 2013, the African Union should provide new guidance to states on how to safeguard the right to assemble and express views online.
Finally, new continent-wide measures are needed to ensure that Africans’ online rights are recognized and respected by their governments.
Although the UN Human Rights Council’s resolution to protect online freedoms is not binding, it offers a starting point for ensuring that governments allow citizens to use the Internet as a tool for maximizing political participation.
Such interventions are needed now more than ever.
The Kenyan, Zimbabwean, and Ethiopian legislatures are currently considering laws that would permit significantly greater government control over Internet access.
Last year, Tanzania adopted legislation that has already been used to charge individuals with crimes who have criticized President John Magufuli on social media.
Whether governments bar citizens from gathering in public, signing petitions, or accessing the Internet and posting on social media makes no difference.
All such measures are designed to strip citizens of their rights.
The battle for freedom, as Zone 9 has shown, is no less real when the public square is the digital domain.
Capturing Africa’s High Returns
WASHINGTON, DC – Since 2000, at least half of the world’s fastest-growing economies have been in Africa.
And by 2030, Africa will be home to 1.7 billion people, whose combined consumer and business spending will total $6.7 trillion.
Seven years ago, the Harvard Business Review pointed out that Africa is also home to many of the world’s biggest opportunities.
And yet, despite its tremendous business potential, Africa has not risen to the top of Western business leaders’ agendas.
In fact, between 2014 and 2016, US exports to Africa fell by almost half, from $38 billion to $22 billion.
And while the United Kingdom’s investments on the continent more than doubled between 2005 and 2014, reaching £42.5 billion ($57.6 billion), only 2.5% of its total exports are to Africa.
Western countries are quickly losing ground to China, which increased its exports to Africa more than sevenfold – to $103 billion – from 2005 to 2015.
If Western businesses hope to keep up, they will need to tap into the African countries and sectors with the highest potential for growth.
By 2030, more than half of Africa’s population will reside in seven countries: Nigeria, Ethiopia, the Democratic Republic of Congo, Egypt, Tanzania, Kenya, and South Africa.
But, more important, 43% of Africans will belong to the middle or upper classes, up from 39.6% in 2013, implying considerably higher demand for goods and services.
By 2030, household consumption is expected to reach $2.5 trillion, up from $1.1 trillion in 2015.
Nearly half of that $2.5 trillion will be spent in three countries: Nigeria (20%), Egypt (17%), and South Africa (11%).
But there will also be lucrative opportunities in Algeria, Angola, Ethiopia, Ghana, Kenya, Morocco, Sudan, and Tunisia.
Any one of these countries would be a good bet for companies seeking to enter new markets.
By 2030, the sectors generating the most value in Africa will be food and beverages ($740 billion), education and transportation ($397 billion), and housing ($390 billion).
But there will also be strong growth in consumer goods ($370 billion), hospitality and recreation ($260 billion), health care ($175 billion), financial services ($85 billion), and telecommunications ($65 billion).
Of course, much of this growth will depend on the African Union properly implementing its new Continental Free Trade Area, which would create a single market for goods and services, offering corporations many points of entry.
Moreover, the CFTA will increase the need for connectivity, so there will be new opportunities to invest in infrastructure and sectors ranging from transportation and energy to information and communications technology (ICT) and water supplies.
For its part, the African Development Bank can help investors find promising projects through its Program for Infrastructure Development in Africa.
Another major growth area between now and 2030 will be in African business-to-business spending, which will reach $4.2 trillion, up from $1.6 trillion in 2015.
Here, the largest sectors will be agriculture and agricultural processing ($915 billion), manufacturing ($666 billion), and construction, utilities, and transportation ($784 billion), followed by wholesale and retail ($665 billion), resources ($357 billion), banking and insurance ($249 billion), and telecommunications and ICT ($79.5 billion).
The expected growth in agriculture and agricultural processing reflects the fact that food and beverages will constitute the largest share of total household spending.
Moreover, 60% of the world’s unused arable land is in Africa, which still contributes a meager share of worldwide agricultural exports.
That means there is a lot of room for growth.
And, because severe hunger still affects many African countries, investors can even contribute to the public good by investing in fertilizers, machinery, water and irrigation systems, and other areas of the agriculture sector.
As of 2012, the African countries with the highest agricultural value-added in terms of annual growth included Burkina Faso, Ethiopia, Nigeria, Mali, Mozambique, Rwanda, and Tanzania.
In addition, Angola, Morocco, and South Africa now all have sizable markets, and have committed to expanding their agricultural sectors.
According to the Harvard Business Review, Africa also has the potential to become “the world’s next great manufacturing center.”
China is expected to lose from 85-100 million low-cost, labor-intensive manufacturing jobs by 2030, and Africa stands to capture many of them.
This helps to explain why manufacturing will be the second-largest sector in terms of business-to-business spending.
Another reason is that many of the manufacturing opportunities in Africa happen to be in globally competitive sectors such as automobiles and transport equipment, refined petroleum, computers, and office and industrial machinery.
South Africa, Egypt, and Nigeria are already becoming promising places to invest in these areas.
And investors will also be able to find high returns and favorable business environments in Ethiopia, Morocco, and Rwanda.
Africa is the world’s last frontier market, and Western businesses need to start taking advantage of its tremendous potential, as Chinese firms already are.
Doing business in Africa will also create sustainable jobs and advance the United Nations Sustainable Development Goals to eliminate poverty and hunger.
And that, too, will be good for the bottom line.
As the Business and Sustainable Development Commission has shown, pursuing the SDGs “could raise trillions in new market opportunities in ways that extend prosperity to all.”
Strengthening African Science
URBANA, ILLINOIS – In late March, Africa’s leading scientists, innovators, and policymakers met in Kigali, Rwanda, to brainstorm solutions to an increasingly pressing problem: the low quality of science on the continent.
Any good leader knows that scientific discovery and innovation fuels progress, facilitates development, and can help tackle issues like food insecurity, water shortages, and climate change.
And yet most African governments are failing to fund research and development adequately in their countries.
According to the UNESCO Institute for Statistics, countries in Sub-Saharan Africa spend, on average, just 0.5% of GDP on research and development.
In the West, the share is closer to 3%.
This disparity underscores the development challenges that Africans face.
Africa is home to 15% of the world’s population and 5% of its GDP, but accounts for a paltry 1.3% of total research spending.
Moreover, African inventors hold just 0.1% of the world’s patents, meaning that even when money is spent on science, innovation, and research, the findings rarely translate into solutions for the continent’s most immediate challenges.
To be sure, these trends are not universal; some African governments are investing heavily in science-led innovation.
In South Africa, for example, authorities have pledged to double R&D spending by 2020 – to 1.5% of GDP.
This follows a 2016 commitment by African heads of state to increase science and technology budgets to at least 1% of GDP by 2025.
A handful of countries – including Kenya, Rwanda, and Senegal – are working hard to reach this funding threshold.
Africa also benefits from generous research-related aid and international support.
One of the top donors, the Bill & Melinda Gates Foundation, has invested more than $450 million in African science initiatives over the last decade.
Projects include a $306 million program to boost crop yields and a $62.5 million grant to improve health outcomes.
These and other funding streams have helped African researchers develop drought-resistant crops, produce vaccines for infectious diseases like Ebola, and expand opportunities for science and technology education.
Unfortunately, many African governments lack the resources to fund programs that could build on these gains.
Simply put, a new, more collaborative approach to African science is urgently needed.
Africa’s leaders have pooled their science resources before.
In 2003, the African Union and the New Partnership for Africa’s Development began implementing a continent-wide strategy “to develop and use science and technology for the socioeconomic transformation of the continent and its integration into the world economy.”
It was an ambitious goal that yielded early results.
Between 2005 and 2014, continent-wide spending on R&D increased, while research output more than doubled in many countries.
Since then, however, progress has stalled.
The recent meeting in Rwanda, hosted by President Paul Kagame and organized by the Next Einstein Forum, was designed to help get the agenda back on track.
But summits are only part of the solution; governments must also commit to improving research quality, and they can start by focusing attention on three key areas.
First, Africa’s leaders must engage with CEOs, philanthropists, and donors who understand the long-term value of investing in science.
Innovation is expensive, and seed money will be needed to help strengthen the continent’s scientific capacity.
Second, African universities and institutions should align their research agendas with national and regional goals.
For example, given that one of Africa’s most pressing challenges is feeding its growing population, schools specializing in agricultural research should ensure that their work contributes to solutions.
Last but not least, countries should encourage entrepreneurship within research organizations.
One way to do this is by establishing commercialization offices, which could help scientists bring their research to market.
Scientists everywhere need help navigating bureaucracy when turning an idea into a commercial venture, and this process is particularly challenging in a region where R&D pipelines are in their infancy.
Boosting Africa’s scientific capabilities will require the continent’s leaders to do more than ask tough questions at summits; they must also allocate more funding and forge new partnerships.
To overcome Africa’s human development challenges, African governments must invest in the people who can overcome them.
The High Cost of Food Monopolies in Africa
LAGOS – In May, global food prices increased 1.2%, reaching their highest level since October 2017.
This upward trajectory is having a disproportionate impact in Africa, where the share of household income spent on food is also rising.
To ensure food security, governments must work quickly to reverse these trends, and one place to start is by policing the producers who are feeding the frenzy.
According to data compiled by the World Economic Forum, four of the world’s top five countries in terms of food expenditure are in Africa.
Nigeria leads the list, with a staggering 56.4% of household income in 2015 spent on food, followed by Kenya (46.7%), Cameroon (45.6%), and Algeria (42.5%).
By comparison, consumers in the United States spend the least globally (6.4%), far less than people in emerging economies like Brazil (16%) and India (30%).
One reason for the distortion is the price of food relative to income.
As Africa urbanizes, people are buying more imported semi- or fully processed foods, which cost more than locally produced foods.
And in most countries, wages have not kept pace with inflation.
But the primary cause is poor public policy: African governments have failed to curb the power of agribusinesses and large food producers, a lack of oversight that has made local agriculture less competitive.
In turn, prices for most commodities have risen.
The absence of antitrust laws, combined with weak consumer protection, means that in many countries, only two or three major companies control markets for items like salt, sugar, flour, milk, oil, and tea .
The impact is most pronounced in African cities, where prices for white rice, frozen chicken, bread, butter, eggs, and even carbonated soft drinks are at least 24% higher than in other cities around the world.
These prices hit consumers both directly and indirectly (owing to pass-through of higher input costs by food conglomerates and service providers).
The Food and Agriculture Organization of the United Nations (FAO) has long argued that food security and fair pricing depends on markets that are free from monopolistic tendencies.
The OECD concurs, and has frequently called on authorities to address “anti-competitive mergers, abuse of dominance, cartels and price fixing, vertical restraints, and exclusive practices” in the food sector.
And yet, in many African countries, this advice has rarely been heeded.
To be sure, this is not a new problem.
Between 1997 and 2004, for example, the FAO counted 122 allegations of “anti-competitive practices” in 23 countries in Sub-Saharan Africa. Violations included a “vertical monopoly” in the Malawi sugar sector, price fixing in Kenya’s fertilizer industry, and a “buyer cartel” in the Zimbabwean cotton industry.
And, despite the considerable attention such cases have received, the underlying problems persist.
According to the World Bank, more than 70% of African countries rank in the bottom half globally for efforts to protect “market-based competition.”
While 27 African countries and five regional blocs do have antitrust laws on the books, enforcement is rare.
The remaining countries have no regulations at all and have made little progress in drafting them.
There is one notable exception: South Africa.
Since 1998, the country’s Competition Act has prohibited any company controlling at least 45% of the market from excluding other firms or seeking to exercise control over pricing.
Violators face penalties of up to 10% of their earnings, and during the last two decades, some of the biggest companies in the country – including Tiger Brands, Pioneer Foods, and Sime Darby – have been penalized.
As Tembinkosi Bonakele, head of South Africa’s Competition Commission, noted last year, the government is “determined to root out exploitation of consumers by cartels,” especially in the food industry.
Other countries should follow South Africa’s lead.
Companies and special-interest groups will always seek to benefit from the absence of regulation.
The need for reform is greatest in countries like Nigeria and Ghana, where food expenditures are high and food-industry pressure is most pronounced.
Fortunately, there is growing recognition of the need to address these challenges.
Babatunde Irukera, Director General of the Consumer Protection Council in Nigeria, recently asserted that, “In a large vibrant and loyal market such as Nigeria, the absence of broad competition regulation is tragic.
Unregulated markets in competition context constitute the otherwise ‘legitimate’ vehicle for both financial and social extortion.”
Reducing the prices of staple food by even a modest 10% (far below the average premium cartels around the world charge) by tackling anticompetitive behavior in these sectors, or by reforming regulations that shield them from competition, could lift 270,000 people in Kenya, 200,000 in South Africa, and 20,000 in Zambia out of poverty.
Such a policy would save households in these countries over $700 million (2015 US dollars) a year, with poor households gaining disproportionately more than rich ones.
Ultimately, it is the responsibility of political leaders to protect consumers from collusion and price-fixing.
There is no question that Africa’s businesses need space to innovate and grow, but their success should never come at the cost of someone else’s next meal.
The Cancer Threat to Africa’s Future
CHICAGO – One of the most pressing public-health challenges in Africa today is also one of the least reported: cancer, a leading cause of death worldwide.
Every year, some 650,000 Africans are diagnosed with cancer, and more than a half-million die from the disease.
Within the next five years, there could be more than one million cancer deaths annually in Africa, a surge in mortality that would make cancer one of the continent’s top killers.
Throughout Sub-Saharan Africa, tremendous progress has been made in combating deadly infectious diseases.
In recent decades, international and local cooperation have reduced Africa’s malaria deaths by 60% , pushed polio to the brink of eradication, and extended the lives of millions of Africans infected with HIV/AIDS.
Unfortunately, similar gains have not been made in the fight against non-communicable diseases (NCDs), including cancer.
Today, cancer kills more people in developing countries than AIDS, malaria, and tuberculosis combined.
But, with Africa receiving only 5% of global funding for cancer prevention and control, the disease is outpacing efforts to contain it.
Just as the world united to help Africa beat infectious disease outbreaks, a similar collaborative approach is needed to halt the cancer crisis.
Surviving cancer requires many things, but timely access to specialists, laboratories, and second opinions are among the most basic.
Yet, in much of Africa, a lack of affordable medications, and a dearth of trained doctors and nurses, means that patients rarely receive the care they need.
On average, African countries have fewer than one trained pathologist for every million people, meaning that most diagnoses come too late for treatment.
According to University of Chicago oncologist Olufunmilayo Olopade, a diagnosis of cancer in Africa is “nearly always fatal.”
Building health-care systems that are capable of managing infectious diseases, while also providing quality cancer care, requires a significant investment in time, money, and expertise.
Fortunately, Africa already has a head start.
Past initiatives – like the Global Fund to Fight AIDS, Tuberculosis, and Malaria, the US President’s Emergency Plan for AIDS Relief, and the World Bank’s East Africa Public Health Laboratory Networking Project – have greatly expanded the continent’s medical infrastructure.
National efforts are also strengthening pharmaceutical supply chains, improving medical training, and increasing the quality of diagnostic networks.
Still, Africans cannot face down this threat alone.
That is why the American Society for Clinical Pathology, where I work, is cooperating with other global health-care innovators to attack the region’s growing cancer crisis.
We have teamed up with the American Cancer Society (ACS) and the pharmaceutical company Novartis to support cancer treatment and testing efforts in four countries: Ethiopia, Rwanda, Tanzania, and Uganda.
Together, we have brought immunohistochemistry, a key diagnostic tool, to seven regional laboratories, an effort we hope lead to more timely cancer diagnoses and greatly improve the quality of care.
To complement these technical efforts, the ACS is also training African health-care professionals how to carry out biopsies and deliver chemotherapy.
That initiative, funded by Novartis, is viewed as a pilot program that could expand to other regional countries.
Finally, our organizations are advocating for enhanced cancer-treatment guidelines in national health-care planning efforts, protocols that we believe are essential to improving health outcomes.
These initiatives are in conjunction with other undertakings, such as a joint ACS-Clinton Health Access Initiative program to broaden access to cancer medications.
When the world took notice that infectious diseases like HIV/AIDS, polio, and malaria were ravaging Africa, action plans were drawn up and solutions were delivered.
Today, a similar global effort is needed to ensure that every African with a cancer diagnosis can get the treatment they need.
Now, as then, success depends on coordination among African governments, health-service providers, drug makers, and non-governmental organizations.
There is no place on Earth that is immune from the dread of a cancer diagnosis; wherever the news is delivered, it is often devastating to recipients and their families.
But geography should never be the deciding factor in patients’ fight to survive the disease.
Cancer has been Africa’s silent killer for far too long, and the global health community must no longer remain quiet in the face of this crisis.
Investing in Africa’s Educators
JOHANNESBURG – Improving education is a slow, arduous, long-term undertaking everywhere, and nowhere more so than in Africa, where tight economic constraints often prevent sustained investment in human capital.
Those who work in the education sector on the continent have to seek solutions that are faster, cheaper, and can be scaled up.
Too often, though, expedient approaches prove shortsighted, and fail to engage local leaders who hold the keys to economic and social progress.
Too often, grassroots-level voices, reflecting firsthand experience addressing their communities’ problems, are ignored.
When global leaders gather in Hamburg this week for the G20 summit, the new G20-Africa Partnership will take center stage.
But those committed to helping Africa should focus squarely on the nuts and bolts of aid and development – and that means investing in local leadership.
Sadly, the best-funded aid organizations in Africa are often run by Westerners, or by Africans who have extensive ties to the West.
I recently spoke to several entrepreneurs who shared anecdotal evidence that organizations in Africa with a Western co-founder raise more than twice the funds of African-run organizations.
This financial prejudice is visible elsewhere, too, and it is perpetuating the dearth of local talent.
The pro-Western bias should worry everyone working to build better communities for our children.
When it comes to addressing social issues – whether it’s educational inequity, poverty, or discrimination – the most committed advocates are those who have first-hand knowledge of the problem they seek to solve.
Personal experience is the best way to create agents for change, because it underpins people’s long-term, personal investment in dismantling systems that exacerbate inequity and injustice.
What would it look like if the leaders overhauling such systems were cultivated from the very communities that needed them most?
Some organizations are answering that question already.
More than 12,000 people have applied to join Teach For Nigeria, a national organization that recruits, trains, and places young teachers in high-need schools.
The program, designed as a fellowship, will choose fewer than 60 of Nigeria’s brightest university graduates and professionals, not only to develop excellent classroom teachers, but also to empower the next generation of social entrepreneurs committed to tackling inequity and deeply connected to local efforts already underway in communities across their country.
After their two-year teaching commitment, which begins in September, these up-and-coming leaders will join a worldwide movement of over 55,000 people who have completed the fellowship in over 40 countries, including the 30 fellows already hard at work next door at Teach for Ghana.
We call this powerful grouping of change-agents “collective leadership,” and we believe it is the only way to ensure positive, lasting change.
Inadequate investment in locally led initiatives is one of the two ways in which we fail to ensure that those who are most affected by inequity have pathways to address it.
The second is the failure to invest in children.
In Uganda, 70% of children do not complete primary school.
Basic education is the foundation for our lifelong ability to analyze information, present ideas and opinions, and challenge the world around us.
And yet, in too many African communities, we are failing to invest in laying those foundations.
Across the continent, educational attainment is sharply stratified: while 82% of children from the wealthiest families complete primary school, only 28% of children from the poorest families do.
If the future of the continent is to be shaped by, or with, those who have most acutely experienced its challenges, programs like Teach for Nigeria and Teach for Ghana are essential.
Imagine what could be accomplished if efforts to place local recruits in low-income schools were expanded.
Imagine how many opportunities to address the challenges facing children and families could be created, potentially reaching hundreds of thousands of children who are also inspired and encouraged to think critically and resolve the problems affecting the world around them.
Some argue that education is meaningless if graduates cannot find work; in fact, job creation in Africa will be a major topic of discussion at the G20 summit.
But while investment in business development and job creation is crucial for economic vitality and growth, it won’t happen without an educated workforce.
A robust job market presupposes a sufficient number of skilled workers to fill available jobs.
But in Sub-Saharan Africa, only 58% of children complete primary school.
This is why, when G20 leaders discuss new economic development strategies for Africa, they should focus on investment in education.
But, more important, they should seek to ensure that resources make it to those who rely on local leadership and innovation.
Sustainable Development Goal 4 – to ensure equitable and inclusive education for all by 2030 – is attainable, but only if solutions come from the ground up, which means from the Africans most committed to them.
Empowering the Other Half of Africa’s Economy
JOHANNESBURG – Julius Nyerere, the founding president of Tanzania, once said that “unity” will not make Africa rich, but “it can make it difficult for Africa and the African peoples to be disregarded and humiliated.”
But, two decades later, Africa remains divided along a key fault line: gender.
To realize Nyerere’s vision of a strong, dignified continent, Africa needs a new era of liberation, one that is fueled by the economic empowerment of the continent’s women.
Although projections by the consultancy McKinsey anticipate that by 2040, Africa will have the world’s largest labor force, with more than 1.1 billion people of working age, more than 60% of Africa’s current population still survive on less than $2 a day.
It is obvious that while many Africans have benefited from political emancipation – the legacy of Nyerere’s generation – poverty remains a significant obstacle.
Unleashing the employment potential of African women is the best way to overcome it.
As it stands, Africa’s women continue to be underrepresented in key industries and executive roles, owing to workplace discrimination and patriarchal expectations at home.
Unless barriers to entering the formal economy are removed and women are presented with options that enable them to realize their full potential, Africa’s socioeconomic development will continue to be impeded.
But while women are essential to the continent’s progress, they are still too often regarded as being secondary.
Women must therefore claim their right to sit where decisions are made, and to shape the policies, plans, and strategies that will affect their lives and the lives of Africans for generations to come.
Studies have shown that if more women had access to male-dominated occupations in Africa, worker productivity would rise by as much as 25%.
That would be good for the overall economy, but also for women in general, as it would open up new avenues for social empowerment.
When women participate in the job market and engage actively in business or political decision-making, patriarchal power dynamics shift, elevating the social status of women.
Economic equality also challenges accepted beliefs, and dispels harmful myths that perpetuate narrow definitions of gender norms.
In other words, bringing more women into the workplace leads to an emancipation of mindset – in men and women alike.
What Nyerere so eloquently said of Africa as a whole is no less true for its women: unity is the key to realizing our potential.
When we come together as generators of wealth, it becomes impossible for us to go unrecognized for our economic contributions and marginalized in our entrepreneurial endeavours.
At the Graça Machel Trust, we are joining together with civil-society actors, the private sector, and governments across the continent to lead a new economic liberation movement for women.
Divided, we are weak, but together, Africa’s women have the ability to confront and overcome the barriers that have kept us from full participation in our respective economies.
There is power in networks.
My organization’s approach to economic advancement is to establish and strengthen informal and official networks, through which women can, in time, increase their participation and visibility in key sectors.
That is why we are launching the “Women Advancing Africa” initiative, which is part of our ongoing effort to amplify the voices of Africa’s underrepresented and to establish a pan-African women’s movement, in which women can come together to transform the continent.
The inaugural Women Advancing Africa Forum will take place this week in Dar es Salaam, Tanzania, and will convene more than 250 women leaders from across the continent.
Under the overarching theme of “Driving Social and Economic Transformation,” the Forum will focus on three strategic goals: promoting financial inclusion, increasing market access, and driving social change.
We aim to emerge from the Forum with a common agenda for our participation as full economic actors.
It has been just over 20 years since Nyerere encouraged us to work toward African unity.
Today, Africa’s women are helping to shape the policies and practices that will bring about economic and social liberation in their respective countries.
We have some way to go before African unity is fully realized.
But enabling women to become full partners in Africa’s economic future, is among the best ways to ensure that we succeed.
Capitalizing on Africa’s Youth Dividend
TORONTO – When South African university students took to the streets in 2016 as part of the “Fees Must Fall” protest movement, the “decolonization of the curriculum” was among the movement’s chief concerns.
It was a pivotal moment in South Africa’s history, as young people rose to demand quality and accessible education.
But a crucial question was missing from the debate over fees and curricular relevance: how can changes to higher education empower Africa’s youth to drive the continent’s economic transformation?
For Africa, the question is no longer “if” students are taught, but “what.”
Unfortunately, while access to education has improved significantly in recent decades, school curricula have changed little since the colonial era, when secondary education was an elite privilege designed to advance the careers of a select few.
Technical and vocational education and training (TVET) programs have also suffered from neglect.
Today, these initiatives are marked by outdated courses and rote learning methods that fail to prepare young people for the demands of the twenty-first-century job market.
The trouble goes beyond traditional components of the curriculum, like math, science, and language. There is also a deficiency in critical “soft” skills, such as communication, teamwork, and problem solving.
Though neglected, it is these skills that enable young people to become adaptable, lifelong learners.
The mastery of soft skills correlates to improved outcomes in school, work, and life.
Yet, until recently, training in soft skills has not been integrated into formal education systems on the continent.
Fortunately, that is changing.
Across the continent, secondary schools and TVET systems are transforming themselves to prepare Africa’s young minds with the skills they need to make the transition from school to employment, and to become more engaged citizens.
These adjustments are coming at a critical time for Africa, where many countries are experiencing a demographic dividend of declining fertility rates and rising productivity.
In particular, these changes mean more opportunity for young people as they prepare to enter the job market.
But to succeed on the job, young people must have the skills and education that a modern economy requires.
At The MasterCard Foundation, where I manage education and learning programs, we’ve put together a blueprint – called Skills at Scale – to help African educators revitalize their curricula to capitalize more effectively on the economic potential of youth.
One of the continent’s most successful efforts already underway is the USAID-funded Akazi Kanoze Youth Livelihoods Project, designed by the Education Development Center (EDC) in Boston.
Akazi Kanoze epitomizes how a small initiative can catalyze wider education-sector reform, by emphasizing links to local employers that provide access to entry-level jobs, internships, and apprenticeships.
The focus on personal development, interpersonal communication, and leadership training has ensured that students are well equipped to enter the labor market upon graduation.
Rwanda’s Ministry of Education has already moved to integrate elements of the program in TVETs across the country.
The government recently integrated Akazi Kanoze’s approach in the national curriculum to equip secondary and TVET students with the soft skills they require to succeed.
National exams in the 2018-2019 academic year will also reflect the new competency-based curriculum.
Since 2009, Akazi Kanoze trainings have prepared more than 37,000 youth for work, with more than 65% of participants in the initial round of training employed six months after graduation.
Based on the success of integrating soft skills into the curriculum in Rwanda, The MasterCard Foundation and EDC will launch a similar program in Senegal later this year.
Case studies from Skills at Scale highlight six components to a successful skills-training initiative.
These include an enabling policy environment, in which the government is supportive and sets clear goals for education sector reform; vocal backing for these changes from strong political champions; wide stakeholder engagement, especially in the design and implementation phases of the reform; decentralization of authority for education; flexibility on the part of donors; and the ability to measure the changes’ impact on youth employment and entrepreneurship.
Change is not without challenge.
Adapting models of skills training to vastly different education systems across Africa will take time.
It will also be difficult to ensure that intensive training models reach all young people, including those no longer in school.
Experience in Rwanda shows that curriculum redesign requires close cooperation with education and workforce development authorities, as well as government officials, teachers, and school administrators.
New curriculum content also requires developing new teaching and learning materials.
Achieving scale also requires a markedly different approach to training teachers than is currently on offer in most African school systems.
Trainings must go beyond traditional, one-off approaches, by providing ongoing teacher support.
New pedagogies also require continual supervision and practice, especially early on.
The old “cascade” model of teacher training simply won’t work.
African governments, with support from the international community, can help students’ transition from school to work by relying on a curriculum that elevates the importance of soft skills.
If done well, these changes can ensure young people are positioned to drive Africa’s future prosperity.
Africans deserve a forward-looking education system, not one that remains stuck in the past.
As students in South Africa demonstrated last year, the continent’s youth will settle for nothing less.
A Big Bond for Africa
LAGOS – The countries of Sub-Saharan Africa have reached a critical juncture.
Strained by a collapse in commodity prices and China’s economic slowdown, the region’s growth slipped to 3.4% in 2015 – nearly 50% lower than the average rate over the previous 15 years.
The estimated growth rate for 2016 is lower than the population growth rate of about 2%, implying a per capita contraction in GDP.
Sustained economic growth is essential to maintain progress on reducing poverty, infant mortality, disease, and malnutrition.
It is also the only way to create sufficient good jobs for Africa’s burgeoning youth population – the fastest growing in the world.
As Gerd Müller, Germany’s development minister, noted at a recent press conference, “If the youth of Africa can’t find work or a future in their own countries, it won’t be hundreds of thousands, but millions that make their way to Europe.”
One way to sustain growth and create jobs would be to collaborate on planning and implementing a massive increase in infrastructure investment across Africa.
Public infrastructure is particularly important.
This includes highways, bridges, and railways linking rural producers in landlocked countries to Africa’s urban consumers and external markets; mass transit and Internet infrastructure to accommodate greater commercial activity; and electricity transmission lines integrating privately financed power plants and grids.
Major regional projects are also needed to knit together Sub-Saharan Africa’s many tiny economies.
This is the only way to create the economies of scale needed to increase the export potential of African agriculture and industry, as well as to reduce domestic prices of food and manufactured goods.
While governments in Africa are spending more on public infrastructure themselves, outside finance is still required, especially for regional projects, which are rarely a top priority for national governments.
Yet aid from Africa’s traditionally generous foreign donors, including the United States and Europe, is now set to shrink, owing to political and economic constraints.
But there may be a solution that helps Africa recover its growth in a way that Western leaders and their constituents find acceptable.
We call it the “Big Bond” – a strategy for leveraging foreign aid funds in international capital markets to generate financing for massive infrastructure investment.
Specifically, donors would borrow against future aid flows in capital markets.
That way, they could exploit current low interest rates at home, as they generate new resources.
With 30-year US Treasury rates of about 3%, donors would have to securitize only about $5 billion to raise $100 billion.
That money could come from the $35 billion in annual official development assistance (ODA) to Africa (which totals about $50 billion) that takes the form of pure grants.
Donors would pass on the interest cost to African countries, reducing their own fiscal costs.
For African countries, the terms would be better than those provided by Eurobonds.
In fact, as audacious as it may sound, passing on the interest costs to recipient countries could actually bolster their debt sustainability.
According to a study of eight countries by the African Development Bank’s Policy Innovation Lab, a 3% interest rate in US dollar terms would be lower than the marginal cost of commercial borrowings undertaken by several African countries over the last five years.
Moreover, far longer maturities and grace periods, compared to market finance, would ease growing pressure on foreign-exchange reserves.
Frontloading aid in this way is not new.
Doing so in the early 2000s to finance vaccines saved millions of lives in the developing world.
Big Bond resources, managed by the African Development Bank, could be used to help guarantee financing for major regional infrastructure projects that have long been stuck on the back burner, such as the East Africa Railway connecting Tanzania, Rwanda, and Burundi, and a highway stretching from Nigeria to Côte d’Ivoire.
Such projects could also be co-financed by private investors.
Moreover, the Big Bond could help to reinvigorate the relationship between donors and African countries.
And, as it supports investments with important country-level benefits, it could serve as an incentive for African countries to pursue reforms that increase their absorptive capacity, in terms of choosing and executing public infrastructure investments.
The Big Bond approach represents a much-needed update to the ODA framework – one that supports higher and more sustainable growth in recipient countries, while lowering the burden on donor countries.
At a time when aid is under political pressure, perhaps such a bold approach to maximizing the efficiency of donor resources is exactly what the world needs.
Accelerating Africa’s Energy Transition
PARIS – For much of Africa, the transition from fossil fuels to cleaner forms of energy is seen as an environmental imperative.
With fossil fuels comprising a majority – as high as 70% in some cases – of the energy mix, the situation on the continent is indeed ecologically dire.
But Africa’s energy transition is economically urgent as well.
Each year, oil subsidies consume 1.5% of the continent’s GDP – roughly $50 billion.
That is enough money to provide solar power to some 300 million people.
If the continent could rebalance its energy portfolio, moving away from hydrocarbons slowly, those subsidies could be reallocated in ways that would yield both environmental and economic benefits.
Today, neither oil exporters nor importers are adequately insulated from price shocks.
When oil prices declined rapidly in 2015, for example, Africa’s energy importers spent less on oil, while exporting countries suffered financially.
When prices rebounded, the relationship switched: energy-exporting countries’ revenues inched up, while importing countries struggled to maintain consumption levels.
This is a needless cycle.
Integrating cleaner power into national energy systems would not only raise local capacities; it would also free up hydrocarbons for export.
The resulting revenue could then be invested into new forms of greener power.
Such a transition, which would require cooperation with the oil sector, promises to boost socioeconomic progress.
Among the biggest benefits would be the electrification of areas that, under current distribution systems, are literally in the dark.
Today, just 30% of Africa has access to reliable electricity.
But, with a total capacity estimated at around ten terawatts, installed solar capacity in Africa could broaden access dramatically.
In fact, according to some estimates, the increase in solar generation by 2030 could range from 15 to 62 gigawatts.
Fossil fuels are not destined to be phased out anytime soon, but an energy mix that included a significant increase in solar power would have major economic advantages for Africa, especially in areas where agriculture is the largest economic sector.
Electrifying agricultural areas would facilitate the storage and transportation of farmed products, improve food security, and increase farmers’ earning capacity.
In the drive to rebalance Africa’s energy mix, the continent maintains one crucial advantage over developed economies: a clean slate.
The relative absence of legacy investments is the principal reason why green power is Africa’s best energy option.
Although every country must balance its own energy needs, reliance on renewable sources, and solar power in particular, is the most cost-efficient strategy for fostering rapid economic development throughout the continent.
Evidence of this potential can be found in the few photovoltaic power plants that have begun operating in Africa.
For example, the Senergy 2 solar plant in Senegal sells electricity to the Senegalese power utility at a price that lowers the cost of the energy mix by 50%.
Similar solar solutions are being implemented by African telecoms to electrify communication towers.
The best way to accelerate the transition from hydrocarbons to greener forms of energy would be to redirect a portion of national oil subsidies to renewables.
This would create stronger incentives to reduce fossil-fuel consumption, while encouraging investment and growth in green-energy output.
For Africa’s rural regions, moreover, such policies would help bring communities out of darkness and lead to the installation of other critical infrastructure that economic growth requires.
But while renewables hold the key to Africa’s long-term prosperity, the continent’s transition to cleaner power should not lead to an immediate, full-scale repudiation of hydrocarbons.
The oil sector will still have an important role to play.
The industry’s experience on the continent will be needed to navigate the energy transformation.
And, because fossil fuels will remain part of the continent’s energy mix, the oil sector must be encouraged to clean up its own act.
This may sound like an impossible alliance.
But as policymakers across the continent seek to secure adequate supplies of clean energy to ensure rapid, inclusive economic growth and environmental sustainability, they are likely to find that there is no alternative.
Cooperation between old and new energy industries may be the only engine that is capable of powering Africa forward.
Africa’s Vaccination Test
BOSTON – In February in Addis Ababa, African health ministers signed a widely celebrated declaration of their commitment to keeping immunization at the forefront of efforts to save the continent’s children from death and disease.
Fulfilling that commitment will be no easy feat.
Immunization is not just a health issue; it is also an economic challenge.
The case for vaccination is strong.
Globally, an estimated 2-3 million child deaths and 600,000 adult deaths are prevented annually through immunization.
Moreover, immunization is considered one of the most cost-effective public-health interventions for reducing child morbidity, mortality, and disability.
A recent study estimates that every dollar spent on vaccination will save $16 in costs of illnesses averted.
Accounting for the value individuals place on longer and healthier lives, net returns on investments in immunization soar to some 44 times the cost.
And net returns exceed costs for all vaccines.
Significant progress has been made.
In 2014, 86% of children were immunized against diphtheria, tetanus, and pertussis, compared to less than 5% in 1974.
And there have been extraordinary advances in the number and kinds of vaccines that are available.
Yet, worldwide, an estimated 18.7 million infants are not being reached by routine immunization services.
The problem, of course, is access.
Detailed analysis of immunization reveals significant disparities within and across countries.
More than 60% of the non-immunized infants live in just ten countries: the Democratic Republic of the Congo (DRC), Ethiopia, India, Indonesia, Iraq, Nigeria, Pakistan, Philippines, Uganda, and South Africa.
Routine immunization coverage remains particularly low in Africa; indeed, it has stagnated over the last three years, against a backdrop of weak and under-resourced health systems.
As a result, one in five African children still do not receive lifesaving vaccination.
In 2014, an estimated 42% of all global deaths from measles were in Africa.
Most of Africa’s under-immunized children live in Nigeria, Ethiopia, the DRC, South Sudan, and Guinea.
Poor people, those living in rural areas, and families with lower education levels comprise the majority of those who are not reached.
Clearly, money is a leading factor shaping immunization outcomes.
Beyond inadequately financed health systems, which remain weak and inefficient, especially in rural areas, African countries face challenges in affording new, more expensive vaccines.
New vaccines should be enabling us to save more lives.
Yet Médecins Sans Frontières estimates that the introduction of new vaccines made it 68 times more expensive to vaccinate a child in 2014 than in 2001 in most African countries.
Another study showed that in 2001, the total cost of the original set of six World Health Organization-recommended vaccines was less than one dollar.
In 2014, the number of WHO-recommended vaccines had risen to 11 – and the cost had reached about $21 for boys and $35 for girls.
The added costs of delivery, currently estimated at about $25 per child, bring the total cost of fully immunizing a child today to $50-60.
That same study found that, in many low- and middle-income countries, immunization budgets are currently insufficient to sustain vaccination programs, much less incorporate the new costlier vaccines.
As several health ministers pointed out in Addis Ababa, high vaccine prices force poor countries’ governments to make tough choices about which deadly diseases they can afford to prevent.
For some countries, the situation is about to get worse, as Gavi, the international group which has helped to finance the dramatic global expansion of new vaccines, phases out support for countries deemed to have “graduated” from assistance.
Without eligibility for the lower prices obtained by Gavi, many of these countries may not be able to afford newer vaccines.
In order to cope with this challenge, African political leaders have committed to invest in the continent’s capacity to develop and produce its own vaccines.
But this is a long-term strategy that will require coordinated regional investment planning, market development, and stronger regulatory capabilities.
In the short to medium term, African countries would do well to look into the power of collective bargaining to strike better deals for needed vaccines.
While Africa can and should do more to improve vaccination, the global community also has a responsibility to make a concerted effort to bring down vaccine costs.
The recently announced reduction in the price of pneumococcal vaccine is a step in the right direction, but it is not enough.
Without collective action, equitable and sustained access to immunization in Africa will remain a major problem – and children’s lives will continue to be lost.
Africa’s Avoidable AIDS Crisis
NEW YORK – At Uganda’s largest AIDS clinic, I recently witnessed a remarkable celebration of life. The performers were a troupe of young African singers, drummers and dancers, ranging in age from roughly eight to 28.
“This is a land,” they sang,
“Where beautiful people
Laugh and dance in harmony.
Africa.
O Africa.”
And, indeed, these young people laughed and danced not only in harmony but with a joie de vivre that lit up their faces and filled us all with happiness.
Listening, it was hard to imagine that they could easily be dead – and would be, if not for this clinic.
Each of those splendid performers is living with HIV.
Some arrived at the clinic so ill that they could scarcely walk.
Others showed few symptoms but, having tested positive, came to be treated.
They were mothers and fathers, sisters and brothers, children and grandparents.
All were alive and healthy for one reason only: the Joint Clinical Research Center in Kampala, and the drugs that it provides them.
Uganda was the epicenter of the AIDS epidemic. There the scourge began in earnest; there (as elsewhere in Africa) it exacts its highest toll.
Yet Uganda is also a success story.
A decade ago, fewer than 10,000 people were taking the new generation of antiretroviral drugs that suppress the disease and offer the promise of a normal life.
Today, that figure is 200,000, thanks in large measure to generous support from the United States (under its PEPFAR program) and the Global Fund in Geneva.
We have seen similarly encouraging progress elsewhere.
Botswana, among others, has invested heavily to offer universal treatment, and now is well on its way to ensuring that no baby is born with HIV – a reality in developed countries, but not so in Africa, where 400,000 children are born with the disease each year.
South Africa, with the largest number of people living with HIV, has spent nearly $1 billion over the past year in an ambitious counseling and testing campaign to roll back the epidemic.
But there is a new and growing danger that these advances might not be sustained.
Peter Mugyenyi, who runs the Joint Clinical Research Center, told me that part of the problem is the sheer weight of numbers.
In Uganda, only about half of those with HIV/AIDS are being treated.
Meanwhile, money for treatment is drying up.
Because of the global recession, some international donors are threatening to cap their financial support.
Countries such as Malawi, Zimbabwe, and Kenya, as well as Uganda, are requesting assistance for emergency drug supplies.
In Kampala, Dr. Mugyenyi has begun placing new patients on a waiting list.
As many as seven million Africans who should be getting treatment for HIV are not.
Worldwide, the number is about 10 million.
Compounding the problem: donors have also been shifting their focus from AIDS to other diseases, because there is a sense that more lives can be saved more cheaply.
At a time when we should be scaling up to meet the AIDS challenge, we are dialing back.
In our global war on AIDS, the international community is on the verge of snatching defeat from the jaws of victory.
Those who rallied to the fight are alarmed. They fear that the impressive gains of the last decade will be lost.
“We are sitting on a time bomb,” Dr. Mugyenyi told me.
Every day, he is forced into moral choices that no one should have to make.
How do you choose to treat a young girl but not her little brother?
How do you turn away a pregnant mother, sitting with her children, crying for help?
Surely we can do better.
In Kampala, I promised my young friends that I would do everything I could to help.
In Washington recently, the United Nations rolled out an action plan that should dramatically accelerate progress on maternal and child health, including HIV.
At the International AIDS Conference in Vienna, in July, I hope that the international community will rally around UNAIDS’ launch of Treatment 2.0 — the next generation of HIV treatment, which must be more affordable, more effective, and accessible to all.
As chair of this year’s replenishment of the Global Fund, I urge all donors to see to it that countries such as Uganda get the support they need, so that Dr. Mugyenyi and other front-line soldiers in the fight against AIDS need not make those difficult choices.
I left Uganda with a snatch of song that still echoes within my heart.
Its inherent truth would be obvious, had you been there to see:
We are still useful.
To our countries, to our families.
All we need is a way to live our days,
All we need is to survive in Africa.
Yes, times are hard.
That is all the more reason to act out of compassion and with generosity.
Africa’s Diaspora to the Rescue
DAKAR – There is something dismally familiar about the tide of news reports concerning Africa’s increased suffering – more poverty, malnutrition, civil strife, and death – in the face of the recent global financial crisis.
Almost everywhere, the media translates academic conclusions into graphic illustrations of brutality and despair in places such as Guinea and the Democratic Republic of Congo.
But there is another, woefully under-reported, side to the story.
African countries that were locked out of international capital markets for most of the past five decades have largely been spared the twin woes of financial turmoil and economic downturn.
The continent’s economies experienced a slowdown, but not a recession.
Indeed, according to McKinsey & Company, Africa was the third-largest contributor to world economic growth in 2009, after China and India.
Moreover, several African countries have received ratings from credit agencies, which has opened up global financial centers to them.
In some cases, these ratings have proved equivalent to or higher than those of countries such as Turkey or Argentina.
Stock exchanges are being established across the continent.
Furthermore, countries such as China, India, and Brazil has provided a platform for increased exports and the inception of a model of cooperation based on trade, investment, and technology transfer, rather than “aid.”
China-Africa trade alone increased from $10 billion in 2000 to $107 billion in 2008, and billions of dollars are being invested in oil production, mining, transportation, electricity generation and transmission, telecommunications, and other infrastructure.
These developments have combined to improve African countries’ macroeconomic performance dramatically.
Inflation has been halved since the 1990’s, and foreign-exchange reserves have increased 30%.
Public finances showed a 2.8%-of-GDP surplus in 2008, compared to a 1.4%-of-GDP deficit in 2000-2005.
Savings rates are between 10% and 20%, and external debt has decreased from 110% of GDP in 2005 to 21% in 2008.
Since 2000, sub-Saharan African countries have achieved economic growth of 5-7%.
Many factors have contributed to this upturn.
Emerging-market demand has pushed up commodity prices.
Urbanization has given rise to a dynamic informal sector.
Improved governance, higher food production, increased inter-regional trade, debt cancellation, better use of official development assistance (ODA), and thriving telecommunications and housing markets have helped as well.
But transfers from the African diaspora stand out as the most significant contributing factor.
A study commissioned by the Rome-based International Fund for Agricultural Development indicates that more than 30 million individuals living outside their countries of origin contribute more than $40 billion annually in remittances to their families and communities back home.
For sub-Saharan African countries, remittances increased from $3.1 billion in 1995 to $18.5 billion in 2007, according to the World Bank, representing between 9% and 24% of GDP and 80-750% of ODA.
Migrants’ remittance behavior is essentially dictated by the regulatory environment and the quality – in terms of speed, cost, security, and accessibility – of products and services offered by banks, money-transfer companies, micro-finance institutions, and informal operators.
In this respect, there are three different strategies in place in Africa.
The Anglophone strategy focuses on freeing up the remittance market by encouraging competition, relaxing regulatory constraints for non-bank operators, offering financial incentives, encouraging technical and financial innovation, and stimulating collaboration among market players.
This approach, also adopted by Italy, contributes to reducing costs and increasing the overall volume of funds for beneficiaries.
The Hispanic approach emphasizes migrants’ involvement in banking by offering a range of banking services in both the country of origin and the host country, products of specific interest to migrants, and low commissions on foreign transfers.
This approach, widely developed by Morocco and the Portuguese-speaking world, is epitomized by the zero-commission policy initiated by the Spanish bank Santander and its Moroccan counterpart, Attijariwafa Bank.
Finally, the Francophone approach relies on two types of monopoly.
The first is enjoyed by Western Union, which controls up to 90% of the total formal transfer volume within Africa’s 16-member Franc Zone.
Western Union charges fees as high as 25% on transfers to these countries, compared to an average global benchmark of 5%, and has required that Franc-Zone countries sign exclusivity agreements, thereby preventing foreign-exchange bureaux, post offices, and micro-finance institutions from carrying out money transfers.
The second monopoly is exercised in the banking sector.
France has a veto within the boards of directors of the Franc Zone’s two central banks, while two French commercial banks, BNP-Paribas and Société Générale, exercise a quasi-monopoly on lending programs, mainly centered on short-term trade financing and the needs of governments, public and private companies, and the elite.
All other local banks have adopted the same approach, severely restricting access to financial services for households and entrepreneurs.
Despite the increasing importance of remittances from Italy, Spain, and the United States, the largest share in absolute terms still originates from France.
There is thus a real need in the Franc Zone for a financing institution that would convert migrant remittances into productive investments, thereby generating jobs and wealth, and that would broaden access to banking services, mortgages, insurance products, pension plans, and technical assistance.
Official statistics for 2009 are likely to show that migrants’ remittances fell sharply, as the global recession severely eroded job opportunities abroad.
That makes it all the more important that African countries, many of which have laid a strong groundwork for sustainable growth, have a financial system in place that can leverage remittances effectively as the global economy recovers.
Africa’s Dictator-Diplomat
BRUSSELS – The recent death in Brussels of Ethiopian Prime Minister Meles Zenawi finally brings to light what lay behind his mysterious two-month disappearance from public life.
Ethiopia’s government had strenuously denied rumors of serious ill health caused by liver cancer.
Now that the worst has, indeed, proven true, Ethiopia and all of East Africa will need to learn to live without the stabilizing influence of its great dictator-diplomat.
Meles was certainly both.
Ethiopia has undergone a remarkable transformation under his strongman rule since 1991, when his Tigrayan minority group from the country’s north came to power with the overthrow of the odious Communist Derg led by Mengistu Haile Mariam (still enjoying a comfortable retirement in Robert Mugabe’s Zimbabwe).
Initially serving as the president of the first post-Derg government, and then as Ethiopia’s prime minister from 1995 until his death, Meles (his nom de guerre in the revolution) oversaw 7.7% annual GDP growth in recent years.
Strong economic performance is somewhat surprising, given his party’s interventionist policy approach, but Meles showed himself to be a consummate pragmatist in attracting investment – particularly from China – to drive growth.
Meles’s own political provenance as the leader of the Tigrayan People’s Liberation Front was Marxist-Leninist.
But, when the Cold War ended, so, too, did his dogmatism.
To his credit, child mortality was reduced by 40% under his government; Ethiopia’s economy became more diversified, with new industries like car manufacturing, beverages, and floriculture; and major infrastructure projects, including Africa’s largest hydroelectric dam, were launched.
Once a basket-case associated in the world’s eyes only with famine and drought, Ethiopia has become one of Africa’s largest economies – and without the benefit of gold or oil.
Perhaps more important than Meles’s domestic achievements was his diplomatic record.
He was an indispensable ally of the West in the fight against Islamist terrorism, culminating in Ethiopia’s military operation in neighboring Somalia in 2006.
More recently, Meles coordinated efforts with Kenya to stage limited strikes against the al-Shabaab militia, which has waged an unrelenting war to turn Somalia into a fundamentalist Islamic theocracy.
At the same time, Meles courted China as both an investor and as a hedge against the West’s criticism of his human-rights record.
And yet he controversially but rightly held out a hand of friendship to the breakaway region of Somaliland, before it became fashionable, and went as far as he could short of formal re-recognition of that ray of democratic hope in the Horn of Africa.
Meles will be sorely missed in Hargeisa, as he planned to run a Chinese-financed gas pipeline through Somaliland territory from the Ogaden to the coast.
More important, Meles put Addis Ababa on the map as the home of the African Union, and as a capital where Africa’s worst problems could be discussed in a pragmatic manner, unburdened by colonial grudges.
Meles himself became a major diplomatic player, particularly over climate-change policy, and most recently was active in mediating border and natural-resource disputes between Sudan and the newly independent (and oil-rich) South Sudan.
He will be remembered for accepting the painful secession of Eritrea in 1993, rather than prolong the civil war, and for his efforts to reach an agreement with Egypt over the use of the Blue Nile waters.
The great stain on Meles’s record will always be his intolerance of dissent.
To be sure, his human-rights record was far better than the Derg’s.
For example, he allowed a private press to flourish, and in 2000 he became the first Ethiopian leader to hold multi-party parliamentary elections.
Moreover, compared to neighboring Eritrea under President Isaias Afewerki or Omar al-Bashir’s Sudan, his regime was by no means the worst offender in the region.
Nor was there much evidence of personal enrichment or widespread corruption.
Nevertheless, following a violently contested parliamentary election in 2005, in which more than 30 parties participated, Meles demonstrated open contempt for democratic pluralism and press freedom, jailing several journalists in recent years.
At the same time, he imposed increasingly strict central control on his ethnically and linguistically diverse country.
Although nominally governed by “ethnic federalism,” where this threatened secession, as in Oromia or the Ogaden, Meles was quick to ignore the constitutional set-up.
Although he strengthened religious freedom and peaceful coexistence between Muslims and Christians, the human-rights situation in Ethiopia remained poor.
For example, groups like Freedom House and Human Rights Watch have documented widespread official repression of the Oromo people.
And yet Meles is irreplaceable – unmatched intellectually as an African leader (he dropped out of medical school, but went on to teach himself impeccable English and obtain European university degrees by correspondence), and unmatched politically at home, with no obvious successor groomed to replace him.
In the Horn of Africa, there is no leader of his stature who could ensure the stability and strong governance that the region so desperately needs.
Hailemariam Desalegn, Meles’s foreign minister, will take over Ethiopia’s government.
But there will be considerable concern in the West about the danger of a power vacuum or struggle in a geopolitically vital but fractious country – and just when neighboring Somalia is supposed to be undergoing a transition to a new parliament and elected government.
For his admirers and critics alike, Meles leaves behind a potent political legacy.
He will be remembered as an African leader of major historical significance: visionary, despotic, and indispensable.
Africa’s Economic House Divided
DAKAR – The world economic downturn and financial-market tremors have strained budgets across Africa.
With the exception of Ghana, and a few other states, in 2009 most African countries’ fiscal balances deteriorated.
But, thanks to prudent management of public finances during previous periods of robust growth, a significant number of African countries have endured the current crisis in better fiscal shape than during past crises.
In 2009, aggregate GDP growth in Africa averaged 1.6%, down from about 5.7% during the 2002-2008 period – but growth all the same.
Moreover, several African countries continued to implement long-term reforms to improve their business and investment climate, despite the daunting challenges presented by the crisis.
Now that international trade and global industrial production are on the mend, sub-Saharan economies look set for more robust growth, as demand for and prices of oil and other minerals rebound and general economic activity resumes.
Of course, numerous downside risks – adverse weather shocks, military conflict, and political turmoil – still can undermine the hard-earned benefits of this social and economic record.
But it is the dichotomized nature of their economies and finances that represents Africa’s most intractable structural imbalance.
Frankly, two Africa’s are emerging: a modern economy and a cash-based economy.
Across Africa, almost all governments praise – some honestly, some not – economic modernization as the cornerstone of prosperity and the yardstick by which their effectiveness should be measured. Many boast of the modernity of the financial infrastructure of their economies, which is based on an entire set of legal, regulatory, accounting, credit reporting, and payment and settlement systems.
National payment systems operate electronic-based payment products and services.
A high-value inter-bank funds-transfer system settles transactions in real time, eliminates credit risk between system participants, increases circulation of funds, and enhances monetary-policy implementation.
Banks are provided with a facility to monitor their positions in real time and hence make cost-effective investment decisions.
So far, only a few registered financial institutions, primarily offshoots of Western commercial banks, have access to such payment-system facilities.
Non-banking financial institutions such as foreign exchange bureaus, post offices, and micro-finance lenders are not admitted, even when they are financially sound and sustainable.
The effects of banks’ hijacking of national payment systems to service only the modern economy are compounded by the exclusive agreements that banks and money-transfer companies such as Western Union have signed with most African countries.
These agreements lock out non-banking entities from the highly lucrative market for migrant remittances from the African diaspora, which remain a key engine of growth.
Yet rapid urbanization everywhere in Africa has given rise to a dynamic informal sector unconnected to the modern economy.
Although marginalized by African officials, this cash-based economy is a major contributor to the continent’s productive capacity.
It employs more than 90% of the workforce and is home to 75% of the retailers.
But, despite the pivotal economic role that the informal sector plays, it has no access to conventional bank loans.
Micro-finance institutions provide the only credit lines open to informal operators.
The micro-finance business model is based on lending that is guaranteed by the group.
This translates into a solidarity network and a support mechanism that mitigates credit risk and encourages payment discipline. Credit repayment in well-managed micro-finance institutions is around 95%. All studies undertaken in the area have also revealed that women are not only the most active among informal-sector entrepreneurs, but they are also quicker to meet their commitments.
African states must now recognize that modernizing their informal sectors by integrating them into the modern economy can be a major development tool. Yet only a few countries have started moving in that direction.
Nigeria has refrained from signing any exclusive agreements with Western Union and others, and its newly consolidated banking industry is making significant inroads across the region.
Rwanda, too, has enacted regulations that eliminate exclusive agreements, opening doors for micro-finance institutions to become payment-service providers.
The South African Reserve Bank has created a special platform within its national payment system for micro-finance institutions and non-banks.
Malawi’s national payments system is directly accessible to non-bank participants, including third-party service providers.
Giving micro-finance institutions access to national and regional payments systems and electronic retail facilities will go a long way toward meeting the requirements of the retail and business sector in terms of banking facilities.
It will also help facilitate access by the poorest to financial services, thus helping to reduce the high proportion of the un-banked population.
All of this will invariably spur development and integration of national financial systems and intra-regional trade.
This will be a welcome development, because a large proportion of intra-regional trade is carried out by informal operators and small and medium enterprises that do not have access to the banking system.
Moreover, economic integration and increased intra-regional trade are the best entry point into global markets for all countries.
When it comes to analyzing what ails Africa, it is customary to dwell at length on the continent’s traumatic past.
But it strains the imagination to link Africa’s colonial-era pains with the willingness of African leaders to spend a fortune to equip their countries with state-of-the-art settlement systems, and then proceed to exclude their citizens from using them.
Abraham Lincoln once said that a house divided cannot stand.
There is an economic corollary to this: an economic house divided cannot prosper.
Africa’s Hard Black Gold
LAGOS - Few infrastructure services in the developed world may be as taken for granted as electric power.
To consumers in industrialized countries, uninterrupted power supply is a given.
Not so in much of Africa, which experiences some of the world’s greatest power deficits, and where only two in ten people have access to electricity.
According to the International Monetary Fund’s most recent Regional Economic Outlook for Sub-Saharan Africa, in 2007 alone, nearly two-thirds of the countries in the region experienced an acute energy crisis marked by frequent and extended electricity outages.
There is no shortage of hydropower plants for electricity generation in Africa.
However, many of these plants are unable to keep up with rapid population growth and attendant increases in demand.
Furthermore, they are prone to frequent drought, which reduces their output significantly, leaving many as little more than decorative infrastructure landmarks.
Increasingly burgeoning populations in countries like Nigeria and Ghana imply a greater extraction of water resources for power generation.
Rapid expansion of agricultural activity is requiring more and more water all across the continent.
Other resources like fuel oil, diesel, light crude, solar, and gas are also available as means of electricity generation, but their costs are all quite prohibitive.
These factors make a good argument for coal as a cheap alternative source of Africa's power.
Coal has historically played a crucial role as a source of energy worldwide, and has several important advantages over other fossil fuels.  First is its relative abundance.
The current level of proven coal reserves worldwide stands at roughly 850 billion tons.
Africa has about 50 billion tons.
Coal is also much more widely distributed geographically than any other fossil fuel.
Worldwide energy demand has increased by more than 50% since 1980, and is expected to grow annually by 1.6% between now and 2030.
More than 70% of this new demand will come from developing countries, with fossil fuels projected to account for about 80% of total energy demand by the end of this period.
Coal is the world’s fastest growing fossil fuel, with annual production increasing by 6.4% since 2004.
It is already the dominant source of power generation in some very important energy-consuming nations.
Much of the future increases in coal-fired electricity generation will come from strategically important developing countries like China and India.
In 2006 alone, China added about 93,000 megawatts of coal- fired electricity generating capacity, and this trend is expected to continue as the country tries to meet its huge energy needs.
Even in many developed countries, coal still accounts for a large share of power generation.
Coal plants currently provide more than half of America’s electricity supply.
Denmark, which houses some of the most efficient coal-fired power plants in the world, equally relies on coal for half of its electricity production.
The same is true for Germany, which is home to some of the most efficient pulverized coal combustion units in Europe.
Poland uses coal for 98% of its electricity production, and South Africa uses coal for about 50% of its electricity production.
Against this picture then, it is hard not to expect developing countries to exploit their abundant coal resources to generate power for their own development, especially given that modern technology can help produce coal cleanly.
Some argue that gas might be a better alternative to hydro or coal, but for countries that must import much of their gas the benefits of a stable and reliable source of cheap fuel in the form of coal present a very strong counter-argument to the capital costs of a gas plant.
Unlike prices for coal, which is abundant and dispersed geographically, gas prices are subject to significant volatility, and the long-term trend in the face of fossil fuel depletion is uncertain.
In contrast, coal prices are more stable, and may remain that way for a long time.
Apart from electric-power generation, coal also has wide application in a number of industries.
It is pivotal in both steel and cement production.
Moreover, the use of wood by Africa’s growing population is causing increasingly rapid deforestation in many countries.
There is significant potential domestic demand for coal briquettes to replace wood for cooking and domestic and industrial heating.
The demand outlook thus appears favorable for the coal industry, creating significant investment opportunities.
Clearly, there are environmental drawbacks from the use of coal as an energy resource, and these concerns are far too important to overlook.
The massive reserves notwithstanding, coal is still a finite resource.
It must be mined with greater efficiency and with a view to mitigating the environmental impact.
Fortunately, much greater attention is paid today to mine safety and the management of the by-products of coal use.
With acid rain and other public-health hazards linked to coal combustion, more technologies are emerging for reducing harmful emissions from power plants.
Fueled by research, the past few years have witnessed the development of increasingly cleaner and more energy-efficient coal-fired generation plants and the retirement of older technologies, especially in the developed world.
Developing countries have lagged behind in this process, but, with the common threat of global warming, there is now growing pressure to adopt conservation policies.
Africa's mineral-rich countries must exploit their abundant natural resources.
They must use coal to advance their economic development.
Failure to do so would be a missed opportunity at a time when African countries must avail themselves of all available resources for poverty reduction.
Africa’s Immunity
ACCRA – The United States suffers rising job losses.
Britain nationalizes its banks.
Once high-flying small economies like Ireland, Hungary, and Iceland break down.
Even robust China and India are experiencing slower growth, curtailed ambitions, and broken dreams.
Yet, in sub-Saharan Africa, there are few hints of the global financial crisis that is consuming the capitalist world.
In fashionable African cities, residential home prices remain stratospheric.
A typical Western-style house in Kampala or Accra, for example, now costs an astonishing two to three times the price of a comparable home in, say, Cleveland or other cities in the American heartland.
While home prices are crashing from Madrid to Dublin and Miami to Los Angeles, African prices remain near or at record-high levels.
African banks, meanwhile, are rock-solid compared to their debt-heavy counterparts in the US and Europe.
While international bankers went bust by making legions of bad loans, African bankers stuck to earning profits the old-fashioned way: paying very little to depositors, and earning a big “spread” by buying guaranteed government debt, which yielded healthy returns.
Even government deficit spending – long the bane of Africa – seems positively puny compared to the massive debts that the US and some European countries face.
The new Obama administration is proposing spending plans that would create a record US deficit of more than one trillion dollars – and this coming on top of the outgoing Bush administration’s record deficit.
And yet there are good reasons to believe that it is just a matter of time before Africa and its peoples experience the ill effects of the global crisis.
From Ghana to Kenya, governments are having increased difficulty in raising money for infrastructure projects and selling official debt.
Foreign investment in sub-Saharan Africa, which reached record levels in recent years, is retreating, which is evidence of investor caution, not any underlying lack of optimism about the region.
And exports of raw materials to China, India, Europe, and the US – a key factor in Africa’s recent growth surge – may suffer simply because the global slowdown means less consumption everywhere.
All of these factors suggest that an African financial bust is possible.
Popular equity investments, such as shares in Safaricom, are already trading at unexpectedly low levels.
If real estate prices were to fall dramatically, a chain reaction could occur, taking down big and small investors alike, and over time causing wide suffering to ordinary Africans.
Even assuming stability in real estate prices, the global crisis surely will cause a fall in remittances by Africans working good jobs in Europe, the US, Canada, Australia, and the Middle East.
Remittances are already believed to be falling, which makes sense: immigrants in rich countries are and will be disproportionately hurt by slowing economic activity.
Immigration itself may even slow dramatically, depending on the length and depth of the economic slowdown.
Fewer Africans working in rich countries will automatically translate into less money circulating in African countries.
The decline in remittances, however, cuts both ways.
Remittances have long spurred inflation in many parts of Africa.
A Ugandan doctor working in Norway, for instance, cares little about the cost of a beer in Kampala.
He is also willing – and able – to pay more than a local doctor for services and, of course, a home in Uganda.
Fewer remittances flowing into Uganda could mean less economic activity – or simply lower prices.
The financial meltdown in the US, which incubated the global crisis, is either coming under control or threatening to mutate into a new, more virulent form that could destroy not only America’s paper economy of trading and brokering, but also its real economy of goods and services.
President Barack Obama, acting as if the latter scenario remains likely, is betting on large-scale government spending to prop up the real economy.
If his administration succeeds, the chances that Africa will remain relatively unscathed will grow.
Even if Obama fails, however, Africans should escape the worst of the global crisis, for both good reasons and bad.
The good reasons have to do with African self-reliance and a growing awareness among scholars and policymakers that trade within the region – especially between urban and rural Africa – will ultimately deliver enormous benefits.
Another factor working in Africa’s favor is its private companies’ and consumers’ low dependence on borrowed money.
People tend to pay cash for goods and services, however costly.
In the US, loans for cars and homes – loans that now aren’t being paid back – are the major factor behind the financial crisis.
In Africa, very few people borrow money for such purchases.
Africa’s cash-based economy has in the past constrained development.
After all, by allowing people to spend more than they have, borrowed money can fuel growth.
But today, Africa’s pay-as-you-go practices are a powerful defense against financial contagion.
Another way of looking at Africa’s paradoxical economic position is to admit that the region’s historical marginalization within the international financial system – so costly in times of global plenty – is proving to be an unexpected benefit when the wealthiest of the world are sick unto death.
Ensuring Africa’s Continued Rise
LAGOS – Africa’s rise is in danger of faltering.
After years during which the continent’s economy grew at an average annual rate of 5%, global uncertainty, depressed commodity prices, and jittery external conditions are threatening to undermine decades of much-needed progress.
Ensuring the wealth and wellbeing of the continent’s residents will not be easy; but there is much that policymakers can do to put Africa back on an upward trajectory.
First and foremost, policymakers must secure the financing needed to pursue sustainable development in an uncertain global environment.
The World Bank estimates that Africa will require at least $93 billion a year to fund its infrastructure needs alone.
Climate-friendly, sustainable infrastructure will cost even more.
And yet, as long as global growth remains weak, Africans cannot count on developed countries to fully honor their commitments to help attain the Sustainable Development Goals.
Africa must rapidly develop its own resources, beginning by nearly doubling tax revenues.
Across Sub-Saharan Africa, tax revenues account for less than one-fifth of GDP, compared to more than one-third in OECD countries.
This means there is plenty of room for improvement.
From 1990 to 2004, for example, Ghana reformed its tax system and raised revenues from 11% to 22% of GDP.
Admittedly, such progress is difficult; in Nigeria, we saw an opportunity in raising non-oil tax revenues, but struggled to seize it.
Another source of domestic resources is the roughly $380 billion in pension assets held by just ten African countries.
Policymakers should be leveraging these considerable sums.
At the same time, African countries will have to find a way to diversify their economies.
Diversification requires investment in the future, in the form of education and well-developed infrastructure, including telecommunications, power, roads, rail, and water.
There are plenty of models to follow: Dubai, Singapore, Thailand, Malaysia, Mexico, Indonesia, and South Korea are all admired by Africans as economies that managed to transform themselves.
Dubai, for example, set out more than three decades ago to prepare for a future without oil.
The government implemented a step-by-step transformation of the country into a service economy, putting in place the infrastructure and incentives necessary to build up financial services, tourism, medical services, real estate, media, arts, and culture.
South Korea and Singapore, which had few natural resources on which to rely, are no less inspiring.
The secret behind these countries’ success is relentlessly focused leaders, whether entrenched but benign dictators or democratically elected politicians with a shared vision of a broad-based economy.
Sub-Saharan Africa has paths for diversified growth that many of the trailblazers did not: value-added agriculture and agro industry, the processing of mineral resources, petrochemical complexes, manufacturing of durable and consumer goods, tourism and entertainment, and an emerging information-technology sector.
As the necessary measures for diversification are implemented, policymakers must ensure that the economic growth they are pursuing creates jobs.
Sadly, this has not always been the case.
Much of the recent growth has benefited only a few, leaving many behind – most notably young people and women.
From 2006 to 2013, inequality rose in many of the continent’s most important economies, including South Africa, Nigeria, Ghana, Tanzania, and Rwanda.
These were challenges that we were starting to address in Nigeria when I was finance minister.
We knew that we needed not just to secure growth, but also to improve the quality of that growth.
To that end, policymakers must ensure that growth is channeled into sectors that create jobs, such as agriculture, manufacturing, and services.
They may also have to redistribute income and strengthen social safety nets to protect better those at the bottom of the ladder.
Matching skills to job opportunities will be crucial.
Some 70% of Africa’s population is under 30, and the continent is home to half the world’s primary-school-age children who have been deprived of the opportunity to study.
Offering Africa’s children basic reading, writing, and technology skills, as well as vocational, technical, and entrepreneurial training, must be a top priority.
Weak health-care systems must also be strengthened in order to tackle the endemic diseases that sap productivity, such as malaria, as well as improving preparedness for outbreaks of deadly epidemics.
The stakes are high.
The World Bank estimates the Ebola outbreak shrank the economies of Sierra Leone, Guinea, and Liberia by 16%.
As the world economy sputters, African countries will have to develop trade with one another.
In 2013, African goods and services accounted for just 16% of trade within the continent, and just over 3% of world trade.
One problem is that most African countries produce the same type of commodities and trade them with very little value-added.
Policymakers must encourage greater specialization; differentiated goods and services will add value and volume to trade.
Logistics pose another obstacle to intra-African trade.
Policymakers must make it easier to move goods across borders, by improving connectivity between countries and reducing bureaucratic hurdles and administrative costs.
For example, road transport tariffs across Africa are estimated at $0.05-$0.13 per ton-kilometer, compared to the average of $0.01-$0.05 for all developing countries.
The Rift Valley Railway project, which will eventually link Mombasa on the Kenyan coast to Kampala in Uganda, is a good example of the benefits that investments in transportation could provide.
The African Development Bank estimates that it will double the volume of trade between the two countries, while reducing marginal costs by 30%.
As they make these investments, policymakers must not forget that much of Africa’s recent growth can be credited to good macroeconomic policies and sound economic management.
Extending the continent’s rise will require strengthening the continent’s economic fundamentals.
This means ensuring that prices in the economy are correct, starting with the exchange rate.
Some countries may need temporary controls to curb damaging capital outflows, but policymakers should aim for a market-based exchange rate and a solid plan for governing inflation, debt, foreign-exchange reserves, current accounts, and fiscal balances.
Africa’s potential can hardly be overstated.
The continent is well placed to build diversified economies based on low-carbon, sustainable infrastructure.
But policymakers cannot simply assume that Africa’s rise will continue.
They must take the right steps to ensure that it does.
Africa’s Urban Farmers
NAIROBI – When I met Eunice Wangari at a Nairobi coffee shop recently, I was surprised to hear her on her mobile phone, insistently asking her mother about the progress of a corn field in her home village, hours away from the big city.
A nurse, Wangari counts on income from farming to raise money to buy more land – for more farming.
Even though Wangari lives in Kenya’s capital, she is able to reap hundreds of dollars a year in profit from cash crops grown with the help of relatives.
Her initial stake – drawn from her nursing wages of about $350 a month – has long since been recovered.
Wangari is one of thousands of urban workers in Kenya – and one of hundreds of thousands, even millions, across Africa – who are increasing their incomes through absentee agriculture.
With prices for basic foodstuffs at their highest levels in decades, many urbanites feel well rewarded by farming.
Absentee agriculture also bolsters national pride – and pride in traditional diets – by specializing in vegetables specific to the region.
“For too long our country has been flooded with imported food and Westernized foods,” Wangari says. “This is our time to fight back – and grow our own.”
Across Africa, political leaders, long dismissive of rural concerns, have awakened to the importance of agriculture and the role that educated people, even those living in major cities, can play in farming.
In Nigeria, former President Olusegun Obasanjo has a huge diversified farm and has pushed for policies to help absentee farmers prosper.
In Uganda, Vice President Gilbert Bukenya routinely travels the country, promoting higher-value farming, such as dairy production.
Perhaps the most visible political support for absentee agriculture is in Liberia, a small West African country where civil war destroyed agriculture, rendering the population dependent on food imports, even today.
President Johnson-Sirleaf, recognizing that educated people could contribute much to an agriculture revival, launched her “Back to the Soil” campaign in June 2008 in large part to encourage urban dwellers to farm.
To be sure, absentee farming by elites and educated urban workers can’t solve all of Africa’s urgent food needs.
Moreover, absentee farmers face unexpected problems.
Because they don’t visit their fields often, they rely heavily on relatives and friends.  When I decided to farm wheat for the first time this spring on leased land in my childhood village, my mother agreed to supervise plowing, planting, and harvesting.
Without her help, I might not have farmed at all.
Even with mother’s help, I have worries.
Although I grew up around wheat fields, my knowledge of farming is thin.
Fertilizer and spraying were both more expensive than I thought.
While my wheat stalks are sprouting on schedule, I now fear that at harvest time – in November – prices will fall and I won’t recoup my costs.
One key tool is the mobile phone.
My hopes for success are buoyed by my ability to call my mother inexpensively and discuss the farm.
We even decided over the phone what kind of pesticide to use and which tractor company to hire.
Because they know both the tastes of fellow city dwellers and rural conditions, many urban farmers are succeeding.
In fact, some city dwellers don’t even bother with acquiring land or gaining distant help. Certain crops can be grown in their own homes.
James Memusi, an accountant, grows mushrooms in a spare bedroom, selling them to nearby hotels and supermarkets.
Nevertheless, most people living in Africa’s cities have access to land in the countryside, which is why Liberia’s government rightly highlights the potential for farm expansion.
In a new advertising campaign rolled out this summer, the authorities declared, “The soil is a bank; invest in it.”
In Liberia, the main push is to reduce imports of staples such as rice and tomatoes.
In more prosperous countries, African elites are motivated by a complex interplay of national pride, dietary concerns, and the pursuit of profit.
In Zambia, for example, Sylva Banda ignited a craze for authentic traditional meals two decades ago with a chain of popular restaurants.
Now, ordinary Lusakans want to cook similar meals in their own homes, driving demand for farmers who produce such delicacies as dried pumpkin, “black jack” leaves, and fresh Okra.
Similarly, in Nairobi, Miringo Kinyanjui, another woman entrepreneur, is supplying unrefined – and more nutritious – maize and wheat flour.
In another move to distinguish her ingredients from Western versions, Kinyanjui also sells through grocery stores flour flavored with Amarathan, a green vegetable that grows around Kenya.
The revival of traditional foods has attracted the attention of large multinational corporations.
Last year, Unilever’s Kenyan branch ran a “taste our culture” campaign in support of its line of traditional East African herbs and spices.
Such campaigns go hand-in-hand with expanded farming, because sellers of these foods prefer nearby growers – even if these growers increasingly live in the city.
Building Africa’s Scientific Talent
TORONTO – Ten years ago, South African physicist Neil Turok made a bold prediction: the world’s next Einstein will be from Africa.
A decade later, it is worth considering whether the continent is any closer to finding the next global genius.
Statistically, there is indeed a high probability that it will happen.
By 2050, 40% of the world’s young people will be African.
By virtue of demographics alone, it stands to reason that Africa is destined to generate prodigies in science or technology.
Africans have led the world in science before.
In fact, some of humanity’s greatest innovations – from vaccines to brain surgery – were pioneered by Africans.
One of the oldest measuring devices ever used, the Lebombo Bone, was carved by people believed to have lived some 35,000 years ago in modern-day eSwatini (Swaziland).
In other words, mathematics itself is an African invention.
For decades, science and policy luminaries like Calestous Juma, a global advocate for science-driven sustainable development, and Wangari Maathai, an environmental activist and Nobel laureate, championed Africa’s science agenda.
With these visionaries now gone, Africa needs a new brain trust to inspire future generations of ethical and public-spirited researchers.
But how do we ensure Africa discovers, supports, and develops innovative, game-changing scientists?
The missing element has been an African education system that supports innovation in research, and that provides the next African revolutionary scientist with the training and support he or she needs – in Africa.
Across the continent, there is a growing consensus among governments that education and research in science, technology, engineering, and mathematics (STEM) is critical for economic growth and development.
At the moment, however, too many of Africa’s young researchers see no option but to go abroad for school and work.
That can change, but only with concrete investments in homegrown talent.
This means rethinking the entire education system in Africa.
Three priorities stand out.
First, African countries need to fix the knowledge pipeline.
That means investing in teacher training, improved learning outcomes, retention of girls in STEM courses, supporting research earlier in university, helping young researchers through so-called sandwich programs, establishing university-private sector labs on campus, and more.
Second, Africa needs indigenous knowledge creation.
This requires facilitating both fundamental and applied research and creating the necessary infrastructure for the dissemination of research outcomes.
This could include making more funding available to researchers and research institutions, as well as promoting open sources for knowledge sharing.
The third priority is putting knowledge into practice.
This could involve making scientific information accessible to the general public and innovators, and supporting public-private partnerships to pilot, demonstrate, and apply research outcomes, thereby creating jobs addressing public problems.
A good example is Zipline, which deploys drone technology to deliver blood transfusions to remote areas of Rwanda.
To deploy this technology, which is based on American research but piloted in-country, Zipline signed agreements with the aviation authority and the ministry of health, among others, and a public-private partnership was set up to fund the program.
After successfully deploying the technology in Rwanda, it is currently being rolled out in Ghana.
Zipline has saved hundreds of lives and demonstrated the potential of technology transfer with large-scale impact.
The Next Einstein Forum (NEF), an initiative of the African Institute for Mathematical Sciences (AIMS) and the brainchild of Turok, supported partly by the Mastercard Foundation, is demonstrating that Africa produces strong scientific talent.
The NEF focuses on convening Africa’s innovators to highlight breakthrough discoveries and catalyze scientific collaboration for human development.
Since the first cohort of NEF Fellows was selected in 2015, the program has highlighted the contributions of young African researchers who are working to tackle some of the world’s toughest scientific and technological challenges.
NEF’s current cohort includes Somalia’s Abdigani Diriye, who created a blockchain-enabled lending platform in Kenya and was recently named one of Africa’s top 30 innovators; Nigeria’s Peter Ngene, whose work on nanotechnologies is being used to improve renewable energy and who also recently created a hydrogen-based eye sensor that detects lactose intolerance; and Vinet Coetzee of South Africa, whose research in non-invasive measures of health has led to a patent application for a device that could detect malaria.
With so many complex issues vying for attention today, Africa will need innovative education and research models.
But as long as the NEF and similar efforts continue to nurture the continent’s brightest young scientists and tackle systemic issues like funding, mobility, and research infrastructure, the odds are good that those leading the search for solutions will be the very people Turok predicted.
Improving African Women’s Health Through Financial Inclusion
ACCRA – In late October, the World Health Organization’s Regional Office for Africa signed an agreement with the United Nations International Telecommunication Union (ITU).
The aim of the unlikely partnership is to encourage the use of digital services “to save lives and improve people’s health.”
But perhaps the pact’s most innovative feature is the vow to merge financial inclusion strategies with modern health-care delivery.
Financial inclusion is a proven pathway to improving people’s health, especially the health of women in developing countries.
Women who can easily access bank accounts or cash payment options tend to invest more in their businesses and families.
In turn, they live healthier, more satisfying lives.
Yet, too often, initiatives like the one signed in October focus on one or the other – e-health or financial products like insurance.
Because Africans’ ability to earn and save money can be the difference between good care and no care at all, this represents a missed opportunity to help patients and build more resilient communities.
The cost of this choice is disproportionately high for Africa’s women.
In Nigeria, for example, 400,000 women live with obstetric fistula, a disabling condition often caused by complications in childbirth.
In Tanzania, some 8,000 women die annually during pregnancy or delivery; most of these deaths could be prevented.
And, across the continent, women’s life expectancy at birth is just 58 years, compared to more than 80 years in developed countries.
Progress is being made to connect women’s health solutions and financial inclusion.
At a recent conference in Dar es Salaam, experts from the technology and financial services sector joined investors, philanthropists, and development specialists to devise ways to make finance work for Africa’s women.
Through programs like these, development experts can advocate for digital solutions as a means of social and financial empowerment.
Unfortunately, cooperation like the pact signed in October is the exception, rather than the norm.
Banks, regulators, finance ministries, and telecommunications companies all frequently gather to consider financial inclusion without the local and global health community.
This must change if we are to build more inclusive platforms for African patients and clients.
The first step is to identify missed opportunities.
A big one stems from the disparate approaches to bringing financial services and digitized health care to rural parts of Africa.
At the moment, banks and mobile network operators are working to expand their digital banking services to unbanked and under-banked clients.
At the same time, community health workers (CHWs) are operating in these regions to prevent, treat, and refer patients to clinics.
Combining these efforts makes sense, because both initiatives rely heavily on trust.
Through pre-established networks, CHWs could augment their e-health offerings with financial products, like mobile cash payment systems.
Broadening digital disease management and access to health information to include financial wellbeing would create natural synergies.
While there are some concerns that adding responsibilities to CHWs could undermine health-care quality, a fragmented approach to prosperity is even more damaging.
Once opportunities for expansion are identified, other issues will need to be addressed before women’s health and financial inclusion programs can be widened.
For starters, a lack of sex-disaggregated data makes it difficult to draft policies based on health quality and financial need.
Although some countries, such as Burundi and Senegal, are working to improve their gender-specific data collection, a broader, more coordinated push is needed.
Raising the region’s financial literacy will be another challenge.
The ability to understand and execute matters of personal finance is the weakest link in transforming women’s opportunities through financial inclusion.
Moreover, financial literacy is a pre-requisite for the rollout of financing initiatives, such as programs that support women-led small and micro-enterprises.
If financial literacy levels can be raised, women can access resources such as land and credit, tools that hold the keys to business development, social mobility, and personal growth.
Progress has been made in leveling the playing field, but these gains must be sustained.
The agreement between the WHO and the ITU will help promote wealth creation in parts of Africa where access to health care and financial services is lacking.
To maintain this momentum, deeper commitments are needed, especially from the global health community.
But, however African governments proceed in digitizing their health and financial services offerings, women’s needs must remain at the center of any solution.
Closing the Youth Apathy Gap
NAIROBI – When the United Nations’ member countries adopted the Sustainable Development Goals two years ago, they committed themselves to reduce substantially “the proportion of youth not in employment, education, or training.”
That commitment will be virtually impossible to fulfill, unless political participation by young people increases considerably.
Young people are critical to progress.
As US President Barack Obama put it in a 2015 speech in Nairobi, “no country can achieve its full potential unless it draws on the talents of all its people.”
And youth now comprise a large share of those people – 18% of the world’s population, to be precise.
The share is even larger in much of the developing world.
The median age of Africa’s population is just 19.5 years.
Given their numbers, not to mention rising education and literacy rates, young people can make a world of difference, shaping political discourse and electoral outcomes.
But that requires them to be engaged and active.
In the United Kingdom, most young people wish to remain in the European Union.
As a Lord Ashcroft poll showed, 73% of those aged 18-24, and 62% of those aged 25-34, voted accordingly in last year’s referendum.
But most young British did not actually show up to cast their votes, allowing the UK’s older, predominantly pro-Brexit cohorts to win the day.
Presumably having learned their lesson from the Brexit referendum, young Britons contributed to an unexpected victory for Labour in June’s snap general election.
In Kenya’s presidential election, held last month, 51% of registered voters were below the age of 35 years.
Although the Supreme Court annulled the results and ordered a fresh vote, owing to electoral irregularities and illegalities, large numbers of young people are likely to turn out again.
Unfortunately, Kenya is the exception that proves the rule.
Political apathy among young people, like that seen in the Brexit referendum, remains pervasive worldwide.
In many regions of Africa, for example, young people are disillusioned with politics, convinced that wealthy older people will always prevail and advance their own interests, often at the expense of younger generations.
This sense of disempowerment is threatening to turn the developing world’s youth bulge into a youth curse – with serious potential consequences.
The Arab Spring uprisings, which led to violence and instability in most affected countries, were fueled largely by desperate young people demanding rights and opportunities.
To avoid such outcomes, young people need to be part of their countries’ political life, able to advance their own vision of the future.
As young Kenyans repeated during the recent election campaign, “If you are not at the table, you are on the menu.”
So what can be done to increase political awareness and participation among young people?
In Kenya, government efforts have focused on the creation of three institutions: the Ministry of Public Service, Youth, and Gender Affairs, the Youth Enterprise Development Fund, and the National Youth Council.
Though somewhat dysfunctional, these institutions have helped to empower Kenyan youth, driving the high election turnout last month.
But perhaps the most effective approach to closing the apathy gap focuses on initiatives led by young people themselves.
In Nigeria, young people spearheaded the Not Too Young to Run campaign, which led to a constitutional amendment lowering the minimum age for candidates.
Their success inspired a global campaign to support young people’s right to run for office.
In Kenya, the youth-led Jiactivate– the name, which combines Swahili and English, means “Activate Yourself” – has sought to boost youth participation in politics by highlighting the main issues affecting young people.
Jiactivate, in which I am engaged as National Chairperson, aims to serve as a platform that amplifies young Kenyans’ voices, offering them easier ways to take action.
To inspire more such initiatives, there must be a deliberate effort to engage with youth in a way that supports real political engagement, not tokenism and empty rhetoric.
To that end, the Organisation of Africa Youth, of which I am coordinator, has not only worked with local youth groups and community networks; it has also taken lessons from a GeoPoll survey of 2,000 urban and rural Kenyan youth.
That survey showed that, while 27% of respondents had never engaged politically, 26% had attended an event and 34% had posted on social media.
Moreover, 68% of respondents said that they would participate in political action only if they had access to a safe and trusted platform that would protect them from victimization, intimidation, or reprimand.
One lesson than can be drawn from these data is the potential value of social media, which, despite being constrained in many countries during elections, remains a potent tool to facilitate youth political engagement.
For example, by creatively using social media to collect, collate, and amplify young people’s priorities in the Kenyan elections, Jiactivate helped spur their interest in politics.
Nonetheless, many Kenyans who were popular on social media did not make much of an impact on the election’s outcome.
Translating social media energy into effective action in the real world remains a daunting challenge.
Increasing youth involvement in politics will require sustained commitment and hard work.
But, far from a deterrent, this should serve as a powerful incentive to get started.
No one is more affected by past, present, and future policies than young people.
They must take their seat at the table, not wait until one is offered.
The Transformative Power of Africa’s Youth
TORONTO – A few years ago, during a conversation with young people from some of Senegal’s poorest communities, a pair of social entrepreneurs told me about projects they were working on to help their peers succeed.
One young man said he planned to put more computers into primary schools; another had set up a network to connect rural job seekers in the urban tumult of Dakar, Senegal’s capital.
After they finished sharing their plans, I congratulated them, and said that their parents must be very proud.
But instead of accepting the compliment, they demurred.
“My parents are against what I’m doing,” they said, almost in unison, before explaining that young people face family pressure to get a government job or use their English skills to work as a tour guide – not to become a risk-taking entrepreneur.
For ambitious young Africans, there are many obstacles to success.
The journey to a job – whether formal or informal, entrepreneurial or traditional – is often a solitary one.
Many young people lack access to skills training or even a favorable social environment to try something new.
As I was reminded that day in Senegal, helping young people find gainful employment is the most important thing that the international community can do to help Africa develop.
Africa is home to the world’s largest population of young people.
In about 25 years, those young people will be part of the biggest workforce in the world, with more than 1.1 billion people of working age.
By some forecasts, 11 million people will enter Africa’s labor market each year for the next decade, most of whom will be first-time job seekers.
If African countries boost job growth and equip young people with employable skills, this youth bulge can deliver rapid, inclusive, and sustainable economic growth to the continent.
In turn, millions would have the opportunity to lift themselves out of poverty.
But Africa cannot achieve this future alone.
At the Mastercard Foundation, we believe that, if Africa is to reach its potential, gaps in two keys areas must be closed.
The first area is access to financial products and services.
According to the World Bank, some two billion people around the world currently lack such access.
In Sub-Saharan Africa, just 34% of adults have a bank account, making it difficult for people to put money aside for unplanned events, like a bad harvest, or to save for school.
This must change, with Africans gaining not only better access to banking systems, but also improved financial literacy.
The second key challenge that must be addressed is exclusion from secondary and higher education.
While progress has been made in some regions, only about one-third of Africa’s young people graduate from high school.
Girls are particularly disadvantaged; according to UNESCO, in Sub-Saharan Africa, an estimated nine million girls under the age of 11 have never been to school, compared to six million boys.
To address these issues, the Mastercard Foundation has established partnerships with local organizations to design education and financial-literacy programs aimed at helping young people find and keep jobs.
By building a better-trained workforce, the Foundation’s programs are helping to empower the next generation of Africa’s community members and leaders, so that they can help their families, communities, and countries achieve a brighter and more prosperous future.
Already, a new generation of educated and ethical entrepreneurs, like those I met in Senegal, is emerging across Africa, demonstrating a profound commitment to building a stronger Africa.
For example, when I ask young people participating in our Scholars Program what they plan to do with their new skills, they almost always reply that after getting a job, they plan to help somebody else, by returning to their secondary schools to serve as mentors to younger students.
Some of our program’s graduates have even established community projects in their villages to address HIV/AIDS or to build shelters for orphans and young children.
Every one of these bright young Africans – examples of what the Mastercard Foundation calls “transformative leadership” in action – has the potential to drive change in their own countries and communities.
Those of us working in the field of international development can help level the playing field even more, by giving young Africans from all backgrounds an opportunity to lead in transformative ways.
If we succeed, Africa’s dreamers of today will be the catalysts of positive change tomorrow.
Africa’s Defining Challenge
ADDIS ABABA – Africa has the youngest population in the world, and it’s growing fast.
By 2055, the continent’s youth population (aged 15-24), is expected to be more than double the 2015 total of 226 million.
Yet the continent remains stubbornly inhospitable – politically, economically, and socially – to young people.
The success of African governments’ efforts to address this will be the single most important factor determining whether the continent prospers or suffers in the coming decades.
A business-as-usual approach would risk exposing Africa not only to economic underperformance and a brain drain, but also to criminality, political and social unrest, and even armed conflict.
But Africa can thrive if its governments act now to tap the energy and dynamism of the burgeoning youth population.
What is needed is a comprehensive policy agenda, comprising demographically informed measures that address political, cultural, and economic exclusion in a synchronized manner.
This will be no small feat, not least because of the massive age gap between Africa’s young majority and their leaders: the average age of an African president is 62, while the median age of Africa’s population is 19.5.
That is the world’s largest age gap between governors and the governed, and it raises concerns about how well decision-makers understand the needs and aspirations of young people.
It does not help that a tradition of gerontocracy prevails in many countries, meaning that young people’s political participation and influence is restricted on cultural grounds.
To help overcome this barrier, governments should treat generational inequality with the same sense of urgency as other forms of inequality, accelerating efforts to introduce youth quotas for political parties, parliaments, and other decision-making institutions.
Much work also remains to be done on the economic front.
According to the African Development Bank, 12 million young people entered Africa’s labor force in 2015, but only 3.1 million jobs were created.
That means that millions of young people were left without a stake in the economy.
In the short and medium term, it will be virtually impossible to create enough jobs to meet the needs of the unemployed and vulnerably employed.
Africa does not have a large labor-intensive manufacturing sector to absorb its mushrooming young population.
But there are programs that can help.
For example, YouthConnekt Africa, launched by the United Nations Development Programme and the government of Rwanda, encourages youth-friendly policies, such as access to finance and skills development, that match the needs of the market in particular countries.
Still, given the dearth of opportunities at home, many young Africans view migration as a chance for social mobility.
Yet, as the CEO of a major company based in Sub-Saharan Africa recently lamented to me, acquiring work visas for Africans is extremely difficult.
In fact, it can be easier to get a work visa for a British citizen than for, say, a Ghanaian with the same skills.
Africa’s vision for economic integration, as set out in the African Union’s Agenda 2063, cannot be realized without labor migration that creates African careers paths for young people.
It is telling that so many Africans are willing to risk drowning in the Mediterranean Sea, living in appalling detention centers in North Africa, or sleeping in public parks in European cities, rather than remaining in Africa.
Yet, contrary to popular belief, young people are not migrating from Africa exclusively for economic reasons.
Rather, they are motivated by the promise of opportunities for genuine self-improvement and the freedom to decide who to be and how to live.
That is certainly what led me to leave Africa and head to Europe at a young age.
In fact, the desire for self-improvement through migration is a key element of the human story – one that no desert, sea, or artificial barrier has been able to quell.
Political and cultural exclusion intensifies it.
Given this, any strategy that does not address the broader environment of marginalization is a bridge to nowhere.
So far, Africa seems to be sleepwalking into a future of lost opportunity and, potentially, serious instability.
And Africa’s international partners have remained preoccupied with containing migration from the continent, rather than addressing its underlying causes.
But there may be reason for hope.
The fifth European Union-Africa Summit, to be held later this year, will focus squarely on the continent’s young people.
Likewise, the African Union’s theme for 2017 is “Harnessing the Demographic Dividend Through Investments in Youth.”
One hopes that the growing recognition of the need to create opportunities for young people leads to effective, solidarity-based initiatives that address the barriers to youth empowerment on the continent, instead of erecting barriers to prevent young people from leaving.
To paraphrase Martin Luther King, Africa confronts the fierce urgency of now.
There is such a thing as being too late.
Listening to Africa’s Future Farmers
NAIROBI – Africa is in the midst of a youth employment crisis.
By 2035, some 350 million new jobs will be needed, and agriculture, the continent’s biggest industry, could provide the bulk of them.
But at the moment, young Africans are shunning life on the farm for work in the city.
If Africa’s employment gap is to be closed, agribusinesses must find ways to recruit younger hands.
This challenge was the focus of my research as part of the Youth Think Tank, a youth-led research initiative in partnership with Restless Development Uganda and the Mastercard Foundation.
In a recent report, we examined the experiences of young African agriculturalists in seven countries.
And what we discovered is that the best way to entice young people back to the farm is by improving access to and engagement with emerging technologies.
Many of the young people with whom we spoke said that their biggest obstacle to a career in farming is learning the digital and technical skills necessary to succeed in today’s agricultural market.
With technologies like cloud computing, soil sensors, and weather drones changing how food is produced, packaged, and distributed, digital literacy is as important as arable land and high-quality seeds.
It stands to reason, then, that if more young people could master digital skills, more would find work in the field.
To understand how important technology is to the young African farmer, consider competition for land.
Most farmland is acquired through hereditary or communal distribution systems, and when new plots are allocated, they are typically smaller than those provided to previous generations.
To remain profitable, younger growers must produce larger crops from smaller spaces, which requires innovation.
Our study found that in many cases, the best solutions for young farmers are already being designed by young people.
For example, in Kenya, one vegetable grower turned her kitchen garden into a vertical farm to increase its output.
Today, she runs her own business designing, fabricating, and installing similar structures for a variety of customers.
Another interviewee created a mobile app to help farmers connect with local seed and fertilizer suppliers.
Unfortunately, these types of youth-driven innovations rarely receive the necessary political or financial backing to make them viable and scalable.
Despite having great ideas, most young agricultural innovators do not feel supported in their efforts.
Young people can help solve Africa’s unemployment challenges, but those closest to the problem have yet to be made part of the solution.
Our research suggests several strategies to achieve this outcome.
For starters, young people need places to engage with like-minded innovators.
Recognizing this, policymakers and the private sector should work together to create incubation centers and ideation hubs to help young people build, discuss, and access farm-related technologies.
Moreover, those who promote new farm technologies should travel to the places where young people gather, to provide hands-on, audience-specific training.
If the newest farm gadgets and tools are marketed only on social media, as is often the case, uptake in rural areas will remain weak.
Next, young people need access to financial products and services to help them turn their ideas into marketable businesses.
And, finally, countries must find ways to involve their youth in early stages of the technology-development pipeline.
As the experience of the Kenyan gardener illustrates, young people are often the best judges of what will deliver long-term, practical results.
Last year, I had the privilege of presenting these findings at the Global Youth Economic Opportunities Summit in Washington, DC.
I spoke about the role young people play in Africa’s economy, and the importance of soliciting their views on the future of African agriculture.
It was an important first step in bringing young peoples’ ideas to the table.
But much work remains to be done.
According to the Food and Agriculture Organization of the United Nations, the average age of an African farmer today is about 60, while 60% of the population is under the age of 24.
To breathe new life into Africa’s farms, the entire industry must innovate.
And, as our research shows, the best way to do that is by working much more closely with those who have the most to gain from progress.
After Assimilation
Human migration is as old as history. Even migration to distant places and remote cultures is nothing new.
In the nineteenth century, millions of Europeans sought liberty and prosperity in the Americas, notably in the United States.
What is new today is the scale of migration, often across huge cultural divides - and often without a definite aim.
The African boat people in the Mediterranean are often not even sure whether they want to be in Italy, Germany, or Britain.
Even those who are certain, like North Africans in Spain and France, or Turks in Germany, had as their priority escaping the hopelessness of their home countries, not arriving at a particular destination.
This modern form of migration raises massive problems for countries on the receiving end. In Europe, it is probably the most serious social issue today, because no one has a clear idea about how to manage the resulting clash of cultures.
Once upon a time, North America, notably the US, seemed to provide the answer.
It was that of the "melting pot": different peoples made their own contribution to American culture, but, above all, they made every effort to accept what they found and integrate.
"No," the Russian woman who came to the US in the early twentieth century replied to the grandchild who asked whether her ancestors arrived with the Pilgrims on the Mayflower. "Our ship had a different name, but now we are all Americans."
More recently, this has changed, giving rise to a process described by Arthur Schlesinger, the historian and former aide to President John F. Kennedy, in his book The Disuniting of America.
No longer are all US citizens Americans. They have become hyphenated Americans: Italian-Americans, African-Americans, Hispanic-Americans, and so on.
The ingredients of the melting pot are separating.
Even in Israel, the last true immigration country - at least for Jews - assimilation is no longer so easy.
Recent newcomers from Russia have their own political party, and old Europeans have become a distinct minority.
Israel and America continue to have mechanisms to integrate new migrants.
Language is an important underlying factor, and in Israel, there is the army, while in America, the values embodied in the Constitution still represent a shared secular faith.
But these mechanisms are weakening everywhere, and are virtually non-existent in European countries.
Modern societies are characterized by acute problems of belonging.
They don't offer the implicit, unconscious ties of community that citizens felt in the past. As a result, people have begun to cling to other, more primordial group identities.
They resist assimilation, fearing that it will rob them of their identity without offering a new one.
What then is the alternative to assimilation?
The "salad bowl" of so-called multiculturalism is no real alternative, because it does not provide the necessary glue that binds communities together.
All the ingredients remain separate from the outset.
The only viable alternative for which there are examples is probably that of London or New York. The main characteristic of this alternative is the coexistence of a common public sphere shared by all and a considerable degree of cultural separation in the "private" sphere, notably in residential areas.
The public space is multicultural in terms of people's backgrounds, but is governed by agreed values, even a common language, whereas the people's private lives are - to use an ugly word - ghettoized.
In theory, this is a distinctly second-best solution to the cultural consequences of migration; in practice it is the best answer we have.
But it cannot be had for nothing.
Even the necessary minimum of a common language requires a deliberate effort, to say nothing of certain rules of behavior.
Living in London, I marvel at the way in which we Londoners have come to terms with Indian family shops and West Indian-run public transport, while not asking many questions about whole districts that are Bangladeshi or Chinese.
No one has yet found a name for this new version of the "separate but equal" doctrine that some of us fought so hard against in the 1960's: separate private lives in a common public space that is equal for all.
This is clearly easier in London and New York than it is in smaller towns or even in the capitals of countries where the world language of English is not spoken.
Berlin's Turkish community and the North African communities around Paris seem increasingly separate, with their own public sphere and often language.
Where this happens, an explosive condition can arise, a kind of separatism within, not by historically separate groups but by newcomers against natives.
If we are forced to abandon the hope of assimilation, our efforts should concentrate on creating a public space to which all contribute and that all enjoy.
Ideally, this should be an expanding public space, for in the end, the element of unity in a modern society is the guarantee of its citizens' liberty.
After Austerity
NEW YORK – This year’s annual meeting of the International Monetary Fund made clear that Europe and the international community remain rudderless when it comes to economic policy.
Financial leaders, from finance ministers to leaders of private financial institutions, reiterated the current mantra: the crisis countries have to get their houses in order, reduce their deficits, bring down their national debts, undertake structural reforms, and promote growth.
Confidence, it was repeatedly said, needs to be restored.
It is a little precious to hear such pontifications from those who, at the helm of central banks, finance ministries, and private banks, steered the global financial system to the brink of ruin – and created the ongoing mess.
Worse, seldom is it explained how to square the circle.
How can confidence be restored as the crisis economies plunge into recession?
How can growth be revived when austerity will almost surely mean a further decrease in aggregate demand, sending output and employment even lower?
This we should know by now: markets on their own are not stable.
Not only do they repeatedly generate destabilizing asset bubbles, but, when demand weakens, forces that exacerbate the downturn come into play.
Unemployment, and fear that it will spread, drives down wages, incomes, and consumption – and thus total demand.
Decreased rates of household formation – young Americans, for example, are increasingly moving back in with their parents – depress housing prices, leading to still more foreclosures.
States with balanced-budget frameworks are forced to cut spending as tax revenues fall – an automatic destabilizer that Europe seems mindlessly bent on adopting.
There are alternative strategies.
Some countries, like Germany, have room for fiscal maneuver. Using it for investment would enhance long-term growth, with positive spillovers to the rest of Europe.
A long-recognized principle is that balanced expansion of taxes and spending stimulates the economy; if the program is well designed (taxes at the top, combined with spending on education), the increase in GDP and employment can be significant.
Europe as a whole is not in bad fiscal shape; its debt-to-GDP ratio compares favorably with that of the United States.
If each US state were totally responsible for its own budget, including paying all unemployment benefits, America, too, would be in fiscal crisis.
The lesson is obvious:  the whole is more than the sum of its parts.
If Europe – particularly the European Central Bank – were to borrow, and re-lend the proceeds, the costs of servicing Europe’s debt would fall, creating room for the kinds of expenditure that would promote growth and employment.
There are already institutions within Europe, such as the European Investment Bank, that could help finance needed investments in the cash-starved economies.
The EIB should expand its lending.
There need to be increased funds available to support small and medium-size enterprises – the main source of job creation in all economies – which is especially important, given that credit contraction by banks hits these enterprises especially hard.
Europe’s single-minded focus on austerity is a result of a misdiagnosis of its problems.
Greece overspent, but Spain and Ireland had fiscal surpluses and low debt-to-GDP ratios before the crisis.
Giving lectures about fiscal prudence is beside the point.
Taking the lectures seriously –  even adopting tight budget frameworks – can be counterproductive.
Regardless of whether Europe’s problems are temporary or fundamental – the eurozone, for example, is far from an “optimal” currency area, and tax competition in a free-trade and free-migration area can erode a viable state – austerity will make matters worse.
The consequences of Europe’s rush to austerity will be long-lasting and possibly severe.
If the euro survives, it will come at the price of high unemployment and enormous suffering, especially in the crisis countries.
And the crisis itself almost surely will spread.
Firewalls won’t work, if kerosene is simultaneously thrown on the fire, as Europe seems committed to doing: there is no example of a large economy – and Europe is the world’s largest – recovering as a result of austerity.
As a result, society’s most valuable asset, its human capital, is being wasted and even destroyed.
Young people who are long deprived of a decent job – and youth unemployment in some countries is approaching or exceeding 50%, and has been unacceptably high since 2008 – become alienated.
When they eventually find work, it will be at a much lower wage.
Normally, youth is a time when skills get built up; now, it is a time when they atrophy.
So many economies are vulnerable to natural disasters – earthquakes, floods, typhoons, hurricanes, tsunamis – that adding a man-made disaster is all the more tragic.
But that is what Europe is doing.
Indeed, its leaders’ willful ignorance of the lessons of the past is criminal.
The pain that Europe, especially its poor and young, is suffering is unnecessary.
Fortunately, there is an alternative.
But delay in grasping it will be very costly, and Europe is running out of time.
Immunization Independence
WASHINGTON, DC – The first years of this century have been heady ones for global health.
International donors – whether national governments, such as the United States, through its PEPFAR program, or new international funding initiatives, such as the Global Fund to Fight AIDS, Tuberculosis, and Malaria and Gavi, the Vaccine Alliance – have invested billions of dollars in national disease-control programs and health systems, saving millions of lives.
But now some of the countries that have benefited from these programs face a new challenge: sustaining the gains they have made once external support is withdrawn.
Ultimately, it is on the basis of this transition that donors’ initiatives – and the health aid enterprise as a whole – will be judged.
Consider Gavi, the Vaccine Alliance.
Founded in 2000 by a partnership of major donors, international agencies, and vaccine industry leaders, Gavi’s goal is to help the world’s poorest countries introduce new lifesaving vaccines and strengthen their immunization programs.
When a country’s annual per capita income rises above a certain threshold – currently $1,580 – it becomes ineligible for Gavi support.
Of course, Gavi doesn’t just cut off funding all at once.
Support is phased out over a period of several years.
During this transition period, countries rapidly increase their financial contribution to their immunization programs and prepare to assume full responsibility.
This approach, which enables Gavi to concentrate its resources on countries with the greatest need, has been in place since 2010.
But it is now being put to a stern test: one-third of the 73 countries to which Gavi extends support are either in the midst of the transition process or have just completed it.
The group includes countries as different from one another as Armenia, Bhutan, Honduras, and Vietnam, as well as India and Nigeria, which have the largest birth cohorts.
The Gavi model is now under the microscope.
Will countries be able to continue purchasing and delivering the vaccines that were introduced with Gavi support?
Equally important, will that commitment hold up over time?
If government budgets are cut, will immunization be protected, along with other essential health services?
Will countries be able to introduce new lifesaving vaccines as they become available?
Will they sustain and strengthen disease surveillance, so that outbreaks are detected and addressed quickly?
Or will fiscal pressures lead, in some countries, to vaccine shortages, to declines in immunization coverage, or even, in the worst case, to vaccines being dropped altogether from national programs, reversing the hard-won gains of recent years?
The answers to these questions are important not only for the countries themselves, but also for their neighbors, which could be put at risk by backsliding on immunization.
After all, infectious diseases do not respect national boundaries.
The recent yellow fever epidemic in Angola, for example, spread to its much poorer neighbor, the Democratic Republic of Congo.
The experiences of countries that have “graduated” from Gavi assistance will also hold important lessons for other international health programs and their beneficiaries.
With so much at stake, international agencies must do whatever they can to prepare countries for “life after Gavi.”
For some of these countries, especially those that have adopted many new vaccines, obtaining adequate and sustainable financing is one of the most daunting challenges posed by the transition.
Although immunization programs require only a relatively small share of health budgets and yield exceptionally high economic returns, securing the needed financing requires careful planning.
A new resource can help countries as they wrestle with this challenge.
Immunization Financing: A Resource Guide for Advocates, Policymakers, and Program Managers provides information on estimating immunization costs, assessing the pros and cons of various sources of financing, shaping purchasing strategies, and navigating policy processes.
It does not prescribe one way forward, but rather provides relevant information and expert analysis.
Countries can then evaluate options in light of their own circumstances, and advocates can ask the right questions.
With Gavi support, close to 580 million children have been immunized since 2000, and more than eight million future deaths have been averted.
These are impressive gains that are worth celebrating.
But only if countries successfully negotiate the transition from Gavi support can they be confident that future generations will enjoy the same health protections.
After Kyoto
The Kyoto Protocol treaty has now entered into force for the 126 nations who have joined it so far.
Now is the time to start thinking about how to engage all nations, including large emitters, in conversations about what to do after the treaty’s expiration in 2012.
This is exactly what the European Commission did recently by providing its first strategy for a post-Kyoto era, which will be discussed by the European Council next March.
While the Kyoto Protocol represents only a modest reduction of carbon emissions in industrialized countries – 5.2% between 2008-2012 relative to 1990 levels, with varying targets for individual countries – real progress can be made in sustaining development efforts and preserving our planet.
But first, all countries must integrate climate concerns into policy planning, and improve their governance in key sectors such as energy, infrastructure, and transport.
In other words, we must act in accordance with the recognition that climate change and its effects on people in both rich and poor countries remains a threat to global security.
At the end of the day, the long-term approach is likely to include a rules-based system, an incentives system, and investments in technology change.
Increasingly, adaptation at the national level will be recognized as a major issue that will require appropriate funding.
Dealing with the impacts of climate change and with emission reductions should not be mutually exclusive, but complementary.
Looking ahead to the post-Kyoto world offers us the chance to start a new dialogue and to look at new options on climate change.
Nations could set the more ambitious goal of limiting the long-term change in the earth’s temperature, and then assign emissions rights among countries in such a way that will eventually limit temperature increases to an acceptable level.
This would require increasing investments in energy research and development for new and improved technologies – a process that needs to be supported by stronger public-private partnerships.
Up to now, with only 15% of the world’s population, rich countries have been responsible for more than 75% of global carbon dioxide (CO2) emissions, and thus most of the environmental damage.
However, it is the developing countries – and thus the world’s poor – who are most vulnerable.
It is unrealistic to ask poor countries, where more than 1.6 billion people do not have access to clean energy and technologies, to bear the costs associated with the much needed technological change.
Working with partners, the World Bank is supporting financial strategies to assist developing countries in meeting the costs caused by climate change.
To date, over $1 billion dollars in Global Environment Facility (GEF) grants, together with about $8 billion in co-financing, have been committed to programs related to climate change.
While the regulatory mechanisms of both Kyoto and the European Trading Scheme have contributed to the establishment of an emerging market for carbon trading, interested parties are now concerned about the immediate future.
Without a regulatory framework beyond 2012, the window of opportunity for initiating project-based transactions will close by 2006/2007.
Given the long lead time between project preparation and the first benefits of emissions reductions, project developers have only a few years to act before carbon payments cease to make a meaningful contribution to project finance in the current context.
Developing infrastructure projects is a long process that requires 3-7 years from identification, through licensing, financing, and construction, and finally to the first certification of carbon emission reductions.
Therefore, projects need to be operational at the latest by 2007.
The World Bank has been instrumental in advancing carbon finance as a viable development tool, and in facilitating private-sector participation in the market.
The Bank is focused on representing the interests of its borrowing countries, helping them to develop assets for carbon trading according to their own priorities.
But, without a commitment by governments to limit greenhouse gas emissions beyond 2012, the carbon market will remain uncertain, and the private sector – vital to the market’s success – is unlikely to expand its participation in a meaningful and sustained way.
According to a recent World Bank-supported survey of companies interested in carbon finance, only one in five respondents declared that they were interested in buying post-2012 emissions reductions.
Now is the chance to look forward and enlist the global community – with no exclusions, although with differentiated responsibilities – in the pursuit of a more secure world, one that avoids the dire risks of environmental degradation and social conflict implied by inaction.
After Paris
NEW YORK – The attacks in Paris by individuals associated with the Islamic State, coming on the heels of bombings in Beirut and the downing of a Russian airliner over the Sinai Peninsula, reinforce the reality that the terrorist threat has entered a new and even more dangerous phase.
Just why the Islamic State decided to stage its attacks now is a matter for conjecture; it may well be that it is going global to compensate for its recent loss of territory in Iraq.
But whatever the rationale, what is certain is that a clear response is warranted.
Actually, the challenge posed by the Islamic State calls for several responses, as there is no single policy that promises to be sufficient.
Multiple efforts are needed in multiple domains.
One is military.
More intense attacks from the air against Islamic State military assets, oil and gas facilities, and leaders are critical.
But no amount of air power on its own will ever get the job done.
A substantial ground component is needed if territory is to be taken and held.
Unfortunately, there is no time to build a partner force on the ground from scratch.
This has been tried and failed, and Arab states are unable or unwilling to constitute one.
The Iraqi army has also come up short.
Iran-backed militias only make matters worse.
The best option is to work more closely with Kurdish troops and select Sunni tribes in both Iraq and Syria.
This means providing intelligence, arms, and being willing to send more soldiers – more than the 3,500 Americans already there, and possibly on the order of 10,000 – to train, advise, and help direct a military response.
Such an effort must be collective.
It can be informal – a “coalition of the willing” that would include the United States, France, the United Kingdom, Arab states, and even Russia under the right circumstances – or carried out under NATO or United Nations auspices.
The packaging matters less than the results.
Symbolic declarations of war, though, ought to be considered with caution, lest the Islamic State appear to be winning every day it does not lose.
A diplomatic component is no less essential to any response.
Syrian President Bashar al-Assad is a recruiting tool for the Islamic State and must go.
But any successor government must be able to maintain order and not permit the Islamic State to exploit a power vacuum, as it has done in Libya.
Moreover, orderly political change can be brought about only with Russian and Iranian support.
One near-term option worth exploring is a coalition government still headed by a representative of the Alawite minority, a concession that could well be the price of moving Assad out of power.
In principle, and over time, a more representative national government could come about, although talk of holding elections in 18 months is fanciful under any scenario.
But reaching a compromise along these lines could well be impossible.
This is why increased military effort is needed to bring about larger and more secure enclaves that could better protect civilians and take the fight to the Islamic State.
Syria is not a normal country in any sense, and it will not be for a long time, if ever.
A Syria of enclaves or cantons is a more realistic model for the foreseeable future.
Other indispensable elements of any effective strategy include expanded help for or pressure on Turkey to do much more to stem the flow of recruits to the Islamic State.
And Turkey, along with Jordan and Lebanon, need more financial assistance as they shoulder the bulk of the refugee burden.
Arab and Muslim leaders can do their part by speaking out to challenge the Islamic State’s vision and delegitimize its behavior.
There is also a domestic dimension to policy.
Homeland security and law enforcement – increasing protection both at borders and within them – will have to adjust to the increased threat.
Retail terrorists – individuals or small groups carrying out armed attacks against soft targets in open societies – are extremely difficult to deal with.
The threat and the reality of attacks will require greater social resilience and quite possibly a rebalancing of individual privacy and collective security.
What is also required is a dose of realism.
The struggle against the Islamic State is not a conventional war.
We cannot eradicate or destroy it any time soon, as it is as much a network and an idea as it is an organization and a de facto state that controls territory and resources.
Indeed, terrorism is and will continue to be one of the scourges of this era.
The good news, though, is that the threat posed by the Islamic State to the Middle East and the rest of the world can be dramatically reduced through sustained, concerted action.
The main lesson of the attack on Paris is that we must be prepared to act over time and place alike.
After Pax Americana?
NEW YORK – It has become popular to suggest that when the dust settles from the global financial crisis, it may become clear that the United States-led post-war world has come to an end.
If so, the global system that has secured peace, security, openness, and economic growth over the past six decades could be in grave danger.
Inspired by American leadership since World War II’s end, Europe, then Japan, then much of Asia and the world rose to new levels of prosperity; the world economy globalized upon the foundation of international institutions, norms, and standards; and foreign students educated in American universities returned home with new ideas about free markets, entrepreneurship, and democracy.
The US military’s protective umbrella gave large swaths of the world a vacation from war, making it easier for them to focus on economic growth and regional integration.
America not only took the lead role in building the institutions of a globalizing world – the United Nations, World Bank, IMF, NATO– it also became the model that many other countries looked to for inspiration.
After eight years of compromised American leadership, a botched war of choice in Iraq, failure to take the lead in global efforts to address climate change, Abu Ghraib, Guantánamo Bay, running up a $10 trillion debt, and igniting a global financial crisis – America’s once-glittering model has lost a good deal of its luster and America’s leadership has been questioned by many.
The point was driven home at the 7th Asia-Europe Meeting (ASEM) in Beijing this autumn, where European and Asian leaders began exploring ideas for a new global financial structure.
For much of the past 60 years, it would have been impossible to hold such a fundamental dialogue without US participation. Today, it is almost becoming a new global norm that neither the international committee nor the US is prepared for.
Despite talk about American decline, the world is not prepared for a post-American era.
As irksome as some of America’s actions have been, particularly over the past eight years, America remains the world’s most critical champion of the progressive values that have lifted hundreds of millions of people out of abject poverty and political repression.
If the US were to play a relatively smaller role in world affairs, and no other system was created to pick up the slack, these values could be at risk.
Although many states now hide behind an alleged universal principle of inviolable state sovereignty, for example, would the international community really want to go back to the old model where states did whatever they wanted to their citizens within the confines of their own borders?
Do countries around the world believe that they will be better off if the global trade system breaks down or international shipping lanes become less secure?
Are countries like China willing to step up and pay their fair share of dues to keep the UN running (China currently pays 2.1% of UN dues, compared to more than 25% for the US), or to capitalize revised international financial institutions or the Global Fund to Fight AIDS, Tuberculosis, and Malaria in a meaningful way?
Unless other countries become more willing to step forward for the common good, a post-American world could quickly become a far more frightening environment than what it would replace.
To make its case for a continued global leadership role, America must, however, step up to the plate.  While the go-it-alone impulse of the Bush administration has been discredited by its consequences, the inverse lessons regarding how important collaborative action is in today’s interconnected world are still being learned.
Even at the apex of American power, America’s greatness was always based on inspiring others, and the opportunities for building market share in that particular category remain unlimited.
It is impossible to overestimate how significant a step Barack Obama’s election is in this direction, but America’s actions over the coming years will be the ultimate determinant of whether the power of America’s model can be restored.
America can and should, for example, become the global leader combating climate change through major investments in alternative energy, conservation, and energy efficiency, and by taking strong actions at home to reduce America’s greenhouse gas emissions.  It should transform its immigration policy to recruit the best and brightest people from around the world to move to the US and become citizens, and remain the world’s leading champion of open markets, especially during the current financial crisis.
Closing the prison at Guantánamo and reaffirming America’s commitment to international law and human rights will also be an important step in this direction.
The world wants to believe in an America that lives up to its own best values.
The prospect of a truly global community of nations working together to achieve the greater good for all is indeed exciting.
But, although America has been far from perfect over the last six decades, the end of the pax Americana has the potential to create a dangerous void in international affairs.
If the world is going to shift in the direction of a new and more globally democratic system, other nations will need to meaningfully step forward to assume new responsibilities.
It is in America’s and the world’s interest that they do so.  The evidence of this will be seen not only in global institutions but also in places like Darfur, Zimbabwe, and Burma.
Until this happens, let us all hope that America can get back on track as the global champion of collaborative action to address the world’s greatest challenges and work with as many other countries  as possible to move collectively in the right direction.
After the Guns of August
The Middle East is a place where the dust hardly ever settles.
When it occasionally does, even for a short interval – as UN Resolution 1701 for cessation of hostilities in Lebanon seems to be holding – it is time to take stock of events in the hopes that a responsible debate may influence those in power.
Let’s start with the United States.
President George W. Bush has been short on neither initiatives nor catchy slogans and acronyms.
Recent years are littered with them: “Global War on Terror” (GWOT), “Road Map,” “Middle East Partnership Initiative “ (MEPI), “Broader Middle East and North Africa” (BMENA) – originally “Greater Middle East Initiative (GMEI) – Democracy Assisted Dialogue (DAD), and so on.
His latest reverie, envisioned in the thick of the recent fighting between Israel and Hezbollah, was the New Middle East (NME), with US clients Israel, Egypt, Jordan, and Saudi Arabia serving as the pillars of regional order.
But like all his previous initiatives since the terrorist attacks on New York and Washington almost five years ago now, the NME ran into trouble from the outset.
Secretary of State Condoleezza Rice announced its birth while rejecting an immediate ceasefire in Lebanon.
Her poor timing made the initiative appear heartless, as thousands of civilians were being uprooted, killed, or maimed by Israel’s efficient but ruthless artillery and air force.
This so embarrassed the three Arab NME partners that each raced to distance itself from the US-sponsored initiative.
Saudi Arabia, which had remained silent for nearly two weeks, did so with a $500 million contribution to rebuilding devastated areas of Lebanon and another billion to support Lebanon’s threatened currency.
Egypt’s heir apparent Gamal Mubarak followed suit in the fourth week of the fighting by heading a 70-member delegation on a solidarity visit to Beirut.
But, rather than earning him the respect of an outraged Egyptian public, revelations in the opposition press that his plane had to obtain a safe passage and authority to land from the Israelis garnered only howls of derision.
As for America, anything it touches in the Middle East has become radioactive, even for longstanding clients and friends.
In the course of maneuvering to delay the UN ceasefire, Bush and Rice continually reiterated the need for a Security Council resolution that deals forcefully with “the roots of the problem.”
Of course, for them and for Israel, this was Hezbollah and the need to eradicate or at a minimum disarm it and force its fighters to a safe distance from settlements and towns in northern Israel.
While this is a reasonable demand, the rest of the Middle East – and, indeed, much of the world, including Europe – regard the root cause of the conflict as Israeli intransigence and arrogance, together with America’s blind support for it.
Both America and Israel have cited foot-dragging in implementing UN Resolution 1559, which calls for disarming all non-state actors in Lebanon and the deployment of government forces all the way to the southern border.
But for years the US and Israel have not uttered a word about the dozens of UN resolutions, going back as far as Resolution 49 on partition in 1947, which called for the establishment of distinct Arab and Jewish states on roughly half of Mandated Palestine.
This and numerous other resolutions seeking redress for injustices toward Palestinians have been ignored by the US.
Thus, for 300 million Arabs and more than one billion Muslims the “root cause” of the Middle East conflict is not Hezbollah.
As its leader, Hassan Nasrallah aptly put it, “We are just a reaction to chronic injustice.”
It may well be that there is more than one root cause – every party to the conflict has a favorite one.
There is no point in belaboring whose pain is greater or whose root cause is deeper.
In fact, arguing over grievances merely drives the sides further apart.
The long overdue UN Resolution 1701 may, with its adoption, indicate that all parties are fatigued, or could no longer withstand international pressure.
This is good news for all concerned and provides an opportunity to tackle each party’s “root cause.”
Seizing the opportunity requires that humility rather than moral supremacy prevails.
Empathy, not ethnocentrism, should be the order of the day now that the guns are falling silent and we have rediscovered the limits of military force.
But if we have learned anything at all from the tragic assassinations of the region’s greatest peacemakers, Anwar Sadat and Yitzhak Rabin, it is that the guns do not remain silent for long.
During any lull, a fanatic from either side could jump to center stage and, through an act of utter madness, kick up the settling dust and dash the hopes of the many on both sides who still long for a lasting peace.
After the Millennium Development Goals
CAMBRIDGE – In 2000, 189 countries collectively adopted the United Nations Millennium Declaration, which evolved into a set of concrete targets called the Millennium Development Goals (MDGs).
These ambitious targets – ranging from halving extreme poverty and reducing maternal mortality by three-quarters to achieving universal primary schooling and halting (and beginning to reverse) the spread of HIV/AIDS – are supposed to be met by the end of 2015.
As the deadline approaches, development experts are debating a new question: What comes next?
It is virtually certain that many of the MDGs will not have been met by the end of 2015, but there have been striking successes in some areas.
For example, the goal of halving extreme poverty (measured by the number of people living on less than $1.25 a day) will likely be achieved ahead of time, largely thanks to China’s phenomenal growth.
At the same time, there is little evidence to suggest that those successes were the result of the MDGs themselves.
China implemented the policies that engineered history’s greatest poverty eradication program prior to, and independently from, the Millennium Declaration and the MDGs.
Clearly, however, the MDGs were a public-relations triumph, which is not to belittle their contribution.
Like all worthwhile PR efforts, the MDGs served to raise awareness, galvanize attention, and mobilize action – all for a good cause.
They amplified the global conversation about development and defined its terms.
And there is evidence that they got advanced countries to pay more attention to poor nations.
Indeed, the MDGs possibly had their clearest impact on aid flows from rich to poor countries.
A study by Charles Kenny and Andy Sumner for the Center for Global Development in Washington, DC, suggests that the MDGs not only boosted aid flows, but also redirected them toward smaller, poorer countries, and toward targeted areas like education and public health.
However, aid was not directly linked to performance and results, and it is much more difficult to know whether it had the desired impact overall.
The MDGs encompass eight goals, 21 targets, and 60 indicators.
Much criticism has focused on the use of these numerical targets and indicators, which, skeptics argue, are misspecified, mismeasured, and divert attention from equally important areas.
But these complaints miss the point.
Any effort that is concrete and implementable needs to monitor the results, and setting clear numerical targets is the best way to do so.
Still, a central paradox plagues the MDGs.
The Millennium Declaration was meant to be a compact between the world’s rich and poor countries.
Poor countries promised to refocus their development efforts while rich countries pledged to support them with finance, technology, and access to their markets.
But, oddly, of the eight goals, only the last one deals with “global partnership,” or what rich countries can and should do.
Even here, the MDGs contain no numerical target for financial aid or any other aspect of rich countries’ assistance, in contrast to the highly specific poverty-related targets set for developing countries.
It is perhaps telling that the “progress charts” prepared by the United Nations Development Program, the agency charged with reporting on progress toward achieving the MDGs, track only Internet usage under that goal.
Why we need a global effort to convince developing countries to do what is good for them is not clear.
Poverty reduction and human development should be the first order of business for governments in these countries, with or without the MDGs.
It is true, of course, that these governments often pursue different goals, for political, military, and other reasons.
But it is wishful thinking to believe that they can be persuaded to act otherwise by international declarations that lack enforcement mechanisms.
If we have learned one thing in the development business, it is that real reform cannot be bought with donors’ money, let alone with vague promises of money.
Equally problematic, the MDGs implicitly assume that we know how to achieve development targets, and that only resources and political will are missing.
But it is doubtful that even well-intentioned policymakers have a good handle on, say, how to raise secondary-school completion rates sustainably or reduce maternal mortality.
Many development economists would argue that significant improvements in governance and political institutions are required before such goals can be achieved.
The most that rich countries can do is to provide an enabling environment for the benefit of developing countries that are willing and able to take advantage of it.
These considerations suggest an obvious direction for the next iteration of the MDGs.
First, a new global compact should focus more directly on rich countries’ responsibilities.
Second, it should emphasize policies beyond aid and trade that have an equal, if not greater, impact on poor countries’ development prospects.
A short list of such policies would include: carbon taxes and other measures to ameliorate climate change; more work visas to allow larger temporary migration flows from poor countries; strict controls on arms sales to developing nations; reduced support for repressive regimes; and improved sharing of financial information to reduce money laundering and tax avoidance.
Notice that most of these measures are actually aimed at reducing damage – for example, climate change, military conflict, and financial crime – that otherwise results from rich countries’ conduct.
“Do no harm” is as good a principle here as it is in medicine.
This kind of reorientation will not be easy.
Advanced countries are certain to resist any new commitments.
But most of these measures do not cost money, and, as the MDGs have shown, setting targets can be used to mobilize action from rich-country governments.
If the international community is going to invest in a bold new public-relations initiative, it might as well focus on areas where the potential payoffs are the greatest.
After the Promised Land
LONDON – At the height of the Arab uprisings last spring, many Europeans were gripped by nightmare visions of a tsunami of migrants crashing against the continent’s shores.
The wave never hit, but its specter fed a tenacious anti-immigrant populism that has concealed an important new trend: migration to Europe – and to the United States – has largely stalled.
In many countries, more immigrants are leaving than are arriving, owing mainly to the economic crisis that has drained jobs in the West.
That reversal is one of the great under-reported stories of 2011 (and of the preceding two years), and the numbers are startling.
Consider Spain, which is on track to lose more than a half-million residents by 2020.
By contrast, between 2002 and 2008, Spain’s population grew by 700,000 a year, driven largely by immigration.
The trends are similar elsewhere in Europe.
While this fact alone will not quiet opponents of immigration, it does give countries more breathing room to repair and strengthen badly broken systems for receiving and integrating newcomers.
Although rapidly aging Western countries are unable to attract the immigrants they need, they allow millions who are already there to suffer discrimination and abuse.
Detentions and deportations take place under sometimes terrible conditions.
Meanwhile, the international community collectively fails to protect vast populations of vulnerable migrants, such as the millions stranded by the recent conflicts in North Africa.
Undoubtedly, rising anti-immigrant populism must be confronted.
While polling suggests that attitudes are influenced more by ethnicity than religion, both help to define identities and mindsets.
Political parties in France, Switzerland, and the Netherlands (to name a few) have run successful campaigns that scapegoat immigrants.
Moreover, governments from Alabama to Hungary are passing laws that undermine what should be migrants’ rights.
Italy recently adopted harsh “emergency” decrees that target migrants by making undocumented entry and residence a criminal offense.
Anti-immigrant rhetoric from the political extremes has fed into mainstream political discourse.
European leaders trip over themselves to declare, one more forcefully than the next, that multiculturalism is dead.
Dutch politician Geert Wilders, whose Freedom Party is informally part of the governing coalition, did them one better by being charged with incitement to anti-Muslim hatred.
In the US, alligator-filled moats and electrified border fences have featured in the current presidential campaign.
Such attacks on immigration might offer some instant political gratification, but their net result is to cleave societies whose cohesion is already seriously challenged by the economic crisis.
Growing discrimination in employment, housing, and education affects not just immigrants and their children; it harms our societies as a whole.
With the lull in net immigration, we now have a window of opportunity to address these shortcomings.
Debunking the myths about migration – that most immigrants enter unlawfully, for example, or that immigration displaces existing workers – would be a good place to start.
It would also be useful to explain that immigration is necessary for prosperity and growth in almost all OECD countries.
If aging societies in the West and elsewhere (like Japan) fail to get immigration right, they will be woefully unprepared when they confront the real tidal wave: the retirement of baby boomers in the coming two decades.
The gaps in these countries’ labor markets – from software specialists to physicians to home health aides – will be immense.
The European Union’s labor force will decline by almost 70 million workers in the next 40 years; in the absence of significant net immigration (combined with a much higher retirement age), European economies and social safety nets will shrivel.
The priorities are clear.
We need to understand better how our economies will evolve in the coming decades, and to redesign our educational systems to produce workers with usable skills.
And, where it is clear that immigrants will be needed, we must be able to identify, welcome, integrate, and protect them.
Meanwhile, our most fundamental institutions – schools, police, and the courts – must be re-engineered to reflect and respond to the diversity of our communities, which is now a fact of life.
Countries must learn to work together to achieve these goals, few of which can be reached by going it alone.
If our toolbox were empty, our inaction might be understandable.
But examples of smart migration practices abound.
Canada and the Philippines, for instance, have a well-functioning accord that protects the rights of temporary workers.
Sweden has developed legislation that minimizes bureaucracy for companies that need foreign workers.
And important advances have been made in ensuring that immigrant children receive the education that they need to become full members of society.
Progress is being made on the global level as well, despite the economic crisis and populist headwinds.
In June, the International Labor Organization’s member states overwhelmingly approved the Domestic Workers Convention, which will significantly increase protections for a vulnerable group of workers – the majority of whom are migrants.
Meanwhile, the Global Forum on Migration and Development, established in 2007, has quickly become an important means of fostering knowledge and partnerships.
The reason for growing international cooperation is simple: countries everywhere are affected by migration, and, increasingly, they are experiencing immigration and emigration simultaneously.
Indeed, roughly one-third of migrants nowadays move between developed countries; one-third move between developing countries; and only one-third move from the developing to the developed world.
Highly skilled workers, such as bankers and engineers, are flocking to China.
Mexico, known primarily as a country of emigration, is home to millions of migrants from Central America.
Millions of people in Southeast Asia venture to the Middle East to work, but millions more cross borders within the region.
The list goes on.
When it comes to migration, we are all in the same boat – and that boat is leaking.
Starting in 2012, countries should redouble their efforts to fix it.
A Future without Precedent
JERUSALEM – In my nearly nine decades of life, I cannot recall a time in which the past was so irrelevant to policymaking.
All of today’s significant developments went unpredicted by anyone.
Experts studied the past, but, constrained by old paradigms, they could not discern the future.
Today’s dynamic complexity, in which a science-based, fast-changing global economy makes so many more phenomena interdependent, prevents us from foreseeing the future through linear extrapolations of the past.
The only certainty is that the future will be defined by scientific progress and innovation, which cannot be known ahead of time.
As a result, the traditional power of states and leaders is declining; in today’s global economy, innovators, not politicians, wield the most influence.
The globalized economy affects every state, yet no single state can determine the outcomes, because science and technology are borderless.
Global companies wish to do business worldwide, eroding not just sovereignty, but also racism and prejudice, as well as significantly weakening nationalism.
This transformation has placed the world in the hands of a younger generation, more technologically savvy than their parents and connected to one another through social networks that are not confined by territory, language, or government.
The young leaders who created Facebook and Google have had a greater global impact than many statesmen and generals.
These young people are also the leaders of erupting political protest movements.
The “Arab Spring,” the tent demonstrations in Israel, Occupy Wall Street, and the protests in Russia reveal not a clash of civilizations, but a battle of generations.
The young generation understands that the way states and economies are currently run is unfit for the new era.
Yet there are political “hitchhikers” who want to exploit the recent awakening, not by promoting an agenda of freedom, but by imposing a different type of coercion.
In the Arab world, it is mainly extreme Islamists who are hijacking the young generation’s wave, stealing their revolution.
Israel has reacted positively to the will of the young generation, but it cannot and should not intervene in events in the Arab world.
Our hearts are with the rebelling youngsters and their legitimate yearning for freedom and basic rights to express themselves, choose their leaders, and earn their own living.
Israelis wait for the day when our country will no longer be the region’s only democracy, because being an island of prosperity in a sea of poverty is unnatural.
Yet there is a real concern that the extremists, who are politically well organized, are seeking to gain control by the ballot over less-organized liberals, thus preventing peace and stability.
Fundamentalist radicals cannot provide real solutions to the region’s basic problems.
The social changes now underway threaten their way of life, which includes discrimination against women and a ban on modern education.
But only profound reforms of traditional authority can pave the way towards freedom and growth.
Israel can serve as an example to others striving to reach economic prosperity and social freedom, because its success is due to the fact that the country had absolutely nothing at the start.
We returned to our homeland, rich with history, but devoid of natural resources.
Israel was left with only one resource: its human capital.
So we invested in education and science, and today we have the world’s highest percentage of scientists and patents per capita.
Roughly 95% of our agriculture is hi-tech.
We use less water and yield more crops per acre than any other country in the world.
What Israel can do, others can do as well.
We will gladly offer a helping hand to whoever is willing to reach for it.
Together, in peace with our neighbors, we can create a region of hope, development, and success.
In particular, we must do everything in our power to end the conflict with the Palestinians.
Israel was not born, and it is not Israel’s destiny, to govern another people.
We are sincerely interested in the establishment of a Palestinian state living peacefully side-by-side with Israel, the democratic state of the Jewish people.
For us, peace is both a moral imperative and a national-security strategy, because resolving the conflict would help to stabilize the region by neutralizing the extremists who seek to manipulate today’s popular movements to advance their radical agenda.
The international community can support these efforts by providing incentives to countries that choose freedom and progress.
At the same time, determined and decisive policies must be taken against extremists.
In particular, Iran is a fount of moral corruption that spearheads extremism and halts reform, crushing the legitimate protest of its own citizens and acting against the brave Syrians now fighting for their freedom.
Iran also uses proxies to instigate terror against moderate forces in the Palestinian Authority, Lebanon, and Iraq.
If Iran is successful in its plan to acquire nuclear weapons, its leaders could shake the Middle East and encourage more extremism and violence.
Israel will defend itself if Iran continues to call for its destruction.
However, the threat is not to Israel alone; Iran is a danger to the peace and stability of the entire world.
The world’s democracies have declared that they will not allow Iran to possess nuclear arms; it is their duty to follow through on that commitment, before doing so becomes impossible.
Beyond the short-term challenges ahead, we all have a duty to profoundly change the way we prepare our children to cope with today’s new world.
In an era where yesterday has become almost irrelevant and we can hardly predict tomorrow, the role of education must allow all children to reach their highest potential.
Today’s educators should inspire our children towards creativity and innovation.
Self-expression is as important as free expression.
I write this in the 88th year of my life, but not because I have learned from experience.
On the contrary, experience is overrated, often constraining the courage needed to face tomorrow and build an unprecedented new world.
The future is already here; there is no point in looking back.
Against Simplification
NEW YORK – It is said that Americans have a genius for simplification.
Gradually, however, the quest for it has become a global trend, one that continues to conquer new territories, just as blue jeans once did.
The speed of our daily life is visibly increased – and not for the better – by this unstoppable evolution.
The tyranny of pragmatism seems to mark all of the complex dilemmas of our time.
Too many valid choices are ignored or skirted through the routine of short-cuts.
Nowhere is this trend more damaging than in today’s mercantile approach to art.
Even the much-praised notion of competition seems fake and cynically manipulated by the “corporate” mentality that now pervades the world of culture – by the financial pre-selection that determines what publishers, producers, and other impresarios will support.
Just imagine what might have happened with the works of, say, Proust, Kafka, Musil, Faulkner, or Borges had they been subjected to mass-market competition like shoes or cosmetics.
Culture is a necessary pause from the daily rat race, from our chaotic and often vulgar political surroundings, and it is a chance to recover our spiritual energy.
Great books, music, and paintings are not only an extraordinary school of beauty, truth, and good, but also a way of discovering our own beauty, truth, and good – the potential for change, of bettering ourselves and even some of our interlocutors.
If this respite and refuge is gradually narrowed and invaded by the same kind of “products” as those that dominate the mass market, we are condemned to be perpetual captives of the same stunted universe of “practicalities,” the ordinary agglomeration of clichés packaged in advertisements.
I was thinking again about these old and seemingly unsolvable questions during my re-reading of a quite challenging novel by a close friend and a great writer, not very present in the vivid landscape of American letters of today.
The theme, style, and echo of his work says a lot, I think, about our simplified world.
The novel is Blinding, by Claudio Magris.
Hailed in Europe as one of the great novels of the twentieth century, Blinding arrived in America only after a great delay, and never received the attention that it deserved.
Unfortunately, that is no surprise.
The number of literary translations done nowadays in the United States is, according to a United Nations report, equal to that of Greece, a country one-tenth the size.
Imported books are thought to be too “complicated,” which is another way of saying that literature should deal with simple issues in a simple way, obeying the rules of the mass market, with its tricks of packaging, accessibility, advertisement, and comfort.
At the core of Magris’ book is the destiny of a group of Italian communists who travel to Yugoslavia after the Second World War to contribute to the construction of a socialist society, only to be caught in the conflict between Stalin and Tito.
They are imprisoned for their Stalinist allegiance; when they are finally allowed to return to Italy, their old comrades refuse to accept them.
The book’s plot spans two centuries of revolution.
Then, suddenly,
“the party vanished, overnight, as if all of a sudden a giant sponge had drained the entire sea, Adriatic and Austral, leaving litter and clots of mud, and all the boats stranded.
How can you go home again if the sea has been sucked down a vast drain that opened up beneath it, emptying it who knows where, into a void?
The earth is arid and dead, but there won’t be another one, nor another heaven.”
The solitude of the individual facing his faith alone, without collective illusions, and forced to do something with himself in the arid, noisy world tells us something important about the exiled world of modernity and its complex and contradictory problems.
Magris’s novel is not only an important literary achievement; it also has a deep connection to the dangers that we face now, particularly the wave of fanaticism, from Mumbai to Oslo, in the name of a holy war against the “other.”
Are all the extremists searching for a new coherence, for a lost illusion of togetherness and a new hope of resurrection?
Can we ever forget September 11, 2001, the start of a bloody century in which the mystical force of hatred and destruction has recovered its strength?
Are Osama Bin Laden’s minions, the bloody Hamas-Hezbollah battalions, or troubled loners like Timothy McVeigh, Theodore Kaczynski, and now Norway’s Anders Behring Breivik, the “heroes” of our contemporary nightmare?
Is this the “rebel” response to an overly globalized, incoherent, and ultimately disturbing reality?
If so, their barbarism demands scrutiny – in relation to both historical precedent and to our modernity – rather than merely being labeled “monstrous” (though it certainly is that).
The new religious militants, fighting in the name of their particular and peculiar God, seem as fanaticized as the Fascists, Nazis, and Communists of earlier decades.
Magris’s main character is a rebel in more than one embodiment: as Salvatore Cipico, one of the inmates in the communist concentration camp in Yugoslavia; as Jurgen Jurgensen,  ephemeral king of Iceland and a convict forced to build his own jail; and as Jason, the mythic adventurer searching for the volatile truth.
A multilayered and complex chronicle of the devastating tragedies of the twentieth century, Blinding is an insistent, informed, and irreplaceable incursion into the moving landscape of the human soul, its wounds and voids, its vitality and versatility, its deep distortions and its unpredictable dynamics.
It is a fascinating story about the conflict between ideals and reality, or Utopia and humanness; about being faithful to a cause and betraying it; and about sacrifice and solidarity.
It is also a rich and original literary achievement that challenges today’s consumerist ethic.
By renouncing simplicity, it also repudiates today’s prevailing confusion of information with literature, of facts with creativity, and best-selling products with true works of art.
An Agenda for Resolving the US-China Conflict
NEW HAVEN – With charges flying back and forth between the United States and China ahead of the eagerly awaited December 1 meeting between President Donald Trump and President Xi Jinping at the upcoming G20 meeting in Buenos Aires, resolving the conflict has taken on great urgency.
The alternatives pose grave risks for both countries: an ever-escalating trade war, a cold war, or even a hot war.
These risks can be avoided, but only if both leaders are willing to engage in principled compromise.
There is no question that a serious conflict has been building for a long time.
Contrary to the US narrative, the problem is not the outsize bilateral trade deficit between the world’s two largest economies.
That is largely an outgrowth of macroeconomic imbalances that afflict both sides: China saves too much and the US saves too little.
These saving disparities give rise to multilateral trade imbalances that cannot be resolved by bilateral efforts.
The US had merchandise trade deficits with 102 countries in 2017, whereas China had trade surpluses with 169 countries in 2016.
Squeeze one part of the multilateral imbalance for a deficit country or a surplus saver, and it simply gets allocated to other trading partners.
For the US, this would lead to higher-cost imports – the functional equivalent of a tax hike on consumers.
For China, it would spell increased export penetration into other markets.
Fixation on the blame game of bilateral trade imbalances overlooks the possibility that this is a classic struggle of codependency.
Yes, China has long relied on the US as the major source of external demand for its export-led economy.
But the US needs low-cost imports from China to make ends meet for its income-constrained consumers; it also relies on China as the largest foreign buyer of US Treasuries to help fund chronic government budget deficits.
And, as America’s third largest and most rapidly growing export market, China has become an increasingly important source of demand for US firms.
The codependency framework is important because it underscores the need for joint resolution and compromise.
As in interpersonal relationships, economic codependency can be destabilizing and ultimately destructive.
When one partner changes course, the other, feeling scorned, lashes out in response.
China, in this case, is the change agent – shifting its growth model from manufacturing to services, from exports to internal consumption, and from imported technology to indigenous innovation.
At the same time, China is also moving from surplus saving to saving absorption, leaving it less to lend to its deficit partner, the US.
Uncomfortable in its own skin, the US feels threatened by a partner that is changing the rules of this relationship.
While Trump has acted on those threats far more aggressively than his predecessors, there can be no mistaking the bipartisan US sentiment now aligned against China.
According to a September 2018 Axios survey, fully 80% of Republicans – long the party most supportive of free trade – believed that increased tariffs would be good for the US.
Leading Republicans, such as Vice President Mike Pence and former Treasury Secretary Henry Paulson, have warned of a new cold war with China, while leading Democrats have come to the view that China has abrogated its role as a responsible global stakeholder.
At a time of ever-escalating threats and counter-threats, the imperative of compromise cannot be understated.
The upcoming meeting between Trump and Xi provides an opportunity to reframe the conflict as a strategic challenge for the world’s two leading economies.
Four possible avenues to consider:
Market access: After ten years of tortuous negotiations, the time for a breakthrough on a US-China bilateral investment treaty (BIT) is at hand.
Both sides would need to offer concessions.
A BIT would lift ownership caps on foreign direct investment by multinational corporations in both countries, eliminating the contentious joint-venture structure in China that the US continues to insist – incorrectly, in my view – has become a mechanism for forced technology transfer.
A BIT would also enable an expansion of Chinese ownership of US-domiciled assets – posing a challenge to the anti-China thrust of recent legislation that broadens the oversight powers of the Committee on Foreign Investment in the United States.
Saving: Both countries need to commit to responsible macroeconomic adjustments.
The US needs to save more, reversing the reckless budget-busting trajectory reinforced by last year’s ill-timed, outsize tax cuts.
Rebuilding saving, rather than tariffs, is the most effective strategy to reduce trade deficits with China or any other trading partner.
At the same time, China needs to save less, putting its vast pool of capital to work funding the country’s social safety net, which is essential for consumer-led economic rebalancing.
Cyber security: The digital realm is the battleground of the Information Age, and the September 2015 accord between President Barack Obama and Xi clearly did not go far enough in defusing persistent tensions over online espionage, hacking, and disruption.
The two countries should take the lead in forging a global cyber accord, complete with pooled metrics of cyber incursions, attack-reduction targets and a robust dispute-resolution mechanism.
Dialogue: It is terrific that the two presidents are meeting again after their earlier tête-à-têtes in Beijing and at Mar-a-Lago.
Those gatherings follow more formal engagements such as the Strategic and Economic Dialogue.
But all of these efforts have been episodic events that are long on glitz and short on substance.
A permanent secretariat that would engage in full-time collaborative efforts on key policy issues (including data sharing, joint research, and public-private consultation) would be far more productive.
In light of contentious recent developments between the US and China, it is hard to be optimistic that a meaningful breakthrough is at hand.
An agenda of substance should be used as a checklist against any accord that may be struck by Trump and Xi.
The world is watching.
The Age of Hyper-Uncertainty
BERLIN – The year 2017 will mark the 40th anniversary of the publication of John Kenneth Galbraith’s The Age of Uncertainty.
Forty years is a long time, but it is worth looking back and reminding ourselves of how much Galbraith and his readers had to be uncertain about.
In 1977, as Galbraith was writing, the world was still reeling from the effects of the first OPEC oil-price shock and wondering whether another one was in the pipeline (as it were).
The United States was confronting slowing growth and accelerating inflation, or stagflation, a novel problem that raised questions about policymakers’ competence and the adequacy of their economic models.
Meanwhile, efforts to rebuild the Bretton Woods international monetary system had collapsed, casting a shadow over prospects for international trade and global economic growth.
For all these reasons, the golden age of stability and predictability that was the third quarter of the twentieth century seemed to have abruptly drawn to a close, to be succeeded by a period of greatly heightened uncertainty.
That’s how things looked in 1977, anyway.
Viewed from the perspective of 2017, however, the uncertainty of 1977 seems almost enviable.
In 1977, there was no President Donald Trump.
Jimmy Carter may not go down in history as one of the best US presidents, but he did not threaten actions that placed the entire global system at risk.
He did not turn his back on America’s international commitments such as NATO and the World Trade Organization.
Nor did Carter go to war with the Federal Reserve or pack its board with sympathetic appointees willing to sacrifice sound money to his reelection prospects.
On the contrary, he appointed Paul Volcker, a towering pillar of monetary stability, as chairman of the Board of Governors.
And although Carter did not succeed in balancing the federal budget, he didn’t blow it up, either.
Whether Trump slaps a tariff on Chinese goods, repudiates the North American Free Trade Agreement, packs the Federal Reserve Board, or undermines fiscal sustainability remains to be seen.
Conceivable outcomes range from mildly reassuring to utterly catastrophic.
Who knows what will happen?
By today’s standards, Carter was the embodiment of predictability.
In 1977, moreover, the prospects for European integration were rosy.
Denmark, Ireland, and, most notably, the United Kingdom had recently joined a rapidly growing European Community.
The EC was attracting members, not losing them.
It was a club that countries sought to join precisely in order to achieve faster economic growth.
Moreover, to buttress its common market, the EC had just established a regional monetary system, the suggestively named “snake in the tunnel.”
While this was far from a perfect monetary system, it had one very positive attribute: countries could leave in hard economic times, and rejoin if and when the outlook brightened.
In 2017, in contrast, negotiations over Brexit will continue to cast a dark cloud of uncertainty over the European Union.
How those negotiations will proceed and how long they will take are anyone’s guess.
Moreover, the main questions raised by Britain’s decision to leave – whether other countries will follow and, indeed, whether the EU itself has a future – remain far from resolved.
Meanwhile Europe’s monetary house remains half built.
The eurozone is neither appealing enough to attract additional members nor flexible enough to grant troubled incumbents a temporary holiday, in the manner of the currency snake. The euro will likely survive the year, inertia being what it is.
In 1977, uncertainties emanating from emerging markets were not on commentators’ radar screens.
Developing countries in Latin America and East Asia were growing, although they depended increasingly on a drip feed of foreign loans from money-center banks.
China, still largely cut off from the world, did not figure in this discussion.
And even if something went wrong in the Third World, developing countries were simply too small to drag down the global economy.
The situation today couldn’t be more different.
What happens in China, Brazil, or Turkey doesn’t stay in China, Brazil, or Turkey.
On the contrary, developments in these countries have first-order implications for the world economy, given how emerging markets have accounted for the majority of global growth in recent years.
China has an unmanageable corporate-debt problem and a government whose commitment to restructuring the economy is uncertain.
Turkey has a massive current-account deficit, an erratic president, and an unstable geopolitical neighborhood.
And if political scandals were export goods, Brazil would have a clear comparative advantage.
Although The Age of Uncertainty was about much more than the year 1977, it captured the tenor of the times.
But if Galbraith were writing the same book in 2017, he probably would call the 1970s The Age of Assurance.
A German Europe?
LISBON/RIGA – Is the Europe that is emerging from the euro crisis a German one?
During the euro crisis, power in the European Union seems to have shifted towards national capitals in general, and towards one national capital in particular: Berlin.
But, with Germany introverted, France downgraded, and Britain semi-detached, the big story in European foreign policy is that the time has come for the little guy who thinks big.
In this Europe, the important moves are now sometimes made in Stockholm or Warsaw, not only in Berlin, Paris, or London.
And, with major foreign-policy issues on Europe’s doorstep – whether in Egypt, Belarus, or now Syria – useful European initiatives are to be welcomed, regardless of where they originate.
Germany, in foreign policy as well as in economics, can exert decisive leadership in the EU – when it wants to.
For example, together with Poland, it led the EU’s attempt to develop a coordinated approach to Russia, and it flexed its muscles on Serbia.
But, on other issues – for example, Libya – Germany did not so much lead as use its newfound room for maneuver to follow its own preferences in the face of other EU members.
So the answer today to Henry Kissinger’s famous question about whom he should call when he wants to speak to Europe, is not necessarily “the German chancellor.”
While Berlin is increasingly imposing its economic preferences on others in the eurozone, it is not prepared to use military force as a foreign-policy tool, as it demonstrated in the case of Libya.
Moreover, Germany, it seems, is becoming a “geo-economic power” driven by the needs of its export sector.
By using economic means to pursue its foreign-policy ends, Germany is gradually turning its back on its European partners.
Meanwhile, as France experiences a loss of power relative to Germany on economic issues, it continues to play a decisive role in foreign policy.
France led the Libya operation, and is doing much the same with attempts to impose stronger sanctions against Iran and provide support for the United Nations in Côte d’Ivoire.
But France’s unilateral approach often antagonizes its European partners.
For example, French President Nicolas Sarkozy preempted a common European position on the Palestinian statehood bid at the UN in September.
In other words, even when France leads, it does not always do so in a constructive way.
Apart from the decisive role that it played in Libya alongside France, Britain is becoming increasingly marginal in European foreign policymaking.
Even before it vetoed a plan by eurozone countries to create a “fiscal union” at the European summit in December 2011, it was playing less of a leadership role than it traditionally has on key European foreign-policy issues.
Britain has continued to support EU enlargement, closer links with Turkey, and development in Africa, but it has not launched any creative initiatives to bring other member states along or change the terms of the EU debate.
On other issues, such as engaging “strategic partners” – China and Russia in particular – the United Kingdom is often a follower as well.
As the “big three” increasingly pursue their own narrowly defined national interests, however, other EU member states are emerging as leaders in key foreign-policy fields.
For example, Sweden – the 14th largest member state in terms of population, and eighth in terms of GDP – under the leadership of Prime Minister Fredrik Reinfeldt and Foreign Minister Carl Bildt punches considerably above its weight.
Last year, it increased annual aid to North Africa by SEK100 million (€11.1 million), proposed an EU mission to Tunisia just a week after the revolution to support democratic aspirations there, and was an early and strong backer of UN resolutions in support of the uprising in Libya.
Poland, too, is emerging as a foreign-policy leader.
Prime Minister Donald Tusk and Foreign Minister Radek Sikorski have particularly taken the initiative on the EU’s strategy towards Russia, where Poland has largely overcome its differences with Germany and is now at the forefront of efforts to develop a genuinely comprehensive approach.
Poland has also led on European defense (though it declined to take part in the military intervention in Libya).
This reflects the strength of the Polish economy, which is expected to grow by more than 3% in 2012 – faster than almost anywhere else in the EU.
Germany might be getting all of the attention in this time of crisis, but the last year has been a reminder that Europe is most effective and influential when the small countries get involved and join forces with – and even lead – the big ones.
For example, on Iran (with exceptions like Greece), Europeans have united around a clear policy and collective positions, such as an oil embargo.
So, Poland and Sweden:  Europe needs your leadership.
But that might not be enough in an EU with more than 500 million citizens.
Other EU states need to follow their example in order to make European foreign policy truly effective and influential.
A German Glimmer in a Global Boom
In 2004, the world economy grew at a rate of 5.1%, the fastest pace in the last 28 years.
While Ifo`s World Economic Climate indicator, generated from quarterly surveys of 1,200 experts in 90 countries, worsened slightly during the first three quarters of 2005, it rose again in the last quarter, indicating a continuation of the boom.
In 2005, growth is estimated to have been about 4.3%, and a similar rate can be expected in 2006, marking a period of sustained rapid global growth unseen since the 1970’s.
But the boom is not uniform.
In the United States, the number of experts giving a favorable assessment of the current situation declined; indeed, a majority believes that the economic situation will worsen during the next six months.
However, in the Asian countries, including China, the optimism is unbroken.
The same is true for Eastern Europe, the ex-Soviet states, and Latin America.
The big surprise is Europe, which, unlike in 2004 and the first half of 2005, now seems to be catching up with the rest of the world.
Whereas growth was a miserable 1.5% in 2005 in the 15 “old” members of the European Union, Ifo expects EU-15 growth to accelerate to 2.1% in 2006.
To be sure, economic performance will vary widely among EU countries.
While Italy will be the laggard, with only 1.1% growth, the Irish rocket will not lose its force, pushing real GDP up by about 4.8%.
In general, the big EU countries are still performing badly, in contrast to the smaller members – hardly surprising, given that the EU is basically an institution to help the smaller countries overcome the drawback of their size by extending the agglomeration advantages that formerly were reserved to the bigger countries.
But even Germany, Europe’s biggest economy, is experiencing an upswing.
The Ifo climate indicator for Germany, based on monthly surveys of 7,000 firms, jumped upwards in the second half of 2005, reaching its highest value since the boom year 2000, with businesses’ assessment of the current situation and expectations improving.
After five years of stagnation, the economy is finally on the move.
The driving force is external demand, as Germany, the world’s second-largest exporter, profits from the global boom.
Exports increased by 6.2% in 2005 and are expected to increase by 7.4% in 2006.
However, as we saw in 2004 and 2005, exports are not enough to create substantial growth if domestic demand does not follow.
The good news for Germany is that investment demand is now growing, too.
While the second half of 2005 was already quite good, Ifo expects investment in equipment to grow by a healthy 6% in 2006.
After many years of contraction, investment in construction also will rise slightly.
Total investment growth is expected to reach 2.9% – weak by past standards, but nonetheless a promising salve for the wounded German mood.
Moreover, any investment growth is vital for Germany, which, according to the latest OECD statistics, currently suffers from the world’s lowest share of net investment in national income.
Even if Germany remains the world’s laggard, rising investment demand as such will contribute to GDP growth, which Ifo estimates at 1.7% in 2006.
That number looks small compared to most other countries.
In fact, all EU countries except Italy and the Netherlands will grow faster.
But everything is relative: Germany’s trend growth rate is just 1.1%, and the country has been the slowest growing EU country since 1995.
Measured against a disappointing past, even Germany is currently experiencing an economic boom.
Indeed, even German unemployment, which has been rising in cycles since 1970, will decline slightly in 2006, from 4.8 to 4.7 million.
The good economic data will reinforce initial favorable impressions of Angela Merkel’s new government, which got off to an excellent start at the EU Summit, where Merkel helped to broker a compromise between Britain and France on the Union’s 2007-2013 budget (by adding another €2 billion to Germany’s annual contribution).
In fact, the government may even have contributed a bit to the good economic data by announcing a serious effort to consolidate Germany’s own public finances – a prerequisite for investor confidence.
According to the government, substantial tax increases will bring the fiscal deficit below the 3%-of-GDP limit set by the Stability and Growth Pact – a target missed for five consecutive years – by 2007.
The real test for the German government is the labor market.
Most observers now agree that Germany needs something like the American earned-income tax credit.
In Germany, it’s called “activating social aid” or “combi wages,” but the principle is the same: the state should reduce the money it pays for doing nothing and pay more for participating in the work force.
That would widen the wage distribution, create jobs, and maintain the living standard of the poor.
Merkel announced in her inaugural speech in the Bundestag that her government will introduce such a system in 2006.
If this is more than lip service, and if she really carries out a serious reform of the German welfare state’s incentive structure, the result could be higher employment and structural economic growth.
In the long term, that would be more promising for the EU – and for the global economy – than the demand-driven performance that Germany is currently enjoying.
Is Pensioner Populism Here to Stay?
MILAN – The right-wing populism that has emerged in many Western democracies in recent years could turn out to be much more than a blip on the political landscape.
Beyond the Great Recession and the migration crisis, both of which created fertile ground for populist parties, the aging of the West’s population will continue to alter political power dynamics in populists’ favor.
It turns out that older voters are rather sympathetic to nationalist movements.
Older Britons voted disproportionately in favor of leaving the European Union, and older Americans delivered the US presidency to Donald Trump.
Neither the Law and Justice (PiS) party in Poland nor Fidesz in Hungary would be in power without the enthusiastic support of the elderly.
And in Italy, the League has succeeded in large part by exploiting the discontent of Northern Italy’s seniors.
Among today’s populists, only Marine Le Pen of France’s National Rally (formerly the National Front) – and possibly Jair Bolsonaro in Brazil – relies on younger voters.
Next spring, this age-driven voting pattern could drive the outcome of the European Parliament election.
According to recent studies, older Europeans – especially those with less education – are more suspicious of the European project and less trusting of the European Parliament than younger Europeans are.
This is surprising, given that memories of World War II and its legacy should be fresher for older generations.
Nevertheless, their skepticism toward democratic EU institutions may explain their receptiveness to authoritarian leaders.
Most likely, a growing sense of insecurity is pushing the elderly into the populists’ arms.
Leaving aside country-specific peculiarities, nationalist parties all promise to stem global forces that will affect older people disproportionately.
For example, immigration tends to instill more fear in older voters, because they are usually more attached to traditional values and self-contained communities.
Likewise, globalization and technological progress often disrupt traditional or legacy industries, where older workers are more likely to be employed.
The rise of the digital economy, dominated by people in their twenties and thirties, is also pushing older workers to the margins.
But, unlike in the past, crumbling pension systems can no longer absorb such labor-market shocks. The result is that older workers who lose their job are condemned to long-term unemployment.
Moreover, pensioners now have reason to worry about threats to their retirement benefits from their own children.
Young people, frustrated with socioeconomic systems that are clearly tilted in favor of retirees, are increasingly calling for fairer intergenerational redistribution of scarce resources.
For example, Italy’s Five Star Movement, which governs in a coalition with the League, recently called for a “citizen’s income” that would be available to all unemployed people regardless of age.
So, while right-wing populists have attracted older voters, left-wing populist have gained a following among younger generations.
By backing right-wing populists, older voters hope to return to a time when domestic affairs were insulated from global forces and national borders were less porous.
At the heart of today’s nationalist politics is a promise to preserve the status quo – or even to restore a mythical past.
Hence, nationalist politicians often resort to nostalgic rhetoric to mobilize their older supporters.
For his part, Trump has pledged to bring back jobs in the American Rust Belt, once the center of US manufacturing.
Likewise, there could be no clearer symbol of resistance to change than his proposed wall on the US-Mexico border.
And his crackdown on illegal immigration and ban on travelers from predominantly Muslim countries signals his commitment to a “pure” American nation.
Similarly, in continental Europe, right-wing populists want to return to a time before the adoption of the euro and the Schengen system of passport-free travel within most of the EU.
And they often appeal directly to older voters by promising to lower the retirement age and expand pension benefits (both are flagship policies of the League).
In the United Kingdom, the “Leave” campaign promised vindication for those who have been left behind in the age of globalization.
Never mind that it also touted the idea of a free and independent “Global Britain.”
The Brexiteers are not known for their consistency.
At any rate, to the extent that today’s populist wave is driven by demographics, it is not likely to crest anytime soon.
In graying societies, the political clout of the elderly will steadily grow; and in rapidly changing economies, their ability to adapt will decline.
As a result, older voters will demand more and more socioeconomic security, and irresponsible populists will be waiting in the wings to accommodate them.
Can anything be done?
To stem the nationalist tide, mainstream parties urgently need to devise a new social compact that addresses the mounting sense of insecurity among older voters.
They will need to strike a better balance between openness and protection, innovation and regulation; and they will need to do so without falling into a regressive populist trap.
The answer is not to suffocate global forces, but to render them more tolerable.
Citizens of all ages need to be equipped to face current and future disruptions.
In this sense, it is better to empower the elderly than simply to protect them. Most advanced economies simply cannot afford massive new benefits for an oversized interest group.
And besides, a policy that makes people reliant on some form of external support is morally questionable, at best.
Instead, governments should focus on upgrading older workers’ skills, creating more opportunities for older and younger generations to work together, and holding disruptors accountable for the socioeconomic consequences they generate.
Subsidies to the most vulnerable should remain a last resort.
In many ways, older voters’ infatuation with populists is a cry for help.
It is up to enlightened politicians to respond to it constructively.
A Global Agenda for Seven Billion
NEW YORK – Late next month, a child will be born – the 7th billion citizen of planet Earth. We will never know the circumstances into which he or she was born.
We do know that the baby will enter a world of vast and unpredictable change – environmental, economic, geopolitical, technological, and demographic.
The world’s population has tripled since the United Nations was created in 1945.
And our numbers keep growing, with corresponding pressures on land, energy, food, and water. The global economy is generating pressures as well: rising joblessness, widening social inequalities, and the emergence of new economic powers.
These trends link the fate and future of today’s seven billion people as never before. No nation alone can solve the great global challenges of the twenty-first century. International cooperation is a universal need.
The 66th session of the UN General Assembly is a renewed opportunity for the countries of the world to set aside narrow, short-term interests and commit to cooperative efforts to address humanity’s long-term imperatives.
At a time when all nations are experiencing individual challenges, we need to forge a worldwide common agenda that can help to ensure that the seven billionth baby and future generations grow up in a world characterized by sustainable peace, prosperity, freedom, and justice.
To help create this future, I am focusing my second term as Secretary-General on five global imperatives – five generational opportunities to shape the world of tomorrow by the decisions we make today.
The first and greatest of these imperatives is sustainable development. We all must understand that saving our planet, lifting people out of poverty, and advancing economic growth are one and the same fight. We must connect the dots between climate change, water scarcity, energy shortages, global health, food security, and women’s empowerment. Solutions to one problem must be solutions for all.
In the next five years, we need to create a new economic vision for sustainable development and forge global consensus on a binding climate change agreement.
Fostering economic growth, realizing the Millennium Development Goals, and combating climate change will all depend on creating a new energy system for the twenty-first century and extending it to every person on the planet.
Prevention as a framework for international cooperation is a second opportunity.
This year, the UN peacekeeping budget will total $8 billion. Think of what we could save by avoiding conflicts – by deploying political mediation missions, for example, rather than troops.
We know how to do this.
Our record proves it – in Guinea, Kenya, and Kyrgyzstan.
A third imperative is building a safer and more secure world. In this effort, we must be courageous in standing up for democracy, human rights, and peace.
This year was one of signature achievements in restoring and securing peace – in Côte d’Ivoire, Darfur, Egypt, and elsewhere. But hatred and bloodshed still stand in the way of our vision for peace.
In the Middle East, we must break the stalemate.
Palestinians deserve a state.
Israel needs security.
Both want peace. A negotiated settlement can produce these outcomes, and the UN is a platform for forging such a peace.
So, too, will we continue our efforts to foster democratic governance in Iraq, Afghanistan, the Democratic Republic of Congo, and Sierra Leone. And, in the name of all of humanity, we will continue to push forward on nuclear disarmament and non-proliferation, in service of realizing a world free of nuclear weapons.
The fourth big opportunity is supporting countries in transition.
This year’s dramatic events in North Africa and the Middle East inspired people around the globe.
Let us help make the Arab Spring a true season of hope for all.
In Libya, we are deploying a new UN support mission to assist the country’s transitional authorities in establishing a new government and legal order, consistent with the aspirations of the Libyan people.
Syria is a special concern.
For six months we have seen escalating violence and repression.
The government has repeatedly pledged to undertake reforms and listen to its people. It has not done so.
The moment to act is now.
The violence must stop.
Last but not least is the imperative of working with and for women and young people.
Women hold up more than half the sky and represent much of the world’s unrealized potential.
We need their full engagement – in government, business, and civil society.
The UN has placed a high priority on promoting women at all levels of the Organization and this year, for the first time, UN Women is operating to promote the interests and rights of women all over the world.
Seven billion people now look toward the United Nations for solutions to the world’s great global challenges.
They hold different religions and backgrounds but common dreams and aspirations.
Our global future depends on bringing these individual talents and universal rights together in common cause.
Let our common agenda begin.
A Global Consensus Against Terrorism
Mention the United Nations and the first reaction is likely to be the ongoing oil-for-food scandal and what it will mean for Secretary-General Kofi Annan’s ability to lead the organization for the remaining year and a half of his tenure.
But there is much more going on at the UN than investigations.
Reform is in the air – in part because of the scandal, but also because of the UN’s inability to deal effectively with challenges ranging from Rwanda and Kosovo to Iraq and, most recently, Sudan.
Even the UN’s most ardent supporters now recognize that change is called for if the organization is to make a significant contribution to international peace and security.
Some of the reform talk concerns the UN Security Council’s composition.
The Security Council represents what the World War II Allies believed the post-war world would look like and how it should be run.
This helps to explain why a much-weakened France was made a permanent member of the Council – and why Germany and Japan (and a not-yet independent India) were not.
Defending the Security Council’s current make-up is impossible; the need for change is beyond debate.
But coming up with an approach that gains broad international support will prove extremely difficult.
Great Britain and France will resist being replaced by a single EU seat, while making Germany a permanent member would only exacerbate the problem of Europe’s relative over-representation.
Pakistan would object to adding India to the Security Council; Argentina, Chile, and Mexico to adding Brazil; Nigeria to South Africa (and vice-versa); and several countries, including China, Indonesia, and South Korea, might resist creating a permanent seat for Japan.
Clearly, fixing the Security Council will require considerable time and political effort.
In the meantime, there is important work to be done. One productive avenue would be to follow up on one of the recommendations of the High Level Panel that was endorsed by Annan; namely, that all UN members go on record declaring that terrorism has no place in today’s world.
This will prove more difficult than it first sounds.
For too long, the international community has tolerated terrorism – the intentional killing of civilians and noncombatants by non-state actors for political purposes – on the grounds that, on occasion, “one man’s terrorist is another man’s freedom fighter.”
Historians have the luxury of debating whether terrorism may have been justified in certain situations in the past.
We do not.
Modern terrorism is too destructive to be tolerated, much less supported.
Weapons of mass destruction – nuclear, biological, and chemical weapons – are just that, and no cause can excuse their use.
Moreover, as the terrorist attacks on America of 2001 showed, weapons as basic as box-cutters can become weapons of mass destruction if they are used to exploit the vulnerabilities of modern, global life.
Terrorism is even less justified given that political avenues exist nowadays for pursuing political aims.
Palestinians can negotiate their future relationship with Israel and can count on American, Russian, European, and UN assistance.
Iraqis have elected their own representatives and are poised to write their constitution.
No one pursuing reasonable goals and who is prepared to compromise can argue that terrorism is his or his group’s only option.
The world has already taken some important steps against terrorism.
A dozen international conventions and numerous UN resolutions commit governments to oppose hostage taking, the hijacking of civilian aircraft, and terrorism more broadly.
Similarly, the mandate of the Financial Action Task Force, created in 1989 to curb money laundering, has grown and become focused mainly on curbing terrorist financing.
UN Security Council Resolution 1373, passed after the September 11 attacks, calls on states to deny safe haven to terrorists, bring to justice anyone associated with terrorism, suppress recruitment by terrorist groups, block terrorists’ efforts to acquire weapons, and cooperate with other governments and international organizations in tracking suspects and boosting security.
What is missing is a new, 13th convention that closes the loophole that seems to permit governments to decide what constitutes terrorism and what does not.
Broad agreement is needed that any intentional killing of civilians and noncombatants is unacceptable, and that its perpetrators and supporters must be punished.
Of course, such a convention will not prevent all future acts of terrorism.
But ideas matter.
Terrorism needs to be de-legitimized in the way that slavery has been.
Doing so will make governments and individuals think twice before becoming a party to terrorism; it should also make it less difficult to garner support for international action against those who nevertheless carry it out.
We are taught early on in our lives that the end cannot justify the means.
It is time to put this principle into effect before many more innocent lives are lost.
A Global Green New Deal
NAIROBI – With unemployment soaring, bankruptcies climbing, and stock markets in free-fall, it may at first glance seem sensible to ditch the fight against climate change and put environmental investments on hold.
But this would be a devastating mistake of immediate, as well as inter-generational, proportions.
Far from burdening an already over-stressed, over-stretched global economy, environmental investments are exactly what is needed to get people back to work, get order books flowing, and assist in powering economies back to health.
In the past, concern for the environment was viewed as a luxury; today, it is a necessity – a point grasped by some, but by no means all, economic architects yet.
A big slice of President Barack Obama’s $825 billion stimulus package for the United States includes a boost to renewable energy, “weatherizing” a million homes, and upgrading the country’s inefficient electricity grid.
Such investments could generate an estimated five million “green-collar” jobs, provide a shot in the arm for the construction and engineering industries, and get America back into the equally serious business of combating climate change and achieving energy security.
The Republic of Korea, which is losing jobs for the first time in more than five years, has also spotted the green lining to grim economic times.
President Lee Myung-Bak’s government plans to invest $38 billion employing people to clean up four major rivers and reduce disaster risks by building embankments and water-treatment facilities.
Other elements of Lee’s plan include construction of eco-friendly transportation networks, such as high-speed railways and hundreds of kilometers of bicycle tracks, and generating energy using waste methane from landfills.
The package also counts on investments in hybrid vehicle technologies.
Similar pro-employment “Green New Deal” packages have been lined up in China, Japan, and the United Kingdom.
They are equally relevant to developing economies in terms of jobs, fighting poverty, and creating new opportunities at a time of increasingly uncertain commodity prices and exports.
In South Africa, the government-backed Working for Water initiative – which employs more than 30,000 people, including women, youth, and the disabled – also sees opportunity in crisis.
The country spends roughly $60 million annually fighting invasive alien plants that threaten native wildlife, water supplies, important tourism destinations, and farmland.
This work is set to expand as more than 40 million tons of invasive alien plants are harvested for power-station fuel.
As a result, an estimated 500 megawatts of electricity, equal to 2% of the country’s electricity needs, will be generated, along with more than 5,000 jobs.
So it is clear that some countries now view environmental investments in infrastructure, energy systems, and ecosystems as among the best bets for recovery.
Others may be unsure about the potential returns from investing in ecosystem services such as forest carbon storage or in renewable energy for the 80% of Africans who have no access to electricity.
Still others may simply be unaware of how to precisely follow suit.
In early February, the United Nations Environment Program will convene some of the world’s leading economists at the UN’s headquarters in New York.
A strategy for a Global Green New Deal, tailored to different national challenges, will be fleshed out in order to assist world leaders and ministers craft stimulus packages that work on multiple fronts.
The Global Green New Deal, which UNEP launched as a concept in October 2008, responds to the current economic malaise.
Spent wisely, however, these stimulus packages could trigger far-reaching and transformational trends, setting the stage for a more sustainable, urgently needed Green Economy for the twenty-first century.
The trillions of dollars that have been mobilized to address current woes, together with the trillions of investors’ dollars waiting in the wings, represent an opportunity that was unthinkable only 12 months ago: the chance to steer a more resource-efficient and intelligent course that can address problems ranging from climate change and natural-resource scarcity to water shortages and biodiversity loss.
Blindly pumping the current bail-out billions into old industries and exhausted economic models will be throwing good money after bad while mortgaging our children’s future.
Instead, political leaders must use these windfalls to invest in innovation, promote sustainable businesses, and encourage new patterns of decent, long-lasting employment.
A Global Growth Bargain
LONDON – US President Barack Obama caught the imagination of the world when he talked recently of a new “Sputnik moment.”
He outlined a bold plan for improving education, infrastructure, and technology, and vividly compared the resolve required to put a man on the moon to the determination needed to restore growth to the US economy.
Obama is right to say that the West faces not only great challenges, but also great opportunities. In the last decade, the global economy was transformed by one billion Asian workers entering the ranks of industrial producers. In 2011, for the first time in two centuries, Europe and America face being out-produced, out-exported, and out-invested by China and the rest of the world.
Yet Asia’s growth also gives the West unprecedented economic hope.
In this decade, the world will be transformed yet again by the rise of the Asian consumer. By 2020, Asia’s domestic markets will be twice the size of America’s.
The world’s middle class will have swelled from one billion consumers to three billion.
The opportunities for growth in Europe and the US from this additional global demand are enormous.
The countries and companies that will flourish in Asia’s new markets will be those that can provide the technology-driven, custom-built, high value-added goods and services needed to serve Asia’s two billion consumers.
But neither Europe nor the US is in a strong enough position to take best advantage of these new markets.
The West must again begin to out-invent, out-innovate, and out-skill the rest of the world if it is to seize the opportunities that Asia presents. Indeed, unless the West significantly expands its capital investment in engineering, science, and new technologies, it will be marginalized by countries whose governments back their innovators with hard cash.
Obama’s investment plan could be the foundation stone for a formal global agreement that delivers higher levels of growth to all corners of the world and creates millions of new jobs.
Under such an agreement, Europe would join the US in raising levels of investment – complementing America’s “moonshot” initiative with a program of structural reform aimed at building a digital, green, energy-efficient, and competitive economy – while China would play its part by increasing its consumption.
I believe that such an agreement could boost the world economy by around 3% by 2014 – and lift 100 million people out of poverty.
I presented this plan when I chaired the G-20 in London in 2009.
I wanted East and West to commit to a formal strategy to deliver more enduring results than those promised by the rescue packages that we were putting together at the time.
Our attention was focused on preventing recession from turning into depression.
I argued that this was also the moment to pioneer a more lasting framework of growth.
In the end, no agreement was possible on a shared growth objective, and there has not yet been enough political will for the coordinated action to achieve it.
Since then, Europe and America have grown well below their capacity (despite huge unmet demand throughout the world) and unemployment has climbed to around 10% on both continents (with youth unemployment reaching an alarming 20%).
The global growth agreement that evaded us in 2009 remains the unfinished work of the G-20.
Front-loaded public investment could be funded through an enhanced European Investment Bank.
China has already laid the foundation for playing its part: its policy of xiaokang (reducing poverty and expanding the middle class) should create a market for billions of dollars of Western goods and services.
The West should propose that if China’s consumption increases by 2-4 percentage points of its GDP over the next three years (entirely possible as it improves its social safety net, cuts taxes, and puts homeownership within reach of ordinary citizens), America and Europe will expand their public investment by similar amounts.
If other Asian countries do likewise, and agree to create a level playing field for exporters, we could create around 50 million additional jobs.
Of course, in the West, an investment plan invites criticism from those who prefer that we do nothing but talk about growth strategies.
Indeed, critics argue that raising public investment conflicts with the drive to reduce deficits, and warn of higher interest rates on the back of further spending.
But critics are wrong about the impact on the deficit of focused investment.
A recent study by the International Monetary Fund produced unequivocal evidence that we can actually maintain deficit-reduction plans while benefiting from the additional capital investment that the US and European economies need.
My extrapolation of the IMF model shows that Western countries can boost their long-term GDP growth significantly by increasing their levels of capital investment over a three-year period.
An annual stimulus equivalent to just 0.3% of GDP yields a return in the US of 0.8% in economic growth at its peak in 2013, and 0.4% in Europe.
This approach, which secures growth and cuts unemployment without raising the deficit, is needed to energize the private sector and mobilize some of the capital that has accumulated on corporate balance sheets in recent years.
It also underscores the importance of the G-20 and the IMF in seeking global consensus now.
The West is well placed to play its part in global renewal.
Its extraordinary workforces produce world-class goods and services.
But the West’s workforce must not be condemned to policies that willfully produce a decade of slow growth and low employment.
That would be a human tragedy, not just an economic disaster.
A Global Perfect Storm
NEW YORK – Dark, lowering financial and economic clouds are, it seems, rolling in from every direction: the eurozone, the United States, China, and elsewhere.
Indeed, the global economy in 2013 could be a very difficult environment in which to find shelter.
For starters, the eurozone crisis is worsening, as the euro remains too strong, front-loaded fiscal austerity deepens recession in many member countries, and a credit crunch in the periphery and high oil prices undermine prospects of recovery.
The eurozone banking system is becoming balkanized, as cross-border and interbank credit lines are cut off, and capital flight could turn into a full run on periphery banks if, as is likely, Greece stages a disorderly euro exit in the next few months.
Moreover, fiscal and sovereign-debt strains are becoming worse as interest-rate spreads for Spain and Italy have returned to their unsustainable peak levels.
Indeed, the eurozone may require not just an international bailout of banks (as recently in Spain), but also a full sovereign bailout at a time when eurozone and international firewalls are insufficient to the task of backstopping both Spain and Italy. As a result, disorderly breakup of the eurozone remains possible.
Farther to the west, US economic performance is weakening, with first-quarter growth a miserly 1.9% – well below potential.
And job creation faltered in April and May, so the US may reach stall speed by year end.
Worse, the risk of a double-dip recession next year is rising: even if what looks like a looming US fiscal cliff turns out to be only a smaller source of drag, the likely increase in some taxes and reduction of some transfer payments will reduce growth in disposable income and consumption.
Moreover, political gridlock over fiscal adjustment is likely to persist, regardless of whether Barack Obama or Mitt Romney wins November’s presidential election.
Thus, new fights on the debt ceiling, risks of a government shutdown, and rating downgrades could further depress consumer and business confidence, reducing spending and accelerating a flight to safety that would exacerbate the fall in stock markets.
In the east, China, its growth model unsustainable, could be underwater by 2013, as its investment bust continues and reforms intended to boost consumption are too little too late.
A new Chinese leadership must accelerate structural reforms to reduce national savings and increase consumption’s share of GDP; but divisions within the leadership about the pace of reform, together with the likelihood of a bumpy political transition, suggest that reform will occur at a pace that simply is not fast enough.
The economic slowdown in the US, the eurozone, and China already implies a massive drag on growth in other emerging markets, owing to their trade and financial links with the US and the European Union (that is, no “decoupling” has occurred).
At the same time, the lack of structural reforms in emerging markets, together with their move towards greater state capitalism, is hampering growth and will reduce their resiliency.
Finally, long-simmering tensions in the Middle East between Israel and the US on one side and Iran on the other on the issue of nuclear proliferation could reach a boil by 2013.
The current negotiations are likely to fail, and even tightened sanctions may not stop Iran from trying to build nuclear weapons.
With the US and Israel unwilling to accept containment of a nuclear Iran by deterrence, a military confrontation in 2013 would lead to a massive oil price spike and global recession.
These risks are already exacerbating the economic slowdown: equity markets are falling everywhere, leading to negative wealth effects on consumption and capital spending.
Borrowing costs are rising for highly indebted sovereigns, credit rationing is undermining small and medium-size companies, and falling commodity prices are reducing exporting countries’ income.
Increasing risk aversion is leading economic agents to adopt a wait-and-see stance that makes the slowdown partly self-fulfilling.
Compared to 2008-2009, when policymakers had ample space to act, monetary and fiscal authorities are running out of policy bullets (or, more cynically, policy rabbits to pull out of their hats).
Monetary policy is constrained by the proximity to zero interest rates and repeated rounds of quantitative easing.
Indeed, economies and markets no longer face liquidity problems, but rather credit and insolvency crises.
Meanwhile, unsustainable budget deficits and public debt in most advanced economies have severely limited the scope for further fiscal stimulus.
Using exchange rates to boost net exports is a zero-sum game at a time when private and public deleveraging is suppressing domestic demand in countries that are running current-account deficits and structural issues are having the same effect in surplus countries.
After all, a weaker currency and better trade balance in some countries necessarily implies a stronger currency and a weaker trade balance in others.
Meanwhile, the ability to backstop, ring-fence, and bail out banks and other financial institutions is constrained by politics and near-insolvent sovereigns’ inability to absorb additional losses from their banking systems.
As a result, sovereign risk is now becoming banking risk.
Indeed, sovereigns are dumping a larger fraction of their public debt onto banks’ balance sheet, especially in the eurozone.
To prevent a disorderly outcome in the eurozone, today’s fiscal austerity should be much more gradual, a growth compact should complement the EU’s new fiscal compact, and a fiscal union with debt mutualization (Eurobonds) should be implemented.  In addition, a full banking union, starting with eurozone-wide deposit insurance, should be initiated, and moves toward greater political integration must be considered, even as Greece leaves the eurozone.
Unfortunately, Germany resists all of these key policy measures, as it is fixated on the credit risk to which its taxpayers would be exposed with greater economic, fiscal, and banking integration.
As a result, the probability of a eurozone disaster is rising.
And, while the cloud over the eurozone may be the largest to burst, it is not the only one threatening the global economy.
Batten down the hatches.
A Global Solutions Network
NEW YORK – Great social change occurs in several ways.
A technological breakthrough – the steam engine, computers, the Internet – may play a leading role.
Visionaries, such as Mahatma Gandhi, Martin Luther King Jr., and Nelson Mandela, may inspire a demand for justice.
Political leaders may lead a broad reform movement, as with Franklin Roosevelt and the New Deal.
Our own generation urgently needs to spur another era of great social change.
This time, we must act to save the planet from a human-induced environmental catastrophe.
Each of us senses this challenge almost daily.
Heat waves, droughts, floods, forest fires, retreating glaciers, polluted rivers, and extreme storms buffet the planet at a dramatically rising rate, owing to human activities.
Our $70-trillion-per-year global economy is putting unprecedented pressures on the natural environment.
We will need new technologies, behaviors, and ethics, supported by solid evidence, to reconcile further economic development with environmental sustainability.
United Nations Secretary-General Ban Ki-moon is taking on this unprecedented challenge from his unique position at the crossroads of global politics and society.
At the political level, the UN is the meeting place for 193 member states to negotiate and create international law, as in the important treaty on climate change adopted at the Rio Earth Summit in 1992.
At the level of global society, the UN represents the world’s citizenry, “we the peoples,” as it says in the UN Charter.  At the societal level, the UN is about the rights and responsibilities of all of us, including future generations.
In the past two decades, governments have come up short on solutions to environmental threats.
Politicians have failed to implement properly the treaties adopted at the 1992 Earth Summit.
Ban knows that strong government action remains vital, but he also recognizes that civil society must also play a larger role, especially because too many governments and politicians are beholden to vested interests, and too few politicians think in time horizons that extend past the next election.
To empower global society to act, Ban has launched a bold new global initiative, for which I am grateful to volunteer.
The UN Sustainable Development Solutions Network is a powerful effort to mobilize global knowledge to save the planet.
The idea is to use global networks of knowledge and action to identify and demonstrate new, cutting-edge approaches to sustainable development around the world.
The network will work alongside and support governments, UN agencies, civil-society organizations, and the private sector.
Humanity needs to learn new ways to produce and use low-carbon energy, grow food sustainably, build livable cities, and manage the global commons of oceans, biodiversity, and the atmosphere.
But time is running very short.
Today’s mega-cities, for example, already have to confront dangerous heat waves, rising sea levels, more extreme storms, dire congestion, and air and water pollution.
Agricultural regions already need to become more resilient in the face of increased climate volatility.
And as one region in one part of the world designs a better way to manage its transport, energy needs, water supplies, or food supplies, those successes should quickly become part of the global knowledge base, enabling other regions to benefit rapidly as well.
Universities have a special role to play in the new UN knowledge network.
Exactly 150 years ago, in 1862, Abraham Lincoln created America’s “land-grant” universities to help local communities to improve farming and the quality of life through science.
Today, we need universities in all parts of the world to help their societies face the challenges of poverty reduction, clean energy, sustainable food supplies, and the rest.
By linking together, and putting their curricula online, the world’s universities can become even more effective in discovering and promoting science-based solutions to complex problems.
The world’s corporate sector also has a significant role to play in sustainable development.
Now the corporate sector has two faces.
It is the repository of cutting-edge sustainable technologies, pioneering research and development, world-class management, and leadership in environmental sustainability.
Yet at the same time, the corporate sector lobbies aggressively to gut environmental regulations, slash corporate-tax rates, and avoid their own responsibility for ecological destruction.
Sometimes the same company operates on both sides of the divide.
We urgently need far-sighted companies to join the Sustainable Development Solutions Network.
These companies are uniquely placed to move new ideas and technologies into early-stage demonstration projects, thereby accelerating global learning cycles.
Equally important, we need a critical mass of respected corporate leaders to press their peers to cease the anti-environmental lobbying and campaign-finance practices that account for the inaction of governments.
Sustainable development is a generational challenge, not a short-term task.
The reinvention of energy, food, transport, and other systems will take decades, not years.
But the long-term nature of this challenge must not lull us into inaction.
We must start reinventing our productive systems now, precisely because the path of change will be so long and the environmental dangers are already so pressing.
At the Rio+20 Summit this past June, the world’s governments agreed to adopt a new set of goals on sustainable development for the period after 2015, to build upon the Millennium Development Goals’ success in reducing poverty, hunger, and disease.
In the post-2015 era, the fight against poverty and the fight to protect the environment will go hand in hand, reinforcing each other.
Secretary-General Ban Ki-moon has already initiated several global processes to help establish the new post-2015 goals in an open, participatory, and knowledge-based way.
The Secretary General’s launch of the Sustainable Development Solutions Network is therefore especially timely.
Not only will the world adopt a new set of goals to achieve sustainable development, but it will also have a new global network of expertise to help achieve those vital objectives.
A Good Rate Hike for Europe
Two wrongs don’t make a right.
Just because European governments have failed to put bread on their constituents’ tables doesn’t mean that the European Central Bank should likewise fail in its job of promoting price stability in the euro zone.
That may sound obvious, but abandoning price stability is exactly what some European politicians are advocating.
For example, Italian politicians, who, given Italy’s recent dismal economic performance, would seem the least qualified to offer the ECB advice on monetary policy, are nonetheless advocating interest-rate cuts.
Echoing comments by Italian Prime Minister Silvio Berlusconi, Deputy Economics Minister Mario Baldassarri said in Il Sole 24 Ore last week that all efforts to boost growth are in vain “if someone is pushing on the brake pedal.”
Who’s he kidding?
If anyone is “pushing down on the Italian growth brake” it is Berlusconi himself.
He has made no efforts at economic reform during his term and now seeks to blame the ECB for Italy’s lame economic performance.
But it is precisely the lack of economic reform at home that has made Italy one of the least competitive states in the euro-zone economy.
More than the usual “blame game” is at work here.
Pressures are mounting on the ECB to raise interest rates – and Berlusconi and Co.’s attacks are as much as an attempt to forestall future rate hikes as to get the ECB to loosen its monetary policy.
Soaring energy prices, for example, have become a leading inflation risk.
But higher energy prices, by themselves, will not cause the ECB to pull the interest-rate trigger.
The key will be so-called “second-round effects” – whether growing crude prices lead to higher wage demands from trade unions.
So far, the “social partners,” as ECB president Jean-Claude Trichet likes to call the unions, have been quiet.
Should this change, the ECB will have to raise rates even if Europe’s economic growth remains slack.
The good news is that economic growth in the euro-zone economy appears to be picking up (even in Italy).
Though second-quarter GDP growth was weak — the euro-zone average was only 0.3% year on year – third-quarter data are indicating a sustained economic pick-up in the second half of the year. Only consumption is lagging.
How will the ECB react to better economic news?
Some on the Governing Council have grown uncomfortable that euro-zone interest rates have stayed so low, at 2%, for so long (more than two years).
True, there is no inflation problem in the short run, but the ECB’s monetary policy focuses on the medium term.
One particular worry is that euro-zone money supply is well above the ECB’s benchmark level, indicating an excess supply of liquidity.
It is doubtful that the ECB would raise interest rates to curb excess liquidity so long as economic recovery remains in question.
Slow growth has silenced the monetarists on the ECB’s Governing Council. This will change, however, once the economic pick-up is confirmed.
Interest-rate hikes may be coming sooner rather than later, which is why Berlusconi and French President Jacques Chirac are talking up interest-rate cuts now.
Meanwhile, in Germany, the elections this September may have surprising consequences for ECB monetary policy.
Angela Merkel, the Christian Democrats’ candidate, is a reformer, holding out hope for Germany’s future – and that of Europe.
Unfortunately, Merkel’s campaign is off to a rocky start, and the recent entry of Oskar Lafontaine’s extreme left-wing party into the fray may necessitate the formation of a grand coalition between the Christian Democrats and the Social Democrats.
This would be bad news for the German economy, which could delay possible ECB interest rate hikes.
Because the expected gridlock in parliament would make reforms less likely, companies might hold off on investment, while consumers would be more likely to keep their wallets closed, because official policy would be even less clear than it is now.
On the other hand, a center-right coalition between the Christian Democrats and the Free Democrats could spark the ECB into action.
This raises an interesting point.
The public should be relieved if the ECB raises rates, because this would most likely signal that the long-awaited economic recovery is well under way, and that inflationary repercussions are being addressed.
A hike, in other words, would indicate that good things are happening.
But the public often views interest-rate increases as negative events that increase unemployment and stifle growth.
Blame-game politicians like Berlusconi, who have failed to put bread on the table, their minions in the media, and Keynesian economic professors who don’t understand and misrepresent Keynes sustain this distorted view.
Europe would be a lot better off if someone told the public the truth.
A Good Year for God
LONDON – It’s been a better year for God.
After withering literary assaults on the Almighty from the Oxford academic Richard Dawkins, the essayist Christopher Hitchens, and others, believers have hit back.
Best of all has been The Case for God by the brilliant religion writer Karen Armstrong.
More important still is the news that more people (certainly in Britain) are going to Christian churches of all denominations.
Moreover, the Pope made a very successful visit to Britain in September.
We know already about heavy attendance at the country’s mosques.
At this time of year, of course, many Christians who are not regular churchgoers attend the Nativity services.
Carols, church bells, and mangers are still at the heart of mid-winter festivities, alongside the consumer binge.
This year, however, the “big spend” in Europe may have been inhibited by the big winter freeze and the big austerity programs across most of the continent.
Even in the most Godless households, most children in Western societies probably know the details of the Christmas story.
The travelers who can find no room at the inn.
The birth of a baby in the stables.
The arrival of the wise men bearing gifts of gold, frankincense, and myrrh.
We learn about all this at the same time as we are told about Father Christmas, his Lapland reindeers, and his sacks full of presents.
We rapidly lose our belief in that winter myth.
But we tend to retain into adulthood the same views of God that we formed in childhood.
An old man with a long beard watches over us, and most of us retain a pretty literal opinion of the stories about his Son told in the Bible’s New Testament.
It is this God that atheists like Dawkins and Hitchens attack.
And, with such a target, it is not very difficult to poke holes and pile on the ridicule.
Leave aside the fact that you can make an even stronger case against Godlessness – remember the atrocities of atheist totalitarians in the twentieth century – and consider the assault on those whose commitment to literal interpretations of religious texts means that they deny science and reason.
To them the world was made in six days; evolution is a fanciful tale.
Those of us who think that science and religion dwell in different domains, and who recall that Socrates argued that science did not teach you about morality or meaning, find that our case is undermined by the literalists and fundamentalists in every religion.
There are Christians who know all about the fire and brimstone of the Book of Revelation, but seem not to have heard the instructions about generosity in the Sermon on the Mount.
Likewise, there are hard-line Jews, such as the settler groups who drive Palestinians from their homes in East Jerusalem and Hebron, who have forgotten the early teachings of Jewish scholars who argued that strangers should be treated like your own people.
And there are Muslims who ignore the Koran’s commands of pluralism, tolerance, and peace.
Where the atheist assault is often correct is in pinpointing the amount of harm frequently done in our world by such fundamentalists.
Right-wing American attitudes about their country’s place in the world are invigorated by fundamentalist dogma.
The United Nations is the devil’s own creation.
President Barack Obama is an un-American Muslim.
Palestine from the Jordan River to the coast should be handed to Israel so that the world can end with a cataclysmic Christian triumph.
Jewish fundamentalists obstruct any peace process that is left in the Middle East and build more illegal settlements.
Islamic fundamentalists define jihad as a war of terror against the West and call for an Islamic caliphate from the Atlantic to the Pacific.
The strident and damaging dogmatism of fundamentalists of every stripe has a common feature: a truculent sense of grievance, rooted in fear and resentment of modernity.
Christian fundamentalism in America harks back to nineteenth-century populism and anti-intellectualism.
Members of evangelical churches associate their beliefs with the rugged individualism of the early pioneers.
They are contemptuous of the establishment.
Jewish fundamentalists believe that Israel’s critics are anti-Semitic or, in the case of Jewish opponents of Israel’s harder-line policies, “self-hating Jews.”
Islamic fundamentalists reckon that what the rest of us regard as the liberalizing influence of technological progress and globalization is a brash re-run of Western colonialism.
For a happier New Year, we should listen to the core messages of all these great religions, above all the Confucian golden rule that we should never do to others what we would not like to be done to us.
What religion should teach us is not how to hate, but – to borrow again from Confucius – how to develop societies that look after and welcome the poor, the stranger, and the oppressed.
That is the most important message for everyone, atheists included, to take from the Christian story of Christmas.
A Gravity Test for the Euro
CAMBRIDGE – Although I appreciate that exchange rates are never easy to explain or understand, I find today’s relatively robust value for the euro somewhat mysterious.
Do the gnomes of currency markets seriously believe that the eurozone governments’ latest “comprehensive package” to save the euro will hold up for more than a few months?
The new plan relies on a questionable mix of dubious financial-engineering gimmicks and vague promises of modest Asian funding.
Even the best part of the plan, the proposed (but not really agreed) 50% haircut for private-sector holders of Greek sovereign debt, is not sufficient to stabilize that country’s profound debt and growth problems.
So how is it that the euro is trading at a 40% premium to the US dollar, even as investors continue to view southern European government debt with great skepticism?
I can think of one very good reason why the euro needs to fall, and six not-so-convincing reasons why it should remain stable or appreciate.
Let’s begin with why the euro needs to fall.
Absent a clear path to a much tighter fiscal and political union, which can lead only through constitutional change, the current halfway house of the euro system appears increasingly untenable.
It seems clear that the European Central Bank will be forced to buy far greater quantities of eurozone sovereign (junk) bonds.
That may work in the short term, but if sovereign default risks materialize – as my research with Carmen Reinhart suggests is likely – the ECB will in turn have to be recapitalized.
And, if the stronger northern eurozone countries are unwilling to digest this transfer – and political resistance runs high – the ECB may be forced to recapitalize itself through money creation.
Either way, the threat of a profound financial crisis is high.
Given this, what arguments support the current value of the euro, or its further rise?
First, investors might be telling themselves that in the worst-case scenario, the northern European countries will effectively push out the weaker countries, creating a super-euro.
But, while this scenario has a certain ring of truth, surely any breakup would be highly traumatic, with the euro diving before its rump form recovered.
Second, investors may be remembering that even though the dollar was at the epicenter of the 2008 financial panic, the consequences radiated so widely that, paradoxically, the dollar actually rose in value.
Although it may be difficult to connect the dots, it is perfectly possible that a huge euro crisis could have a snowball effect in the US and elsewhere.
Perhaps the transmission mechanism would be through US banks, many of which remain vulnerable, owing to thin capitalization and huge portfolios of mortgages booked far above their market value.
Third, foreign central banks and sovereign wealth funds may be keen to keep buying up euros to hedge against risks to the US and their own economies.
Government investors are not necessarily driven by the return-maximizing calculus that motivates private investors.
If foreign official demand is the real reason behind the euro’s strength, the risk is that foreign sovereign euro buyers will eventually flee, just as private investors would, only in a faster and more concentrated way.
Fourth, investors may believe that, ultimately, US risks are just as large as Europe’s.
True, the US political system seems stymied in coming up with a plan to stabilize medium-term budget deficits.
Whereas the US Congress’s “supercommittee,” charged with formulating a fiscal-consolidation package, will likely come up with a proposal, it is far from clear that either Republicans or Democrats will be willing to accept compromise in an election year.
Moreover, investors might be worried that the US Federal Reserve will weigh in with a third round of “quantitative easing,” which would further drive down the dollar.
Fifth, the current value of the euro does not seem wildly out of line on a purchasing-power basis.  An exchange rate of $1.4:€1 is cheap for Germany’s export powerhouse, which could probably operate well even with a far stronger euro.
For the eurozone’s southern periphery, however, today’s euro rate is very difficult to manage.
Whereas some German companies persuaded workers to accept wage cuts to help weather the financial crisis, wages across the southern periphery have been marching steadily upwards, even as productivity has remained stagnant.
But, because the overall value of the euro has to be a balance of the eurozone’s north and south, one can argue that 1.4 is within a reasonable range.
Finally, investors might just believe that the eurozone leaders’ latest plan will work, even though the last dozen plans have failed.
Abraham Lincoln is credited with saying “You can fool some of the people all of the time, and all of the people some of the time, but you cannot fool all of the people all of the time.”
A comprehensive euro fix will surely arrive for some of the countries at some time, but not for all of the countries anytime soon.
So, yes, there are plenty of vaguely plausible reasons why the euro, despite its drawn-out crisis, has remained so firm against the dollar so far.
But don’t count on a stable euro-dollar exchange rate – much less an even stronger euro – in the year ahead.
A Green Alternative to Austerity?
OXFORD – While austerity in Europe faces increasing social resistance, in principle it has the merit of simplicity.
As the debate on fiscal consolidation versus growth intensifies, it is clear that there is little agreement on how to kick-start the economy, beyond fielding broad stimulus packages.
One idea is that environmental technology might feed a virtuous cycle of innovation and employment.
To some, green growth evokes a countryside covered with windmills and urban roofs lined with solar panels.
But it is broader than that.
For example, when Airbus moved from injection molding to 3D printing to produce the metal hinges for its airplanes’ doors, it reduced their weight by half, yielding phenomenal savings in material and associated fuel consumption over a lifetime of flying those hinges around the world.
Still, it is easier to find exciting anecdotes than it is to show how they scale up to revitalizing an entire economy.
Moreover, there is a great diversity of narratives on the green economy – and their proliferation is likely to grow.
This June, thousands of activists, policymakers, and business people will converge on Rio de Janeiro for the third giant United Nations Sustainable Development Conference (Rio+20), whose theme is the green economy.
The conference will unleash new arguments about green jobs, growth, cost increases, cost reductions, changes in values, consumer choice – green this and green that.
As a co-author of A New Growth Path for Europe, a report commissioned by the German government, I am guilty of contributing to this cacophony of complementary perspectives on green growth.
The European Climate Foundation had already published its Roadmap 2050, A Practical Guide to a Prosperous, Low-Carbon Europe.
Since then, the UN Environment Program has released its Green Economy Report; McKinsey has written about the Resource Revolution; and the International Trade Unions Council has published Growing Green and Decent Jobs – to name but a few.
All take somewhat different approaches and offer different recommendations, making it hard for policymakers to see the forest through the trees.
And, at the root of this multiplicity of perspectives lays the fact that economics struggles to explain how growth and innovation move an economy as a whole.
The macroeconomic models on which policymakers depend are solid tools in times of smooth and incremental evolution, but green growth is not about gradual change.
For example, the European Union’s goal of achieving an 80% reduction in greenhouse gas emissions by 2050 implies a complete overhaul of EU infrastructure in just a few decades.
Economists’ inability to model such rapid, radical change should not be taken as a condemnation of the discipline; it is simply a reflection of the state of our knowledge, and of the fact that the economy is really, really complicated.
We simply do not yet have sufficiently precise insights into how all of its elements interact during times of far-reaching change, whether it be a financial crisis or a growth spurt.
Yet, the studies of green growth mentioned above all appear to provide such explanations.
So, what do they really tell us?
In practice, each is limited to just one or two aspects of the economy, and describes how these interact.
Growing Green and Decent Jobs looks at the relationship between investment and jobs.
A New Growth Path for Europe examines the impact of expectations and learning-by-doing.
Roadmap 2050 focuses on greening the power system.
The authors then make a leap of faith to derive conclusions about the economy as a whole.
But, while the value of these studies is in the light that they shed on the parts, the ensuing headlines invariably are about the whole, articulated in terms of GDP and jobs.
Each of the studies describes a part of a green economy, but none can capture the whole – not because they are deficient, but because it is simply beyond our capability.
That said, the fact that one cannot prove conclusively how green growth would work does not mean that we should give up on the idea.
We know from history that waves of innovation, from the steam engine to the information and communications revolution, have led to dramatic increases in economic growth.
We cannot prove that a wave of environmental innovation will have a similar effect, but the studies of the parts make such an outcome highly plausible.
As humans, we are uniquely equipped to make decisions on the basis of ambiguous information – in fact, we do it all the time.
When we choose a career or a spouse in our private lives, or when a politician seizes an opportunity from a plethora of possibilities, the task at hand is always about making highly consequential decisions based on imperfect information.
A big pile of green-growth reports demonstrates the plausibility of this path to recovery from an historic economic crisis.
It is now up to us to realize its potential.
Green growth offers a realistic alternative to the faltering austerity approach to overcoming the current economic crisis.
Policymakers should incorporate this thinking into the “beyond austerity” narrative that is taking shape in a growing number of key EU member states.
Ethics and Agriculture
MELBOURNE – Should rich countries – or investors based there – be buying agricultural land in developing countries?
That question is raised in Transnational Land Deals for Agriculture in the Global South, a report issued last year by the Land Matrix Partnership, a consortium of European research institutes and nongovernmental organizations.
The report shows that since 2000, investors or state bodies in rich or emerging countries have bought more than 83 million hectares (more than 200 million acres) of agricultural land in poorer developing countries.
This amounts to 1.7% of the world’s agricultural land.
Most of these purchases have been made in Africa, with two-thirds taking place in countries where hunger is widespread and institutions for establishing formal land ownership are often weak.
The purchases in Africa alone amount to an area of agricultural land the size of Kenya.
It has been claimed that foreign investors are purchasing land that has been left idle; thus, by bringing it into production, the purchases are increasing the availability of food overall.
But the Land Matrix Partnership report found that this is not the case: roughly 45% of the purchases involved existing croplands, and almost a third of the purchased land was forested, indicating that its development may pose risks for biodiversity.
The investments are both private and public (for example, by state-owned entities) and come from three different groups of countries: emerging economies like China, India, Brazil, South Africa, Malaysia, and South Korea; oil-rich Gulf states; and wealthy developed economies like the United States and several European countries.
On average, per capita income in the countries that are the source of these investments is four times higher than in the target countries.
Most of the investments are aimed at producing food or other crops for export from the countries in which the land is acquired, for the obvious reason that richer countries can pay more for the output.
More than 40% of such projects aim to export food to the source country – suggesting that food security is a major reason for buying the land.
Oxfam International calls some of these deals “land grabs.”
Its own report, Our Land, Our Lives,indicates that, since 2008, communities affected by World Bank projects have brought 21 formal complaints alleging violations of their land rights.
Oxfam, drawing attention to large-scale land acquisitions that have entailed direct rights violations, has called on the Bank to freeze investments in land purchases until it can set standards ensuring that local communities are informed of them in advance, with the option of refusing them.
Oxfam also wants the Bank to ensure that these land deals do not undermine either local or national food security.
In response, the World Bank agreed that there are instances of abuse in land acquisition, particularly in developing countries in which governance is weak, and said that it supported more transparent and inclusive participation.
At the same time, it pointed to the need to increase food production to feed the extra two billion people expected to be alive in 2050, and suggested that more investment in agriculture in developing countries is required to improve productivity.
The Bank rejected the idea of a moratorium on its own work with investors in agriculture, arguing that this would target precisely those who are most likely to do the right thing.
One may ask whether transparency and the requirement that local landholders consent to a sale is enough to protect people living in poverty.
Supporters of free markets will argue that if local landowners wish to sell their land, that is their choice to make.
But, given the pressures of poverty and the lure of cash, what does it take for people to be able to make a genuinely free and informed choice about selling something as significant as a right to land?
After all, we do not allow poor people to sell their kidneys to the highest bidder.
Of course, hardline supporters of free markets will say that we should.
But, at the very least, it needs to be explained why people should be prohibited from selling kidneys, but not from selling the land that grows their food.
Most people can live without one kidney.
No one can live without food.
Why does the purchase of body parts give rise to international condemnation, while the purchase of agricultural land does not – even when it involves evicting local landholders and producing food for export to rich countries instead of for local consumption?
The World Bank may indeed be more concerned about local landholders’ rights than other foreign investors are.
If so, the 21 complaints made against Bank projects are most likely the visible tip of a vast iceberg of violations of land rights by foreign investors in agricultural projects in developing countries – with the others remaining invisible because victims have no access to any complaint procedure.
One such case belatedly came to the attention of the United Nations Human Rights Committee.
In November, the Committee concluded that Germany had failed to police the Neumann Kaffee Gruppe regarding its complicity in the forced eviction of several villages in Uganda to make way for a large coffee plantation.
But the evictions took place in 2001, and the villagers are still living in extreme poverty.
They found no remedy, in either Uganda or Germany, for the violation of rights that, according to the Committee, they possess under the International Covenant on Civil and Political Rights, to which Germany is a signatory.
Are we to believe that landholders fare better with Chinese or Saudi investors?
The Rise of the Food Barons
BERLIN – The industrial-agriculture sector has long faced criticism for practices that contribute to climate change, environmental destruction, and rural poverty.
And yet the sector has taken virtually no steps to improve quality and sustainability, or to promote social justice.
This is not surprising. Although there are more than 570 million farmers and seven billion consumers worldwide, just a handful of companies control the global industrial-agriculture value chain – from field to shop counter.
Given the high profits and vast political power of these companies, changes to the status quo are not in their interest.
Moreover, market concentration in the agriculture sector is on the rise, owing to increased demand for the agricultural raw materials needed in food, animal feed, and energy production.
As the middle class in southern countries has grown, its members’ consumption and nutritional habits have changed, boosting global demand for processed foods – and setting off a scramble for market power among multinational agricultural, chemical, and food corporations.
The biggest players in these sectors have been buying out their smaller competitors for years.
But now they are also buying out one another, often with financing provided by investors from completely different sectors.
Consider the seed and agrochemical sector, where Bayer, the second-largest pesticide producer in the world, is in the process of acquiring Monsanto, the largest seed producer, for €66 billion ($74 billion).
If the United States and the European Union approve the deal, as seems likely, just three conglomerates – Bayer-Monsanto, Dow-DuPont and ChemChina-Syngenta – will control over 60% of the global seed and agrochemical market.
“Baysanto” alone would be the proprietor of almost every genetically modified plant on the planet.
With other large mergers also being announced, the global agriculture market at the end of 2017 could look very different than it did at the beginning.
Each of the three major conglomerates will be closer to its goal of achieving domination of the seed and pesticide markets – at which point they will be able to dictate food products, prices, and quality worldwide.
The agrotechnical sector is experiencing some of the same changes as the seed sector.
The five largest corporations account for 65% of the market, with Deere & Company, the owner of the John Deere brand, in the lead.
In 2015, Deere & Company reported $29 billion in sales, surpassing the $25 billion that Monsanto and Bayer made selling seeds and pesticides.
The most promising new opportunity for food corporations today lies in the digitization of agriculture.
This process is still in its early stages, but it is gathering momentum, and eventually it will cover all areas of production.
Soon enough, drones will take over the task of spraying pesticides; livestock will be equipped with sensors to track milk quantities, movement patterns, and feed rations; tractors will be controlled by GPS; and app-controlled sowing machines will assess soil quality to determine the optimal distance between rows and plants.
To maximize the benefits of these new technologies, the companies that already dominate the value chain have begun cooperating with one another.
The John Deeres and Monsantos have now joined forces.
The confluence of soil and weather “big data,” new agrotechnologies, genetically modified seeds, and new developments in agrochemistry will help these companies save money, protect natural resources, and maximize crop yields worldwide.
But while this possible future bodes well for some of the world’s largest companies, it leaves the environmental and social problems associated with industrialized agriculture unsolved.
Most farmers, particularly in the global South, will never be able to afford expensive digital-age machinery.
The maxim “grow or go” will be replaced with “digitize or disappear.”
The ETC Group, an American non-governmental organization, has already outlined a future scenario in which the major agrotechnology corporations move upstream and absorb the seed and pesticide producers.
At that point, just a few companies will determine everything that we eat.
Indeed, the same market-concentration problem applies to other links in the value chain, such as agricultural traders and supermarkets.
And even though food processing is not yet consolidated on a global scale, it is still dominated at the regional level by companies such as Unilever, Danone, Mondelez, and Nestlé.
These companies make money when fresh or semi-processed food is replaced by highly processed convenience foods such as frozen pizza, canned soup, and ready-made meals.
While lucrative, this business model is closely linked to obesity, diabetes, and other chronic diseases.
Worse, food corporations are also profiting from the proliferation of illnesses for which they are partly responsible, by marketing “healthy” processed foods enriched with protein, vitamins, probiotics, and omega-3 fatty acids.
Meanwhile, corporations are amassing market power at the expense of those at the bottom of the value chain: farmers and workers.
International Labor Organization standards guarantee all workers the right to organize, and they prohibit forced and child labor and proscribe race and gender discrimination.
But labor-law violations have become the norm, because efforts to enforce ILO rules are often quashed, while trade union members are routinely threatened, fired, and even murdered.
In this hostile climate, minimum-wage, overtime-pay, and workplace-safety standards are openly neglected.
And women, in particular, are at a disadvantage, because they are paid less than their male counterparts and often must settle for seasonal or temporary jobs.
Today, half of the world’s 800 million starving people are small farmers and workers connected to the agricultural sector.
Their lot will hardly improve if the few companies already dominating that sector become even more powerful.
How to Feed the World
PRAGUE – Hunger has wracked humanity since time immemorial.
Nearly every major society has been shaped by famine; one estimate suggests that China suffered drought or flood-induced starvation in at least one province almost every year from 108 BC to 1911.
Yet the struggle against hunger is a battle that humanity could finally win.
More cereals were produced annually in the last quarter of the twentieth century than in any preceding period, and more grain will be harvested this year than at any time in history.
Since 1992, the number of hungry people worldwide has plummeted by more than 200 million, even as the human population grew by nearly two billion.
But enormous challenges remain.
Affordable, nutritious food is one of people’s top priorities everywhere, and one in nine people still do not get enough food to be healthy.
With today’s population of 7.3 billion expected to reach 8.5 billion by 2030 and 9.7 billion in 2050, food demand will increase accordingly.
Along with more mouths to feed, stresses on food supplies will include conflicts, economic volatility, extreme weather events, and climate change.
Increases in agricultural productivity, owing to improvements in seeds, new fertilizers and pesticides, improved credit access, and technological breakthroughs, have been a key driver in reducing hunger.
Between 1930 and 2000, agricultural output in the United States quadrupled, with productivity growth outstripping that of manufacturing.
Developing countries have begun sharing in these gains: responsible for next-to-none of the world’s fertilizer consumption in 1960, by 2000 they used more than industrialized countries.
The World Bank has found that productivity growth in agriculture can be up to four times more effective in reducing poverty than growth from other sectors.
So how do we keep up this progress?
Investment in research and development is vital.
According to research conducted for Copenhagen Consensus, which I direct, investing an extra $88 billion in agricultural R&D over the next 15 years would increase yields by an additional 0.4 percentage points each year, which could save 79 million people from hunger and prevent five million cases of child malnourishment.
Achieving these targets would be worth nearly $3 trillion in social good, implying an enormous return of $34 for every dollar spent.
Scientific breakthroughs also play a key role in fighting specific nutritional challenges such as vitamin A deficiency, the leading cause of preventable childhood blindness.
Robert Mwanga was awarded this year’s World Food Prize for inspiring work that resulted in the large-scale replacement of white sweet potato (with scant Vitamin A content) by a vitamin A-rich alternative in the diets of Uganda’s rural poor.
Another way to increase agricultural productivity is through labor.
When Copenhagen Consensus researchers examined responses to global warming in Bangladesh, they found that increasing agricultural labor productivity “is the only way to increase the resilience of Bangladesh to climate change and to meet long-term development goals.”
Investing around $9,000 per worker over two decades could boost agricultural productivity by 10%.
Bangladesh is an instructive case, because it is susceptible to flooding and the effects of climate change, and its agricultural productivity lags behind other developing and middle-income countries.
Unsurprisingly, the Bangladeshi prime minister’s office is striving to lead in global innovation, sustaining an agriculture innovation lab that shares best practices and ideas.
Copenhagen Consensus has worked with the world’s largest NGO, BRAC, to find out the policy wishes of people living in rural Bangladesh, including the “ultra-poor” with whom BRAC works closely.
These laborers, housewives, and others, some of whom live on the equivalent of $0.60-0.70 or less a day, are seldom given a place at the table to discuss policy.
Across nine rural forums in far-flung parts of the country, the participants overwhelmingly spoke with one voice, calling for the same policy priority: increased agricultural productivity.
“Everyone knows Rangpur has a Monga problem,” said a local from Chandpara in the Rangpur division, using the Bengali term for the annual cyclical phenomenon of seasonal hunger.
“We cannot feed our people two times a day – we need to increase our agricultural productivity.”
A Mukimabad villager had the same vision for Bangladesh: “We need crops and seeds which are not vulnerable to salinity and flood so that we do not have to die from food shortages.”
Humanity’s fight against hunger can be won.
Great progress has been made, but the world needs more agricultural R&D and higher productivity.
As a rural villager from Deukhola, near the Brahmaputra River in remote northern Bangladesh, starkly put it: “Our survival depends on it.”
We would do well to listen.
An Arab Marshall Plan
OXFORD – The wave of revolts that swept across the Arab world two years ago were fueled by demands for freedom, bread, and social justice.
But, although the revolutions toppled dictators and transformed societies, these core objectives remain as distant as ever.
In fact, the economic challenges facing the Arab Spring countries have become even more pressing, weighing heavily on these countries’ political prospects.
Unemployment has nearly doubled in Tunisia and Egypt, and foreign direct investment has dried up across the Arab world.
Tourism revenues, while resilient, are declining, and fiscal challenges remain considerable.
But the economic urgency is not reflected in the policy response, which has been painfully slow or non-existent.
For example, Egypt’s fiscal deficit will exceed 11% of GDP this year.
But the country’s leaders have been stalling on the terms of a much-needed International Monetary Fund loan.
The government’s reduction of fuel subsidies last year was not followed by additional reforms, and the required tax increase was delayed soon after President Mohamed Morsi announced it.
Almost all political stakeholders in Egypt, as in the other Arab countries in transition, recognize the need for economic reform.
But neither citizens nor policymakers appear willing to bear its social and political costs.
In a charged and uncertain political climate, in which new crises erupt on a daily basis, it is unsurprising that economic reform has been postponed repeatedly.
Politicians know that macroeconomic stabilization and social cohesion can be irreconcilable in the short run.
Slashing food and energy subsidies in order to reduce fiscal strain is unlikely to win favor in a country like Egypt, where 40% of per capita income is allocated to food.
Politics is thus constraining efforts to strengthen public finances.
At the same time, narrow IMF prescriptions threaten to exacerbate political instability, with citizens no longer afraid to take to the streets to demonstrate their dissatisfaction.
The current impasse on economic reform highlights a larger point: subsidy and tax regimes cannot be reformed without first redefining the underlying social contract, which has long exchanged welfare distribution for political acquiescence.
But such a move is far too risky for an individual politician, or even a single country, at a time of economic uncertainty and high unemployment.
In order to create the political space needed for economic reform, Arab leaders must underwrite a regional growth pact – a Marshall Plan of sorts – that would facilitate major new investments aimed at reviving economic activity.
It is much easier to reform subsidy programs when the economy is expanding.
Moreover, building competitive markets is essential to ensuring sustainable GDP growth.
To this end, regional trade barriers, which are more pervasive in the Arab world than even in Sub-Saharan Africa, must be dismantled.
By agreeing to the pact, Arab countries would commit to reforming their subsidy systems and to reducing restrictions on cross-border economic exchange.
The regional dimension of prosperity has long been ignored in the Arab world.
But weak regional linkages limit small firms’ growth potential, forcing them to depend on state patronage.
Although Arab leaders often cite Turkey as a beacon of hope, they rarely acknowledge that the country’s recent transformation from the “sick man of Europe” to one of the world’s fastest-growing emerging markets would not have been possible had it not pursued regional synergies.
Such linkages are particularly important for Egypt and Tunisia, which will struggle to reduce unemployment unless Libya’s labor market – which has historically absorbed migrants from its North African neighbors – is reopened.
And, while Tunisia’s situation seems to be the most promising, a crippling investment shortfall is threatening to derail reform efforts there.
With Europe mired in crisis, capital flows from Tunisia’s resource-rich Arab neighbors are its best hope.
Furthermore, Arab countries must ratchet up development spending.
Given that existing development banks in the region have largely failed to act as vehicles of coordination and commitment, a new institution – resembling the European Bank for Reconstruction and Development – would have to be established to oversee a regional aid push and underwrite the costs of economic transition.
New investment vehicles, such as sovereign wealth funds and Islamic finance, can contribute financing to credit-starved firms.
At the same time, Arab countries must streamline current aid efforts.
For too long, Arab governments have simply thrown money at problems, with the rich Gulf countries effectively subsidizing their troubled neighbors’ public services.
Over the last two years, Saudi Arabia has provided more than $3 billion to Yemen.
Qatar has provided  $5 billion to Egypt since 2011, with a promise of $3 billion more.
And the United Arab Emirates recently pledged $2.5 billion to Bahrain.
But unconditional aid only delays reforms, because it weakens budget constraints, which reduces pressure on policymakers and creates moral hazard.
The Arab Spring has exposed fault lines that run not just through individual countries, but also through the entire region.
This calls for redefining relationships not only between citizens and states, but also among Arab countries.
Above all, it is no longer prudent to divide Arab countries between donors and recipients, or between resource-rich and resource-poor countries.
It is in the interest of the entire region – including those countries that do not seem to face an imminent threat of revolt – to contribute to their neighbors’ economic revival and facilitate their political transitions.
The Ahistorical Federal Reserve
BERKELEY – Economic developments over the past 20 years have taught – or ought to have taught – the US Federal Reserve four lessons.
Yet the Fed’s current policy posture raises the question of whether it has internalized any of them.
The first lesson is that, at least as long as the current interest-rate configuration is sustained, the proper inflation target for the Fed should be 4% per year, rather than 2%.
A higher target is essential in order to have enough room to make the cuts in short-term safe nominal interest rates of five percentage points or more that are usually called for to cushion the effects of a recession when it hits the economy.
The Fed protests that to change its inflation target even once would erode the credibility of its commitment to ensuring price stability.
But the Fed can pay now or it can pay later.
After all, what good is credibility today when it means sticking tenaciously to a policy that deprives you of the ability to do your job properly tomorrow?
The second lesson is that the two slope coefficients in the algebraic equation that is the Phillips curve – the link between expected inflation and current inflation, and the responsiveness of future inflation to current unemployment – are both much smaller than they were back in the 1970s or even in the 1980s.
Then-Fed Chair Alan Greenspan recognized this in the 1990s.
He rightly judged that pushing for faster growth and lower unemployment was not taking excessive risks, but rather harvesting low-hanging fruit.
The current Fed appears to have a different view.
The third lesson is that yield-curve inversion in the bond market is not just a sign that the market thinks that monetary policy is too tight; it is a sign that monetary policy really is too tight.
The people who bid up the prices of long-term US Treasury bills in anticipation of interest-rate cuts when the Fed overshoots and triggers a recession are the same people who are now on tenterhooks wondering when to start cutting back on investment plans because a recession will soon produce overcapacity.
The Fed today has a “habitat theory” about why this time is different – that is, why the preferences of investors for particular maturity lengths imply that a yield-curve inversion would not mean what it has always meant.
But 2006, just before the financial crisis hit, was supposed to be different, too.
(And there were plenty of times before then that were supposed to be different, too.)
History suggests that this time is highly unlikely to be different – and that it will not end well if the Fed continues to believe and behave otherwise.
The fourth lesson similarly reflects developments extending back further than 20 years.
Back in the 1980s, it was not unreasonable to argue that the next large shock to the US macroeconomy was likely to be inflationary.
It is much more difficult to reasonably argue that today.
For the past three and a half decades, the principal shocks have not been inflationary, like the 1973 and 1979 oil crises, but rather deflationary, like the US savings and loan crisis in the 1980s and 1990s, the 1997 Asian crisis, the 2000 dot-com bust, the terrorist attacks of September 11, 2001, the 2007 subprime collapse that began in the US, and the 2010 European debt crash.
Former Fed Chair Janet Yellen told me back in the 1990s that, in her view, conducting the Fed’s internal debate within the framework of interest-rate rules had greatly increased the ease of getting from agreement about the structure and state of the economy to a rough consensus on appropriate policy.
But, at least as I see it, right now the Fed’s process of getting from a realistic view of the economy to an appropriate monetary policy does not seem to be functioning well at all.
Perhaps it is time for the Fed to place its internal discussions in a more explicit framework.
One can imagine, for example, the Fed adopting an “optimal control” method, whereby monetary-policy settings are established by running multiple simulations of a macroeconomic model using different combinations of interest rates and balance-sheet tools to project future inflation and unemployment.
The problem for optimal control methods is that the real world is not some closed system where economic relationships never change, or where they change in fully predictable ways.
The most effective – and thus the most credible – monetary policy is one that reflects not only the lessons of history, but also a willingness to reconsider long-held assumptions.
A History Lesson for Koizumi
Once again, protests against Japanese Prime Minister Junichiro Koizumi’s annual visit to the Yasukuni shrine are breaking out in China as well as South Korea.
Koizumi’s insistence on paying homage to the war dead interred at Yasukuni, where convicted war criminals from World War II are among the buried, has been damaging relations with Japan’s neighbors for years.
Indeed, Chinese President Hu Jintao continually affirms that he will not hold a summit with a Japanese prime minister who goes to Yasukuni, which most Chinese regard as a glorification of past Japanese aggression and colonialism.
Even some in Japan are becoming critical of Koizumi.
While the public remains negative about Chinese outbursts against Japan, a recent survey indicates that more than 70% of Japanese view the current state of Japan-China relations as unacceptable.
More people are not supporting Koizumi’s annual pilgrimage to Yasukuni, with seven former prime ministers jointly demanding that he refrain from the visits.
Yet Koizumi remains defiant.
Moreover, Chief Cabinet Secretary Shinzu Abe, the front-runner to succeed him, has openly declared that he will continue to visit the shrine as prime minister.
Foreign Minister Taro Aso, another possible successor to Koizumi, has called for the Japanese Emperor to pray at Yasukuni.
So pessimism appears to be settling in, and the deadlock over Yasukuni appears to be deepening.
But the past can bring us more than just troubles of this kind.
Even on the issue of Yasukuni, there are positive lessons to be learned.
Consider Yasuhiro Nakasone, Koizumi’s predecessor in the 1980’s.
Both are master politicians who remained popular and served long terms in office.
Both are conservative and nationalistic, advocating the revision of the constitution and an assertive political and military role for Japan abroad.
Finally, both are pro-American, with Nakasone declaring Japan to be America’s “unsinkable aircraft carrier” in East Asia and Koizumi sending troops to Iraq in support of the United States-led war effort.
But a crucial difference between Nakasone and Koizumi is often overlooked: their handling of the Yasukuni controversy and relations with China.
Nakasone broke the taboo by being the first prime minister to worship at the Yasukuni shrine in his official capacity on August 15, 1985, the fortieth anniversary of the end of World War II.
The decision triggered a severe response from China, where students held demonstrations against his visit.
Bilateral relations were frozen.
But, instead of capitalizing on domestic resentment over China’s criticisms, Nakasone decided not to visit Yasukuni again.
He chose to mend relations with China by focusing on the positive aspects of bilateral ties.
In 1986, Nakasone went to Beijing at the personal invitation of Chinese Communist Party General Secretary Hu Yaobang and laid the cornerstone for a Sino-Japanese Youth Exchange Center, promising to forge future friendships with China.
This genuine embrace of reconciliation provided much-needed support to Chinese leaders, who were eager to control anti-Japanese sentiments.
Hu praised Nakasone’s courage and warned Chinese youth publicly that if they “think merely of the well-being of their own country… they are not sober-minded patriots.”
Nakasone emerged from the crisis and was recognized as a capable statesman in managing Japan’s diplomacy with China.
There was no accusation that Nakasone was “selling out” to Beijing.
Nor were his conservative, nationalist, and pro-American credentials damaged.
This episode suggests that Koizumi’s hardline position isn’t the only option.
A Japanese prime minister can be strong without exploiting domestic resentment against the country’s neighbors, and conservative, patriotic, and pro-American while forging a healthy working relationship with China.
Indeed, the cessation of Yasukuni visits would likely open the door to the long-overdue Sino-Japanese summit, which in turn might strengthen moderate voices in China seeking a future-oriented relationship with Japan.
Unfortunately, Koizumi and his allies are not prepared to move forward on the Yasukuni issue.
As Foreign Minister Aso recently put it: “The more China voices [opposition], the more one feels like going there.
It’s just like when you’re told ‘Don't smoke cigarettes,’ it actually makes you want to smoke.”
No one expects the current Japanese and Chinese leaders to embrace, as Nakasone and Hu did two decades ago, but it is a sad state of affairs when the leaders of neighboring giants pretend not to see each other at international forums.
If Nakasone, who now urges Koizumi to stop the Yasukuni pilgrimage, were to respond to Aso, he might simply extend the analogy: it is not in Japan’s national interest to continue to inhale Koizumi’s second-hand smoke.
Israel versus America versus Iran
TEL AVIV – Israel’s concern about the specter of a nuclear Iran has now degenerated into a crisis of confidence concerning the United States.
Prime Minister Binyamin Netanyahu has embarked on a campaign to force President Barack Obama to set a red line that Iran must not cross, lest it risk unleashing an American military response.
Implicit threats of a unilateral Israeli attack, together with conspicuous meddling in the US presidential election campaign, have compounded Netanyahu’s effort to twist Obama’s arm.
The controversy between the two allies partly reflects their divergent timelines: for Israel, the red line is Iran’s imminent burial deep underground of its uranium-enrichment facilities; for the US, it is the start of a dedicated weapons program.
But, equally important, the dispute underscores their different objectives.
For Israel, war with Iran is not about neutralizing an existential threat; it is about reasserting its regional status.
Israel’s leaders see their country’s standing in the region being seriously threatened by the emergence of a hostile Islamist regime in Egypt; the possibility that a similarly hostile regime will eventually emerge in Syria; the fragility of traditionally friendly Jordan; and the dangerous boost that the regional Islamist awakening has given to Israel’s sworn enemies, Hamas and Hezbollah.
Both Netanyahu and Defense Minister Ehud Barak thus regard an attack on Iran as a major strategic move aimed at the broader Middle East, which implies that they would not discount a military campaign that goes well beyond surgical air strikes.
Indeed, they probably contemplate land incursions into Iran, and possibly a decisive – and, from their perspective, long overdue – showdown with Hamas in Gaza and Hezbollah in Lebanon.
Though determined to prevent Iran from acquiring nuclear weapons, even if doing so requires military action, the US weighs the consequences of a military showdown in very different terms.
A superpower that has earned only frustration in its abortive efforts – whether war or regional diplomacy – in the dysfunctional Middle East, the US faces the Iran crisis in the midst of its epochal strategic shift to Asia and the Pacific.
The fallout from a war in Iran would pin down the US in the Middle East for years to come, undermining its new strategic priorities.
As a result, the US, though certainly better equipped than Israel for a war to ensure that Iran forever abandons its nuclear ambitions, could nonetheless conclude that that objective is simply too costly.
The recent report by The Iran Project, whose signatories include the former US national security advisers Brent Scowcroft and Zbigniew Brzezinski, concluded that an American military attack on Iran could only delay its nuclear program for up to four years.
To guarantee that Iran never acquires a nuclear bomb, the US would need to maintain military pressure on Iran for several years.
And, if forced to impose regime change as the ultimate solution to the dilemma, the report assumes that this would require military occupation, which would entail a commitment of resources and personnel greater than what the US invested in the Iraq and Afghanistan wars combined.
Moreover, the conventional assumption that the region’s Sunni Arab regimes would give tacit approval to a military attack on Iran’s nuclear installations must be revisited in the wake of the Arab Spring – particularly in the aftermath of the recent, sudden upsurge in anti-American violence throughout the Muslim world.
The pre-Arab Spring paradigm that framed the Middle East as being divided between “moderates” and “extremists” has become obsolete.
The Islamist governments that have emerged from the downfall of America’s puppet regimes are no friends of an Iranian nuclear empire.
But, in their struggle to survive, they must channel popular anti-Americanism.
For Egyptian President Mohamed Morsi, that imperative meant placating the angry mob that recently attacked the US embassy rather than merely condemning the violence.
An attack on Iran, especially if it develops into a longer war involving regional proxies, is bound to become the trigger for mass anti-Israel and anti-US hysteria, which might draw the Islamist regimes in the region into a dynamic of escalation.
It would be impossible to rule out a regional war.
The main problem facing a military operation in Iran is the need to ensure its legitimacy.
China and Russia would never allow the US to secure a United Nations mandate for an attack.
Moreover, while Iranian provocations that clearly reveal the regime’s intentions to develop a nuclear-weapons capability might help build support for American military action, it is far from certain that Europeans, or others, would rush to join another US-led “coalition of the willing.”
The dire legacy of Iraq and Afghanistan weighs heavily on the Western democracies.
The saddest part of the story is Israel’s utter indifference to the need to build international legitimacy for its drive to stop Iran’s nuclear program.
Netanyahu thinks in bold military terms, not in terms of geopolitical strategy.
His careless Palestine policy has left Israel with few friends in the international community, let alone in the Arab Middle East.
Indeed, many regard Netanyahu’s Iran obsession as nothing more than a successful ploy to divert attention from the Palestinian issue.
Only a generous, bold peace initiative that would genuinely revive the two-state solution, accompanied by a freeze on construction and enlargement of West Bank settlements, would help to recover the good will of the Palestinians and their brethren throughout the Arab world.
And only that outcome can secure the international goodwill that both Israel and the US will need for a showdown with Iran.
A Human Rights Crime In Gaza
Atlanta -- The world is witnessing a terrible human rights crime in Gaza, where a million and a half human beings are being imprisoned with almost no access to the outside world by sea, air, or land. An entire population is being brutally punished.
This gross mistreatment of the Palestinians in Gaza was escalated dramatically by Israel, with United States backing, after political candidates representing Hamas won a majority of seats in the Palestinian Authority parliament in 2006. The election was unanimously judged to be honest and fair by all international observers.
Israel and the US refused to accept the right of Palestinians to form a unity government with Hamas and Fatah and now, after internal strife, Hamas alone controls Gaza.  Forty-one of the 43 victorious Hamas candidates who lived in the West Bank are now imprisoned by Israel, plus an additional ten who assumed positions in the short-lived coalition cabinet.
Regardless of one’s choice in the partisan struggle between Fatah and Hamas within occupied Palestine, we must remember that economic sanctions and restrictions in delivering water, food, electricity, and fuel are causing extreme hardship among the innocent people in Gaza, about one million of whom are refugees.
Israeli bombs and missiles periodically strike the encapsulated area, causing high casualties among both militants and innocent women and children.
Prior to the highly publicized killing of a woman and her four little children last week, this pattern was illustrated by a previous report from B’Tselem, the leading Israeli human rights organization: 106 Palestinians were killed between February 27 and March 3. Fifty-four of them were civilians who didn't take part in the fighting, and 25 were under 18 years of age.
On a recent trip through the Middle East, I attempted to gain a better understanding of the crisis.
One of my visits was to Sderot, a community of about 20,000 in southern Israel that is frequently struck by rudimentary rockets fired from nearby Gaza.
I condemned these attacks as abominable and an act of terrorism, since most of the thirteen victims during the past seven years have been non-combatants.
Subsequently, I met with leaders of Hamas, both a delegation from Gaza and the top officials in Damascus, Syria.
I made the same condemnation to them, and urged that they declare a unilateral ceasefire or orchestrate with Israel a mutual agreement to terminate all military action in and around Gaza for an extended period.
They responded that such previous action by them had not been reciprocated, and they reminded me that Hamas had previously insisted on a ceasefire throughout Palestine including both Gaza and the West Bank, which Israel had refused.
Hamas then made a public proposal of a mutual ceasefire restricted to Gaza, which the Israelis considered and also rejected.
There are fervent arguments heard on both sides concerning blame for a lack of peace in the Holy Land.
Israel has occupied and colonized the Palestinian West Bank, which is approximately one-fourth (28.5%) the size of the nation of Israel as recognized by the international community.
Some Israeli religious factions claim a right to the land on both sides of the Jordan River, and others aver that their 205 settlements with some 500,000 people are necessary for “security.”
All Arab nations have agreed to full recognition of Israel if it will comply with key United Nations resolutions.
Hamas has agreed to accept any negotiated peace settlement between Palestinian Authority President Mahmoud Abbas and Israeli Prime Minister Ehud Olmert, provided it is approved in a referendum among the Palestinian people.
This holds promise of progress, but despite the brief fanfare and positive statements at the peace conference last November in Annapolis, Maryland, a retrogression has occurred in the process.
Nine thousand new Israeli settlement housing units have been announced in Palestine, the number of roadblocks within the West bank has increased, and the stranglehold on Gaza has been tightened.
It is one thing for other leaders to defer to the US on the crucial peace negotiations, but the world must not stand idle while innocent people are treated cruelly.
It is time for strong voices in Europe, the US, Israel, and elsewhere to speak out and condemn this human rights tragedy among the Palestinian people.
A Hundred Years of Superconductivity
CHICAGO – The world’s first “quantum” computer – a machine that harnesses the magic of quantum phenomena to perform memory and processing tasks incredibly faster than today’s silicon-based computer chips – was recently sold by D-Wave Systems of Canada to Lockheed-Martin.
And, while some question whether the machine is truly a quantum computer, its designers have published articles in peer-reviewed journals demonstrating that the basic elements of this novel computer are indeed superconducting quantum bits.
This spring marked the 100th anniversary of the discovery of superconductivity – the ability of materials to carry electrical current with no loss.
Currents set up in superconducting wires can exist for years without any measurable decay.
Because of this property, superconductors have unique features that can be exploited in many ways.
They can carry enormous amounts of current, making them ideal for urban power grids. And, when wound into coils, they can produce extremely strong magnetic fields.
Such superconducting magnets have been applied in a variety of technologies.
The best-known examples are the magnets that drive the magnetic resonance imaging (MRI) machines found in most hospitals.
Perhaps the most exotic are the huge magnets used to accelerate particles in the Large Hadron Collider, which seeks to discover the fundamental principles of matter.
Despite their great promise, however, superconductors have limits, the primary one being that most superconduct at very low temperatures – indeed, near absolute zero (-273 ºC).
Such temperatures can be achieved only through liquid-helium cooling.
Thus, Swiss researchers caused excitement in 1986 by announcing the discovery of superconductivity in an oxide of copper at twice the temperature of the previous record holder.
Shortly thereafter, researchers in the United States found a related material that superconducts above the temperature at which air liquefies.
As Time magazine proclaimed in May 1987, with the discovery of these so-called “cuprates,” the superconducting revolution had begun.
Alas, the revolution soon bogged down.
Cuprates are notoriously difficult materials to work with, because they are very brittle.
This is exacerbated by their strong anisotropy – the materials have a quasi-two-dimensional structure consisting of a weakly coupled stack of conducting sheets. As such, they are a challenge for industry, though applications are beginning to appear.
Since the cuprates first appeared, a variety of other “high temperature” superconductors have been discovered – one is a simple compound of magnesium and boron, and another involves a mixture of iron and arsenic.
Although none of them superconduct at temperatures as high as liquid air, they may ultimately be better materials with which to work.
Given the vast number of combinations of elements that can form compounds, there is a good chance that better superconductors await our discovery.
In the coming years, superconductors are expected to play a growing role in technology.
Already, “second generation” cuprate wires are being used to make high-capacity cables for electric-power transmission, and lighter-weight generators for wind turbines.
Stronger superconducting magnets are leading to the development of MRIs with more sophisticated diagnostic capabilities.
Superconductors are being used for levitated trains in high-speed rail transport, and as microwave filters for improved signal bandwidth in cellular base stations.
The discovery of a new superconductor with enhanced properties could lead to even greater technological innovation.
This brings us to the intellectual challenge of superconductors.
It took 46 years from the discovery of superconductivity to the 1957 Bardeen, Cooper, and Schrieffer (BCS) theory of how the phenomenon occurs.
Along the way, a number of famous physicists tried and failed to get the answer – Albert Einstein, Werner Heisenberg, and Richard Feynman being notable examples.
Discovering the solution required the development of advanced theoretical techniques.
What had been difficult to figure out was how to get electrons to superconduct.
The basic discovery of BCS was that if the electrons pair up, those couples could indeed superconduct.
Fortunately, the mechanism for such coupling was known.
Although electrons are negatively charged, and therefore repel one another, the positive ions that they leave behind when they flow through a metal can mediate an effective attraction between two electrons under restrictive conditions (for example, the metal must be very cold).
The suspicion, though, is that this is not the case in the new superconductors.
Cuprates superconduct at much higher temperatures, but, more importantly, they possess some exotic properties: they are formed by doping electrical carriers into a host material that is a magnetic insulator – the last place one would look for a conventional superconductor.
And, unlike BCS theory, in which the pairs are isotropic – with identical properties in all directions in space – the pairs in cuprates are strongly anisotropic, resembling a cloverleaf.
How can one pair electrons without ions holding them together, thereby enabling higher-temperature superconductors?
While ideas about this abound, new theoretical breakthroughs most likely will be needed to develop the machinery required to solve such electron-electron theories, perhaps even involving black holes.
Whatever the theory turns out to be, it is certain to revolutionize physics.
Lies, Damned Lies, and AI
CAMBRIDGE – Algorithms are as biased as the data they feed on.
And all data are biased.
Even “official” statistics cannot be assumed to stand for objective, eternal “facts.”
The figures that governments publish represent society as it is now, through the lens of what those assembling the data consider to be relevant and important.
The categories and classifications used to make sense of the data are not neutral.
Just as we measure what we see, so we tend to see only what we measure.
As algorithmic decision-making spreads to a wider range of policymaking areas, it is shedding a harsh light on the social biases that once lurked in the shadows of the data we collect.
By taking existing structures and processes to their logical extremes, artificial intelligence (AI) is forcing us to confront the kind of society we have created.
The problem is not just that computers are designed to think like corporations, as my University of Cambridge colleague Jonnie Penn has argued. It is also that computers think like economists.
An AI, after all, is as infallible a version of homo economicus as one can imagine.
It is a rationally calculating, logically consistent, ends-oriented agent capable of achieving its desired outcomes with finite computational resources.
When it comes to “maximizing utility,” they are far more effective than any human.
“Utility” is to economics what “phlogiston” once was to chemistry.
Early chemists hypothesized that combustible matter contained a hidden element – phlogiston – that could explain why substances changed form when they burned.
Yet, try as they might, scientists never could confirm the hypothesis.
They could not track down phlogiston for the same reason that economists today cannot offer a measure of actual utility.
Economists use the concept of utility to explain why people make the choices they do – what to buy, where to invest, how hard to work: everyone is trying to maximize utility in accordance with one’s preferences and beliefs about the world, and within the limits posed by scarce income or resources.
Despite not existing, utility is a powerful construct.
It seems only natural to suppose that everyone is trying to do as well as they can for themselves.
Moreover, economists’ notion of utility is born of classical utilitarianism, which aims to secure the greatest amount of good for the greatest number of people.
Like modern economists following in the footsteps of John Stuart Mill, most of those designing algorithms are utilitarians who believe that if a “good” is known, then it can be maximized.
But this assumption can produce troubling outcomes.
For example, consider how algorithms are being used to decide whether prisoners are deserving of parole.
An important 2017 study finds that algorithms far outperform humans in predicting recidivism rates, and could be used to reduce the “jailing rate” by more than 40% “with no increase in crime rates.”
In the United States, then, AIs could be used to reduce a prison population that is disproportionately black.
But what happens when AIs take over the parole process and African-Americans are still being jailed at a higher rate than whites?
Highly efficient algorithmic decision-making has brought such questions to the fore, forcing us to decide precisely which outcomes should be maximized.
Do we want merely to reduce the overall prison population, or should we also be concerned about fairness?
Whereas politics allows for fudges and compromises to disguise such tradeoffs, computer code requires clarity.
That demand for clarity is making it harder to ignore the structural sources of societal inequities.
In the age of AI, algorithms will force us to recognize how the outcomes of past social and political conflicts have been perpetuated into the present through our use of data.
Thanks to groups such as the AI Ethics Initiative and the Partnership on AI, a broader debate about the ethics of AI has begun to emerge.
But AI algorithms are of course just doing what they are coded to do.
The real issue extends beyond the use of algorithmic decision-making in corporate and political governance, and strikes at the ethical foundations of our societies.
While we certainly need to debate the practical and philosophical tradeoffs of maximizing “utility” through AI, we also need to engage in self-reflection.
Algorithms are posing fundamental questions about how we have organized social, political, and economic relations to date.
We now must decide if we really want to encode current social arrangements into the decision-making structures of the future.
Given the political fracturing currently occurring around the world, this seems like a good moment to write a new script.
A Better Global Framework to End AIDS
STOCKHOLM, GENEVA – This week, we celebrate the tremendous progress that has been made in the struggle against HIV and AIDS.
In many countries with strong health systems, HIV is no longer a death sentence, but a chronic condition.
And Africa has reached a critical milestone: each year, there are now more Africans starting HIV treatment than being infected.
Still, even as we celebrate, we must also mourn the 1.1 million people who lost their lives to the disease this year.
HIV still infects 6,000 people every day, and AIDS remains a leading cause of death among children, adolescents, and women in Africa.
The movement against AIDS has inspired all of us to help the people who continue to be left behind, and to commit to ending AIDS once and for all.
Fortunately, we already have the know-how, resources, and, crucially, the political momentum to do this; and at the High-Level Meeting on Ending AIDS this year, United Nations member states made ambitious commitments that will put us on the fast track toward our goal.
What’s more, in September, Canada hosted a successful financing conference for the Global Fund to Fight AIDS, Tuberculosis, and Malaria, which brought in almost $13 billion, replenishing the Global Fund for 2017-2019.
Meanwhile, individual countries have increased their domestic investments, and international partners – big and small – have maintained their support, which is how we will reach the $26 billion needed for the global AIDS response in 2020.
But funding parts of the global health system is not enough.
The international community must take a more holistic view and reinforce a global-response architecture that features a clear division of labor and seamless cooperation among various stakeholders.
Ultimately, the goal of such a framework must be to support countries’ own health systems, by marshaling public and private actors at all levels in a given country, so that every facility – from the public hospital in the capital to the village clinic – is properly provisioned.
Sweden is proud to continue its support for the Global Fund; at the replenishment conference in September, it pledged 2.5 billion krona ($271 million).
The Global Fund is by far the largest multilateral source of financing for efforts to fight AIDS, tuberculosis, and malaria; but just like the Global Alliance for Vaccines and Immunization (now known as Gavi, the Vaccine Alliance), it is part of a global architecture, and relies on a range of partners to deliver aid effectively.
So, if country-level support for other global-health organizations – such as UNAIDS, the World Health Organization, and the UN Development Programme – dries up, continued progress in the fight against HIV and AIDS will be at risk.
Providing the necessary support will require donors to coordinate with one another, so that all parts of the existing architecture for managing global health issues are adequately funded.
This will then ensure that all countries – and, more importantly, all people – receive the support they need.
UNAIDS is setting a powerful example for international collaboration, by organizing partners around a common 2016-2021 Strategy to end AIDS.
This unique and innovative partnership brings together 11 co-sponsoring UN agencies, each with diverse sector-specific expertise, and mobilizes various government stakeholders.
Partners include business, community, and faith leaders, as well as teachers, judges, members of law enforcement, parliamentarians, and many others outside the health sector whose actions nonetheless affect health outcomes.
One of UNAIDS’ tasks is to encourage national governments to keep AIDS high on their public-health agendas, and to invest in joint efforts to end the disease.
It is also the only organization with a mandate to set norms and standards for the global response to AIDS, which means that it plays a key role in the current international framework.
UNAIDS maintains a close partnership with the Global Fund.
It has a presence in more than 80 countries, and its regional teams provide technical support and strategic information, which helps the Global Fund direct its grants to the right programs, locations, and populations at sufficient scale.
Moreover, it helps to create the social, legal, and political conditions for people to use health services, not least by promoting gender equality and ensuring that populations at higher risk of contracting HIV do not face adverse discrimination.
UNAIDS engages with civil society at all levels, by leveraging the international AIDS response to promote equality, dignity, and human rights around the world.
As such, UNAIDS works to expand the political space for – and investment in – civil society.
Yet, despite its broad mandate and many functions, UNAIDS lacks adequate resources, which threatens past achievements and future programs alike, and poses a danger to people and communities that depend on the lifesaving support the organization helps facilitate.
Sweden and UNAIDS will work together to ensure that the international AIDS response continues to transform – and save – lives.
We will safeguard and empower women and girls, and make sure that vulnerable populations’ voices are heard.
But, at the same time, the international community must strengthen the existing framework for managing global-health issues.
As Swedish Prime Minister Stefan Löfven said in Montreal in September: “Today we are focusing on the Global Fund, but tomorrow let’s not forget to provide sufficient funding for the entire global health architecture.”
It is time for the international community to meet that challenge, by pledging to support our global health infrastructure, so that no agency – and no country or person – is left out.
AIDS, NCDs, and the ABCs of Organizing
GENEVA – Non-communicable diseases (NCDs), like heart disease, stroke, cancer, diabetes, and chronic lung disease, are responsible for 70% of all deaths.
There is incontrovertible evidence that tobacco use, inactivity, unhealthy diets, and excessive alcohol consumption increase the odds of dying prematurely from an NCD.
And yet, despite widespread knowledge of the risks, global obesity goes largely unchecked, while tobacco and alcohol use continue to rise.
It is against this backdrop that networks of NCD alliances met December 9-11 at the second Global NCD Alliance Forum, in the United Arab Emirates.
As they search for solutions to bring NCDs under control, they should look for inspiration to the movement to fight AIDS.
People living with and affected by HIV continue to drive response efforts, and their unique form of mobilization has been instrumental to progress.
While the battle is not over, AIDS activists know that it can be won.
Similarly, a mobilized NCD movement can turn the tide against that epidemic.
Yet, in 2015, Richard Horton, the editor of The Lancet, described the NCD community as needing an “electric shock to its semi-comatose soul.”
He added: “But who has the courage to deliver it?”
We believe there are lessons to be learned from AIDS activists.
As global attention focuses on NCD prevention, those seeking to control preventable illnesses should look to the “ABCs” of AIDS organizing for guidance.
The first letter that the NCD community should consider is “A,” for activism.
Anyone over 40 will recall images of AIDS activists performing “die-ins” at scientific meetings around the world.
In the United States, AIDS activists took to the streets, even shutting down the Food and Drug Administration’s headquarters for a day in October 1988.
Globally, activists lobbied governments and pharmaceutical companies to make medicines more affordable.
This activism continues, and should serve as a model for action on NCDs.
Next, the NCD community must adopt a bolder approach to budgets – the “B” of the AIDS movement’s strategy.
Civic organizing and grassroots activism may fuel early energies, but organizing and sustaining a broad-based coalition takes money.
The AIDS movement was clear about this from the beginning, and lobbied for resources to support its advocacy and accountability effectively.
“C” is for coalitions: the AIDS movement was quick to understand that progress would come only with diverse support.
Activists established links between people living with HIV and those with other concerns, such as women’s rights, intellectual property, nutrition, and housing.
Issue-specific coalitions and campaigns work best when they bring together government insiders and outsiders, to combine perspectives and expertise.
The AIDS movement also understood that a holistic response to the epidemic was essential.
Thus, “D,” the underlying determinants of health, was to draw attention to the interconnectivity of the drivers of challenge.
For example, lobbying education leaders to keep girls in school longer has contributed to providing young people with the knowledge and agency to make smart decisions about when and with whom to negotiate safe sex.
Similarly, links were forged between groups working on poverty, gender, and nutrition – factors that played a role in driving the AIDS crisis.
NCDs are no less isolated in their causality, and similarly require a multi-sector approach to prevention.
Engagement – “E” – was what helped the AIDS movement become so influential.
By borrowing from the playbook of the disability rights movement, which championed the mantra “Nothing About Us Without Us,” AIDS advocates demanded representation on the bodies established to address the disease.
For example, UNAIDS remains the only United Nations agency with seats on its board for representatives from civil society.
This norm is so powerfully embedded in the AIDS movement that it would be almost unthinkable for an AIDS meeting to take place without representation from the community.
Disease prevention movements must also develop persuasive narratives, and “F” – framing the issue – was essential to the AIDS community’s effort to gain support from political leaders.
In particular, access to AIDS treatment was framed as a matter of economic justice.
Framing the narrative this way led to a dramatic reduction in the price of medicines, so much so that more than half of people living with HIV in low- and middle-income countries are in treatment.
An equally important framing issue for AIDS, which is highly relevant to the NCDs movement, is that of responsibility.
The AIDS community worked hard to shift the focus from blaming individuals’ lifestyle choices to putting the onus on the state for providing health care and removing legal discrimination.
In the AIDS debate, gender – our movement’s “G” – was a significant focal point.
HIV was initially seen as a “gay disease,” and gender identity was embedded in the DNA of the AIDS movement early on.
Gender dimensions of NCDs are no less important; one only has to consider how alcohol and tobacco are marketed to understand that.
Gender, therefore, must become a focus of NCDs prevention efforts.
Finally, “H” – human rights – was the bedrock of the AIDS response.
Campaigns were launched against discrimination in workplaces, schools, and health centers.
Strategic litigation helped ensure equality under the law.
The AIDS movement refused to hold major conferences in countries with punitive laws against people living with HIV.
The NCD movement could take a similar tack by, for example, refusing to meet in countries that fail to restrict advertising of junk food to children.
The list of AIDS lessons could continue throughout the alphabet, but ending with “H” is apt, given that human rights drove the response, and should drive the response to NCDs.
Poverty, exclusion, and social and economic marginalization put people at higher risk for HIV.
It is no different for NCDs.
The early mainstream reaction to the AIDS epidemic was to ask, “Why don’t those people make better choices?”
The AIDS movement made clear that that was the wrong question.
Today, with 70% of the planet at risk of premature death from preventable illnesses, “those people” are many of us.
The NCD and AIDS communities can learn from one another.
We are a stronger movement when we join forces.
The views expressed here do not necessarily reflect those of UNAIDS.
Aid Works
NEW YORK – The critics of foreign aid are wrong.
A growing flood of data shows that death rates in many poor countries are falling sharply, and that aid-supported programs for health-care delivery have played a key role.
Aid works; it saves lives.
One of the newest studies, by Gabriel Demombynes and Sofia Trommlerova, shows that Kenya’s infant mortality (deaths under the age of one year) has plummeted in recent years, and attributes a significant part of the gain to the massive uptake of anti-malaria bed nets.
These findings are consistent with an important study of malaria death rates by Chris Murray and others, which similarly found a significant and rapid decline in malaria-caused deaths after 2004 in sub-Saharan Africa resulting from aid-supported malaria-control measures.
Let’s turn back the clock a dozen years.
In 2000, Africa was struggling with three major epidemics.
AIDS was killing more than two million people each year, and spreading rapidly.
Malaria was surging, owing to the parasite’s growing resistance to the standard medicine at the time.
Tuberculosis was also soaring, partly as a result of the AIDS epidemic and partly because of the emergence of drug-resistant TB.
In addition, hundreds of thousands of women were dying in childbirth each year, because they had no access to safe deliveries in a clinic or hospital, or to emergency help when needed.
These interconnected crises prompted action.
The United Nations’ member states adopted the Millennium Development Goals in September 2000.
Three of the eight MDGs – reductions in children’s deaths, maternal deaths, and epidemic diseases – focus directly on health.
Likewise, the World Health Organization issued a major call to scale up development assistance for health.
And African leaders, led by Nigeria’s president at the time, Olusegun Obasanjo, took on the challenge of battling the continent’s epidemics.
Nigeria hosted two landmark summits, on malaria in 2000 and on AIDS in 2001, which were a crucial spur to action.
At the second of these summits, then-UN Secretary-General Kofi Annan called for the creation of the Global Fund to Fight AIDS, TB, and Malaria.
The Global Fund began operations in 2002, financing prevention, treatment, and care programs for the three diseases.
High-income countries also finally agreed to reduce the debt owed by heavily indebted poor countries, allowing them to spend more on health care and less on crippling payments to creditors.
The United States also took action, adopting two major programs, one to fight AIDS and the other to fight malaria.
In 2005, the UN Millennium Project recommended specific ways to scale up primary health care in the poorest countries, with the high-income countries helping to cover the costs that the poorest could not pay by themselves.
The UN General Assembly backed many of the project’s recommendations, which were then implemented in numerous low-income countries.
Donor aid did start to rise sharply as a result of all of these efforts.
In 1995, total aid for health care was around $7.9 billion.
This inadequate level then crept up slowly, to $10.5 billion by 2000.
By 2005, however, annual aid for health had jumped another $5.9 billion, and by 2010, the total had grown by another $10.5 billion, to reach $26.9 billion for the year.
The expanded funding allowed major campaigns against AIDS, TB, and malaria; a major scaling up of safe childbirth; and increased vaccine coverage, including the near-eradication of polio.
Many innovative public-health techniques were developed and adopted.
With one billion people living in high-income countries, total aid in 2010 amounted to around $27 per person in the donor countries – a modest sum for them, but a life-saving one for the world’s poorest people.
The public-health successes can now be seen on many fronts.
Around 12 million children under five years old died in 1990.
By 2010, this number had declined to around 7.6 million – still far too high, but definitely an historic improvement.
Malaria deaths in children in Africa were cut from a peak of around one million in 2004 to around 700,000 by 2010, and, worldwide, deaths of pregnant women declined by almost half between 1990 and 2010, from an estimated 543,000 to 287,000.
Another $10-15 billion in annual aid (that is, roughly $10-15 more per person in the high-income world), bringing total aid to around $40 billion per year, would enable still greater progress to be made in the coming years.
The MDGs for health could be achieved even in many of the world’s poorest countries.
Unfortunately, at every step during the past decade – and still today – a chorus of aid skeptics has argued against the needed help.
They have repeatedly claimed that aid does not work; that the funds will simply be wasted; that anti-malaria bed nets cannot be given to the poor, since the poor won’t use them; that the poor will not take anti-AIDS medicines properly; and so on and so forth.
Their attacks have been relentless (I’ve faced my share).
The opponents of aid are not merely wrong.
Their vocal antagonism still threatens the funding that is needed to get the job done, to cut child and maternal deaths by enough to meet the MDGs by 2015 in the poorest countries, and to continue after that to ensure that all people everywhere finally have access to basic health services.
A decade of significant progress in health outcomes has proved the skeptics wrong.
Aid for health care works – and works magnificently – to save and improve lives.
Let us continue to support these life-saving programs, which uphold the dignity and well-being of all people on the planet.
The AIIB and Global Governance
HONG KONG – Despite official American and Japanese opposition, 57 countries have opted to be among the founding members of the China-led Asian Infrastructure Investment Bank (AIIB).
Regardless of what naysayers believe, this remarkable turn of events can only benefit global economic governance.
According to former US Treasury Secretary Larry Summers, the AIIB’s establishment “may be remembered as the moment the United States lost its role as the underwriter of the global economic system.”
Asia Development Bank (ADB) President Takehiko Nakao, by contrast, does not believe that there will be a “major change to the world of development finance,” though he conceded that “there can be interpretations as to the symbolic meaning of this.”
Who is right will depend largely on the decisions that the AIIB’s top shareholders make regarding its operating structure.
So far, the AIIB has not sought to amend the principle that the largest contributor to a multilateral organization gets the largest say in running it.
Just as the US dominates the World Bank and Europe leads the International Monetary Fund, China will head the AIIB.
This implies a larger global leadership role for China – which the world, including its traditional powers, should welcome.
After all, global leadership is not just a matter of might; it also reflects the provision of global public goods.
When World War II ended, the US, aside from being the world’s leading military and economic power, was the largest provider of such goods, through the Marshall Plan, support for the United Nations, and contributions to the Bretton Woods institutions (the International Monetary Fund and the World Bank).
But massive debts have lately undermined the ability of the US – not to mention Europe and Japan – to continue making such large contributions.
Fortunately, China is willing and able to fill the gap.
In fact, China might have done so within the Bretton Woods institutions, were the distribution of voting rights within them not skewed so heavily toward the incumbents, who still enjoy veto power.
For example, China has a 3.8% voting share in the IMF and World Bank, even though it accounts for more than 12% of world GDP.
The United Kingdom and France – which are one-third the size of China – each have a 4.3% share.
With the incumbents unwilling to bring China’s voting share in line with its economic might, China had little choice but to launch its own institution.
But the AIIB has its own objectives, which do not align precisely with those of, say, the World Bank.
Specifically, the bank is a critical element of China’s “one belt, one road” strategy, which encompasses two initiatives: the overland Silk Road Economic Belt, connecting China to Europe, and the 21st Century Maritime Silk Road, linking China to Southeast Asia, the Middle East, and Europe.
While the US “pivots” to the east, China is pirouetting west, applying the lessons of its development to its trading partners across Eurasia and beyond.
Perhaps the most important of these lessons is that connectivity is vital to economic growth.
Over the last three decades, the construction of roads, railways, ports, airports, and telecommunications systems in China has fostered trade, attracted investment, and, by linking the country’s land-locked western and southern provinces to its more prosperous coastal areas, helped to reduce regional disparities.
China’s Silk Road initiative, which aims to boost prosperity among China’s trading partners largely through infrastructure investment, is a logical next step – one on which China is spending significantly.
In addition to its initial contribution of up to $50 billion to the AIIB, China has committed $40 billion to its Silk Road Fund, $32 billion to the China Development Bank, and $30 billion to the Export-Import Bank of China.
According to estimates by HSBC, the “one belt, one road” initiative could end up costing as much as $232 billion – just under two-thirds of the World Bank’s balance sheet in 2014.
The $100 billion AIIB will play a central role in this effort.
Given massive global demand for infrastructure finance – which, according to ADB estimates, will amount to $8 trillion in Asia alone over the next decade – the AIIB should not be considered a threat to the World Bank, the ADB, or other multilateral lenders.
Nonetheless, it will compete with them, owing to its distinctive – and probably more efficient – approach to lending.
In fact, the AIIB’s operations will most likely resemble those of the World Bank in the 1960s, when engineers with hands-on development experience dominated the staff and could design lending conditions that worked for borrowers.
In the late 1980s, the World Bank began to implement the Washington Consensus, pushing for economic and political liberalization, without sufficient regard for local political or economic realities.
The result was conditional lending, with terms – created mostly by policy wonks – that many developing-country borrowers could not meet (at least not without hiring consultants to adjust their official reporting).
The acid test of the AIIB’s effectiveness will be its governance model.
One failing of the Bretton Wood institutions is their full-time shareholder boards of directors, which tend to undermine effectiveness by micro-managing and often requesting conflicting lending conditions.
The World Bank has wasted far too much time re-organizing itself under various presidents, without recognizing the fundamental problem with its own governance structure.
Even if the AIIB does not deliver as promised, its establishment is an important reminder that in a fast-changing world, economic governance cannot remain stagnant.
If Western leaders really do believe in innovation, competition, and meritocracy, they should welcome the AIIB.
AIPAC in Decline
MADRID – The American Israel Public Affairs Committee’s lobbying power in the United States is undeniable.
But AIPAC’s supposed ability to control US policy decisions is a Potemkin village myth, cultivated by friends and rivals alike.
In fact, thanks to Israeli Prime Minister Binyamin Netanyahu, AIPAC’s influence is under threat – though Netanyahu himself will be just fine.
Claims about AIPAC’s clout have long shaped analysis of US foreign policy.
For example, Steve Walt and John Mearsheimer, in their notorious essay “The Israel Lobby,” asserted that AIPAC manufactured the Iraq War.
But the reality is far less sinister: in that case, AIPAC merely surfed on the pro-invasion wave unleashed by President George W. Bush, with his Messianic urges, and Vice President Dick Cheney, a one-man war lobby.
The truth about AIPAC – that it is influential, but far from invulnerable – has recently been revealed, both to the public and to the group itself.
Having been pushed by Netanyahu into an unwinnable fight against US President Barack Obama’s administration over its nuclear deal with Iran, AIPAC is now crumbling under the weight of its own hubris.
In fact, AIPAC has never overcome resolute opposition from an American president, particularly in a matter of US national security.
It failed to stop Jimmy Carter from selling F-15 Eagle fighters to Saudi Arabia in 1978, or to prevent Ronald Reagan from supplying AWACS reconnaissance planes to the Saudis three years later.
And its 1991 battle with President George H.W. Bush over the linkage of US loan guarantees for Israel with Prime Minister Yitzak Shamir’s support of the 1991 Madrid peace conference – one of Bush’s key legacies – ended in defeat.
Against this background, AIPAC should have known that its attempt, in close cooperation with Obama’s Republican opponents, to block the Iran nuclear deal (one of Obama’s most important achievements) would fail.
Indeed, Obama even used a tactic similar to that of George H.W. Bush to win the day.
Just as Bush openly denounced the “thousand lobbyists” working the halls of the US Congress against a vital national interest, Obama said in a conference call that his critics “would be opposed to any deal with Iran,” and called out AIPAC’s $20 million advertising campaign against the agreement.
He also put AIPAC in the same category as the Republicans who “were responsible” for leading the US into the Iraq war.
For AIPAC – which has traditionally relied on a broad coalition of social and political forces in the US that view Israel’s security as both a moral cause and a vital national interest – this is not any old defeat.
The Republican-backed crusade against a key agreement negotiated by a Democratic president, with his party’s overwhelming support, has threatened the bipartisan foundations of Israel’s cause in America.
Of course, the nuclear deal involved more than just the US and Iran.
AIPAC was opposing an international agreement that six major world powers – China, France, Germany, Russia, the United Kingdom, and the US – had already signed and that the United Nations had approved.
Even some of Israel’s staunchest supporters in Congress were unlikely to deal a potentially devastating blow to America’s international credibility, and the idea that the negotiating countries would all agree to reopen the talks to produce a “better deal” was sheer fantasy.
Yet that is the objective that Netanyahu set for AIPAC.
The row over the Iran deal is bound to be a watershed moment for American Jews, among whom sharp divisions have formed.
Indeed, the American Jewish Committee 2015 Survey of American Jewish Opinion reports the emergence of “two diverging Jewish sub-communities,” with a growing number of Jews feeling alienated by the organizations that claim to represent them.
AIPAC represents a striking anomaly in the life of American Jews.
It is increasingly identified with the Republican agenda and Israel’s evangelical Christian supporters, even though polls have repeatedly shown that Jews are America’s most liberal ethnic group.
The truth is that American Jews largely opposed the Iraq war.
They overwhelmingly vote for the Democratic Party.
They define their religion as moderate and liberal, with many upholding gay rights and abortion, both anathema to evangelical Christians.
The majority of American Jews even support the creation of a Palestinian state.
And, although they are far from united on the Iran deal, the agreement’s supporters outnumber its opponents.
Much of the blame for the damage that has been done – to AIPAC, American Jewish communities, and even the US political process – falls on Netanyahu.
But he is unlikely to face retribution for any of it.
On the contrary, the Obama administration has already begun the discussions it promised on upgrading Israel’s strategic capabilities.
As Arab countries throughout the Middle East melt down – with increasingly significant spillover effects in the West – Israel continues to represent a stable regional partner for the US.
More dangerous, Netanyahu could achieve his next goal: preventing a strategic détente between the US and Iran that would enable cooperation in resolving major regional conflicts, from Yemen to Syria.
After all, Obama’s victory on the nuclear deal may have been inevitable, but it was far from easy.
An odd coalition of Iranian radicals, AIPAC, the Saudi-led Sunni alliance, the Israeli government, and US politicians from both parties have already compelled Obama to promise additional sanctions on Iran for its sponsorship of terrorism.
As a result, America’s cold war with Iran is likely to persist.
The Dawn of Climate-Friendly Air Travel
MONTREAL – As the world becomes increasingly interconnected, demand for air travel is growing, with more than 30,000 new large aircraft expected to take to the skies in the next few years.
But if we are to sustain growth in air travel without aggravating global warming, we must quickly reduce aviation-related CO2 emissions, which are substantial and not covered by the Paris climate agreement that more than 190 countries agreed to last December.
Fortunately, now is the perfect time to decouple aviation emissions from air-travel growth.
Representatives from 191 countries convened in Montreal this week for the 39th Session of the United Nations’ International Civil Aviation Organization; after decades of wrangling, they have agreed to an aviation-specific climate agreement.
The new ICAO framework aims for “carbon-neutral growth” in international aviation from 2020 onward, and has as its centerpiece a global market-based measure (GMBM) to help airlines affordably cap their net emissions at 2020 levels.
When implemented, it will be the first carbon-emissions cap on a global industry that does not noticeably increase costs for consumers.
And airlines will purchase emissions reductions from other economic sectors, thus funneling billions of dollars into low-carbon development around the world.
For the first six years, the new framework will apply only to flights between countries that have voluntarily adopted it, which means that the ICAO will have to encourage adequate participation for the program to be effective.
This opt-in approach has some critics, but whether a program is categorized as “voluntary” or “mandatory” is beside the point, because international accords generally apply only to the sovereign countries that have decided to join them.
Some 64 countries have already signaled their willingness to sign on to the ICAO agreement, and together they account for nearly 80% of expected growth in CO2 emissions above 2020 levels.
That isn’t 100%, but it’s a great start, and we can expect more countries to join when they see others reaping the benefits of low-carbon development.
The airlines themselves will welcome a coherent global framework that establishes clear and predictable compliance metrics, rather than a regulatory patchwork that differs from country to country and complicates international operations.
To minimize compliance costs – and because environmental sustainability is now a key competitive marker for customers and investors alike – airlines will likely encourage the countries where they do business to participate in the ICAO program.
The new agreement provides an enormous opportunity to prevent the emission of 2.5 billion tons of CO2 in the first 15 years – the equivalent of taking roughly 35 million cars off the road every year the program is in force.
The agreement will also spur major manufacturers such as Boeing, Airbus, Bombardier, and Embraer – which are already investing in quieter, more fuel-efficient aircraft and efficiency improvements for existing models – to develop cleaner technologies that will allow them to purchase fewer emissions offsets.
However, the framework decided in Montreal is not complete, and crucial details need to be worked out quickly so that airlines can begin to plan how they will meet the new environmental targets.
Developed countries have already offered to help implement the GMBM, which, it is hoped, will pave the way for investments in emerging economies that are becoming new aviation powerhouses.
If the countries can leapfrog over old technologies, they can become new leaders in carbon-smart flying.
They should seize the opportunity before them and join the ICAO framework so that their manufacturers have a clear and predictable path forward.
At the Paris climate talks last year, we witnessed the power of global collective action to address climate change.
No fewer than 187 countries – large and small, developed and developing – announced emissions-reduction targets in the months before the conference, which created the momentum to reach a landmark accord.
With the Paris climate agreement on track to enter into force in the coming months – more rapidly than anyone ever thought possible – we still have that momentum.
The ICAO agreement is the next wave in the international battle against climate change.
Together, the two agreements will boost our chances of delivering environmentally sustainable economic growth.
By cleaning up our carbon footprint now, future generations of air travelers from all countries will be able to look out their window onto a healthy planet.
Europe’s Airpocalypse
SINGAPORE – European policymakers like to lecture the rest of the world on air pollution.
Asia, and China in particular, is a favorite target for criticism.
Indeed, it sometimes seems as if no major environmental conference is complete without a presentation by European policymakers on their continent’s supposed “best practices,” which the rest of the world should emulate.
When it comes to air pollution, however, Europe might consider doing less talking and more listening.
Air pollution is a growing concern across Europe.
The World Health Organization has called it the continent’s “single largest environmental health risk,” estimating that 90% of Europe’s citizens are exposed to outdoor pollution that exceeds WHO air-quality guidelines.
In 2010, some 600,000 European citizens died prematurely because of outdoor and indoor air pollution, and the economic costs have been put at $1.6 trillion, roughly 9% of the European Union’s GDP.
London and Paris suffer from particularly severe air-quality problems.
Nitrogen dioxide levels in some parts of London regularly reach 2-3 times the recommended limit.
In the United Kingdom, air pollution kills some 29,000 people a year, putting it second only to smoking as a cause of premature death.
Paris may be even worse off; in March, after air-pollution levels surpassed Shanghai’s, the city imposed a partial driving ban and introduced free public transportation.
Sadly, Europe’s policymakers do not seem up to the challenge.
George Osborne, the UK’s chancellor of the exchequer, has argued against British leadership in the fight against climate change.
“We are not going to save the planet by shutting down our steel mills, aluminum smelters, and paper manufacturers,” he declared in 2011.
Osborne is not alone.
With European politicians arguing that introducing environmental safeguards will hurt the EU’s already-weakened economy, it comes as little surprise that measures to limit air pollution fall far short of the mark.
The EU’s proposed standards regulating toxic emissions from coal plants are even less strict than China’s, Greenpeace reports.
Yet various European politicians have called for watering them down even further, with Hungary suggesting that they be scrapped altogether.
To be sure, air pollution levels in Asia are truly worrisome.
The continent is home to nine of the world’s ten most polluted countries, according to Yale University’s 2014 Air Quality Ranking.
New Delhi is ranked as the most polluted city on earth, with air pollution exceeding safe levels by a factor of 60.
Owing to Beijing’s unhealthy air, foreign companies pay a “hardship bonus” of up to 30% to employees working there.
But at least policymakers in Asia have recognized the problem and are taking steps to address it.
China, for example, has declared a “war on pollution.”
By 2017, Beijing – once dubbed “Greyjing” by the international media – will spend some CN¥760 billion ($121 billion) to combat air pollution.
At the heart of China’s measures are improved public transportation, green trade, and a revision of the energy mix.
The government has decided to install bus stops every 500 meters in city centers, reduce tariffs to 5% or less for a list of 54 environmental goods, and decommission many outdated and inefficient coal plants.
The share of non-fossil fuels in primary energy consumption is expected to increase to 20% by 2030.
These targets are likely to be rigorously implemented, given strong political support from the very top.
Meanwhile, in India, the state governments in Gujarat, Maharashtra, and Tamil Nadu are about to launch the world’s first cap-and-trade schemes for particulates.
India’s Supreme Court even suggested an extra charge on privately owned diesel vehicles in New Delhi.
Other parts of Asia are also taking steps to improve air quality.
Vietnam aims to construct eight urban rail lines in the coming years.
Bangkok, which has been tackling air pollution since the 1990s, has planted 400,000 trees.
And Japan is offering subsidies for hydrogen cars and creating new pedestrian-only areas.
Europe, as one of the world’s wealthiest regions, ought to be at the forefront of the effort to promote environmental sustainability.
When it comes to air pollution, however, Europe’s policymakers should stop preaching to others and focus on fixing their own problems.
A Japanese Metamorphosis?
OSAKA – Yesterday’s landslide general-election victory by the Democratic Party of Japan (DPJ) terminated the one-party-dominated system that the catch-all Liberal Democratic Party (LDP) has controlled almost without interruption since 1955.
For most of the last decade, the DPJ was not seen as a viable alternative to the LDP, although they appeared to form a pseudo-two-party system.
Twenty years after the Cold War’s end, Japan will at last have a post-Cold War system of government.
The Japanese public, even now, remains uncertain about the DPJ’s ability to govern and is skeptical of its rosy programs of wealth redistribution, which lack solid funding.
The public is also fully aware that the ideologically fragmented DPJ lacks a pragmatic, coherent foreign and security policy
Yet the DPJ will form the next government because of public disgust with the LDP.
For the last four years, the LDP had shown itself to be utterly unresponsive to the key issues of popular concern: pensions, unemployment, and the fraying social safety net.
Moreover, the LDP was plagued by a string of minor scandals and consistent bungling.
The LDP’s need for three different prime ministers in the space of little more than a year made plain that the party’s power nucleus had melted down.
Once in power, the DPJ will immediately confront the massive bureaucracy and entrenched mandarins, which usually sabotage any efforts at administrative reform that threatens their power and vested interests.
Indeed, immediately after the election, the budget estimates for the next fiscal year are due.
The figures that will be presented are the result of a lengthy process, in which the bureaucracy closely consulted with LDP.
So, without breaking the regular budget cycle, the DPJ will be forced to implement not only the supplementary budget drawn up by the LDP, but will also be stuck with next year’s budget, which embodies LDP policies that the DPJ has denounced.
As a result, the DPJ has announced plans to revoke the LDP’s guidelines for a ceiling on budget requests so as to formulate its own budget from scratch.  It will also revise the supplementary budget as well.
But time is short, and few of new DPJ lawmakers possess the legislative experience and budgetary expertise to make that happen.
To gain control of the mandarins, the DPJ plans to place 100 lawmakers in the ministries’ top leadership, as well as three dozen political appointees to policy staffs in the office of the prime minister.
Unfortunately, the DPJ scrapped an LDP-sponsored civil-service reform bill, which would have allowed the DPJ to replace mandarins with an army of political appointees.
The DPJ, despite its manifesto, seems unprepared to tame the mandarins, and so may be forced to rely on them.
The ascendency of the mandarins is a legacy of Japan’s unique historical development dating back to its early modern period.
Unlike in Europe, Japan developed its state before building a strong civil society.
Indeed, full-fledged “society”-building started only after the 1868 Meiji Restoration, which tipped the balance of power definitively in favor of the state.
As a result, the mandarins survived WWII and the postwar American occupation relatively undamaged, and they will strive to survive the DPJ government as well.
They will most likely succeed.
LDP lawmakers and mandarins developed a routine in which mandarins drafted cabinet-sponsored bills, LDP lawmakers checked the bills, and the two together finalized legislative drafts before they were introduced to the Diet (parliament).
Since the LDP, recently with a coalition partner, controlled the Diet, the legislative process was simply the interaction between LDP lawmakers and mandarins, centered in the LDP’s headquarters.
The Diet’s role was merely pro forma.
Indeed, under the LDP-led one-party-dominant system, this extra-constitutional mechanism became an integral part of Japan’s government polity.
The DPJ government will collide head-on with the mandarins, partly because the party will find it hard to recruit sufficiently qualified policymakers.
The mandarins have maintained their privileged position in this regard, owing partly to the tax system, which prevents the emergence of non-profit institutions, especially think tanks, where independent policy expertise can be forged.
Moreover, perhaps in anticipation of a change in power, the mandarins have moved forward the annual personnel changes in the major ministries’ top administrative positions.
And what of the LDP?
Having fallen from power, it will lose its control of the redistribution of government funds.
Unable to pay off its constituencies, disintegration looms, for the LDP has never been a party with entrenched grass-roots support, but instead operates as a machine of power and redistribution through a web of insiders across the country’s industrial sectors, occupational associations, and local communities.
Only by recruiting new blood and reorganizing itself with a solid ideological platform will an LDP comeback be possible.
The DPJ has even weaker grass-roots support, so the mandarins will most likely use their standard techniques of divide and rule to cajole the party by teaching it to mimic the LDP in using state money and contracts to underwrite its major constituencies, such as labor unions and other interest groups.
The birth of the DPJ government can yet be a turning point.
A major power shift in favor of “society” has taken place.
If the DPJ can break free of mandarin control by centralizing policy formation in the office of the prime minister, as it intends, Japan can emerge as a more resilient democracy with a full-fledged two-party system and greater willingness to assume an international leadership role.
A Jobless Recovery?
CAMBRIDGE – Who will suffer the longest and the most from the implosion in 2008-2009 of Wall Street and the ensuing world recession?
Not the bankers and financiers who created the disaster.
Some financiers, like Bernard Madoff, will go to prison for fraud.
But, although Madoff was only the tip of the iceberg of rampant financial malfeasance, most suspect financiers need not fear arrest, either because their behavior merely skirted the law, or because financial impropriety more subtle than outright fraud is often difficult to prove.
Some bank bosses will retire in shame, but with huge payments to ease their pain – such as the $55 million golden parachute handed to Bank of America’s Ken Lewis, with his, and the £25 million pension bestowed on Royal Bank of Scotland’s Fred Godwin.
But, buoyed by government bailout money, guarantees, and low interest rates, many banks have again begun to pay their top managers huge bonuses while fighting vigorously against reforms designed to restrain their risk-taking and compensation.
The big losers from this economic disaster are workers in the advanced countries that bought into the laissez-faire flexibility of American-style capitalism.
From 2007 to October 2009, the United States lost nearly eight million jobs, which reduced the employment-population ratio from 63% to 58.5%.
The unemployment rate at the end of 2009 was above 10%, duration of joblessness was the longest since the Great Depression, millions had had their working hours cut, and millions more were too discouraged by a lack of jobs to seek work.
Advanced Europe, Canada, and Japan also suffered major job losses that will last for a long time.
Spain, which allows for widespread temporary contracts, has had the biggest increase in unemployment, because Spanish workers can be fired as quickly as those in the US.
Some countries – for example, Germany, Sweden, and South Korea – have “hidden” their joblessness by paying firms to keep workers on the payroll.
This can work in the short term, but it cannot be sustained over time.
From the 1980’s through the mid-2000’s, employment has increasingly lagged GDP in economic recoveries.
In the US, there was a jobless recovery under President Bill Clinton until the dot.com boom in the latter part of the 1990’s, and there was a jobless recovery under George W. Bush in the wake of the 2001 slowdown.
In the early 1990’s, Sweden suffered a huge recession precipitated by a housing bubble and a banking crisis. Its unemployment rate rose from 1.8% in 1990 to 9.6% in 1994, before bottoming out at 5% in 2001.
Sixteen years after the crisis, the unemployment rate was 6.2% – more than triple the rate in 1990.
In 1997, Korea suffered not only from the Asian financial crisis, but also from insistence by the US and the International Monetary Fund that it raise interest rates and undertake “Washington Consensus”-style reforms to receive aid.
Employment recovered, but primarily in “non-regular” jobs with limited benefits, low wages, and little job security.
Inequality in Korea rose from moderate levels to second highest (behind the US) among advanced OECD countries.
Weakness in the job market takes a huge toll on economic and personal well-being.
Young people seeking their first jobs and experienced workers who lose jobs in a weak job market suffer economic losses that will last their entire lives.
Studies of happiness show that unemployment reduces happiness by as much as the loss of a family member.
It is difficult to see the US re-attaining full employment anytime soon.
From 1993 to 1998, the US created millions of jobs, which raised the employment rate by 5.4 percentage points.
If employment began rising at this rate in 2010, it would take until 2015 before it reached its pre-recession level.
And slow recovery in the US will drag down recovery in other advanced countries, reducing their employment as well.
A long, painful period of high unemployment runs counter to what most experts believed the flexible US economic model would ever produce.
From the early 1990’s on, many analysts viewed America’s weak unionization, at-will employment, limited legal job protection, and high job turnover as major factors in achieving a lower unemployment rate than most EU countries.
Many OECD countries initiated various kinds of flexibility reforms in the hope of improving their economies along US lines.
The view that flexibility is the key factor in employment is no longer tenable.
In its 2009 Employment Outlook , the OECD took a hard look at its favored policy reforms and found them deficient in helping countries adjust to a finance-driven recession.
According to the OECD, “there does not appear to be any strong reason to expect that recent structural reforms mean that OECD labor markets are now substantially less sensitive to severe economic downturns.”
So the lesson from the recession is clear.
The weak reed in capitalism is not the labor market, but the financial market.
At worst, labor-market failures impose modest inefficiency costs on society, whereas capital-market failures harm society greatly, with workers, rather than the perpetrators of financial disaster, suffering the most.
Moreover, globalization means that the US capital market’s failure spreads misery around the world.
We owe it to workers victimized by this recession to reinvent finance so that it works to enrich the real economy, instead of enriching only the financiers.
This means changing the incentives and rules that govern the financial sector.
Since other countries’ economies and jobs are also at stake, they owe it to their citizens to press the US to deliver meaningful financial reforms.
France’s Midsummer Night’s Dream
PARIS – Bastille Day, the French national holiday, was glorious this year.
The military parade, dominated by the celebration of “victory” in Mali and the joint participation of African and United Nations troops, had the perfection of a gracious, albeit muscular, ballet.
The classical concert that preceded the magisterial fireworks that ended the day was the closest thing to a French version of the Proms in London, mixing light classical and popular songs.
The Eiffel Tower imbued the evening with its magic.
Paris, in case anyone had any lingering doubts, remains the capital of the world – or so it seemed for a night.
The melancholia that began to seize France many years ago was all but forgotten.
The celebration of the glory of the past, mixed with popular English songs of the present, seemed to indicate renewed national confidence.
What was the meaning of this moment of grace?
Was it purely the product of a collective delusion, an emotional Potemkin village of sorts, encouraged, if not conceived, by the authorities to restore some level of self-assurance among France’s depressed citizens?
Even if the positive emotions remain only fleeting (as seems most likely), they were real and palpable.
The French seemed to be in the mood to celebrate.
Of course, it could simply have been the weather; a gorgeous summer has finally settled in after a miserable spring.
But it might also have been one of those natural turning points, a collective and spontaneous decision to say: “Enough of depression, let’s move on.”
We French may not be what we used to be, the celebrants seemed to be saying, but we are still much more than people think we are.
We have a great revolutionary past that still conveys universal values – liberty, equality, fraternity – and an army that, as in Mali, continues to make a difference in the world.
One can draw two lessons from this collective form of escapism.
The first is that, beyond the many layers of depression and distrust in France, there is potential for a new and collective departure.
This would require, of course, less cynical political elites who can transcend their petty ambitions and divisions for the sake of the country.
The second lesson, even more obvious, is that reality cannot be changed with a simple public spectacle.
France is not Imperial Rome, where panem et circenses made a fundamental difference.
It is a weakened democracy mired in an economic and social crisis so deep that it verges on becoming an identity crisis.
The proof was provided by a third traditional event on Bastille Day, between the morning’s military parade and the evening’s music and fireworks: President François Hollande’s speech to the nation, which took the form of an interview with two prominent journalists.
He, too, was in a reassuring mood.
According to Hollande, the economic upturn – la reprise – had just started, and hope was around the corner.
His tone and message had changed.
He was no longer the “normal man” of his election campaign and tenure until now; instead, he tried to present himself, like his predecessor, Nicolas Sarkozy, as a superhero.
Of course, given his personality and low public-approval ratings, his address was the least convincing event of the day.
Who could have said with certainty that the economic upturn announced by Hollande was real rather than aspirational?
Beyond his message’s wishful thinking, the public’s reaction to the messenger was a mixture of disbelief and indifference.
Seeing the behavior of friends, all French, listening with me to Hollande, I was reminded of another moment.
It was December 31, 1989, and I was in the Soviet Union.
I had found myself in a restaurant in the old city of Suzdal, listening to President Mikhail Gorbachev’s “New Year wishes.”
I was moved: The man who symbolized glasnost and perestroika, who had allowed the peaceful emancipation of most of Eastern and Central Europe, was speaking.
But I was alone in paying attention to him.
The restaurant’s customers, like my French friends now, could not have cared less.
Their president had become background noise.
Has Hollande become, in this sense, a French Gorbachev?
For the left and the Greens, he is close to being a traitor.
These voters chose him a year ago not only because he was not Sarkozy, but because he incarnated the values of the true left, even if his centrist moderation seemed a bad omen.
Voters of the center or even the center-right are disappointed, too, by their president’s lack of charisma, if not sheer incompetence.
After a year of Hollande, France is witnessing a fundamental political revolution.
During the half-century of the Fifth Republic, a bipartisan system of left and right has traditionally prevailed.
But now France is becoming a country dominated by a “tripartite system” of more or less equal strength: the left, the right, and the extreme right.
If France wants to capitalize on the positive emotions of Bastille Day, it needs much more responsible elites, ready to unite in the fight against unemployment and its causes (lack of competitiveness and labor-market rigidity) and consequences (the rise of populist, non-republican forces).
What Bastille Day revealed, even briefly and superficially, is that the potential to unite France exists.
But doing so requires more than shallow promises.
A Kick-Off for Peace?
Yerevan – Armenian President Serzh Sargsyan’s recent invitation to Turkish President Abdullah Gul to visit Yerevan to watch a football match together was historic.
Given the two countries’ long-strained relations, this visit would have been remarkable at any time.
But coming as it does only one month after the alarming Russian-Georgian confrontation, it may offer real hope that tensions in the volatile Caucasus region can be eased.
Of course, ancient and difficult issues divide Armenia and Turkey.
But now is the moment for both countries to put the past aside in order to address their common security concerns.
In the new context set by the war in Georgia, the urgency of Turkey becoming a real bridge between the nations of the Caucasus is not lost on anyone.
This expectation is an inevitable consequence of Turkey’s geography and history.
Situated figuratively between modernity and tradition, secularism and Islam, and democracy and tyranny, Turkey also is an actual physical bridge between East and West.
For the peoples of the Caucasus, Turkey marks our path to Europe.
It is a NATO member, bordering the three Caucasus republics that have NATO Individual Partnership Action Programs.
It aspires to join the European Union, and would bring the EU to our three borders, even as we, too, aspire to join one day.
Indeed, Turkey has never missed an opportunity to present itself as a regional broker.
Immediately after the collapse of the Soviet Union, Turkey proposed the Black Sea Economic Cooperation.
This year, as the American-led effort to mediate a Middle East peace settlement began to falter, Turkey took up the job of mediator in both the Israeli-Palestinian conflict and the conflict between Syria and Israel.
Now, in the immediate wake of the Russia-Georgia crisis, Turkey’s leaders have stepped forward once again to take a leadership role in the Caucasus.
The world must fervently hope that the Turkish proposal for a Caucasus Stability and Cooperation Platform is more serious and sustained than previous similar efforts.
But, in order to succeed, Turkey must firmly pursue a pledge from all the region’s players to repudiate the use of force in settling their disputes.
If this pledge is adopted and respected, conflicts in the region will be viewed in a wholly different, more tolerant context, marking a historic breakthrough to peace.
In fact, why not take the idea of such a pact one step further?
We in this region can, and I believe should, call for a non-aligned Caucasus, free of security blocs and adversarial alliances.
After all, security alliances and guarantees only create dividing lines, with their attendant security challenges.
Our countries and peoples have, throughout history, lived under a common umbrella for far longer than we have been divided.
Today, we share a common vision of European integration, and it is in this broader context that our conflicts should be resolved.
French President Nicolas Sarkozy’s and German Chancellor Angela Merkel’s visits to Georgia and Russia proved that there is no substitute for Europe insofar as the Caucasus is concerned.
Only Europe can play the role of honest broker in the region’s atmosphere of suspicion and intolerance.
But, at the end of the day, we ourselves must be willing to work toward a region of peace and cooperation.
The Caucasus is too small a space for closed borders and explosive conflicts.
Although some of those tensions appear purely bilateral, the Georgian-Russian conflict demonstrates that there is no such thing anymore in this globalized world, and certainly not in this interconnected region.
In fact, real peace in the Caucasus requires two key strategic transformations.
One is a lesson from history: Russia’s strategic interests here cannot be ignored.
To believe and behave otherwise would lead to regional chaos.
The other lesson is that Turkey and Armenia cannot remain adversaries forever.
There must be normalization in our relations in order for the Caucasus to coalesce into a functional region.
Ironically, both Russia and the United States recognize that this is in their interest.
The Russians view normal relations between Turkey and Armenia as a way to minimize Georgia’s strategic role in the region.
The US views an opening to Turkey as a way to decrease Armenia’s real and imagined reliance on Russia.
Beyond the emotional impact of President Gul’s visit to Yerevan, real improvement in Turkish-Armenian relations requires opening the two countries’ closed border – the last in Europe.
Or, for a start, the existing railroad link between the two countries could be made operational.
If this does not happen within the coming weeks and months, then Turkey will have demonstrated that all this was just a show.
President Gul’s visit does mark a watershed – either as a failure to make history, or as the beginning of a new era.
Truth and Consequences
NEW YORK – The recent re-election of Colombia’s president, Juan Manuel Santos, brings hope to a country seeking to end a half-century of conflict.
But, as with so many peace processes, finding a balance between creating a stable accord and acknowledging the terrible injustices that occurred during the conflict can be difficult to achieve.
Many countries and communities, from Nepal to Northern Ireland, have grappled with legacies of ethnic, ideological, or religious division and violence, often with limited success.
This is frequently the case because the mechanisms established to cope with post-conflict reconciliation, truth, and justice, have proved inadequate.
In Bosnia and Herzegovina, the International Criminal Tribunal for the former Yugoslavia (ICTY) has made important contributions to truth seeking.
But victims complain that its procedures are slow and abstruse; and many Bosnian Serbs are convinced that the tribunal is selective and politically motivated.
An agreement between Nepal’s government and Maoist guerrillas to establish a truth commission and investigate the “disappeared” was delayed for seven years.
When legislators finally enacted the enabling legislation in May 2013, victims were dismayed to discover that the commission would be allowed to recommend amnesties for crimes against humanity, in contravention of international principles and United Nations guidelines.
In Northern Ireland, the Good Friday Agreement, justly acclaimed for staunching the bloodshed and starting reconciliation, has – to the great frustration of victims – run into political resistance over one integral element of the peace process: the establishment of mechanisms to clarify past crimes.
Peace negotiators understandably fear that criminal accountability for past crimes will threaten their side’s leaders and supporters.
Many have wrongly assumed – based on a misinterpretation of the South African experience – that truth commissions provide a “soft” alternative to justice.
As a result, they have willingly incorporated these mechanisms into peace agreements (conveniently ignoring the fact that the victims are forced to choose between seeking justice and learning the truth).
Predictably, as truth commissions have become established components of transitional justice, former fighters have become increasingly worried that their reputations and political credibility could be on the line should past crimes ever come to light.
Seeking the truth can be unsettling and painful for anyone, but it comes with serious consequences for those with reason to fear justice.
Indeed, conflict mediation and transitional justice rely on truth commissions as a fundamental building block of peace not because such commissions provide impunity for the worst crimes; on the contrary, they reinforce comprehensive rights-based policies and access to justice.
As a recent symposium, organized by the Kofi Annan Foundation and the International Center for Transitional Justice, concluded, truth commissions contribute most to peace by reasserting the rule of law, recognizing victims, and supporting institutional reform.
But, in order to succeed, these commissions must be effective, independent, and legitimate.
Half-measures will not do.
Truth commissions therefore should never be established as “box-ticking” exercises to assuage local public opinion or the international community, as witnessed in Nepal.
Even when broad mandates and functions are established with the best of intentions, truth commissions are often deprived of the necessary resources, leading to further frustration and disillusion.
Moreover, a commission should not be led or staffed by individuals of questionable integrity, thereby undermining the legitimacy of the process.
Above all, truth commissions must be adapted to a country’s particular circumstances.
As we have seen in Bosnia, Colombia, Nepal, Northern Ireland, and elsewhere, the nature of conflicts and how they are resolved differ widely; so should their respective commissions.
A “one-size-fits-all” solution ends up fitting no one.
It is vital that the details of each case of post-conflict transitional justice are understood and implemented.
It is all too easy for political leaders to ignore victims or suppress the truth in their quest for a peace deal.
But recognizing victims’ rights is an indispensable condition for lasting peace.
Human suffering and victims’ dignity are too powerful to be erased by others’ political pacts.
Eventually, the past demands its due: justice is not just an ideal; it is an investment in a better future.
Alan Greenspan on Trial
The release of Alan Greenspan’s ghostwritten memoirs The Age of Turbulence has elicited charges that he was not such a great central banker after all.
Stan Collender of National Journal sees the fingerprints of the White House on these attacks: Greenspan is harshly critical of George W. Bush’s administration, after all, and to attack the credibility of Republican ex-policymakers who are critical of Bush is standard counterpunching for it.
But what is one to make of the criticisms of Greenspan’s tenure at the Federal Reserve?
The indictment contains four counts: that Greenspan wrongly cheered the growth of non-standard adjustable-rate mortgages, which fueled the housing bubble; that he wrongly endorsed Bush’s tax cuts; that he should have reined in the stock market bubble of the 1990’s; and that he should have done the same with the real estate bubble of the 2000’s.
To the first two counts, Greenspan now pleads guilty.
He says that he did not understand how the growth of non-standard mortgages had lured borrowers and investors into bearing dangerous risks.
He was, he now says, focusing on how fixed-rate mortgages are relatively bad deals for borrowers in times of low inflation, which was a mistake.
Greenspan also pleads guilty to a mistake in early 2001.
He thought that he was giving balanced testimony to Congress on government budget issues.
He testified that it is important to run surpluses to pay down the debt, but that surpluses must not be so large that the government winds up owning American industry.
He also testified that tax cuts are better than spending increases to keep surpluses from growing too large, but that uncertainty is enormous, so that any tax cuts should be canceled if they threatened to bring us back to an age of deficits.
Robert Rubin and Kent Conrad warned him that the press would not interpret his testimony as being balanced, and that Congress would interpret it as an excuse to abandon fiscal discipline.
They were right.
Greenspan also pleads guilty to misunderstanding the character of the Bush administration.
He thought that his old reality-based friends from the Ford administration were back in power.
He thought that he – and Treasury Secretary Paul O’Neill – could win the quiet “inside game” for sensible policy without resorting to an “outside game” that would make his reappointment in 2004 unlikely.
He was wrong.
But how serious are these policy-political crimes to which Greenspan now pleads guilty?
In my view, they are misdemeanors.
Against them you have to set what former Treasury Secretary Larry Summers calls Greenspan’s “golden glove” performance at avoiding and minimizing recessions during his years at the Fed.
The “felonies” of which Greenspan stands accused are the other two charges: that he should have done more to stop the stock market bubble of the late 1990’s, and that he should have done more to stop the housing bubble of the early 2000’s.
Here, Greenspan holds his ground, and pleads not guilty.
The only way, he says, for the Fed to have kept stock prices in reasonable equilibrium ranges in the late 1990’s would have been to raise interest rates so high that they hit the real economy on the head with a brick.
Interest rates high enough to curb stock market speculation would also have curbed construction and other forms of investment, raised unemployment, and sent the economy into recession.
To cause a significant current evil in order to avoid a possible future danger when our knowledge is limited and our judgments uncertain is, Greenspan believes, unwise.
In this, he is following a tradition of caution that extends from Edmund Burke to John Maynard Keynes.
Greenspan mounts a similar defense concerning the housing bubble.
High construction employment has been good for American workers in the past half-decade – a period that has not produced much good for them.
Higher interest rates to reduce the housing boom seem, even in retrospect, ill advised if the cost is mass unemployment.
And Greenspan eschews paternalism: he would not assume the role of a regulator telling people that they cannot buy a house even though a lender is willing to finance it.
But Greenspan would have served the country and the world better if he had been somewhat more paternalist in slowing the growth of non-standard adjustable-rate mortgages.
He would have served the country and the world better had he been less of a loyal Republican working the inside game of trying to convince Bush’s political advisors that good policy was important, and more of a nonpartisan steward of America’s long-term fiscal stability.
Of course, such a Greenspan would never have been re-appointed.
All in all, Greenspan served the United States and the world well through his stewardship of monetary policy, especially by what he did not do: trying to stop stock and housing speculation by halting the economy in its tracks.
A Lasting Poison
NEW YORK – Next year will mark the twentieth anniversary of the collapse of communism in Europe.
Liberated from the complexity of knowing too much about the cruel past, the young people of Eastern Europe’s post-communist generation seem uninterested in what their parents and grandparents endured.
Yet the recent revelation of the Czech writer Milan Kundera’s presumed complicity in the face of Stalinism is but the latest of the long half-life of a toxic past.
Other examples come to mind: the accusations of collaboration with the secret police raised against Lech Walesa, Romania’s public controversies surrounding Mircea Eliade’s fascist past, and the attacks on the alleged “Jewish monopoly of suffering” which equate the Holocaust with the Soviet Gulag.
Friedrich Nietzsche said that if you look in the eye of the Devil for too long, you risk becoming a devil yourself.
A Bolshevik anticommunism, similar in its dogmatism to communism itself, has from time to time run riot in parts of Eastern Europe.
In country after country, that Manichean mindset, with its oversimplifications and manipulations, was merely re-fashioned to serve the new people in power.
Opportunism has had its share in this, of course.
In 1945, when the Red Army occupied Romania, the Communist Party had no more than 1,000 members; in 1989, it had almost four million.
One day after Nicolae Ceausescu’s execution, most of these people suddenly became fierce anticommunists and victims of the system they had served for decades.
Residual traces of totalitarian thinking can also be found in the hostility to former dissidents like Adam Michnik or Václav Havel, both of whom argued that the new democracies should not exploit resentments or seek revenge, as the totalitarian state did, but instead build a new national consensus to structure and empower a genuine civil society.
Former generals of the secret police and members of the Communist nomenklatura, untouchable in their comfortable villas and retirements, must derive great pleasure from watching today’s witch hunts and manipulation of old files for immediate political purposes.
But the case of Kundera appears different – though no less disturbing.
In 1950, Kundera, then a 20-year-old Communist, reportedly denounced to the criminal police as a Western spy a man he had never met – a friend of his friend’s girlfriend.
The man was later brutally interrogated in a former Gestapo torture facility and spent 14 years in prison.
Kundera’s name was contained in the investigating officer’s report, which was authenticated after a respected historian discovered it in a dusty Prague archive.
The reclusive Kundera, who immigrated to Paris in 1975, has declared that “it never happened.”
Moreover, Czechoslovakia’s fearsome secret police, who had every interest in silencing or compromising the famous dissident writer, never used the incident to blackmail or expose him.
Until more information is forthcoming, both from Kundera and from the authorities, the case will not be solved “beyond reasonable doubt.”
But if it happened, the case calls for a deeper reflection.
As far as we know, Kundera never was an informer before or after this incident, and we cannot ignore that he later freed himself from the compulsory totalitarian happiness that communism propagated.
Indeed, his case also serves as a reminder that the early 1950’s was the most brutal period of “proletarian dictatorship” in Eastern Europe – a period of great enthusiasm and terrible fear that poisoned the minds and souls of devoted believers, fierce opponents, and apathetic bystanders alike.
Moreover, Kundera’s case is hardly unique.
In 2006, the Nobel Prize-winning German author Günter Grass’s disclosed that, 60 years earlier, he was, as a teenager, a member of the Waffen-SS.
Similarly, a few years ago, the world was shocked to learn that famous Italian writer Ignazio Silone had, in his youth, collaborated with the fascist police.
Daily life under totalitarianism, be it communist or fascist, was routinely based on a deep duplicity whose effects are longstanding.
I don’t agree with those who say we should not be interested in the dark episodes in the life of a great writer.
Why not?
We should be interested not for prosecutorial purposes, but in order to gain a more profound understanding of a bloody, demagogical, and tyrannical Utopia – and of human weakness and vulnerability. We may even consider it a rewarding testament to an artist’s ability to overcome his past mistakes and still produce priceless work.
But can we justifiably defend morally compromised artists and intellectuals on the basis of their work’s merit, yet condemn ordinary people for often less grave offenses?
An egregious example of this was the way followers of Romanian philosopher Constantin Noica defended his support for the fascist Iron Guard and his later collaboration with the Communists, while at the same time condemning even a generic cleaning woman for mopping the floors in the offices of the secret police.
Shouldn’t that cleaner’s drudgery to support her family, children, and her own survival be taken equally into account?
Life under totalitarianism was an extreme situation that requires us to apply special, nuanced rules to all the captives of that ordeal.
In order to understand that epoch, we have to know and carefully judge often ambiguous and overwhelming circumstances, never simplifying a multilayered daily reality for the sake of current political goals.
If nothing else, in order to forgive, we have to know what we are forgiving.
In Eastern Europe today, old and young alike stand to benefit from that lesson.
Moses wandered with his people in the desert for 40 years, until they had rid themselves of the poisonous slave mentality.
The Albanian Miracle
TIRANA – Five years ago, Albania faced a truly ominous situation.
With Greece and Italy reeling from the euro crisis, remittances and capital inflows were falling and the economy suffered a severe slowdown.
The fiscal deficit ballooned to over 7% of GDP, financed to a large extent by arrears, as access to external financial markets had collapsed and domestic interest rates were sky high.
In addition, the power distribution company was in both an operational and a financial crisis, unable to pay for the electricity that it was supposed to buy from power generation companies.
The arrears of both the government and the power company were fueling an increase in non-performing loans in the banking system.
All the ingredients of a catastrophic outcome were there.
Fast-forward to the present: the economy is growing at a robust 4.2% rate, led by double-digit export growth in agriculture, mining, manufacturing, energy, tourism, and business services.
At a time when emerging-market economies as diverse as Argentina, Turkey, Nigeria, and South Africa face plummeting currencies and rising interest rates, Albania has its lowest interest rates on record and a strengthening currency.
It now has the lowest sovereign spread for any country in its rating class, indicating that markets think the rating agencies have been asleep at the wheel.
Once the North Korea of Europe under Communist dictator Enver Hoxha, Albania’s per capita income level is now 25% that of Germany.
If it can maintain its current growth rate, it will reach Germany’s current income in 32 years.
At a time when economists are being blamed for all sorts of disappointing outcomes, and multilateral institutions such as the International Monetary Fund and the World Bank are accused of failing to advise countries properly, it is refreshing to find that they may not be entirely useless after all.
What was the secret of Albania’s turnaround?
First, as opposed to many countries that delay action until it is too late, Prime Minister Edi Rama called in the IMF as soon as he got into power in September 2013.
His government then negotiated a program that allowed Albania to gain financial support while it was putting its fiscal house in order.
The three-year program ended successfully almost two years ago, and the debt-to-GDP ratio remains on a downward trend.
This year, it is declining by 2.5% of GDP, while the country is significantly expanding its public investment budget.
To be able to grow in the midst of fiscal consolidation, something else has to pull the economy forward, typically exports.
And exports are growing in Albania – where I have been leading a Harvard Center for International Development research effort since 2013 – not because of good luck, but thanks to a relentless effort to remove bottlenecks and seize opportunities.
In the process, Albania eschewed the temptation to focus on general Doing Business indicators, which assume that randomly following international best practices might do some good.
Instead, the authorities followed a diagnostic approach to prioritize their policies.
Mentored by Matt Andrews of Harvard Kennedy School of Government, policymakers used an implementation strategy based on a problem-driven iterative process, which starts by nominating a problem, identifying its causes, and devising ways to fix it.
This led to many ideas that proved to be powerful.
In agriculture, the development of aggregators helped small farmers connect to better technologies and more lucrative markets, creating a boom in vegetable exports.
In the power sector, the government adopted an unorthodox strategy to change citizens’ behavior regarding electricity theft and non-payment, which led in 2015 to a turnaround of almost 2% of GDP in the distribution company’s cash flow.
Likewise, consultative groups in manufacturing and tourism identified areas for improvement.
Albania has invested in the recovery of its historic cities and is now investing in 100 villages with strong agro-tourism potential that happen to be in areas that are both poor and pristine.
No wonder that tourism is growing at double-digit rates.
Moreover, the country’s ambassadors are now being used in a concerted strategy to promote foreign investment through direct engagement with firms.
And policymakers are now engaging Albania’s diaspora – found to be an important source of talent, investment, market opportunities, and business ideas – to great effect.
The innovations have not been only at the national level.
Erion Veliaj, the mayor of Tirana, has tripled municipal revenues since he took over in 2015 and used the proceeds in ways that have made the city one of the most pleasant in the region.
Albania’s capital has won European awards for its development of high-quality urban spaces and for solving mobility and environmental problems in innovative ways.
The lessons for other countries are clear.
Success in the face of difficulties happens when governments are conscious of their predicament and their weaknesses, can articulate and own their goals, and search relentlessly for ways to achieve their aspirations.
In this process, countries are not alone.
The system of international financial assistance led by the IMF and the development-finance institutions can be very helpful.
But countries must figure out when and how best to use them.
They can enhance government capacity but cannot substitute for government commitment.
The lesson for the European Union is also clear: when thinking about accession countries like Albania and the rest of the Western Balkans, it is important to look not only at what these countries are or have been, but also at the zeal with which they act in order to become what they aspire to be.
For much of its history, Albania looked hopeless.
But hopeless is as hopeless does.
Now Albania’s turnaround is a source of hope for the rest of us.
Toward a More Reflective Planet
CAMBRIDGE – The last time the atmosphere held as much carbon dioxide as it does today was about three million years ago – a time when sea levels were 10-30 meters higher than they are now.
Climate models have long struggled to duplicate those large fluctuations in sea levels – until now.
Indeed, for the first time, a high-quality model of Antarctic ice and climate has been able to simulate these large swings.
That is smart science, but it brings devastating news.
The new model shows that melting in Antarctica alone could increase global sea levels by as much as one meter (3.2 feet) by the end of this century – well above prior estimates.
Worse, it suggests that even extraordinary success at cutting emissions would not save the West Antarctic Ice Sheet, locking in eventual sea-level increases of more than five meters.
As little as one meter could put at risk entire cities, from Miami to Mumbai, and cause enormous economic disruption.
We need to turn down the heat – and fast.
To this end, albedo modification – a kind of geoengineering intended to cool the planet by increasing the reflectivity of the earth’s atmosphere – holds tremendous promise.
Injecting synthetic aerosols that reflect sunlight into the stratosphere, for example, could help counter the warming caused by greenhouse gases.
The mechanism is similar to wearing a white shirt in the summer: white reflects sunlight and cools what is underneath, whereas darker colors absorb sunlight and heat.
To be sure, even in the best-case scenario, solar geoengineering alone could not stabilize the world’s climate.
For that, we must both stop pumping carbon pollution into the atmosphere and learn how to remove what is already there.
That is why emissions cuts should receive the lion’s share of resources devoted to combating climate change.
But, as the recent study shows, emissions cuts alone cannot save the West Antarctic Ice Sheet and prevent a drastic sea-level rise.
If they are pursued in conjunction with moderate albedo modification, however, there is a chance of halting rising temperatures, helping to keep the world under 1.5° Celsius above pre-industrial levels, the more ambitious target agreed at the Paris climate talks last December.
(It should be noted that, given carbon-cycle feedbacks, such as the thawing of permafrost, there is a chance that the world would face a 1.5°C rise, even if emissions were eliminated today.)
Most of the world’s state-of-the-art climate models have explored albedo modification, and each of them has found that the process does have the potential to mitigate climate change.
Beyond limiting total warming, it can help to check the rise in peak temperatures, decreasing the risk of destructive heat waves.
And it seems to be particularly effective at reducing extreme rainfall, which holds profound implications for minimizing flood damage.
Albedo modification remains uncertain and risky, owing partly to a dearth of organized research into the subject.
And, in fact, albedo modification would undoubtedly make some things worse.
But there is not a single climate model run that shows that a moderate intervention would make any region worse off overall.
Moreover, the large potential upside, measured in trillions of dollars, contrasts with low direct costs – in the single-digit billions for full-scale deployment.
In fact, albedo modification is so cheap that direct costs will not be the deciding issue.
Instead, it is a risk-risk trade-off – one that will require more research to assess.
Given the lack of knowledge, no sensible person would push for deploying albedo modification today.
But it would make no sense to ignore its potential.
After all, no one would argue that we should abandon research on a promising cancer drug because it is unproven.
The US National Academy of Sciences first called attention to what it then described as “climate modification” in a 1983 report.
It recommended careful research in 1992 and again in 2015.
Major environmental groups such as the Environmental Defense Fund and the Natural Resources Defense Council support careful, small-scale research.
Yet no such program exists.
One reason for this is concern about the diversion of resources from other approaches.
And, of course, there are tradeoffs.
But the US, for example, has an annual climate science budget of around $3 billion.
An exploratory solar geoengineering program, costing only a few tens of millions of dollars per year, is entirely feasible.
A larger obstacle to progress is fear that more attention to geoengineering solutions would sap motivation to cut emissions.
Maybe so, but it would be barking mad to take up smoking simply because an experimental cancer treatment showed some promise on a lab rat.
And, in fact, it is conceivable that a concerted effort to advance research on albedo modification could spur action to cut emissions, much like a graphic look at the side effects of chemotherapy prompts some to stop smoking.
Whichever reaction prevails, the moral imperative to explore a technology that can protect the poorest and most vulnerable this century would seem to trump amorphous concerns that doing so could weaken the incentive to pursue solutions that would largely benefit future generations.
China has initiated a limited research program on albedo modification.
The US has not.
Given that albedo modification is the kind of technology that necessitates an open, transparent, and international research effort – precisely the kind of effort in which the US excels – this is a serious failing.
The US government should take the lead now in researching albedo modification.
Even if the result was that albedo modification does not work, the dividends of such research would be enormous, owing to the added pressure to cut emissions.
And if it turned out to be successful, the social, environmental, and economic returns would be tremendous.
India’s Prohibition Hypocrisy
NEW DELHI – Last month, 18 people in the Gopalganj district of India’s Bihar state died after consuming illicit alcohol, highlighting – once again – the peculiar relationship between morality and tragedy in India.
The victims were poisoned because this April, in a fit of moralism, Bihar adopted a draconian law prohibiting the sale, possession, and consumption of alcohol.
It is far from the first such ban that has ended badly.
In a country where the national hero is the saintly Mahatma Gandhi, who considered alcohol an unmitigated evil, drinking has always carried a whiff of disrepute.
India’s constitution, in its non-enforceable Directive Principles, urges Indians to work toward prohibition, and the government does not serve alcohol even at state banquets and official receptions.
Four out of 29 Indian states (Bihar, Gujarat, Manipur, and Nagaland) and one union territory (Lakshadweep or the Laccadive Islands) are currently attempting to enforce total prohibition.
But maintaining a sweeping prohibition policy has long proved difficult in India.
In Manipur in 2002, the 1991 ban was lifted in five hill districts, where alcohol consumption is a centuries-old local tradition.
Lakshadweep makes an exception for an uninhabited island, where a tourist resort is allowed to operate a bar.
When I was a child, what was then Bombay excused anyone with a doctor’s note confirming alcoholism.
(Well-heeled executives tripped over themselves to be labeled alcoholics.)
The state that best illustrates the appeal and the pitfalls of such moralism is Kerala, which announced in 2014 that it was implementing a partial ban on the sale of alcohol, with the goal of achieving total prohibition in ten years.
It has been backsliding ever since.
A coastal state, Kerala has long been viewed as a tourist paradise – a reputation no doubt kept afloat on a sea of easily available libations.
Before the ban, Kerala held a somewhat dubious distinction: India’s highest per capita consumption of spirits.
But in India, where prohibition is popular among many segments of the electorate, politicians find it particularly difficult to resist the self-righteous urge to improve their fellow citizens.
So Kerala’s government introduced the ban.
And, at first, many approved.
The influential Christian churches applauded the move, as did the Christian-affiliated political parties.
Kerala’s Muslim leadership, including the then-ruling coalition’s ally, the Indian Union Muslim League, was equally vocal in its support.
Working-class women, tired of watching their laborer husbands blow their monthly wages on booze, also welcomed the decision, as did traditionalists, Gandhians, and other moralists, of which India has an abundance.
No public figure of any consequence in Kerala stood up to oppose the decision.
Any politician who might have been inclined to do so knew that they would be instantly tarred as a votary of evil alcohol, an agent of the “liquor mafia,” a bar-loving enemy of good, wholesome Gandhian values.
But there were good reasons to oppose the ban – reasons that had nothing to do with religion, morality, or alcoholism.
Excise duties on liquor account for 22% of the state revenues that sustain generous welfare programs in Kerala, which boasts the best social development indicators in India.
Another 26% of state revenues come from tourism, which would surely also take a hit.
Furthermore, much of Kerala’s economic viability depends on dynamic knowledge and services sectors.
Attracting talent and investment from abroad would become much more difficult if prohibition hampered the state’s quality of life.
(IT professionals in Bangalore, in the neighboring state Karnataka, flock to that city’s bars and pubs after long hours at work.)
Kerala’s leaders should have known that their state could not afford to do without widely available, heavily taxed liquor.
But they began to implement the policy anyway.
Almost immediately, 20,000 bar workers and distillery employees lost their jobs, in a state that already struggles with high unemployment.
Tourism operators were stung by cancelations, as would-be visitors decided to visit Sri Lanka or Goa instead; 50% of existing convention bookings were canceled.
And IT companies contemplating moving to clean, green, tech-friendly Kerala expressed concern about the prohibition policy.
It was not long before Kerala’s government decided that prohibition would apply only to hard alcohol, and closed bars could reopen as wine and beer parlors.
But that was not enough to save the government in June’s state election, which produced a new communist administration that, advocating education about the evils of alcohol instead of a ban, has promised to review the prohibition policy.
So Kerala is no longer hurtling toward disaster in the name of saving people from themselves.
But it never should have gone as far as it did, given experience with prohibition in other states, where falling revenues and rising crime (including smuggling, tax evasion, and illicit liquor production) forced its revocation.
Four states – Andhra Pradesh, Haryana, Mizoram, and Tamil Nadu – have repealed prohibition policies.
To be sure, not everyone loses out from a prohibition policy.
When Kerala first announced its plans, neighboring Tamil Nadu’s alcoholic beverages corporation, TASMAC, promptly declared its intention to open a string of new outlets along the states’ border, to cater to the demands of Keralite consumers.
In other words, excise duties from Kerala would now fill Tamil Nadu’s coffers.
Banning alcohol in India has been economically devastating.
Yet politicians continue to use the promise of prohibition to win votes.
When elections were called in Tamil Nadu early this year, its chief minister declared herself in favor of prohibition.
After the election was won, however, all such talk discreetly subsided.
My late father liked to say: “India is not only the world’s largest democracy; we are also the world’s largest hypocrisy.”
I suppose we can drink to that.
Leaders for a Leaderless World
PARIS – The newspaper commentaries that I write often have a dark perspective.
Sadly, this one will be no different.
But there are two pieces of good news that break through the gloom.
First, the global significance of US President Barack Obama’s reelection is clear: the world has escaped a disaster for international cooperation.
The US was on the verge of sinking into isolationist nationalism, reinforced, perhaps, by xenophobic sentiment.
Obama’s victory, despite America’s economic travails, clears the way for cooperation based on a sympathetic ear to others and on negotiations in which the US does not deny the legitimacy of a global public interest (as it has done, unfortunately, on the issue of climate change).
The other piece of good news concerns France, and thus is more “local,” but is crucially important nonetheless.
Like everywhere else in the developed world, the global crisis has hit the French economy hard, with output stagnating, unemployment rising, job insecurity mounting, government debt soaring, and the stock market at risk of crashing.
Manufacturing production has plummeted, the trade balance has deteriorated sharply, and corporate bankruptcies are increasingly frequent.
For six months, France has had new leadership – a new president, government, and parliament.
But President François Hollande and his government were strangely inactive after the elections, limiting themselves to reducing the impact of unfair budget cuts and taxation reforms implemented by the previous government of Nicolas Sarkozy.
Many began to wonder whether Hollande was aware of the scope of the crisis that the recent downturn might trigger.
In recent weeks, however, the government has introduced energetic and courageous measures to boost the competitiveness of French industries, including a huge €20 billion ($26 billion) tax break for businesses, to be financed by a hike in value-added tax, which means that the general public will pay for it.
The VAT increase will hurt, but there was no other way.
Awareness, boldness, and comprehensive policymaking have come as a relief to French investors, and have left them better positioned to face the crisis.
The French government’s new push to confront the country’s economic plight matters not only to France, but to Europe and the world as well.
After all, France is the eurozone’s second-largest economy, and the fifth-largest economy in the world.
And yet, despite these bright spots, international cooperation on issues ranging from regional conflicts to the protection of global public goods remains weak.
Antarctica, the only land in the world that is administered directly by the international community, is a recent case in point.
The Antarctic Treaty, negotiated in 1959, prohibits any and all military activities in Antarctica and forbids the establishment of any borders.
Three agreements – the Convention for the Conservation of Antarctic Seals (1972), the Convention on the Conservation of Antarctic Marine Living Resources (CCAMLR, 1980), and the Protocol on Environmental Protection to the Antarctic Treaty (PEP, 1991), which prohibits any activity relating to mineral resources – have since been added to the treaty.
The Antarctic Treaty System includes three annual meetings: one deals with the supervision and management of the Treaty itself, and the other two concern the CCAMLR and the PEP.
In recent years, proposals have been considered that would establish marine reserves around the continent and end the risk of growing scarcity, or the outright disappearance, of a variety of species of fish and cetaceans.
The principle that international cooperation is required to protect fishery resources, which are dwindling everywhere, was adopted at the 2011 CCAMLR meeting.
At the 2012 CCAMLR meeting, which concluded at the beginning of November in Hobart, Australia, three proposals (from the US, New Zealand, and France/Australia) to establish marine reserves in three different areas were discussed.
They were compatible and would reinforce one another.
Yet the discussion foundered, and no decision was taken.
Russia and Ukraine – and, to a lesser extent, China – blocked efforts to reach an agreement.
This failure reflects the same dynamic at work in the breakdown of global climate-change conferences in recent years: a few cynical countries, whose cooperation is needed to save the planet, fuel the madness of those bent on destroying it.
That will not change until a new consciousness emerges worldwide to persuade states to support binding international law.
The US has now reelected a president who understands this.
France has a president who understands the need for bold, far-reaching actions as well.
Their active leadership, and that of others, is needed now more than ever to turn the tide.
Assured Mutual Dependence
LONDON – During the Cold War, the certainty of “mutually assured destruction” steered the nuclear arms race away from catastrophe: a would-be attacker would face immediate retaliation, inevitably ending in both sides’ annihilation.
Today, a very different race is taking place – a race for the earth’s vital resources, and it threatens to undermine stability in key regions of the world.
The growing dependence of countries on one another’s food, water, and energy requires that the global response to sustainability is taken to the highest political level.
Unlike the nuclear arms race of the twentieth century, the resource-security agenda is not linear.
Mutually assured destruction was explicitly acknowledged during the Cold War in statements from both sides.
In the race for resources that defines the twenty-first century, no actor is directly or indirectly threatening other players to curtail food or energy exports, but all bear the systemic risks.
Countries have become unavoidably interdependent, and climate change, water stress, and the loss of ecological resilience all increase the volatility of this mutual dependence.
In a world of limited and scarce resources, countries and companies will be forced to make decisions that affect one another’s security.
In order to navigate this interdependence, the Earth Security Index 2014, produced by the Earth Security Initiative, shows countries’ combined vulnerabilities that might increase the risk exposure of governments and companies, unless more strategic approaches and sustainable investments are put in place.
The ESI identifies four areas of mutual dependence that will likely shape global security in the coming decades:
·         Choke points.
Countries’ growing demand for energy, water, food, and land cannot be satisfied without incurring tradeoffs among limited available resources.
Choke points are reached when the available resources are insufficient to satisfy demand.
In China and India, for example, this means that in certain regions there may not be enough water in the short term to run coal-fired thermal power stations and irrigate large fields to grow crops.
In China, 60% of planned coal-fired power plants will be built in water-stressed regions.
·         Food.
The growing dependence of many countries on food, water, and energy imports creates new opportunities for trade and investment, but it also exposes countries to critical vulnerabilities.
Australia, for example, is a large coal exporter but imports most of its refined fuels and holds just three days of fuel stockpiles.
The challenges of mutual dependence are particularly acute with respect to food.
As the ESI shows, some countries – including Egypt, Peru, and the United Arab Emirates – are heavily dependent on cereal imports from a small number of suppliers.
Moreover, grain suppliers’ exposure to extreme weather may compromise their ability to sustain supplies, with knock-on effects for import-dependent countries.
In 2010, for example, Russia imposed an export ban on wheat, following a severe drought.
The resulting food-price increases are believed to have played a role in Egypt’s revolution.
·         Teleconnections.
Anticipating systemic ecological risks will be increasingly important for sectors such as reinsurance and infrastructure investments.
“Teleconnections” refer to weather events that are related to one another over large geographic distances.
They are well known to science but not properly discussed by the industries, investors, and governments whose security depends on environmental stability.
For example, tropical rainforests play a crucial function in maintaining stable weather and rainfall, acting as a “pump” that helps moisture travel between different regions.
Deforestation can thus have a destabilizing effect on weather patterns, amplifying the frequency and severity of extreme events such as floods and droughts.
The resulting liabilities to key industries and the financial sector are clear.
In Brazil, for example, deforestation in Amazonia has slowed significantly over the last five years, but Brazil has already lost more than 11 million hectares of rainforest; its exposure to extreme weather has also steadily risen, with floods causing $4.7 billion in losses in 2011 alone.
·         Land productivity bottlenecks: Agriculture systems are reaching resource limits, and persistent governance gaps compromise their ability to ensure food security, dignified livelihoods, and ecological stewardship.
Companies, investors, governments, and communities confront a series of critical barriers to increasing the food availability that the world needs: Local populations’ insecure land ownership; receding water tables, owing to unsustainable extraction rates; inefficient use of pollution-causing inputs like fertilizers and pesticides; the loss of vital ecosystems, affecting the resilience of food production; and certain areas’ inability to cope with extreme weather.
In some regions of India, for example, these issues are playing out in tandem.
Insecure land tenure acts as a disincentive for smallholder farmers to commit to productivity-enhancing investments; water extraction rates are depleting aquifers as a result of permissive policies; and food security remains out of reach for millions of people, despite rapid economic growth in urban areas.
Countries and companies will increasingly need to invest in sustainable land in order to hedge their resource risks.
In 2015, global frameworks are due to be agreed to address climate change, coordinate responses to natural disasters, and guide the world’s development agenda.
Some of these multilateral processes – in particular, those seeking an ambitious global climate agreement – appear to be moving in slow motion and against the grain of geopolitical interests.
In the past, the case for high-level nuclear governance was urgent and clear, but required processes for creating a common understanding of risks and opportunities across national borders.
Successful multilateral responses, like the Nuclear Non-Proliferation Treaty, continue to be supported by more flexible global platforms, such as the Nuclear Threat Initiative, based on relationships and trust established outside the box of formal multilateralism.
This year, as world leaders discuss the next generation of sustainability, development, and climate frameworks, they will need to put their security and mutual dependence at the heart of the responses.
Here, too, the world will need to create informal platforms that supplement traditional multilateralism.
In particular, the outdated divisions between rich and poor countries and their responsibilities must be revised.
As new powers like China, Brazil, India, and other G-20 economies bid to reform global governance systems, their vulnerability to resource security must invigorate these processes.
Only then will the world be on track to improve the security of all.
After Aleppo
DENVER – The end of the fighting in Aleppo will not end the Syrian war, despite the countrywide ceasefire that has just been agreed.
Nor will it ease the suffering of the city’s population, much of which has been displaced.
What the Aleppo siege will do is clinch Syria’s place in history as, to borrow former US Secretary of State Warren Christopher’s phrase, another “problem from hell.”
And, like other hellish recent regional conflicts, such as those in Bosnia (to which Christopher was referring) and Rwanda, future historians will emphasize a crucial feature of the Syria conflict: the spectacular diplomatic failures that enabled it to escalate.
Good diplomacy begins with a keen analysis of interests, both of the country in question and of relevant external powers.
It demands a careful assessment of how the pursuit of those interests will affect the regional and international order.
And it seeks ways to strengthen the capacity of regional or world powers to help solve problems.
Throughout this process, universally shared and consistently reinforced values – both critical in getting disparate actors to work together to resolve problems and challenges – must provide a moral compass and common ground for action.
The key is to ensure that values do not become weapons, deployed by one actor against another in a way that exacerbates tensions and undermines solutions.
Consider the 1990s Bosnian War – the result of unfinished business from the breakup of the Austrian and Ottoman empires and the creation of nation-states earlier in the twentieth century.
The conflict erupted in the immediate aftermath of the Cold War, at a moment when one set of international organizing principles had collapsed and a new set had not yet been created.
Partly as a result of this, the conflict was characterized by large-scale civilian carnage and human-rights violations.
But, as a test for the new world order, the Bosnian War ended up catalyzing change in the international community’s institutional structure (including the establishment of war crimes tribunals).
Could the nascent post-Cold War system handle the inchoate problems of the former Soviet Union?
Could NATO take on new roles and missions?
Could the West work with the new Russian Federation?
Could the transatlantic relationship weather the storm?
The answer to all of these questions turned out to be yes.
As a result, though the region continues to be beset by serious problems, the gates of hell have remained closed – as they have in Rwanda.
And yet, just 20 years later, it seems that the world’s collective memory of how to cooperate has failed.
To be sure, there was never a clear path to peace in Syria.
President Bashar al-Assad, whose forces now control all of Aleppo for the first time since 2012, is a brutal dictator who has waged war on his own people, including civilians, and has even used chemical weapons.
The temptation to seek regime change – a goal embraced by the United States and some European countries – was understandable.
Yet, in a display of spectacularly incompetent diplomacy, the US set about pursuing that goal without any serious effort to marshal international support, or even to take stock of other opinions or interests.
And make no mistake: there are a lot of (often conflicting) opinions and interests.
After all, Syria is strategically perched on the Mediterranean; shares borders with Israel, Jordan, Turkey, and Iraq; and, like Iraq, has its own restive Kurdish minority.
It is not the kind of country to which international and regional powers would be indifferent.
In fact, when Western powers called for regime change, other actors – including Iran, Russia, and Shia interests in neighboring Lebanon – objected.
Nonetheless, the US soldiered on with its own poorly formulated agenda, supplying weapons to virtually unknown combatants on the ground before properly vetting them.
That gave the Assad regime’s allies all the justification they needed to supply weapons of their own.
Some argue that, if the US had just provided more weapons sooner, Assad would not have had time to galvanize support and hold onto power.
But that neglects the strategic importance of Syria to so many external powers, as well as the fragmentation and unpredictability of the US-based combatants.
America’s real mistake was failing to engage with all sides, including Assad and the Sunni opposition, which it deemed sectarian.
(During the Bosnian War, by contrast, the US talked to rump Yugoslavia’s ruler, Slobodan Milošević.)
With that narrow-minded approach – reflected in the lack of any articulated vision for a post-war Syria – the US effectively handed the diplomatic reins over to Russia.
Now, the US is essentially playing the role of agitator, offering little more than displays of moral outrage and stale references to a stillborn Geneva process.
Reacting to the carnage in Aleppo, Samantha Power, the US ambassador to the United Nations, was reduced to demanding of Assad’s Russian ally, “Are you truly incapable of shame?”
Meanwhile, the conflict rages on, with severe spillover effects on US allies like the European Union.
As for Russia, it, too, is pursuing a version of diplomacy that utterly lacks inclusiveness.
It is working with Turkey (a NATO member that seems increasingly lost at sea) to bring the Syrian opposition and representatives of the Assad government together in Kazakhstan for a new series of peace talks, facilitated by the ceasefire, of which Russia and Turkey are guarantors.
Iran will be there.
But where are the Sunni Arab states?
More important, where is the US?
It is often observed that, every four years, the US does without a foreign policy.
This time, it seems to have gotten an early start.
Alexander Hamilton’s Eurozone Tour
PRINCETON – Europe’s debt crisis has piqued Europeans’ interest in American precedents for federal finance.
For many, Alexander Hamilton has become a contemporary hero.
Perhaps one day his face should appear on the €10 banknote.
Specifically, for European states groaning under unbearable debt burdens, Hamilton’s negotiation in 1790 of the new federal government’s assumption of the states’ large debts looks like a tempting model.
Indeed, after Thomas Sargent won the Nobel Prize in Economics last year, he cited it as a precedent in his acceptance speech.
Hamilton argued – against James Madison and Thomas Jefferson – that the debts accumulated by the states during the War of Independence should be assumed by the federation.
There were two sides to his case, one practical, the other philosophical.
Initially, the most appealing argument for his plan was that it would provide greater security to creditors, and thus reduce interest rates, from the 6% at which the states financed their debt to 4%. Hamilton emphasized the importance of a commitment to sound finance as a prerequisite to public economy.
“When the credit of a country is in any degree questionable,” he argued, “it never fails to give an extravagant premium upon all the loans it has occasion to make.”
While that logic certainly appeals to Europeans today, Hamilton insisted on a stronger reason for pursuing sound finance than merely the pursuit of expediency.
There is, he maintained, “an intimate connection between public virtue and public happiness.”
That virtue consisted in honoring commitments, and it would build solidarity in the new political community of the United States.
Indeed, public virtue made federal finance what he called “the powerful cement of our union.”
The condition for success in the American case was that the US raised its own revenue, with federally administered customs houses initially providing the bulk of its receipts.
The logic of a need for specific revenue applies also in modern Europe, where a reformed fiscal system might include common administration of value-added tax (with the additional benefit of eliminating a considerable amount of cross-border fraud).
In the American case, however, unity carried a price: a ceiling was imposed on Virginia’s exposure to the common debt.
Only this inducement to the most powerful state in the union persuaded Madison to drop his opposition to the proposal.
That compromise (which also led to the US capital’s relocation to the District of Columbia, on the border of Virginia and Maryland) may serve as a precedent for limiting Germany’s liabilities if Eurobonds, or some other debt-mutualization scheme, are introduced.
The US experiment in federalized finance was not immediately successful.
Two important components of Hamilton’s financial architecture were not realized, or were realized imperfectly.
He proposed a model of joint-stock banking on a national scale, which ran into immediate opposition (curiously, his proposal was much more influential in Canada).
Second, opponents eventually blocked his proposal for a national central bank.
The charter of the First Bank of the United States was allowed to lapse in 1811; a generation later, in 1836, President Andrew Jackson successfully opposed the charter of the Second Bank of the United States.
Nor did the Hamiltonian scheme of federal finance guarantee a peaceful commonwealth.
In fact, the fiscal union proved to be explosive rather than adhesive.
As international capital markets developed in the early nineteenth century, state governments borrowed on a large scale, quickly turning them from creditors into debtors.
A wave of state defaults followed in the late 1830’s.
A generation later, in the 1860’s, the Civil War between northern and southern states resulted in large part from a dispute about the character of financial burdens –amp at least from the South’s perspective.
Abraham Lincoln’s original proposal to end the immoral practice of slavery by compensating slave owners for manumission was unacceptably expensive, so the Union, according to the slave-holding Confederacy, was determined to expropriate the South.
The federal assumption of states’ debts by itself could not guarantee political order.
The Civil War revealed the centrality of a common foundation of morality to Hamilton’s approach to debt and public finance.
As a result, his approach foundered on the differences between the different states’ conception of morality.
Europeans today have latched onto the practical side of Hamilton’s argument – that is, the idea that debt mutualization might be a means to cheaper credit; but they have worked out neither the political institutions, nor the shared public virtue, that Hamilton deemed crucial.
The extended and politicized debate about debt restructuring has made a Hamiltonian solution more difficult, because the credit of the countries that would be party to it has become questionable.
An obvious starting point for a Hamiltonian Europe would be to set some standard limit for federalized national debt – perhaps the tarnished threshold of 60% of GDP that was mandated (without adequate enforcement) by the Maastricht convergence criteria, or perhaps a lower limit.
Debt exceeding that amount would be left to the responsibility of the member states.
Collective burden-sharing is in the long run the only non-catastrophic way out of Europe’s current crisis, but that requires a substantially greater degree of political accountability and control on a European level.
The lesson to be learned from Hamilton and the US is that the necessary institutions will not function without a greater degree of moral consensus as well.
Can Navalny Save Russia?
MOSCOW – In 1811, assessing the possibility – or, rather, the impossibility – of Russia ever undergoing a Western-style transformation, the diplomat and counter-Enlightenment philosopher Joseph de Maistre famously wrote, “Every nation has the government it deserves.”
Fourteen years later, the Decembrist revolt – a movement of poets and army officers to topple Czar Nicholas I and establish a constitutional monarchy – seemed to refute de Maistre’s claim.
Yet the revolt was suppressed, and the Decembrists were executed or exiled.
One doomed officer famously declared, “You can’t hang us all.”
Russia’s brutal twentieth century, with its totalitarianism and gulags, nearly proved that officer – and de Maistre – wrong.
No one “deserves” to be ruled so monstrously.
An estimated 20 million Russians perished under Stalin’s rule, and the rest were paralyzed with terror.
The twenty-first century has been kinder to Russians, at least so far.
But, while terror and famine have been absent, many of the oppressive tactics of the past have been revived under Vladimir Putin’s misrule, now in its 14th year.
Since 2003, when the billionaire oil oligarch Mikhail Khodorkovsky was arrested for alleged embezzlement and fraud – after he dared to support Putin’s political opponents – Russia’s elite has been largely brought to heel.
None of them envisaged rotting in a labor camp like Khodorkovsky.
Under Putin, it seems, de Maistre’s maxim has received a new lease on life.
Then in 2011, massive protests against Putin and his party of “crooks and thieves” erupted, and Alexei Navalny, who coined that epithet, became the face of Russia’s opposition.
Navalny, a 37-year-old anti-corruption lawyer, has been a thorn in Putin’s side ever since.
Recently, he announced that he has presidential ambitions; in the meantime, he is seeking to become the mayor of Moscow (arguably the second most important political post in Russia).
The mayoral campaign is now in full swing, with the election on September 8 the first in Moscow in ten years, as Putin had simply been appointing loyalists as mayors and governors throughout the country.
The incumbent mayor, Sergey Sobyanin, who has the full support of the Kremlin political-media machine, has been receiving personal-approval ratings above 90% in recent opinion polls.
But Navalny’s approval ratings are not far behind, at 80%, and he has achieved them entirely on his own.
Navalny’s candidacy received a recent boost when he became a convicted criminal, following a trial that resembled Khodorkovsky’s in terms of blatant political manipulation.
Accused of fraud, Navalny received a five-year prison sentence for allegedly embezzling from Kirovles, a provincial timber company.
But, in an unusual twist, Navalny was released from custody pending appeal of his conviction only a day after it was handed down.
That, some say, was because his supporters immediately took to the streets.
The likelier motivation is that Putin decided to let the election play out, relying on Navalny to lose.
In that case, Sobyanin, who was appointed in 2010, would gain the legitimacy that he has lacked until now, and the opposition movement would be discredited in the capital, whose residents form the core of Navalny’s political base.
But what if Navalny is elected?
Would his sentence be commuted, postponed, or annulled?
Would he go to prison, Muscovites’ choice notwithstanding?
In a new challenge to de Maistre’s maxim, almost 200 young businessmen overcame the fear inspired by Khodorkovsky’s fate and donated funds to Navalny’s campaign.
Thirty-seven of them signed what they called a new “social contract.”
According to their manifesto, they “expect Navalny to defend the rule of law, support independent courts, and ensure that officials are really accountable before society.”
They are investing “reputational, financial, organizational, and other resources” in a man who promises to hire competent advisers and free the city – and eventually the country – from endemic corruption and abuse of power.
Most of these young entrepreneurs have risen within the “knowledge economy.”
They include the inventor of a cloud-computing service, the founder of an online luxury-goods business, a developer of new banking technologies, and the creator of a social-networking platform for doctors.
All of them have good educations, and many hold American business degrees.
Many of these business leaders would have preferred to stay out of politics; but Russia’s poor education system, economic feudalism, official homophobia, and other festering problems have left them no choice.
And Putin himself has become an insufferably vulgar embarrassment.
To be sure, Navalny’s backers could emigrate comfortably; but, invigorated by their candidate’s campaign, they are willing to see whether he can make a difference.
Indeed, Navalny has become the only hope for competitive politics in Russia.
At the same time, Navalny’s unapologetic nationalism makes many people nervous.
And, while Russian leaders may start out as reformers, they do not often remain so.
Boris Yeltsin began the 1990’s as a courageous democrat, only to end up a corrupt, bibulous buffoon, while Putin initially vowed to bring law and order to the post-Yeltsin chaos.
So Moscow’s mayoral election is a moment of truth for Navalny, the business leaders investing in his campaign, all Muscovites, and perhaps Russia as a whole.
As in the time of the Decembrists, anyone in Russia can suffer from overweening government power, regardless of political belief.
Fear and apathy have become riskier than taking a stand.
But the question remains: Come September 8, can Navalny and his supporters change Russia’s political culture of fear, or was de Maistre right after all?
How We Lose Our Marbles
ATHENS – George Clooney has reignited a longstanding debate after suggesting, in response to a Greek journalist’s question, that removing the Parthenon Marbles, known in Britain as the Elgin Marbles, from London’s British Museum and returning them to their ancient home in Athens would be “the right thing to do.”
In the early nineteenth century, the friezes and sculptures were removed from the Parthenon by Lord Elgin, Britain’s ambassador to the Ottoman Empire from 1799 to 1803.
Elgin sold them to the British government, which put them in the British Museum.
Greece wants them back.
The occasion for this latest round of historical jousting is the release of Clooney’s new film The Monuments Men, which details Allied efforts to rescue art works from the Nazis during World War II.
His comments infuriated London’s provocative mayor, Boris Johnson, himself a classics scholar and author, who shot back that Clooney’s position on the issue was similar to that of the Nazis portrayed in his film.
But the film is of less interest in this dispute than the identity of the characters involved.
Perhaps the most important question is this: Whom is the public inclined to believe – Clooney or Johnson (or perhaps the Nazis)?
Of course, one might ask why the people involved should matter at all; surely the facts of the case should speak for themselves.
And yet, on questions such as this – as with so many important political, social, economic, and cultural issues – what we come to believe is not based on the facts alone, if at all.
Sometimes we may indeed think deeply about the pros and cons of each argument, actively seeking information and data that would support one view over another; in other cases, however, we rely on a “quick and dirty” evaluation of the arguments, focusing not on evidence, but rather on an advocate’s expertise or popularity.
Social and cognitive psychologists have long understood these two basic processes in their study of “dual-process” models, which explain how we process information and eventually form an opinion.
We take the peripheral route to information processing when buying, say, a toaster on a whim, whereas we take the so-called central route – thoroughly considering technical, safety, and aesthetic features – when buying a car.
The systematic study of persuasion began during World War II, when the US Army recognized that fighting a nation mesmerized by Hitler would require bolstering troop motivation and rallying popular support for the war.
They sought help from Yale University psychologist Carl Hovland and his associates, who produced what has become a well-known model of persuasion, comprising three groups of variables related to the communicator, the audience, and the message.
Hovland drew upon ideas dating back to Aristotle’s Rhetoric, which argued that persuasiveness is built on the communicator’s ethical character, the audience’s emotional state, and the logic of the argument, the latter being the most powerful.
Psychological research has shown that any one of these three can be persuasive, depending on the speaker’s attractiveness or the audience’s predisposition.
For example, star-struck female film fans may be especially prone to believe any utterance from Hollywood’s most famous silver fox. Or, in the case of the Nazis, fear may predispose the audience to be persuaded.
But in most cases, when people are confronted with matters of great importance, they are more likely to use the so-called central route to information processing, and rightly so.
Issues of world cultural heritage, for example, deserve conscious, thoughtful deliberation of the facts.
Indeed, it is our duty, and the very basis of any successful civilization, that important decisions are made only after scrutinizing all relevant information and weighing the relative merits of every position.
Once that duty has been fulfilled, a logical person will understand that the Parthenon Marbles, long held by a former imperial power’s flagship museum, were violently severed from the rest of the Parthenon sculptures – an outrage against art and an unhealed scar inflicted by the British on the long-suffering Greek people.
At that point, only one conclusion is possible: The plundered Marbles must be reunited in their historical home and exhibited to the world as the ancient artists intended.
Persuaded?
Perhaps not – I am Greek, after all.
But do not take Clooney’s word for it, either (or Johnson’s).
Deciding the disposition of the world’s cultural patrimony is not like buying a toaster.
Living Big Data
CAMBRIDGE – Big data is made from the digital trail that we leave behind when we use credit cards, mobile phones, or the Web.
Used carefully and accurately, these data give us unprecedented scope to understand our society, and improve the way we live and work.
But what works in theory may not translate well in the real world, where complex human interactions cannot always be captured, even by the most sophisticated models.
Big data requires us to experiment on a big scale.
My own laboratory, for example, is building a Web site which, based on Google maps, uses society’s digital trail to map poverty, infant mortality, crime rates, changes in GDP, and other social indicators, neighborhood by neighborhood – all of which will be updated daily.
This new capability allows viewers to see, for example, where government initiatives are working or failing.
But, while such impressive visualization tools can dramatically enhance transparency and public knowledge, they are surprisingly limited when applied to solving society’s problems.
One reason is that such rich streams of data encourage spurious correlations.
Even the use of the normal scientific method no longer works; given so many measurements, and so many more potential connections among what’s being measured, our standard statistical tools generate nonsensical results.
Without knowing all possible alternatives, we cannot form a limited, testable set of clear hypotheses.
And if we can no longer rely on laboratory experiments to test causality, we must test it in the real world, using massive volumes of real-time data.
This involves moving beyond the closed, question-and-answer process typical of the lab, and applying our ideas in society, earlier and more frequently than ever before.
To see how things work in reality, we must construct living laboratories – that is, communities willing to try new ways of doing things (to be blunt, to act as guinea pigs).
An example of such a living lab is the “open data city,” which I launched with the city of Trento in Italy, along with Telecom Italia, Telefónica, the research university Fondazione Bruno Kessler, the Institute for Data Driven Design, and local companies.
Importantly, this living lab has the approval and informed consent of all involved; they understand that they are participating in a gigantic experiment whose goal is to create a better way of living.
One major challenge for a living lab is to protect individual privacy without diminishing the potential for better government.
The Trento lab, for example, will pilot my proposed “New Deal on Data,” which gives users greater control over their personal data through trust-network software such as our open PDS (Personal Data Store) system.
We hope that the ability to share data safely, while protecting privacy, will encourage individuals, companies, and governments to communicate their ideas widely, and so increase productivity and creativity across the entire city.
But the biggest difficulty in using big data to build a better society is being able to develop a human-scale, intuitive understanding of social physics.
Although dense, continuous data and modern computation allow us to map many details about society, and to explain how communities might work, such raw mathematical models contain too many variables and complex relationships for most people to understand.
What is needed is some kind of dialogue between human intuition and the compelling reality of big data – a dialogue that is currently absent from management and government systems.
If big data is to be deployed effectively, people must be able to understand and interpret the relevant statistics.
This calls for a new understanding of human behavior and social dynamics that goes beyond traditional economic and political models.
Only by developing the science and language of social physics will we be able to make a world of big data a world in which we want to live.
Peril and Promise in Algeria
MADRID – Five years after the start of the so-called Arab Spring, the hope that initially characterized those revolutions has largely been dashed.
In many cases, the revolutions have evolved into brutal and protracted internal conflicts, with no solution in sight.
Amid all of this strife, the international community has paid little attention to countries like Algeria, where the revolutionary spirit was stifled while still incipient.
But Algeria’s fate is back on the world’s radar – and not a moment too soon.
On February 7, Algeria’s parliament approved a new package of constitutional reforms, which, among other things, limit presidents to two terms (President Abdelaziz Bouteflika, the last surviving leader of Algeria’s war of independence against France, has been in office since 1999) and recognize some fundamental freedoms.
These steps, in the making since 2011, aim to strengthen Algeria’s democratic standing; but they have been widely criticized as insufficient.
What is not in doubt is that the reforms come at a sensitive time, when Algeria is plagued by political and economic uncertainty.
The “consensus” that supposedly shapes Algerian politics has, in fact, paralyzed decision-making for many years now.
With the ailing Bouteflika not seen in public for more than a year, important questions have emerged about how the 2019 presidential election will play out.
Efforts over the last three years to curtail the power of the security and intelligence services – in September, Mohamed Mediene, who had been chief of the intelligence services since 1990, was forced to retire – are just one source and manifestation of domestic political tension.
Significant external challenges have exacerbated Algeria’s situation.
In particular, with the oil and gas industry accounting for fully 97% of Algeria’s export income, the sharp decline in oil prices since June 2014 has underscored the unsustainability of the country’s economic model.
Falling oil revenues mean that Algeria’s government cannot maintain the broad array of subsidies that traditionally served as a social balm, helping prevent protest.
The government has already had to increase some taxes, while raising prices for fuel, electricity, and gas.
If the price of oil does not rise soon, and Algeria’s leaders are forced to take more drastic measures, social stability could be jeopardized.
To be sure, some factors may help to stave off social unrest – namely, the population’s memories of the brutal civil war of the 1990s, in which more than 150,000 people were killed.
But, memories fade as time passes, and a new generation of young people lack the same fear of social strife that their parents and grandparents have.
In this social context, and if economic hardship persists, protests and even revolt may not be a distant prospect.
To avoid such an outcome, Algeria’s government must work fast to diversify the economy.
But such concerted action will be difficult in the current political environment, especially in view of the government’s increased focus on security challenges in Algeria’s neighborhood.
Given the revolution in Tunisia, the war in Libya, the rebellion of the Tuaregs in Mali, and, most important, the 2013 terrorist attack on Algeria’s large In Amenas gas plant, the country’s leaders are placing an increasingly high priority on regional security.
Although the constitution explicitly prohibits military intervention in other countries, Algeria has a clear interest – reflected in its foreign policy – in ensuring that its neighbors are stable and capable of dissuading extremist groups.
For example, in Libya, Algeria has defended a process of inclusive national reconciliation of all forces, in support of efforts by the United Nations to stabilize the country.
The United States and Europe have already recognized Algeria’s leadership and cooperation in anti-terror efforts in its neighborhood.
For the European Union, a further strengthening of ties with Algeria is particularly important, given both sides’ interest in the stability of nearby North Africa and the Sahel, as well as Algeria’s potential to help improve the EU’s energy security.
One key way Algeria can help improve security cooperation in its region would be to restore diplomatic relations with Morocco.
True, the countries have been at loggerheads for 40 years, owing to their sovereignty dispute over Western Sahara.
But the economic, commercial, and security-related dividends that renewed cooperation would provide should be enough to persuade them to reconsider this position.
If the two North African giants were to recognize their mutual interests and reestablish ties, they would disentangle relations in the Maghreb.
Algeria’s influence across Africa would also receive a boost.
Already, Algeria’s Africa-wide influence may be set to grow.
Some have suggested that an Algerian candidate could become Chair of the Commission of the African Union when the current term expires next July.
Here, Algeria’s consistent support for the AU and its commitment to regional security – exemplified in its role in the Mali peace agreement and its hosting of the Libya talks – would speak in its favor.
If successful, Algeria would become the first North African country to lead the AU.
The severe challenge posed by falling oil prices and a jittery regional context attest to the urgent need for change in Algeria.
But if the government acts to unblock the political system, diversify the economy, and ramp up diplomatic efforts, Algeria can emerge stronger and more influential than ever.
The Politics of Machine-Learning Algorithms
WASHINGTON, DC – Around 1200 BC, the Shang Dynasty in China developed a factory system to build thousands of huge bronze vessels for use in everyday life and ritual ceremonies.
In this early example of mass production, the process of bronze casting required intricate planning and the coordination of large groups of workers, each performing a separate task in precisely the right order.
A similarly complex process went into fashioning the famous army of terracotta warriors that Qin Shi Huang, China’s first emperor, unveiled one thousand years later.
According to the Asian Art Museum in San Francisco, the statues “were created using an assembly production system that paved the way for advances in mass production and commerce.”
Some scholars have speculated that these early forms of prescriptive-work technologies played a large role in shaping Chinese society.
Among other things, they seem to have predisposed people to accept bureaucratic structures, a social philosophy emphasizing hierarchy, and a belief that there is a single right way of doing things.
When industrial factories were introduced in Europe in the nineteenth century, even staunch critics of capitalism such as Friedrich Engels acknowledged that mass production necessitated centralized authority, regardless of whether the economic system was capitalist or socialist.
In the twentieth century, theorists such as Langdon Winner extended this line of thinking to other technologies.
He thought that the atom bomb, for example, should be considered an “inherently political artifact,” because its “lethal properties demand that it be controlled by a centralized, rigidly hierarchical chain of command.”
Today, we can take that thinking even further.
Consider machine-learning algorithms, the most important general-purpose technology in use today.
Using real-world examples to mimic human cognitive capacities, these algorithms are already becoming ubiquitous in the workplace.
But, to capitalize fully on these technologies, organizations must redefine human tasks as prediction tasks, which are more suited to these algorithms’ strengths.
A key feature of machine-learning algorithms is that their performance improves with more data.
As a result, the use of these algorithms creates a technological momentum to treat information about people as recordable, accessible data.
Like the system of mass production, they are “inherently political,” because their core functionality demands certain social practices and discourages others.
In particular, machine-learning algorithms run directly counter to individuals’ desire for personal privacy.
A system based on the public availability of information about individual community members might seem amenable to communitarians such as the sociologist Amitai Etzioni, for whom limitations on privacy are a means to enforce social norms.
But, unlike communitarians, algorithms are indifferent to social norms.
Their only concern is to make better predictions, by transforming more and more areas of human life into data sets that can be mined.
Moreover, while the force of a technological imperative turns individualist Westerners into accidental communitarians, it also makes them more beholden to a culture of meritocracy based on algorithmic evaluations.
Whether it is at work, in school, or even on dating apps, we have already become accustomed to having our eligibility assessed by impersonal tools, which then assign us positions in a hierarchy.
To be sure, algorithmic assessment is not new.
A generation ago, scholars such as Oscar H. Gandy warned that we were turning into a scored-and-ranked society, and demanded more accountability and redress for technology-driven mistakes.
But, unlike modern machine-learning algorithms, older assessment tools were reasonably well understood.
They made decisions on the basis of relevant normative and empirical factors.
For example, it was no secret that accumulating a lot of credit card debit could hurt one’s creditworthiness.
By contrast, new machine-learning technologies plumb the depths of large data sets to find correlations that are predictive but poorly understood.
In the workplace, algorithms can track employees’ conversations, where they eat lunch, and how much time they spend on the computer, telephone, or in meetings.
And with that data, the algorithm develops sophisticated models of productivity that far surpass our commonsense intuitions.
In an algorithmic meritocracy, whatever the models demand becomes the new standard of excellence.
Still, technology is not destiny.
We shape it before it shapes us.
Business leaders and policymakers can develop and deploy the technologies they want, according to their institutional needs.
It is within our power to cast privacy nets around sensitive areas of human life, to protect people from the harmful uses of data, and to require that algorithms balance predictive accuracy against other values such as fairness, accountability, and transparency.
But if we follow the natural flow of algorithmic logic, a more meritocratic and communitarian culture will be inevitable.
And this steady transformation will have far-reaching implications for our democratic institutions and political structures.
As the China scholars Daniel A. Bell and Zhang Weiwei have noted, the major political alternative to Western liberal-democratic traditions are the communitarian institutions that continue to evolve in China.
In China, collective decisions are not legitimated by citizens’ explicit consent, and people generally have fewer enforceable rights against the government, particularly when it comes to surveillance.
An ordinary Chinese citizen’s role in political life is largely limited to participation in local elections.
The country’s leaders, meanwhile, are selected through a meritocratic process, and consider themselves custodians of the people’s welfare.
Liberal democracies are not likely to shift entirely to such a political system.
But if current trends in business and consumer culture continue, we might soon have more in common with Chinese meritocratic and communitarian traditions than with our own history of individualism and liberal democracy.
If we want to change course, we will have to put our own political imperatives before those of our technologies.
A Sunni-Shia Bridge Too Far
BAGHDAD – Iraq’s recent parliamentary election, the first since United States troops left the country in 2011, was held amid a rising tide of violence that is fast approaching the levels experienced during the 2005-2007 insurgency.
Can the new government restore order and address the many immense challenges that Iraq faces?
The challenges are indeed daunting.
The authorities must resolve fundamental constitutional questions (such as whether Iraq should be a federal state or a confederation), rebuild civil society, reform state institutions, reconstruct the economy, and end the waste and corruption in the oil sector.
But perhaps the most intractable challenge of all is bridging the sectarian rift between the country’s Shia and Sunni citizens.
These fissures are mirrored in other Arab countries (such as Syria, Lebanon, the Gulf countries, and Yemen) and, increasingly, in the wider Muslim world (including Pakistan, Malaysia, and Indonesia).
Is this a historical aberration, or are Islam’s two largest sects condemned to perpetual mutual hostility?
Certainly, there have been periods when the two communities have coexisted peacefully.
But what matters today is that Shia and Sunni relate to their past differently, and that this historical memory can be distorted – and even invented – to create mistrust and hate.
The overthrow of the first Muslim dynasty, the staunchly anti-Shia Umayyads, in the year 750, by the Abbasids, who traced their lineage to the Prophet Muhammad’s uncle, raised hopes, albeit short-lived, of a Sunni-Shia rapprochement.
The 500 years of Abbasid reign that followed provide many valuable illustrations of how these two communities subsequently related to each other.
In particular, there is much to be learned from the different legacies of the caliph al-Nasir (1180-1225) and the last Abbasid caliph, al-Musta’sim (1242-1258).
The rule of al-Nasir – who viewed the Shia as an intrinsic part of the Islamic community and sought to treat all of his subjects equally – was characterized by a marked decrease in sectarian tensions.
By contrast, Sunni-Shia clashes – including killings, arson, and other violence – were common during al-Musta’sim’s rule.
These examples demonstrate the importance of good leadership when communities that uphold different claims to the truth are subject to the same political authority – especially when these communities seek assurance that their survival is not threatened.
Iraq’s current political leaders need to learn from this past and ensure that none of the country’s communities face marginalization or discrimination – lessons that apply throughout the Muslim world.
In Pakistan, for example, there are sectarian killings almost daily; in Malaysia, the tiny Shia population is viewed as an existential threat; and incendiary language dominates discourse about rival sects in Wahhabi circles in Saudi Arabia and far beyond.
Politics and power struggles explain much of the violence and mistrust.
Fear of Iranian-led hegemony, for example, has focused Gulf leaders’ minds on their Shia population’s loyalty.
Malaysia’s political parties use anti-Shia animus to spread fear, helping to attract votes and consolidate power.
Syria and its regional allies are determined to protect a new regional balance of power that shifted in their favor following the US-led invasion of Iraq.
But political calculation cannot explain everything.
The fall of Saddam Hussein in 2003 provides a good example of how a political event, viewed through a sectarian lens, can be interpreted differently.
The US destruction of the Iraqi state brought about a precarious new order that sought to redress years of Sunni dominance by favoring the Shia.
However, the shock of sudden Sunni disempowerment generated a discourse, widely shared in the Muslim world, in which the Shia are guilty of collusion in the US occupation of the country – a view reinforced by events in Syria.
According to this thesis, the Shia simply reverted to their “historic” role as wreckers and fifth columnists.
Was it not the case, it is claimed, that the Shia also colluded with the Mongols in the fall of Baghdad in 1258, culminating in the death of the last Abbasid caliph and the destruction of the Abbasid Empire, the “universal state” of Muslims?
Several medieval Muslim historians pointed to the role of the Shia vizier Ibn al-‘Alqami, arguing that he plotted with the Mongols to bring down the caliphate.
Once the preserve of a handful of scholars, the Ibn al-‘Alqami story now plays a prominent part in today’s Sunni- Shia disputes.
Indeed, “‘Alaqima,” the plural form of the Arabic name “‘Alqami,” is now applied to the Shia as short-hand for treachery.
Social media forums are replete with polemics about the Shia role in assisting both Mongol and US invaders.
Many even claim that Iraq’s Shia are al-‘Alqami’s descendants, and that Nouri al-Maliki, Iraq’s Prime Minister, is his modern incarnation.
These diatribes reflect Iraqi’s polarized historical memory.
Despite ample historical evidence of peaceful inter-communal relations, many people – whether through simple ignorance of history or the need to assert the supremacy of one version of the truth – prefer to consecrate narratives of treachery and betrayal that perpetuate hatred.
More important, the current situation reflects a lack of wisdom, responsibility, and basic decency on the part of political and religious leaders, who prefer to fuel, rather than dampen, inter-communal strife.
Sadly, intolerance has now become a generalized condition.
There is too little knowledge about other communities’ beliefs and history, and what little exists has been overwhelmed by sectarian anger and its poisonous rhetoric.
As long as Sunnis and Shia refuse to think about their past together, it is difficult to foresee a tranquil future together.
And if political and religious leaders are unable or unwilling to seek accommodation, it will be up to like-minded individuals, groups, and civil-society institutions to rebuild mutual respect and find ways to cooperate.
Doing so will require knowledge, patience, and, above all, open minds and hearts.
All in the Family
MUNICH – Big economic crises often cause iconic companies to falter.
Rupert Murdoch’s media empire is a model of the modern global enterprise.
A particularly dynamic and innovative business model came from outside and took over central aspects of British and then American public life.
That model is now threatened by the fallout from the scandal that started with phone hacking in Murdoch’s British press operations.
The Murdoch experience is a microcosm of how modern globalization works.
Murdoch always looked like a foreign intrusion into British life. It was not just that he was Australian; he also brought new ideas.
In particular, the application of digital technology, introduced after a ferocious struggle with the powerful print unions, brought substantial cost savings and allowed a new era of journalism.
Even more importantly, Murdoch represented a concept of family business that is common in many parts of the world, but relatively rare in Britain and the United States.
Family capitalism in the continental European model uses relatively little capital to achieve maximum control.
It frequently depends on very complex corporate structures, with multiple layers of holding companies, as well as privileged shares that can guarantee the continuation of control.
This sort of firm is also very common in the most dynamic emerging-market economies in Asia and Latin America.
The Murdoch family holds only 12% of the shares of News Corporation, the top-level holding company, but it wields about two-fifths of the voting rights; other votes are held by a loyal Saudi prince.
For decades, academic analysts have been fighting over whether such large-scale family businesses should be considered beneficial.
Their defenders point out that such companies often have a much longer-term vision than is true of managerial capitalism, which enables them to establish strong and enduring relationships with their customers and suppliers.
At least in the case of the Murdoch empire, it now appears that they pursue long and binding relationships with politicians and the police as well.
Indeed, political entanglements are one of two sources of weakness in European-style family capitalism, as owners seek political advantages and preferred access as much as they strive for technical innovation.
Murdoch’s empire depended on its closeness to politicians.
In retrospect, three successive British prime ministers – Tony Blair, Gordon Brown, and David Cameron – were on overly familiar terms with a manipulative business leader.
Cameron now talks about the need for “a healthier relationship between politicians and media owners.”
And Murdoch apparently is now saying that he wishes that all these prime ministers would “leave me alone.”
The second notorious weakness of family businesses is the problem of succession.
When he appeared before the British parliament in July, Rupert Murdoch looked like an old man, remote and out of control.
In old-style family firms, there is a clear rule of succession that the oldest son takes over.
But that rule is rightly recognized as being potentially dysfunctional.
There is obviously no guarantee that the oldest son is the best businessman, and the result could be bitter and ferocious sibling rivalry.
Such succession disputes become even more acute when there are multiple marriages and multiple sets of competing children.
Until the eruption of the current scandal, the youngest of Murdoch’s three children from his second marriage, James, was generally believed to stand the greatest chance of succeeding his father.
The complexities of modern marriage patterns make family life much more fraught, especially when phenomenal power and huge sums of money are involved.
All three of Murdoch’s marriages have produced children, though those from his current relationship are too young to be considered potential corporate successors.
In addition, succession planning can become complicated by the emergence of “substitute children” from the company’s management.
Rebekah Brooks, the editor of The News of the World at the beginning of the phone-hacking scandal, and subsequently the chief executive of News International, Murdoch’s British subsidiary, played precisely such a role.
The disintegration of the business empire is then accompanied and amplified by bitter disputes between the children and the substitute children.
Indeed, the crisis of the Murdoch family’s business empire is neither unique nor unprecedented.
In the first half of the 1990’s, many observers of the alleged Asian economic miracle emphasized trust and families’ capacity to cooperate with political authorities in order to realize long-term growth plans.
After the 1997-1998 Asia crisis, and as authoritarian regimes in South Korea and Indonesia disintegrated, these relationships were suddenly interpreted as corrupt, and the counter-view – that “crony capitalism” had become entrenched in these countries – soon prevailed.
The Arab Spring has been in large part a movement against corrupt family capitalism, embodied not only in ruling families like the Ben Alis, the Mubaraks, and the Assads, but also in the large family business empires that depended on and supported them.
As a result of globalization, large family firms could increase their size and their geographic range.
But globalization also increases the chances of backlashes that focus on the vulnerabilities, weaknesses, and mistakes of big family firms.
They are vulnerable to an Arab Spring (and a British summer) – and maybe to a US autumn that will focus not just on the Murdochs’ business, but also on its interplay with politics.
All Man’s Land
NEW DELHI – Ernest Hemingway’s collection of stories, Men without Women, examines tense gender relationships.
In a particularly poignant story, a young man convinces his partner to have an abortion, viewing their unborn child as a hindrance to the status quo. Frustrated, the woman gives in.
That story, published more than 80 years ago, remains relevant today in India, where female fetuses face severe risks.
According to the 2011 census, the sex ratio of the country’s children has dipped from 927 females per 1000 males to 914, a 60-year low.
Ratios in the northern states are particularly alarming: only Himachal Pradesh now has a ratio of girls to boys above 900.
Despite being illegal, ultrasound sex-determination tests are being used across India to identify for abortion extraordinary numbers of healthy female fetuses.
But there are serious concerns about legal operations, too.
Genitoplasty – a sex-change operation on newborn girls – is a mushrooming, and deeply disturbing, business in India.
There’s only one word for it: gendercide.
Left unchecked, it will leave India’s next generation of men with a severe shortage of women.
Indian couples have a strong cultural preference, bordering on obsession, for sons over daughters – despite the strides in education and employment that women have made over the last few decades.
Education and wealth have nothing to do with it – in fact, some of the worst-affected areas are in India’s wealthiest cities.
However discomfiting a possibility, the real culprit might be Indian culture and tradition itself.
The expenses and pressure of the dowry system, and the fact that, in most joint families, only sons inherit property and wealth, contribute to this favoritism.
Perhaps just as important is that sons typically live with their parents even after they are married, and assume responsibility for parents in their old age.
Daughters, who live with their in-laws after they marry, are viewed as amanat – someone else’s property.
In short, sons represent income and daughters an expense.
In the old days, when families typically had 5-10 children, this didn’t matter so much.
The number of sons and daughters often evened out.
But, for today’s smaller families, whether the children are two boys or two girls influences everything from financial planning to preparations for old age.
Many have argued that Indian women should stand up to their families and refuse to abort their daughters.
But Indian women want male children just as much.
Unlike Hemingway’s character, they are often more than willing to abort a girl and try for a boy.
The novelist Salman Rushdie once put the question to supporters of abortion rights: “What should be done when a woman uses her power over her own body to discriminate against female fetuses?”
This raises other questions concerning the consequences of a large shortage of girls.
Will women be valued and treasured?
Or will the oversupply of men result in more bride trafficking, sexual violence, and female suicides?
Niall Ferguson, the British historian, cites scholars who attribute Japan’s imperial expansion after 1914 to a male youth bulge, and who link the rise of Islamist extremism to an Islamic youth bulge.
“Maybe the coming generation of Asian men without women will find harmless outlets for their inevitable frustrations, like team sports or video games.
But I doubt it,” he writes.
He warns us not to be surprised if, in the coming generation, “shrill nationalism is replaced by macho militarism or even imperialism.”
Unfortunately, there is no instant solution.
Saving our girls will require radically altering some of Indian society’s family arrangements, traditions, and attitudes.
And there is no easy way to accomplish this.
Legislation alone won’t help, for tradition is a law unto itself.
Hindu religious law, for example, allows a woman to claim an equal share in her parents’ wealth, but few exercise this right.
Culturally, she feels that she does not have an equal claim on her father’s property.
Nonetheless, India does need new laws – direct and enforceable – that clamp down on the cultural practices that underpin destructive traditions.
For example, India could enforce a ceiling on wedding expenditure – typically a father’s biggest expense associated with his daughter.
Constrained from spending on the wedding, he would compensate her differently – perhaps with a larger inheritance.
Gradually, this would become the norm, and tradition would adjust accordingly.
(Interestingly, the state of Kerala, whose people adhere to matrilineal inheritance, has among the most equal sex ratios and literacy rates in India.)
A more radical measure, which some have advocated, would be direction intervene, with the state providing benefits for families with more girls.
Perhaps the authorities could also penalize families with boys, at least temporarily.
India imagines herself as a woman – Bharat Mata, or Mother India.
The irony is that, unless far-reaching changes are made soon, Mother India could eventually be the only woman left in the country.
All Stimulus Roads Lead to China
BEIJING – Now that the “green shoots” of recovery have withered, the debate over fiscal stimulus is back with a vengeance.
In the United States, those who argue for another stimulus package observe that it was always wishful thinking to believe that a $787 billion package could offset a $3 trillion fall in private spending.
But unemployment has risen even faster and further than expected.
Combine this with the continued fall in housing prices, and it is understandable that consumer spending remains depressed.
The banks, having been recapitalized only to the extent necessary to keep them afloat, still have weak balance sheets.
Their consequent reluctance to lend constrains investment.
Meanwhile, state governments, seeing revenues fall as a result of lower taxable incomes last year, are cutting back like mad.
If there was a case for additional stimulus back in February, that case is even stronger now.
But the case against additional stimulus is also strong.
The US federal deficit is an alarming 12% of GDP, and public debt as a share of national income is already projected to double, to 80% of GDP.
The idea that the US can grow out of its debt burden, as did Finland and Sweden following their financial crises in the 1990’s, seems unrealistic.
Given all this, more deficit spending will only stoke fears of higher future taxes and inflation.
It will encourage the reemergence of global imbalances.
And it will not reassure consumers or investors.
It is possible to argue the economics both ways, but the politics all point in one direction.
The US Congress lacks the stomach for another stimulus package.
It has already faced intense criticism for its failure to get the country’s fiscal house in order.
The slowness with which the first stimulus has been rolled out, and the fact that it will take even more time for its full effects to be felt, provides more fodder for the chattering classes.
Disappointment over the effects of the TARP has already destroyed popular – and Congressional – support for more public money to recapitalize the banks.
So, even those who find the economic logic of arguments for fiscal activism compelling must acknowledge that the politics are not supportive.
A second stimulus simply is not in the cards.
If there is going to be more aggregate demand, it can come from only one place.
That place is not Europe or Japan, where debts are even higher than in the US – and the demographic preconditions for servicing them less favorable.
Rather, it is emerging markets like China.
The problem is that China has already done a lot to stimulate domestic demand, both through government spending and by directing its banks to lend.
As a result, its stock market is frothy, and it is experiencing an alarming property boom.
Through May, property prices were up 18% year on year.
Understandably, Chinese officials worry about bubble trouble.
The obvious way to square this circle is to spend more on imports.
China can purchase more industrial machinery, transport equipment, and steelmaking material, which are among its leading imports from the US.
Directing spending toward imports of capital equipment would avoid overheating China’s own markets, boost the economy’s productive capacity (and thus its ability to grow in the future), and support demand for US, European, and Japanese products just when such support is needed most.
This strategy is not without risks.
Allowing the renminbi to appreciate as a way of encouraging imports may also discourage exports, the traditional motor of Chinese growth.
And lowering administrative barriers to imports might redirect more spending toward foreign goods than the authorities intend.
But these are risks worth taking if China is serious about assuming a global leadership role.
The question is what China will get in return.
And the answer brings us back, full circle, to where we started, namely to US fiscal policy.
China is worried that its more than $1 trillion investment in US Treasury securities will not hold its value.
It wants reassurance that the US will stand behind its debts. It therefore wants to see a credible program for balancing the US budget once the recession ends.
And, tough talk notwithstanding, the Obama administration has yet to offer a credible roadmap for fiscal consolidation.
Doing so would reassure American taxpayers worried about current deficits. Just as importantly, it would reassure Chinese policymakers.
We live in a multipolar world where neither the US nor China is large enough to exercise global economic leadership on its own.
For China, leadership means assuming additional risks.
But for this to be tolerable, the US needs to relieve China of existing risks.
Only by working together can the two countries lead the world economy out of its current doldrums.
A Long March with China
BEIJING – US Vice President Joe Biden’s recent four-day visit to China ended on a high note.
He assured Chinese leaders that the United States is committed to honoring all its debts, despite its recent credit downgrade; he talked enthusiastically about US-China interdependence; and he showcased his granddaughter, who has studied Chinese for several years, as a future bridge between the two countries.
But, behind all the smiles and banquet toasts, serious issues and perception gaps continue to divide the world’s two great powers.
For starters, there is always an attitude problem.
To those who view China’s rise in a negative light, the country is simply becoming ever more arrogant. It is getting tough in its territorial disputes with Japan in the East China Sea; it is becoming assertive in the South China Sea with its neighbors, also over disputed islands; it put its own stealth fighter on display during the US defense secretary’s visit to China; it is sending its first aircraft carrier out to sea for trials, indicating the possibility of establishing naval bases in the Indian Ocean.
Even a brawl between the Chinese and a visiting American basketball team is viewed as evidence of China’s aggressive behavior.
Many Chinese, on the other hand, tend to think that the US is suffering from severe case of conceited superpower syndrome.
As these Chinese see it, the US has a rather dysfunctional government, but nevertheless insists that its political and economic system is the best in the world, and that everyone should emulate it.
It is heavily in debt, but cannot stop spending and borrowing.
It is no longer competitive in manufacturing, but blames others for its huge trade deficit.
And the world’s only military superpower is often seen within China as trigger-happy when intervening in other countries’ internal affairs.
Then, there is the issue of trust.
China’s critics argue that its claims to a peaceful rise are not credible, given the country’s non-democratic, one-party system.
Coupled with this is a zero-sum view of the world, in which any Chinese gain in the share of the global economy, or any increased presence in many parts of the world, must be at the expense of the US or other powers.
Any Chinese military move is portrayed as an expansionary and aggressive act that must be contained.
Any attempts at engagement by Western politicians, such as Biden’s recent trip, are automatically met with doubt and criticism for cozying up to dictators.
Likewise, for those Chinese who are suspicious of US intentions, conspiracy is always in play.
They see a declining superpower using economic, military, and diplomatic means in an unrelenting effort to prevent China’s rise.
Talk of human rights and democracy is nothing but a smoke screen for demonizing China.
Arms sales to Taiwan, Tibetan activism, and “color revolutions” of various kinds are all sponsored by the US and other Western powers, and are aimed at weakening China.
Despite decades of close interaction, with millions of Americans, Europeans, and Japanese visiting China every year and similar numbers of Chinese now visiting the US and other advanced countries, both sides see each other through a glass darkly.
Increased interdependence has not led to better understandings on even some of the most basic issues.
China’s Vice Minister of Foreign Affairs Fu Ying expressed her country’s anxiety about this state of affairs in a recent interview. “The most important thing is the question of whether China and the US are enemies.
Are we going to be in a war?
Are we preparing for a war against each other?”
Biden, while reaffirming that the US does not view China as an enemy, implied that Fu’s worries are not fanciful, saying that the worst scenario is a misunderstanding that leads to an unintended conflict.
So the key issue for China, its neighbors, the US, and rest of the world is not how many aircraft carriers, missiles, submarines, and next-generation fighters China may produce and deploy in the coming years and decades. Rather, it is how China intends to use its newly acquired economic and military strength in pursuing its domestic and foreign-policy goals – and how the world’s leading powers can ensure that they do not end up harming each other by accident or misunderstanding.
To meet these challenges successfully, there is no viable alternative to a positive, continuous, and frank engagement between China and the rest of the world.
The Chinese economy will continue to grow; the Chinese military will continue to modernize; and the Chinese people will remain united in their Great Power aspirations.
A Cold War-style confrontation and containment policy from the West will be met with strong resistance from the Chinese, whose global leverage, particularly in finance, cannot be ignored.
Only a patient, creative, and consistent engagement strategy will mitigate fears on both sides.
China’s rise is a fact; the enduring peacefulness of that rise must be a priority for China, its neighbors, the West, and, most importantly, the US.
Inequality on the Horizon of Need
BERKELEY – By any economic measure, we are living in disappointing times.
In the United States, 7.2% of the normal productive labor currently stands idle, while the employment gap in Europe is rising and due to exceed that of the US by the end of the year.
So it is important to step back and remind ourselves that the “lost decade” that we are currently suffering is not our long-run economic destiny.
As Paul Krugman recently reminded us, John Maynard Keynes perhaps put it best:
“This is a nightmare, which will pass away with the morning.
For the resources of nature and men’s devices are just as fertile and productive as they were.
The rate of our progress towards solving the material problems of life is not less rapid.
We are as capable as before of affording for everyone a high standard of life – high, I mean, compared with, say, 20 years ago – and will soon learn to afford a standard higher still.
We were not previously deceived.
But today we have involved ourselves in a colossal muddle, having blundered in the control of a delicate machine, the working of which we do not understand.
The result is that our possibilities of wealth may run to waste for a time.”
But what is our long-run economic destiny?
Keynes looked forward to a time, perhaps 2050, when everyone (in England, at least) would be able to have the lifestyle of a Keynes.
And, because he imagined that no sane person could want more of the necessities, conveniences, and luxuries of life than a Keynes had, the economic problem would be solved.
We are wiser – and perhaps sadder – than Keynes.
We know that we want hip replacements and heart transplants and fertility treatment and cheap air travel and central heating and broadband Internet and exclusive beachfront access.
Already nearly everybody in the North Atlantic region has enough food to avoid hunger, enough clothing to stay warm, enough shelter to remain dry.
And yet we want more, feel resentful when we do not get it, and are self-aware enough to know that luxuries turn into conveniences, and then into necessities – and that we are very good at inventing new luxuries after which to strive.
So the economic problem will certainly be with us for a long time yet.
But at least we can count on being able to generate a relatively egalitarian middle-class society as we collectively slouch toward our consumerist utopia, right?
It was Karl Smith of the University of North Carolina who explained to me that this was likely to be wrong.
The long post-Industrial Revolution boom, which carried unskilled workers’ wages to previously unheard-of heights – keeping them within shouting (or at least dreaming) distance of the lifestyles of the rich and famous – is not necessarily a good guide to what will come next.
To create wealth, you need ideas about how to shape matter and energy, additional energy itself to carry out the shaping, and instrumentalities to control the shaping as it is accomplished.
The Industrial Revolution brought ideas and energy to the table, but human brains remained the only effective instrumentalities of control.
As ideas and energy became cheap, the human brains that were their complements became valuable.
But, as we move into a future of artificial intelligence that observers like Kevin Drum expect (or even of the artificial moronity that is already clearly at hand), and into a future of biotechnology that grows itself as biological systems do, won’t human brains cease to be the only valuable instrumentalities of control?
It is not necessarily the case that “unskilled” workers’ standards of living will fall in absolute terms: the same factors that make human brains less valuable may well be working equally effectively to reduce the costs of life’s necessities, conveniences, and luxuries.
But wealth is likely to flow to the owners of productive – or perhaps fashionable – ideas, and to owners of things that can be imitated only with great difficulty and high cost, even with dirt-cheap instrumentalities of control, dirt-cheap energy, and plentiful ideas.
The lesson is clear: the market is not guaranteed by nature to produce a long-run future characterized by a reasonable degree of wealth inequality and relative poverty.
Unless and until we recognize this fully, we will remain at the mercy of Keynes’s poorly understood “delicate machine.”
Alpine Schadenfreude
Not surprisingly, the atmosphere at this year’s World Economic Forum was grim.
Those who think that globalization, technology, and the market economy will solve the world’s problems seemed subdued.
Most chastened of all were the bankers.
Against the backdrop of the sub-prime crisis, the disasters at many financial institutions, and the weakening of the stock market, these “masters of the universe” seemed less omniscient than they did a short while ago.
And it was not just the bankers who were in the Davos doghouse this year, but also their regulators – the central bankers.
Anyone who goes to international conferences is used to hearing Americans lecture everyone else about transparency.
There was still some of that at Davos.
I heard the usual suspects – including a former treasury secretary who had been particularly vociferous in such admonishments during the East Asia crisis – bang on about the need for transparency at sovereign wealth funds (though not at American or European hedge funds).
But this time, developing countries could not resist commenting on the hypocrisy of it all.  There was even a touch of schadenfreude in the air about the problems the United States is having right now – though it was moderated, of course, by worries about the downturn’s impact on their own economies.
Had America really told others to bring in American banks to teach them about how to run their business?
Had America really boasted about its superior risk management systems, going so far as to develop a new regulatory system (called Basle II)?
Basle II is dead – at least until memories of the current disaster fade.
Bankers – and the rating agencies – believed in financial alchemy.
They thought that financial innovations could somehow turn bad mortgages into good securities, meriting AAA ratings.
But one lesson of modern finance theory is that, in well functioning financial markets, repackaging risks should not make much difference.
If we know the price of cream and the price of skim milk, we can figure out the price of milk with 1% cream, 2% cream, or 4% cream.
There might be some money in repackaging, but not the billions that banks made by slicing and dicing sub-prime mortgages into packages whose value was much greater than their contents.
It seemed too good to be true – and it was.
Worse, banks failed to understand the first principle of risk management: diversification only works when risks are not correlated, and macro-shocks (such as those that affect housing prices or borrowers’ ability to repay) affect the probability of default for all mortgages.
I argued at Davos that central bankers also got it wrong by misjudging the threat of a downturn and failing to provide sufficient regulation.
They waited too long to take action.
Because it normally takes a year or more for the full effects of monetary policy to be felt, central banks need to act preemptively, not reactively.
Worse, the US Federal Reserve and its previous chairman, Alan Greenspan, may have helped create the problem, encouraging households to take on risky variable-rate mortgages by reassuring those who worried about a housing bubble that there was at most a little “froth” in the market.
Normally, a Davos audience would rally to the support of the central bankers.
This time, a vote at the end of the session supported my view by a margin of three to one.
Even the plea of one of central banker that “no one could have predicted the problems” moved few in the audience – perhaps because several people sitting there had, like me, explicitly warned about the impending problem in previous years.
The only thing we got wrong was how bad banks’ lending practices were, how non-transparent banks really were, and how inadequate their risk management systems were.
It was interesting to see the different cultural attitudes to the crisis on display.
In Japan, the CEO of a major bank would have apologized to his employees and his country, and would have refused his pension and bonus so that those who suffered as a result of corporate failures could share the money.
He would have resigned.
In America, the only questions are whether a board will force a CEO to leave and, if so, how big his severance package will be.
When I asked one CEO whether there was any discussion of returning their bonuses, the response was not just no, but an aggressive defense of the bonus system.
This is the third US crisis in the past 20 years, after the Savings & Loan crisis of 1989 and the Enron/WorldCom crisis in 2002.
Deregulation has not worked.
Unfettered markets may produce big bonuses for CEO’s, but they do not lead, as if by an invisible hand, to societal well-being.
Until we achieve a better balance between markets and government, the world will continue to pay a high price.
Effective Altruism
PRINCETON – Can humans really be motivated by altruism?
My new book, The Most Good You Can Do, discusses the emerging new movement called Effective Altruism, and, in doing interviews about the book, I am surprised by how often that question is asked.
Why should we doubt that some people act altruistically, at least some of the time?
In evolutionary terms, we can easily understand altruism toward kin and others who can reciprocate our help.
It seems plausible that once our ability to reason and reflect has developed sufficiently enough to enable us to understand that strangers can suffer and enjoy life just as we can, then at least some of us would act altruistically toward strangers, too.
The polling organization Gallup asked people in 135 countries whether they had, in the last month, donated money to a charity, volunteered their time to an organization, or helped a stranger.
Gallup’s results, which form the basis of the World Giving Index 2014, indicate that approximately 2.3 billion people, a third of the world’s population, perform at least one altruistic act per month.
More objective evidence of altruism buttresses these findings.
In many countries, the supply of blood for medical purposes relies on voluntary, anonymous donations.
Worldwide, more than 11 million people have put their names on donor registries for bone marrow, signifying their willingness to donate their marrow to a stranger.
A small but growing number of people have gone further still, donating a kidney to a stranger.
There were 177 altruistic donations by living donors in the United States in 2013 and 118 in the United Kingdom in the year to April 2014.
Then there are those who donate to charity.
In the US alone, individuals gave $240 billion to charity in 2013.
Foundations and corporations topped this up to a total of $335 billion, or about 2% of gross national income.
The US is often said to be more charitable than other countries; but, in terms of the proportion of the population donating money, Myanmar, Malta, Ireland, the UK, Canada, the Netherlands, and Iceland all do better.
In Myanmar, 91% of the people surveyed had given money in the past month (the corresponding figure for the US is 68%), indicating the strong hold of the Theravada Buddhist tradition of donating to support monks and nuns.
Myanmar also had the highest percentage of people volunteering time (51%).
The US did, however, have the highest ranking for “helping a stranger.”
That, together with a high ranking for volunteering time, led it to tie with Myanmar as the most generous nation in the world.
Admittedly, not all of this giving is altruistic.
New York’s Lincoln Center announced last month that the billionaire entertainment industry mogul David Geffen has donated $100 million toward the renovation of its concert facility, Avery Fisher Hall, on the condition that it is renamed David Geffen Hall.
That gift seems motivated more by a desire for fame than a desire to do good.
After all, as Geffen presumably knew, the family of Avery Fisher had to be compensated with a payment of $15 million in order to agree to the renaming.
In any case, in a world with a billion people living in extreme poverty, it would not be difficult for an altruist to appreciate that there are many ways of doing more good than renovating a concert hall for well-off music lovers.
At the opposite end of the giving spectrum, psychologists who study giving behavior have suggested that people who give small sums of money to a large number of charities may be motivated less by the desire to help others than by the warm glow they get from making a donation.
By contrast, other donors give larger sums, usually to only a handful of charities chosen on the basis of some knowledge about what the charity is doing.
They want to have a positive impact on the world.
Their gifts may also make their lives better, but this is not what motivates them.
The Effective Altruism movement consists of people who give in the latter way, combining the head and the heart.
Their aim is to do the most good they can with the resources that they are willing to set aside for that purpose.
Those resources may include a tenth, a quarter, or even half of their income.
Their altruism may include their time and talents, and influence their choice of career.
To achieve their aims, they use reason and evidence to ensure that whatever resources they devote to doing good will be as effective as possible.
Several studies show that people who are generous are typically happier and more satisfied with their lives than those who do not give.
And other studies show that giving leads to activity in the reward centers of the brain (the areas of the brain that are also stimulated by tasty food and sex).
But this does not mean that these donors are not altruistic.
Their direct motive is to help others, and their giving makes them happier only as a consequence of the fact that it does help others.
If we had more such people, we would have more giving, and that is what we want.
To define “altruism” so narrowly that the term can be applied only when giving is contrary to a person’s overall interest would miss the point that the best situation to bring about is one in which promoting the interests of others harmonizes with promoting one’s own.
Testing Times for Alzheimer’s
LONDON – Alzheimer’s disease is by far the most common cause of dementia and one of the world’s most feared disorders.
By 2050, there will be 135 million Alzheimer’s sufferers worldwide, a threefold increase from today, with three-quarters of cases occurring in low- and middle-income countries.
Predicting the onset of Alzheimer’s, let alone preventing or curing it, remains an immense challenge.
Alzheimer’s disease was identified more than a century ago from autopsy results that showed characteristic brain lesions called “amyloid plaques.”
The disease is more difficult to diagnose in the living.
Doctors rely on observation of memory loss and other thinking deficits (such as reasoning or language comprehension) – signs that plaques are already present in the brain.
But any cure would have to be administered before the plaques form, and years before symptoms of dementia appear.
Alzheimer’s might be more predictable if scientists had the time and resources to conduct far-reaching longitudinal studies over many years.
Such studies ideally would involve blood, imaging, memory, and medical tests, as well as detailed lifestyle questionnaires filled out by thousands of young and middle-aged people.
Study participants would be followed over decades to see who developed the disease, and which tests proved positive before Alzheimer’s was diagnosed.
In fact, two famous longitudinal studies – the Framingham Heart Study in Massachusetts and the Kungsholmen Project in Sweden – have led to important progress in predicting the disease.
These studies found that short-term memory may be impaired for up to ten years before an Alzheimer’s diagnosis.
Major advances have since been made in brain imaging, biochemical analysis, and, perhaps most important, genetic testing.
Indeed, the risk of Alzheimer’s doubles if a parent or sibling has it, probably due in large part to the presence of the ApoE gene.
The risk triples for Europeans who inherit a particular type of ApoE, called ε4; inheriting two copies of ε4 increases the risk roughly tenfold.
But genetic testing alone is unlikely to be an accurate predictor, because around half of Alzheimer’s sufferers do not carry ε4, and probably half of those with ε4 do not develop the disease.
Moreover, though international studies of more than 70,000 people have found over 20 other genes linked to Alzheimer’s, their impact is minimal.
That said, a groundbreaking 2012 study published in the New England Journal of Medicine, analyzed a rare genetic mutation found in just 500 families around the world, which would lead to Alzheimer’s before the age of 50.
The study showed which tests were able to predict the outcome most accurately decades ahead of onset.
The research found that amyloid-beta – the substance that clumps together and forms amyloid plaques – becomes depleted in the cerebrospinal fluid around the brain as long as 25 years before the onset of dementia.
Fifteen years prior to onset, a positron emission tomography (PET) scan showed amyloid-beta being deposited in plaques in the brain itself.
And detailed short-term memory tests were abnormal ten years before onset, as suggested in the Framingham and Kungsholmen studies.
These tests are now becoming part of clinical practice, and are available commercially.
Memory and other cognitive tests can reveal whether one has minor problems with some aspects of thinking – a condition known as “mild cognitive impairment” that precedes Alzheimer’s disease.
The problem is that the tests must be administered by a trained neuropsychologist and take more than an hour to complete; moreover, many people with mild cognitive impairment do not progress to dementia.
Sampling cerebrospinal fluid via a lumbar puncture (or “spinal tap”) can predict which people with mild cognitive impairment will progress to dementia with over 80% accuracy, but this still means a misdiagnosis for one in five patients.
PET scans are slightly less accurate, while routine MRI brain scans can reveal with perhaps only 70% accuracy subtle abnormalities in people with mild cognitive impairment.
Scientists are therefore still searching for an accurate predictive test that is cheaper, quicker, and less invasive than PET scans or lumbar punctures.
This year, two small studies of blood tests seemed to predict Alzheimer’s 1-3 years before it occurred, but the tests are complicated and require the measurement of ten or more substances.
Whichever predictive methods doctors use over the next few years will probably enable them to inform those patients with mild cognitive impairment about their chances of developing Alzheimer’s in the short term.
The trickier question is whether we will be able to predict Alzheimer’s disease accurately in those with normal cognition and memory, or to predict it more than five years in advance.
Even if accurate early prediction of Alzheimer’s eventually is achieved, there are currently no drugs available to prevent or cure it before the amyloid plaques start destroying the mind.
That will be our next great challenge.
Africa’s Necessary Data Revolution
WASHINGTON, DC – Since the term “data revolution” was introduced, there has been a flurry of activity to define, develop, and implement an agenda to transform the collection, use, and distribution of development statistics.
That makes sense.
Assessing the international community’s next development agenda, regardless of its details, will be impossible without accurate data.
Yet, in Sub-Saharan Africa – the region with the most potential for progress under the forthcoming Sustainable Development Goals – accurate data are severely lacking.
From 1990 to 2009, only one Sub-Saharan country had data on all 12 indicators established in 2000 by the Millennium Development Goals.
Indeed, of the 60 countries with complete vital statistics, not one is in Africa.
While most African countries have likely experienced economic growth during the last decade, the accuracy of the data on which growth estimates are based – not to mention data on inflation, food production, education, and vaccination rates – remains far from adequate.
Inaccurate data can have serious consequences.
Consider Nigeria’s experience earlier this year, when GDP rebasing showed that the economy was nearly 90% larger than previously thought.
The distorted picture of Nigeria’s economy provided by the previous statistics likely led to misguided decisions regarding private investment, credit ratings, and taxation.
Moreover, it meant that Nigeria was allocated more international aid than it merited – aid that could have gone to needier countries.
Contrary to popular belief, the constraints on the production and use of basic data stem not from a shortage of technical capacity and knowhow, but from underlying political and systemic challenges.
For starters, national statistical offices often lack the institutional autonomy needed to protect the integrity of data, production of which thus tends to be influenced by political forces and special interest groups.
Poorly designed policies also undermine the accuracy of data.
For example, governments and donors sometimes tie funding to self-reported measures, which creates incentives for recipients to over-report key data like vaccination or school-enrollment rates.
Without effective oversight, these well-intentioned efforts to reward progress can go awry.
Despite these failings, national governments and international donors continue to devote far too few resources to ensuring the collection of adequate data.
Only 2% of official development aid is earmarked for improving the quality of statistics – an amount wholly insufficient to assess accurately the impact of the other 98% of aid.
And governments’ dependency on donors to fund and gather their core statistics is unsustainable.
In fact, stronger national statistical systems are the first step toward improving the accuracy, timeliness, and availability of the data that are essential to calculating almost any major economic or social-welfare indicator.
These include statistics on births and deaths; growth and poverty; tax and trade; health, education, and safety; and land and the environment.
Developing such systems is an ambitious but achievable goal.
All that is needed is a willingness to experiment with new approaches to collecting, using, and sharing data.
This is where the public comes in.
If private firms, media, and civil-society organizations identify specific problems and call publicly for change, their governments will feel pressure to take the steps needed to produce accurate, unbiased data – for example, by enhancing the autonomy of national statistical offices or providing sufficient funds to hire more qualified personnel.
While it may be tempting to bypass government and hope for an easy technology-based solution, sustainable, credible progress will be difficult without public-sector involvement.
The recognition by governments and external donors of the need for more – and more efficient – funding, particularly to national statistical systems, will be integral to such a shift.
Establishing stronger incentives for agencies to produce good data – that is, data that are accurate, timely, relevant, and readily available – would also help, with clearly delineated metrics defining what qualifies as “good.”
In fact, tying progress on those metrics to funding via pay-for-performance agreements could improve development outcomes considerably.
One concrete strategy to achieve these goals would be to create a country-donor compact for better data.
Such a compact would enable governments and donors to express their shared intention to build a national statistics system over a period of several years, with clear and verifiable milestones.
It would also provide a country-specific framework for innovation on funding mechanisms and the engagement of civil society and the private sector, while mobilizing new technologies for data collection and dissemination.
In short, a data compact would help to mobilize and focus domestic and donor funding to achieve national statistical priorities.
Data are the currency of performance, accountability, and credibility in the global economy, and improvements in data have been linked to better governance and higher levels of private investment.
That is just what Africa needs to support a new decade of growth and development.
The Experts’ Advantage
LONDON – Nearly everyone who sits on Google’s board of directors has at least one computer science or engineering degree or doctorate.
There are two university presidents and eminent scholars – Stanford University’s John Hennessy and former Princeton University President Shirley Tilghman – and several members of the National Academy of Engineering and other illustrious organizations.
For Google, it pays to have technical expertise at the top.
But Google is an unusual corporate giant in promoting those with scientific prowess to the top of the management ladder.
Beyond Silicon Valley, few senior corporate executives boast technical expertise in the products that their companies produce.
American boardrooms are filled with MBAs, especially from Harvard, while firms in the rest of the developed world (with the possible exception of Germany) seem to prefer professional managers over technical or scientific talent.
Nowadays, it seems as anomalous to have knowledge workers serve as professional leaders as it once did to have scientists in the boardroom.
It was previously thought that leadership is less necessary in knowledge-intensive organizations, where experts were assumed to be superior because they were motivated by intellectual pleasure rather than such extrinsic motivations as profit growth and cost targets.
This difference in attitude is evident in many areas of society, not least in hospitals in the United States and the United Kingdom, where knowledge-intensive medical practitioners operate separately from managers.
Hospitals used to be run by doctors; today, only 5% of US hospitals’ CEOs are medical doctors, and even fewer doctors run UK hospitals.
“Medicine should be left to the doctors,” according to a common refrain, “and organizational leadership should be left to professional managers.”
But this is a mistake.
Research shows that higher-performing US hospitals are likely to be led by doctors with outstanding research reputations, not by management professionals.
The evidence also suggests that hospitals perform better, and have lower death rates, when more of their managers up to board level are clinically trained.
We see similar findings in other fields.
My research shows that the world’s best universities, for example, are likely to be led by exceptional scholars whose performance continues to improve over time.
Departmental-level analysis supports this.
A university economics department, for example, tends to perform better the more widely its head’s own research is cited.
With experts in charge, it may not always look like there is an effective reporting structure in place.
But, as the academic saying goes: just because you cannot herd cats, does not mean there is not a feline hierarchy.
As with cats, academics operate a “relative hierarchy” in which the person in charge changes, depending on the setting.
Even in the world of sports, where success is not an obvious preparation for management, we see interesting linkages between experience and organizational performance.
The very best NBA basketball players often make top coaches, while former Formula 1 champion drivers are associated with great team performance.
Of the 92 soccer clubs in the English football league, club managers played an average of 16 years in senior clubs.
Alex Ferguson, arguably Britain’s best manager, scored an average of one goal every two games in his professional career.
But where the pattern does occur, especially in the business world, we should take note.
The senior partner of any professional services firm is likely to have been a top performer during a long career with the firm.
This might be because experts and professionals in knowledge-intensive organizations prefer a boss who has excelled in their field.
The leader’s credibility is vital: if she sets high standards, it seems only right that she should have matched or exceeded them herself.
In short, she must lead by example.
This sort of leadership arrangement creates a virtuous circle.
A leader with prior experience knows how her subordinates feel, how to motivate them, and how to create the right working environment.
She probably makes better hiring decisions, too – after all, the best scientist or physician is more likely than a professional manager to know which researchers or doctors have the greatest potential.
The problem, however, is not simply that today’s leaders lack technical knowledge; it is that experts are often reluctant to lead.
But that can change.
By communicating the importance of management and leadership early in a specialist’s career, and by offering tailored, digestible, and jargon-free training, we could bridge the gap.
Many medical schools are already considering including management education as part of the curriculum.
The trick is to get experts, who are trained to go ever deeper into their specialization, to step back and view the big picture.
With the right preparation, there is no reason why a leader cannot specialize and manage.
The results could be remarkable.
Think of how governments run by scientists with management skills might respond to climate change.
Top minds should be put to top use.
A Mania for Diagnosing Bipolar Disorder
PROVIDENCE, RI – During the past few years, many experts have suggested that bipolar disorder – a serious illness resulting in significant psychosocial morbidity and excess mortality – is under-recognized, particularly in patients with major depression.
Even patients who are diagnosed with bipolar disorder often wait more than 10 years after initially seeking treatment for the correct diagnosis to be made.
The clinical implications of the failure to recognize bipolar disorder in depressed patients include the under-prescription of mood-stabilizing medications, and an increased risk of rapid “cycling” – swings between manic and depressive phases.
But, perhaps as a consequence of concerted efforts to improve the recognition of bipolar disorder, during the past few years we have observed the emergence of an opposite phenomenon – over-diagnosis.
In my own practice, my colleagues and I have encountered patients who reported that they were previously diagnosed with bipolar disorder, despite lacking a history of manic or hypomanic episodes.
To be sure, we have also seen patients seeking treatment for depression who really did have bipolar disorder.
However, there seemed to be more over-diagnosis than under-diagnosis.
We therefore conducted a study to examine empirically how often bipolar disorder might be over- and under-diagnosed.
Seven hundred psychiatric outpatients were interviewed with the Structured Clinical Interview for DSM-IV (SCID) and completed a self-administered questionnaire that asked whether they had been previously diagnosed by a health-care professional with bipolar or manic-depressive disorder.
Family history information was obtained from the patient regarding their immediate relatives.
Slightly more than 20% (145 patients) in our sample reported that they had been previously diagnosed as having bipolar disorder, significantly higher than the 12.9% rate based on the SCID.
Less than half of those who reported that they had been previously diagnosed with bipolar disorder were diagnosed with bipolar disorder based on the SCID.
Patients with SCID-diagnosed bipolar disorder had a significantly higher risk of bipolar disorder in their immediate family members than patients who self-reported a previous diagnosis of bipolar disorder that was not confirmed by the SCID.
Patients who self-reported a previous diagnosis of bipolar disorder that was not confirmed by the SCID did not have a significantly higher risk for bipolar disorder than the patients who were negative for bipolar disorder by self-report and the SCID.
Our findings, validated by family history, thus suggest that bipolar disorder was over-diagnosed.
Any study seeking to determine whether a psychiatric disorder is over-diagnosed will find that some patients with the condition do not have it upon re-interview.
Such is the nature of the imperfect reliability of psychiatric diagnosis.
The question, then, is not whether some patients previously given a diagnosis do not seem to have it upon re-interview, but rather how many.
How high the percentage should be before claiming over-diagnosis is a significant problem and a value judgment.
But we think that an over-diagnosis rate of more than 50% crosses the clinical significance threshold.
Over-diagnosis of bipolar disorder has costs.
Mood stabilizers are the treatment of choice, and, depending on the medication, they can produce potentially significant health complications affecting renal, endocrine, hepatic, immunologic, or metabolic function.
Thus, over-diagnosing bipolar disorder can unnecessarily expose patients to serious side-effects of medication.
The impact of marketing efforts by pharmaceutical companies and publicity probably plays a role in the emerging tendency to over-diagnose bipolar disorder.
Direct-to-consumer advertisements that refer individuals to screening questionnaires can result in patients suggesting to their doctors that they have bipolar disorder.
We have seen evidence of this in our practice.
This does not necessarily reflect a problem with the performance of a screening questionnaire, but rather how these scales are used.
Screening questionnaires maximize sensitivity, at a cost of false positives, because it is presumed that they are followed by expert clinical evaluation.
But insufficient diagnostic rigor can result in over-diagnosis.
Clinicians are inclined to diagnose disorders that they feel more comfortable treating.
We believe that the increased availability of medications that have been approved for the treatment of bipolar disorder might be influencing clinicians who are unsure whether or not a patient has bipolar disorder or borderline personality disorder to err on the side of diagnosing the disorder that is responsive to medication.
This bias is reinforced by the marketing message of pharmaceutical companies to physicians, which has emphasized research on delayed diagnosis and under-recognition of bipolar disorder, possibly sensitizing clinicians accordingly.
The campaign against under-recognition has probably resulted in some anxious, agitated, and/or irritable depressed patients who complain of insomnia and “racing thoughts” being misdiagnosed with bipolar disorder.
The results of our study are consistent with prior studies suggesting possible problems with the diagnosis of bipolar disorder.
With the greater number of medications approved for the treatment of bipolar disorder, along with multiple reports cautioning clinicians against under-diagnosis, it appears that over-diagnosis has become a greater problem than under-diagnosis.
Both can have negative consequences.
While there is still some uncertainty as to the best assessment approach, we recommend that clinicians use a standardized, validated method.
When Tweets Trump Diplomacy
NEW DELHI – Diplomacy often witnesses unusual spats.
There was the Pig and Potato War of 1859, the Affair of the Dancing Lamas in 1924, and the Bogotá Bracelet incident of 1970, to name just a few.
But few were more surprising than the just-concluded Episode of the Offensive Doormats.
The e-commerce giant Amazon – which has lately been cultivating India as the next frontier of its global expansion, reflected in plans to invest $5 billion in the country – was recently startled by a series of intemperate tweets from Indian External Affairs Minister Sushma Swaraj.
In just a few 140-character messages, Swaraj denounced the company and threatened to cancel its employees’ visas and refuse visas to its executives in the future.
What provoked Swaraj’s outburst was a Twitter user’s complaint to her that the Amazon Canada website offered for sale doormats depicting the Indian flag.
The notion that dirty shoes would be wiped on a representation of the Indian flag had outraged the tweeter, Atul Bhobe, who contacted – and found an advocate in – Swaraj.
Amazon was swift to respond.
After clarifying that the offending doormats were technically being offered by a third-party supplier, not Amazon itself, the company removed them from the Amazon Canada website and “implemented measures to ensure that these products could not be sold on any of our other marketplaces or websites.”
Amazon’s India country manager offered an apology to Swaraj for “hurting Indian sensibilities” and, recalling the company’s $5 billion investment commitment, reiterated Amazon’s dedication to the country.
Less than 24 hours after the doormat crisis erupted, the matter was defused.
But the episode raises a number of broader issues that won’t disappear so quickly.
The first issue is Swaraj’s use of Twitter.
Swaraj stands out among her peers in India for her trigger-happy approach to tweeting (though her use of the platform is still dwarfed by that of US President-elect Donald Trump, who often uses Twitter as a bully pulpit).
I certainly do not oppose the use of Twitter by public officials.
On the contrary, I view the growing comfort of government ministers with social media as a matter for celebration.
It is a welcome change from my time as Minister of State for External Affairs, under the previous government, when official computers were barred from accessing social media, and the tweets I issued from my own devices would often become the stuff of needless controversy.
But Swaraj may well be going too far, responding to every individual case of a lost passport or delayed visa tweeted to her – an approach that has earned her the not-entirely-flattering sobriquet of “India’s Minister for Consular Affairs.”
That a foreign minister would respond to a Twitter complaint on such trivial matters, some would argue, seems to indicate that she lacks more important things to do.
(The suggestion undoubtedly reflects the fact that, under Prime Minister Narendra Modi, substantive foreign policy is conducted largely by him and his office, rather than by the External Affairs Ministry that Swaraj leads.)
But the problem extends beyond Swaraj’s communication with ordinary citizens.
In the recent doormat drama, she also used Twitter to issue instructions to her own diplomats, tweeting at the Indian High Commission in Canada to deal with the “unacceptable” matter, by taking it up with Amazon “at the highest level.”
Such a move is unprecedented, and not particularly welcome.
Social media is no substitute for a diplomatic cable.
Also less than diplomatic was the language Swaraj used in her warning to the company.
“Amazon must tender unconditional apology,” she tweeted.
“They must withdraw all products insulting our national flag immediately.
If this is not done forthwith, we will not grant Indian Visa to any Amazon official. We will also rescind the Visas issued earlier.”
A profession famed for summoning ambassadors for a discreet dressing-down has been reduced to upbraiding companies on Twitter.
The final issue that the doormat incident brought to the fore is Indians’ tendency to take offense at the slightest affront – a tendency that is now being elevated, by the thumbs of a top minister, to the level of official policy.
Of course, disrespect for the national flag is derided in most countries, and has been a criminal offense in India since 1971, with the adoption of the Prevention of Insults to National Honor Act, which threatens whoever “mutilates, defaces, disfigures, destroys, tramples upon, or otherwise shows disrespect to” the Indian flag with imprisonment.
But Indians have a particularly low threshold for what qualifies as disrespect.
Whereas in other democracies, flags are used freely and harmlessly on t-shirts, boots, bikinis, and even underwear, in India, the majesty of the flag can, it seems, be tarnished by any tawdry manufacturer of gewgaws.
And it’s not just the flag.
Last year, Amazon enraged many Indians by offering doormats with pictures of Indian gods and goddesses, prompting the furious hashtag #BoycottAmazon.
Two years earlier, the company’s website had caused similar outrage by selling women’s leggings with images of Hindu gods.
So Amazon is no stranger to the anger of offended Indians.
But the company’s swift capitulation in the latest incident – which will surely not be the last – shows that the value of a gigantic market like India far outweighs that of any single product.
China has already proved that it can dictate terms to multinationals that covet its vast market.
India, it seems, will follow suit.
But whoever has emerged as the winner of the doormat debacle – outraged Twitter users, perhaps – diplomacy has been the loser.
Ambivalent Arabia
A democratic tide seems to be sweeping across the Arab world.
Even the traditional Arab monarchies and Emirates are changing in its wake.
Kuwait now allows women to vote, Qatar has embraced an ambitious reform program, Bahrain has shown great tolerance of mass demonstrations, and the U.A.E. is allowing something like a free press.
But Saudi Arabia continues to be deeply wary of any sort of change, and thus remains a huge and seemingly immovable obstacle to region-wide reform.
Although the Saudi ruling family, the al-Saud, is under enormous pressure to follow the example of its neighbors, internal resistance to doing so remains very strong.
So the al-Saud have become Janus-faced: looking in one direction, the royal family encourages democratic reformers to speak out; looking in the opposite direction, it jails them when they do.
On May 15, in a closed trial without legal representation for the accused, three leading reformers – Ali Al Dumaini, a well-known journalist and poet, and university professors Abdullah Al Hamid and Matruk al Falih – were condemned and sentenced to prison terms ranging from six to nine years.
Their crime was to call for a constitutional monarchy.
The official verdict states that they threatened national unity, challenged those in authority, and incited public opinion against the state while using “foreign,” that is, Western, terminology.
Not long after the September 2001 terrorist attacks in the United States, these liberal reformers joined with 160 other professionals to write and sign a petition to Crown Prince Abdullah asking for reforms.
The petition called for the monarchy to work within constitutionally prescribed limits, and for an independent judiciary.
The reformers believe that such reforms are the only way for Saudi Arabia to survive the threat of violence, instability, and national fragmentation that is looming on its horizon.
Only a constitution, they argue, can restore much needed legitimacy to a political system that is widely perceived as deeply corrupt and inept.
Crown Prince Abdullah, Saudi Arabia’s de facto ruler in place of his incapacitated half-brother King Fahd, is keen to be seen as a champion of reform.
He received these proposals with a warm welcome in January 2003.
But his half-brother and more powerful rival, Prince Naif, the Minister of Interior, ordered the arrests, trial, and imprisonment of 13 reformers in March 2004.
Crown Prince Abdullah offered not a peep of opposition, leaving the reform agenda that he initiated in a political netherworld.
In order to maintain absolutist power and to minimize public anger, the Saudi princes, led by Prince Naif, asked the reformers to sign an agreement that they would never again ask for reform.
Prince Naif bans the very word “reform” from public discourse, because it suggests that there is something wrong with the system; his preferred term is “development.”
Of the thirteen reformers who were arrested, ten submitted to this demand, but the other three refused and have paid the price.
They remained in jail in Riyadh without legal representation until the final verdict.
Those who submitted had their passports withdrawn, lost their jobs, and were forbidden to speak to the press.
Under regional and international pressure, the Saudi ruling family has constructed a Potemkin village of reform while retaining absolute control over all political developments.
Earlier this year, they staged partial, and tightly regulated municipal elections, with no independent opinion permitted to influence when and how the ballots were held.
These entire female population was excluded, and only one-quarter of the male population was eligible to vote.
Inevitably, Wahhabi Islamists did best.
The al-Saud face two threats: one from violent Islamists, and the other from liberal reformers.
There is every indication that they fear the reformers far more.
Perhaps the princes believe that it is easier to kill “terrorist” criminals than to crush demands for social justice.
Indeed, killing violent Islamists and al-Qaeda affiliates is applauded by the international community, especially the United States, as success in the “war on terrorism.”
But as they hunt down and kill violent domestic extremists, they are quietly tightening the noose around all those who want moderate reform.
This repression of liberal reformers passes unnoticed in the wider world, with America’s silence particularly noticeable.
This silence is vital to the princes, for what the al-Saud care about most is US support.
As things stand in Saudi Arabia, the US administration has no credible ally for change outside of the existing regime.
So, unlike in Ukraine, Georgia, Kyrgizstan, and Lebanon, it does nothing to encourage popular opposition.
As long as the Saudi regime meets America’s oil needs and fights Islamist radicals, it will continue to receive US support and silence – and hence its tacit consent.
But turning a blind eye is shortsighted, for America and for the Saudis.
Those who make peaceful revolutions impossible make violent revolutions inevitable.
The liberal reformers who have been jailed could have paved the way for a peaceful transition to a reformed Saudi Arabia.
By jailing them, the regime has made it clear that violence is the only avenue open to those seeking change.
Algeria’s Dying Dictatorship
ALGIERS – Despite his failing health, Algerian President Abdelaziz Bouteflika won a fourth term last month, with 81% of the vote – or so the regime claimed.
In fact, far from signaling growing political stability, the 77-year-old incumbent’s sham victory underscores just how few options Algerians have to effect change from within the system.
Under Bouteflika’s leadership, Algeria’s government has failed to address the country’s most pressing economic and social challenges.
And there is no reason to expect this to change.
Since suffering a stroke last year, Bouteflika has barely appeared in public, whether to campaign ahead of the vote or to acknowledge his victory after it.
As a result, the regime is finding it increasingly difficult to claim, as it has for the last 15 years, that Bouteflika’s leadership represents civilian control over the military.
So it has devised a new strategy, aimed at creating a sense of transition: the constitution will be revised to designate a vice president as the president’s legitimate successor.
Of course, the move’s true purpose will be to allow the army to rally around the next compliant “civilian leader.”
The regime will also propose a “national contract,” supposedly to initiate a dialogue with the opposition.
But, in the wake of Bouteflika’s bogus victory, the opposition can no longer accept a sham role in the regime’s reform plans.
In fact, the announcement that Bouteflika planned to run was enough to unite Islamists and leftists – even parties that had previously been co-opted by the regime – and spur them to stage a boycott of the vote.
When the election results were announced, they swiftly rejected the new government as illegitimate.
But, to gain credibility, the opposition parties will have to extend their criticism beyond Bouteflika to the system as a whole.
This has become crucial to their survival, as younger opponents are seeking new ways to bring about political change outside state-controlled politics.
One important development is the growing influence of non-partisan voices of dissent.
Non-violent movements have formed to protest not only Bouteflika’s continued leadership, but also the pervasive role of the army and intelligence services in civil society.
Such movements, like the much-publicized “Barakat” (“Enough”), have encouraged a shift among Algerians from resentful abstention to active boycott.
Underground unions – which mount demonstrations and strikes to protect workers’ rights, while refusing to cooperate with the regime’s official unions – have also criticized the election.
Moreover, young people have assumed a prominent role in opposition efforts, such as by disrupting Bouteflika’s campaign rallies.
Demonstrations by unemployed young people in southern Algeria, the center of the oil industry, drew a direct link between high unemployment and the military’s control of the country’s natural resources.
By organizing peaceful protests to demand accountability for public spending, these movements are raising issues that were not addressed during the election campaign.
More immediately, they are also challenging the government’s ban on street demonstrations – a vestige of the state of emergency that lasted from 1992 until 2011.
With the civil war of the 1990’s long over, security officials cannot explain why Algerians are being arrested for demanding jobs.
Of course, repression continues to intimidate many Algerians.
But it is becoming increasingly easy to rouse their sympathy for their fellow citizens through Twitter, YouTube, and Facebook.
By stimulating daily public debate about local human-rights violations, they spread the message of discontent more efficiently than traditional parties ever have.
By demanding better state services, rather than an “Arab Spring,” Algerians have walked a fine line, highlighting the regime’s inability to deliver security and economic prosperity, despite its efforts to stifle all debate.
Thus, even without explicitly talking about politics, ordinary Algerians are mobilizing in growing numbers against the government.
The majority of street protests have occurred in the most deprived and neglected areas, and the primary demands have been economic: better jobs, housing, health-care services, and infrastructure.
For some, the right to make a living through the informal market would be sufficient.
And demonstrators have gone to great – sometimes destructive – lengths to be heard, blocking roads, occupying factories and government buildings, and sabotaging water and electricity infrastructure.
More than 150 Algerians have even set themselves on fire since 2011, usually in front of public services buildings.
In this context, the failure of the government’s half-baked attempts to buy off protesters is unsurprising.
In 2011, the government, fearing contagion from Tunisia and Egypt, where long-established dictatorships had just been toppled, responded to the spread of protests by public-sector workers by raising their salaries by 100% – retroactively to 2008.
But the plan backfired; protests intensified, with other workers demonstrating for similar benefits and railing against the inflation that the move engendered.
To be sure, street protests have already had a profound impact on Algeria’s authoritarian politics, with official fears of massive uprisings affecting public budgets and political appointments.
But the decision to prolong Bouteflika’s presidency will not provide the kind of strong, transformational leadership that Algeria needs to materialize the regime’s stability promises.
The Algerian authorities face a major challenge, because rejection of pluralist institutions makes it more difficult to find negotiating partners.
The more the regime tries to buy off the protesters, the more overweening it appears – and the angrier citizens become.
And the enraged younger generation, in particular, is not especially fearful of losing the limited benefits offered by the status quo.
America After the Election
NEW YORK – The ongoing presidential campaign in the United States stands out for its lack of civility and the vast differences between the candidates: the anti-establishment businessman Donald Trump on the Republican side and the polished politician Hillary Clinton representing the Democrats.
The contest has exposed deep fault lines within American society and damaged the country’s global reputation.
No surprise, then, that one of the few things Americans seem to agree on is that the campaign has gone on for too long.
But soon it will be over.
The question is: what comes next?
Polls suggest that Clinton, a former senator and secretary of state, will defeat the controversial Trump.
But polls are not to be confused with reality.
After all, going into June’s Brexit referendum, most observers believed that a victory for “Remain” was a sure thing.
More recently, Colombian voters rejected a peace accord that was widely expected to receive popular approval.
All of this is to say that, while a Clinton victory may be likely, it is no certainty.
The only poll that counts is the one on November 8.
Until then, all we can do is speculate.
Yet some predictions can be made with greater confidence.
There is little doubt that the US will emerge from this election a divided country with a divided government, regardless of who is president or which party has a majority in either chamber of Congress.
Neither Democrats nor Republicans will be able to realize their objectives without at least some support from the other.
But no one should think that the only divide in American politics is between Republicans and Democrats.
In fact, splits within the two major parties are just as deep, with large and highly motivated factions pulling each to their respective extremes – Democrats to the left and Republicans to the right.
This makes compromise on centrist positions all the more difficult to achieve.
The rapid resumption of presidential politics will undermine compromise further.
If Clinton wins, many Republicans will assume that it was only because of Trump’s flaws, and they will judge her likely to be a one-term president.
A country favoring change, they will conclude, is unlikely to keep a Democrat in the Oval Office for a fourth term.
Many Republicans (especially those who deny the legitimacy of a Clinton victory) will thus seek to frustrate her administration, lest she be able to run again in 2020 as a successful incumbent.
Similarly, if Trump manages to win, most Democrats (and even some Republicans) will – after recovering from their surprise and dismay – make it their highest priority to ensure that he does not have an opportunity for a second term.
Given how much of Trump’s agenda his fellow policymakers would likely find objectionable, governing would be very difficult during his administration.
In either scenario, it may still be possible to make progress in a few key areas.
The next US government might manage to enact legislation to fund the modernization of America’s aging infrastructure, a policy that both candidates and many in Congress favor.
It might also be able to cobble together a majority to reform the US tax code – in particular, lowering the high rate for corporations and raising taxes on the wealthy.
There could even be some reform of health care, President Barack Obama’s signature achievement, owing to serious implementation problems with the current system.
But other issues requiring cooperation between Congress and the president are unlikely to be addressed any time soon.
One is immigration reform, which is as controversial in the US as it is in Europe.
Another is trade: because the domestic political environment makes policymakers wary of supporting positions with dedicated opponents, both Trump and Clinton oppose the Trans-Pacific Partnership, even though its ratification would benefit America’s economy and strategic standing.
Meanwhile, America’s deficit and debt are certain to rise, as there seems to be little or no will to reduce entitlement spending.
The foreign-policy implications of the election are somewhat different, because, under the US Constitution, the president enjoys considerable latitude.
While only Congress can officially declare war or ratify treaties, presidents may use (or refuse to use) military force without explicit congressional approval.
They can also enter into international agreements other than treaties, appoint powerful White House staff, and change US foreign policy by executive action, as Obama recently did regarding Cuba.
Under Clinton, this discretion could translate into establishing one or more safe areas in Syria, providing more defensive arms to Ukraine, and taking a tougher line toward North Korea as it continues its nuclear and missile buildup.
It is more difficult to guess what Trump would do.
He is, after all, a political outsider, so no one knows how much of his campaign rhetoric would be translated into policy.
Still, one could anticipate a Trump administration distancing itself from some traditional allies in Europe and Asia and standing mostly aloof from the Middle East.
What exactly will happen to America after the presidential election remains an open question.
Though some outcomes can reasonably be expected, the only genuine certainty is that the 96% of the world’s population that does not vote in US elections will feel the effects no less than Americans will.
America and Europe
Deeply frustrated by the Bush administration’s policies, many people and governments in Europe hope for a fundamental change in American foreign policy after the upcoming presidential election.
But it would take a medium-sized political miracle for these hopes not to be disappointed, and such a miracle will not happen – whoever is elected.
The Bush administration made numerous foreign-policy blunders with far-reaching consequences.
But Bush neither invented American unilateralism nor triggered the transatlantic rift between the United States and Europe.
To be sure, Bush reinforced both trends, but their real causes lie in objective historical factors, namely America’s being the sole world power since 1989 and Europe’s self-inflicted weakness.
As long as America remains the sole world power, the next US President will be neither able nor willing to change the basic framework of America’s foreign policy.
It will, of course, be important who wins the presidency: a candidate expected to continue Bush’s foreign policy or someone ready for a new beginning.
In the former case, the transatlantic rift will deepen dramatically.
Four, or even eight, more years of US policy à la Bush would inflict such damage on the substance of the transatlantic alliance as to threaten its very existence.
But if America’s next president is committed to a new direction, US foreign policy might again become more multilateral, more focused on international institutions and alliances, and willing to bring the relationship between military force and diplomacy back to within its historical proportions.
That is the good news.
The bad news is that, even under such auspicious conditions, the US, as a world power, will not relinquish its “free-hand” policy or forget its strength and its claim to preeminence among nations.
Another piece of bad (or good?) news is that a more multilateral American policy will increase the pressure on Europeans to take on more responsibility for international crisis management and conflict resolution – in Afghanistan, Iran, Iraq, the Middle East, Transcaucasia, and Russia, and with respect to Turkey’s future.
To this common agenda, the Europeans should add Africa, climate change, and reform of the United Nations and the world trading system.
For a long time, Europe has underestimated its weight and importance.
Europe’s geopolitical, economic, and social weight is quite obvious.
But Europe’s integration of sovereign states’ interests by means of common institutions could also be an example for much of the world.
In particular, the way Europe, in the process of its enlargement, has projected its power to achieve lasting peace across the whole continent, and fostered development by integrating entire economies, states, and societies within its institutional framework, could become a model for shaping a cooperative world order in the twenty-first century.
This modern, progressive, and peaceful model is unique and superior to all other currently available approaches to the fundamental questions of political order.
But could doesn’t mean will.
Europe’s global influence is feeble because of its internal quarrels and lack of unity, which render the European Union weak and limit its ability to act.
Objectively strong, subjectively infirm – that is how the EU’s present condition can be described.
The current moment of American weakness coincides with a substantially changed international political environment, defined largely by the limits of US power, Europe’s ineffectiveness, and the emergence of new global giants like China and India.
In light of these developments, does it still make sense to speak of “the West”?
I believe it does, more than ever, because the rift between Europe and America leaves both sides substantially weaker in global terms.
The unilateral overstretching of American power offers a chance for a new beginning in US-European relations.
America, more than in the past, will depend on strong partners and will seek such partnerships.
So what are the Europeans waiting for?
Why not start now to overcome the traditional tension between NATO and the EU – especially as French policy toward NATO under President Nicolas Sarkozy has been moving in the right direction?
A regular mutual presence of the Secretary General of NATO and of the head of EU foreign policy in the councils of both organizations doesn’t require much time and effort.
Why not initiate EU-US consultations at a high political level (with the Secretary-General of NATO participating in security matters) – for instance, by inviting the US Secretary of State and other members of the administration, such as the Treasury Secretary or the Administrator of the Environmental Protection Agency, to sit several times a year on the appropriate EU Council meetings?
Why not have routine annual meetings between the European Council and the US President?
Periodic meetings between the appropriate committees of the US Congress and the European Parliament would also be of great importance, as ultimately both bodies will have to ratify any international treaties.
The fate of the Kyoto Protocol should be a lesson to all parties involved.
No such US-EU consultations would require any new agreements, so they could start without any further preliminaries.
There is one certainty that Europeans can take home from the US election campaign even today: with a more multilaterally oriented US foreign policy, Europe won’t be riding comfortably in the US world-political slipstream much longer.
And that is a good thing.
The new transatlantic formula must be greater say in decision-making in exchange for a greater share of responsibility.
America at Stall Speed?
NEWPORT BEACH – Judging from the skittishness of both markets and “consensus expectations,” the United States’ economic prospects are confusing.
One day, the country is on the brink of a double-dip recession; the next, it is on the verge of a turbo-charged recovery, powered by resilient consumers and US multinationals starting to deploy, at long last, their massive cash reserves.
In the process, markets take investors on a wild rollercoaster ride, with the European crisis (riddled with even more confusion and volatility) serving to aggravate their queasiness.
This situation is both understandable and increasingly unsettling for America’s well-being and that of the global economy.
It reflects the impact of fundamental (and historic) economic and financial re-alignments, insufficient policy responses, and system-wide rigidities that frustrate structural change.
As a result, there are now legitimate questions about the underlying functioning of the US economy and, therefore, its evolution in the months and years ahead.
One way to understand current conditions – and what is needed to improve them – is to consider two events that recently attracted considerable worldwide attention: the launch of Boeing’s Dreamliner passenger jet and the tragic death of Apple’s Steve Jobs.
Let us start with some simple aeronautic dynamics, using an analogy that my PIMCO colleague, Bill Gross, came up with to describe the economic risks facing the American economy.
For the Dreamliner to take off, ascend, and maintain a steady altitude, it must do more than move forward.
It has to move forward fast enough to exceed critical physical thresholds, which are significantly higher than those for most of Boeing’s other (smaller) planes.
Failure would mean succumbing to a mid-air stall, with tepid forward motion giving way to a sudden loss of altitude.
Unless we are convinced of the Dreamliner’s ability to avoid stall speed, it makes no sense to talk about all the ways in which it will enhance the travel experience for millions of people around the world.
America’s economy today risks stall speed.
Specifically, the question is not whether it can grow, but whether it can grow fast enough to propel a large economy that, according to the US Federal Reserve, faces “balance-sheet deleveraging, credit constraints, and household and business uncertainty about the economic outlook.”
And, remember, it is just over a year since certain US officials were proclaiming the economy’s “summer of recovery” – a view underpinned by the erroneous belief that America was reaching “escape velocity.”
Stall speed is a terrifying risk for an economy like that of the US, which desperately needs to grow robustly.
Without rapid growth, there is no way to reverse persistently high and increasingly structural (and therefore protracted) unemployment; safely de-leverage over-indebted balance sheets; and prevent already-disturbing income and wealth inequalities from growing worse.
The private sector alone cannot and will not counter the risk of stall speed.
What is desperately needed is better policymaking.
Specifically, policymakers must be open and willing to understand the unusual challenges facing the US economy, react accordingly, and possess sufficiently potent policy instruments.
Unfortunately, this has been far from the case in America (and in Europe, where the situation is worse).
Moreover, US policymakers in the last few weeks have been more interested in pointing fingers at Europe and China than in recognizing and responding to the paradigm shifts that are at the root of the country’s economic problems and mounting social challenges.
This is where the insights of Steve Jobs, one of the world’s best innovators and entrepreneurs, come in.
Jobs did more than navigate paradigm shifts; he essentially created them.
He was a master at converting the complicated into the simple; and, rather than being paralyzed by complexity, he found new ways to deconstruct and overcome it.
Teamwork was an obligation, not a choice.
And he eschewed the search for the single “big bang” in favor of aiming for multiple breakthroughs.
Underlying it all was a willingness to evolve – a drive for perfection through experimentation.
Moreover, he excelled at selling to audiences worldwide both his vision and his strategy for realizing it.
So far, America’s economic policymakers have fallen short on all of these fronts.
Rather than committing to a comprehensive set of urgently-needed reinforcing measures, they seem obsessed with the futile search for the one “killer app” that will solve all of the country's economic problems.
No surprise that they have yet to find it.
Teamwork has repeatedly fallen hostage to turf wars and political bickering.
Little has been done to deconstruct structural complexity, let alone win sufficient public support for a medium-term vision, a credible implementation strategy, and a set of measures that is adequate to the task at hand.
The longer the policymaking impasse persists, the greater the stall-speed risk for an economy that already has an unemployment crisis, a large budget deficit, many underwater mortgages, and policy interest rates floored at zero.
This is an atmosphere in which unhealthy balance sheets come under even greater pressure, and healthy investors refuse to engage.
In the process, the risk of recession remains uncomfortably high, the unemployment crisis deepens, and inequities rise as already-stretched social safety nets prove even more porous.
America, China, and the Productivity Paradox
NEW HAVEN – In the late 1980s, there was intense debate about the so-called productivity paradox – when massive investments in information technology (IT) were not delivering measureable productivity improvements.
That paradox is now back, posing a problem for both the United States and China – one that may well come up in their annual Strategic and Economic Dialogue.
Back in 1987, Nobel laureate Robert Solow famously quipped, “You can see the computer age everywhere except in the productivity statistics.”
The productivity paradox seemed to be resolved in the 1990s, when America experienced a spectacular productivity renaissance.
Average annual productivity growth in the country’s nonfarm business sector accelerated to 2.5% from 1991 to 2007, from the 1.5% trend in the preceding 15 years.
The benefits of the Internet Age had finally materialized.
Concern about the paradox all but vanished.
But the celebration appears to have been premature.
Despite another technological revolution, productivity growth is slumping again.
And this time the downturn is global in scope, affecting the world’s two largest economies, the US and China, most of all.
Over the past five years, from 2010 to 2014, annual US productivity growth has fallen to an average of 0.9%.
It actually fell at a 2.6% annual rate in the two most recent quarters (in late 2014 and early 2015).
Barring a major data revision, America’s productivity renaissance seems to have run into serious trouble.
China is witnessing a similar pattern.
Although the government does not publish regular productivity statistics, there is no mistaking the problem: Overall urban employment growth has been steady, at around 13.2 million workers per year since 2013 – well in excess of the government’s targeted growth rate of ten million.
Moreover, hiring seems to be holding at that brisk pace in early 2015.
At the same time, output growth has slowed from the 10% trend of the 33 years ending in 2011 to around 7% today.
That downshift, in the face of sustained rapid job creation, implies an unmistakable deceleration of productivity.
Therein lies the latest paradox.
With revolutionary technologies now driving the creation of new markets (digital media and computerized wearables), services (energy management and DNA sequencing), products (smartphones and robotics), and technology companies (Alibaba and Apple), surely productivity growth must be surging.
As a modern-day Solow might say, the ���Internet of Everything” is everywhere except in the productivity statistics.
But is there really a paradox?
Northwestern University’s Robert Gordon has argued that IT- and Internet-led innovations like automated high-speed data processing and e-commerce pale in comparison to the breakthroughs of the Industrial Revolution, including the steam engine, electricity, and indoor plumbing.
He maintains that, although these innovations led to dramatic transformations of the major advanced economies – such as higher female labor-force participation, increased transportation speed, urbanization, and normalized temperature control – these changes will be extremely hard to replicate.
Indeed, as taken with today’s revolutionary technologies as we are – I say this staring at my sleek new Apple Watch – I am sympathetic to Gordon’s argument.
If US productivity figures are to be taken at anything close to face value – a persistently sluggish trend interrupted by a 16-year spurt that now appears to have faded – it is possible that all America has accomplished are transitional efficiency improvements associated with the IT-enabled shift from one technology platform to another.
Optimists maintain that the official statistics fail to capture marked quality-of-life improvements, which may be true, especially in the light of promising advances in biotechnology and online education.
But this overlooks a much more important aspect of the productivity-measurement critique: the undercounting of work time associated with the widespread use of portable information appliances.
In the US, the Bureau of Labor Statistics estimates that the length of the average workweek has held steady at about 34 hours since the advent of the Internet two decades ago.
Yet nothing could be further from the truth: knowledge workers continually toil outside the traditional office, checking their email, updating spreadsheets, writing reports, and engaging in collective brainstorming.
Indeed, white-collar knowledge workers – that is, most workers in advanced economies – are now tethered to their workplaces essentially 24 hours a day, seven days a week, a reality that is not reflected in the official statistics.
Productivity growth is not about working longer; it is about generating more output per unit of labor input.
Any undercounting of output pales in comparison with the IT-assisted undercounting of working hours.
China’s productivity slowdown is probably more benign.
It is an outgrowth of the Chinese economy’s nascent structural transformation from capital-intensive manufacturing to labor-intensive services.
Indeed, it was only in 2013 that services supplanted manufacturing and construction as the economy’s largest sector.
Now the gap is widening, and that is likely to continue.
With Chinese services requiring about 30% more workers per unit of output than manufacturing and construction, combined, the economy’s structural rebalancing is now shifting growth to China’s lower-productivity services sector.
China has time before this becomes a problem.
As Gordon notes, there have been long-lasting productivity dividends associated with urbanization – a trend that could continue for at least another decade in China.
But there will come a time when this tailwind subsides and China begins to converge on the so-called frontier of the advanced economies.
At that point, China will face the same productivity challenges that confront America and others.
Chinese policymakers’ new focus on innovation-led growth seems to recognize this risk.
Without powerful innovations, sustaining productivity growth will be an uphill battle.
China’s recent shift to a slower-productivity trajectory is an early warning of what may well be one of its most daunting economic challenges.
There is no escaping the key role that productivity growth plays in any country’s economic performance.
Yet, for advanced economies, periods of sustained rapid productivity growth have been the exception, not the rule.
Recent signs of slowing productivity growth in both the US and China underscore this reality.
For a world flirting with secular stagnation, that is disturbing news, to say the least.
A New Blueprint for US-China Relations
NEW YORK – In the coming decades, nothing will matter more for global peace, prosperity, and governance than how the United States and China handle the ongoing shift in their relative power.
In the long term, today’s other pressing challenges – including Russia’s relationship with the West and events in the tumultuous Middle East – will amount almost to sideshows by comparison.
What makes the Sino-American relationship dangerous is that powerful forces in both countries seem intent on a collision course.
On the Chinese side, under Xi Jinping’s assertive leadership, the government is no longer heeding Deng Xiaoping’s injunction that the country should “hide its strength, bide its time, and never take the lead” in international affairs.
It has pursued manifestly expansionist territorial claims, most notably in the South China Sea, and shown a clear determination to resist the indefinite continuation of American dominance in the region.
The prevailing Chinese mindset is that the US is intent on isolating, containing, and undermining it.
Unhappily, there is plenty of evidence on the US side to feed that sentiment.
Whatever many American policymakers may be saying in private, their public discourse almost invariably reflects an intention to remain the world’s dominant power – and specifically in Asia – in perpetuity.
The most confrontational recent articulation of this position can be found in a report for the Council on Foreign Relations, by Robert Blackwill and Ashley Tellis, arguing that the central objective of American grand strategy must be “preserving US primacy in the global system,” and urging a series of aggressive economic, political, and military measures to “balance” China.
They say this is not a “containment” strategy, but it amounts to nothing less.
Is there another way to manage the relationship that, while reflecting the reality of these forces and mindsets on both sides, would not risk turning legitimate competition into dangerous confrontation?
In a new report for the Harvard Kennedy School’s Belfer Center for Science and International Affairs, Kevin Rudd, former Australian Prime Minister and now head of the Asia Society Policy Institute, outlines just such a strategy, which he calls “constructive realism”.
It’s a clunky label, but his analysis and policy prescriptions are compelling.
The “realist” dimension of Rudd’s argument recognizes that certain areas of disagreement – including Taiwan, territorial disputes in the South and East China Seas, US alliances in Asia, Chinese military modernization, and the legitimacy of China’s political system – will remain intractable for the foreseeable future.
They will defy easy solutions – and thus will require very careful management.
The “constructive” part of Rudd’s thesis argues for systematic collaboration – with the US treating China more as an equal – in tackling a series of other difficult issues at bilateral, regional, and global levels.
Bilaterally, such cooperation might involve an investment treaty, a joint intelligence task force on terrorism, a cyber-security protocol, agreed measures for managing unplanned military incidents, and mutual ratification of the Comprehensive Nuclear Test-Ban Treaty.
On a regional level, Rudd argues, the US and China could work on joint strategies to denuclearize and, ultimately, reunify the Korean Peninsula; tackle the lingering sore of Japan’s war history; harmonize regional trade agreements; and transform the East Asia Summit into a more complete Asia-Pacific Community.
Globally, Rudd believes that the joint agenda could focus on combating climate change, revitalizing the G-20, further internationalizing the renminbi; giving China a greater role in the International Monetary Fund and the World Bank; and reforming other key international institutions within the UN system.
Some in the West – including veteran China watcher David Shambaugh – remain convinced that this kind of collaborative accommodation will not be necessary, because failures of economic and political management will bring about China’s implosion.
Rudd argues that they are wrong, and that Xi will neither overplay his authoritarian hand nor under-deliver on growth.
China’s rise will continue, and the world – including the US – will have to find principled ways of peacefully accommodating it.
Rudd’s recommendations are undoubtedly ambitious.
But, given his credentials – he is a formidable Chinese linguist and creative policy thinker, with long and close personal relationships with key figures in both the US and China – his argument must be taken seriously.
Indeed, though Rudd’s tenure as Australia’s prime minister was anything but smooth, his sheer force of intellect is unmatched by that of any public figure with whom I have interacted over the last 30 years.
(Not that this will much help his evident willingness to be drafted as the next UN Secretary-General: in that role the major powers have always preferred bland secretaries to creative generals.)
No American presidential candidate is likely to be comfortable talking about the US as anything other than Number One.
But we must hope that in the years ahead we hear less talk of “primacy” and “dominance” and much more about cooperation and collaboration.
It is only with such US policies toward China that the world can begin to be confident that the twenty-first century will not, like the last, become a vale of tears.
A Bilateral Foil for America’s Multilateral Dilemma
NEW HAVEN – The good news is that the United States and China appear to have backed away from the precipice of a trade war.
While vague in detail, a May 19 agreement defuses tension and commits to further negotiation.
The bad news is that the framework of negotiations is flawed: A deal with any one country will do little to resolve America’s fundamental economic imbalances that have arisen in an interconnected world.
There is a longstanding disconnect between bilateral and multilateral approaches to international economic problems.
In May 1930, some 1,028 of America’s leading academic economists wrote a public letter to US President Herbert Hoover urging him to veto the pending Smoot-Hawley tariff bill.
Hoover ignored the advice, and the global trade war that followed made a garden-variety depression “great.”
President Donald Trump has put a comparable spin on what it takes to “make America great again.”
Politicians have long favored the bilateral perspective, because it simplifies blame: you “solve” problems by targeting a specific country.
By contrast, the multilateral approach appeals to most economists, because it stresses the balance-of-payments distortions that arise from mismatches between saving and investment.
This contrast between the simple and the complex is an obvious and important reason why economists often lose public debates.
The dismal science has never been known for clarity.
Such is the case with the US-China debate.
China is an easy political target.
After all, it accounted for 46% of America’s colossal $800 billion merchandise trade gap in 2017.
Moreover, China has been charged with egregious violations of international rules, ranging from allegations of currency manipulation and state-subsidized dumping of excess capacity to cyber-hacking and forced technology transfer.
Equally significant, China has lost the battle in the arena of public opinion – chastised by Western policymakers, a few high-profile academics, and others for having failed to live up to the grand bargain struck in 2001, when the country was admitted to the World Trade Organization.
A recent article in Foreign Affairs by two senior officials in the Obama administration says it all: “(T)he liberal international order has failed to lure or bind China as powerfully as expected.”
As is the case with North Korea, Syria, and Iran, strategic patience has given way to impatience, with the nationalistic Trump administration leading the charge against China.
The counter-argument from multilateral-focused economists like me rings hollow in this climate.
Tracing outsize current-account and trade deficits to an extraordinary shortfall of US domestic saving – just 1.3% of national income in the fourth quarter of 2017 – counts for little in the arena of popular opinion.
Likewise, it doesn’t help when we emphasize that China is merely a large piece of a much bigger multilateral problem: the US had bilateral merchandise trade deficits with 102 countries in 2017.
Nor does it matter when we point out that correcting for supply-chain distortions – caused by inputs from other countries that enter into Chinese assembly platforms – would reduce the bilateral US-China trade imbalance by 35-40%.
Flawed as it may be, the bilateral political case resonates in a US where there is enormous pressure to ease the angst of the country’s beleaguered middle class.
Trade deficits, goes the argument, lead to job losses and wage compression.
And, with the merchandise trade gap hitting 4.2% of GDP in 2017, these pressures have only intensified in the current economic recovery.
As a result, targeting China has enormous political appeal.
So, what can be made of the May 19 deal?
Beyond a ceasefire in tit-for-tat tariffs, there are few real benefits.
US negotiators are fixated on targeted reductions of around $200 billion in the bilateral trade imbalance over a two-year time frame.
Given the extent of America’s multilateral problem, this is largely a meaningless objective, especially in light of the massive and ill-timed tax cuts and federal expenditure increases that the US has enacted in the last six months.
Indeed, with budget deficits likely to widen, America’s saving shortfall will only deepen in the years ahead.
That points to rising balance-of-payments and multilateral trade deficits, which are impossible to resolve through targeted bilateral actions against a single country.
Chinese negotiators are more circumspect, resisting numerical deficit targets but committing to the joint objective of “effective measures to substantially reduce” the bilateral imbalance with the US.
China’s vague promise to purchase more American-made agricultural and energy products borrows a page from the “shopping list” approach of its earlier trade missions to the US.
Unfortunately, the big-wallet mindset of a deal-hungry China reinforces the US narrative that China is guilty as charged.
Even if the stars were in perfect alignment and the US was not facing a saving constraint, it stretches credibility to seek a formulaic bilateral solution to America’s multilateral problem.
Since 2000, the largest annual reduction in the US-China merchandise trade imbalance amounted to $41 billion, and that occurred in 2009, during the depths of the Great Recession.
The goal of achieving back-to-back annual reductions totaling more than double that magnitude is sheer fantasy.
In the end, any effort to impose a bilateral solution on a multilateral problem will backfire, with ominous consequences for American consumers.
Without addressing the shortfall in domestic saving, the bilateral fix simply moves the deficit from one economy to others.
Therein lies the cruelest twist of all.
China is America’s low-cost provider of imported consumer goods.
The Trump deal would shift the Chinese piece of America’s multilateral imbalance to higher-cost imports from elsewhere – the functional equivalent of a tax hike on American families.
As Hoover’s ghost might ask, what’s so great about that?
America Confronts Old and New Europe
US Secretary of Defense Donald Rumsfeld's petulant remark of last year about "old and new Europe" was right for the wrong reasons.
He meant it to refer to Europe's divisions, but in May, ten additional states joined the European Union.
The expanded Europe truly forms a new Europe.
Should America be nervous?
Fifty-four years after the announcement of the Schuman Plan that began to knit together the economies of France and Germany, the EU now has 25 countries and a population larger than that of the United States.
Eight of the new members are former Communist countries that were locked behind the Iron Curtain for nearly half a century.
Their attraction to the Union is a sign of the appeal - the "soft power" - of the idea of European unification.
Of course, this new Europe faces many problems.
The per capita income of the new countries is less than half of that of the fifteen members they are joining. Concerns have been raised about the influx of cheap labor.
But average GDP growth rates in the new members are twice as high as in the original members, and this can provide a welcome stimulus to stagnant labor markets and sluggish economies.
Political arrangements are somewhat more problematic.
Negotiations are underway to revise a draft EU constitution.
Some Europeans worry that the constitution will enable courts to carry the integration process further and faster than public opinion in member states will tolerate.
Lack of grassroots support might lead to rejection of the constitution in countries like Britain, where referenda have been promised before the new arrangements come into force.
Across the Atlantic, most Americans (to the extent they pay attention) regard these changes with general approval.
But some express concern that the new Europe will be defined in opposition to the US.
Not only do the remarks of French leaders about recreating a multi-polar world arouse alarm, but recent public opinion polls show a decline in the popularity of the US among Europeans and a desire for more independent policies.
The Iraq War proved costly to American soft power, with the US losing about 30 percentage points of attractiveness on average in Europe, including in countries like Britain, Spain, and Italy, whose governments supported the war.
The recent photographs of detainees being abused and sexually degraded in Baghdad's Abu Ghraib prison added fuel to the fire.
Now some American neo-conservatives argue that the US should drop its longstanding support for European integration.
Such a policy change would be a serious mistake.
Not only would it add to anti-American attitudes and fail to accomplish its objectives, but it over-estimates the extent to which the new Europe is being formed in opposition to the US.
Whatever the rhetoric in France, for example, the policies and attitudes in countries such as Britain or Poland demonstrate that good trans-Atlantic relations can be maintained.
If anything, the risks of a US-Europe split will be reduced rather than increased by the EU's recent enlargement.
Moreover, there are several objective reasons why the current friction between Europe and the US is unlikely to lead to divorce.
For one thing, the divisive war in Iraq may turn out to be the last act of the twentieth century rather than a harbinger of the twenty-first.
American unilateralism is much less in evidence in the world's other hot spots, such as North Korea and Iran, both because of the costs of the war in Iraq and the realities of the situation in those other regions.
Moreover, while the common security threat from the Soviet Union has disappeared, both the US and Europe face a new common threat from radical jihadist terrorism.
Neither side of the Atlantic is immune to the threat, despite the efforts of Osama bin Laden to drive a wedge between Europe and America.
Transnational terrorism can only be confronted by close civilian cooperation such as intelligence sharing, police work across borders, and tracing financial flows. These forms of cooperation survived the divisions over Iraq.
Europe and America also share a common structure of economic interests and values.
While trade produces frictions in democracies, it also enhances wealth.
If one looks at foreign direct investment, it is clear that the two sides of the Atlantic are closely integrated.
In terms of values, while some differences exist between Europe and America, at the fundamental level of democracy and human rights, no other two parts of the globe share more.
As the writer Robert Kagan concluded in the revision of his book in which he declared Europeans to be from Venus and Americans from Mars, it turns out that Americans seeking democratic legitimization of their policies and self-images cannot escape Europe.
In short, it is good for Americans - and for the world - that old and new Europe are becoming one.
We can all benefit from the soft power of an enlarged Europe.
America’s Baby Bust
LONDON – News that the United States’ fertility rate fell in 2017 to 1.75 has provoked surprise and concern.
A buoyant US economy in the 1990s and early 2000s was accompanied by fertility rates of 2.00-2.05 children per woman, up from 1.8-1.9 in the 1980s.
But the increasingly strong economic recovery of the last five years has been accompanied by a declining birth rate.
That seems to presage a long-term shortage of workers relative to retirees, and severe financial pressures on pension funds and health-care provision.
But the assumption that stronger growth and economic confidence must generate higher fertility – with low birth rates reflecting pessimism about the future – is not justified by the evidence.
Moreover, fertility rates at around the current US level do not pose severe problems – and bring some benefits.
In all major developed economies, fertility rates fell during the 1960s and 70s, reaching levels below the replacement rate of around 2.05 children per woman.
The US rate reached 1.77 in the late 1970s, compared to 1.8 in Northern Europe and 1.65 in Western Europe.
And while we cannot be certain, the best expectation is that this shift to fertility rates significantly below the replacement rate will prove permanent, with temporary reversals driven by specific one-off factors.
Some viewed the US return to somewhat higher fertility rates in the 1990s as the consequence of greater economic dynamism and confidence, in contrast to “old Europe.”
But throughout the last 30 years, fertility rates for white and black Americans have remained significantly below replacement level, and the three-decade rise and fall of US birth rates is explained primarily by higher Hispanic fertility, reflecting the common phenomenon that first-generation immigrants’ fertility rates are typically similar to those in their poorer countries of origin.
The same effect explains why Canada – with immigration skewed toward low-fertility Asian countries of origin – has had a significantly lower fertility rate of around 1.6.
But with Latin American fertility rates now in steep decline – Mexico’s is down from 2.9 in 2000 to 2.1 today, and Brazil’s has fallen from 2.5 to 1.7 – the immigrant-induced effect is disappearing, and the US is reverting to a typical fertility rate for a rich developed country.
Absent temporary migration-induced effects, all major developed economies have shifted to fertility rates of 1.2-2.0, with most falling between 1.3 and 1.9.
And while there is some evidence that sudden deep recessions produce temporary fertility dips, followed by rebounds, cross-country comparison provides no evidence of any correlation – positive or negative – between medium-term economic success and precise fertility rates within this range.
Canada, with its lower fertility rate, is quite as successful and confident as the US.
Strong German growth over the last 20 years has been combined with a fertility rate of 1.4-1.5, well below the 1.98 rate in less successful France.
South Korea has maintained economic expansion with a fertility rate of just 1.2-1.3.
Latin America’s most prosperous economy, Chile, has a fertility rate of 1.76, well below less successful Argentina’s rate of 2.27.
The recent decline in US fertility is therefore unsurprising; and, provided it does not fall to much lower levels, there is no cause for concern.
Of course, in the long run, a lower fertility rate, combined with rising life expectancy, will produce a higher ratio of those over 65 years old to those conventionally labeled as “working age.”
But as people live longer and healthier lives, retirement ages can and should be increased.
And in a world of radical automation potential, which threatens low wage growth and rising inequality, a rapidly growing workforce is neither necessary nor beneficial, and a slightly contracting supply of workers may create useful incentives to improve productivity and support real wage growth.
Notably, fears that robots will take jobs are much less prevalent in Japan and China than in higher-fertility Western countries.
In rich developed societies with modern attitudes to the role of women, fertility rates somewhat below replacement levels may thus be both inevitable and broadly welcome.
But degree matters, and extremely low fertility, such as Japan’s rate of 1.4, will create major problems if permanently maintained.
The United Nations median projection suggests that the total population of North and South America, after growing by another 15-20% between now and 2050, will remain roughly stable for the rest of the twenty-first century.
By contrast, Japan’s population is projected to fall from 125 million today to around 80 million.
Demographic contraction on that scale will severely stress Japan’s ability to support an aging population.
Intelligent policy should therefore identify and remove any barriers unnecessarily depressing birth rates, such as labor-market discrimination, limited parental leave, or inadequate childcare facilities, which make it difficult for women to combine careers with having as many children as they wish.
The Scandinavian countries are exemplary in this respect, though fertility rates there have not returned to replacement levels, but only to about 1.75-1.9.
Similar policies in the US might marginally increase the fertility rate from today’s 1.75, with a mildly beneficial net effect.
But the predominant response to America’s recent fertility decline should be to accept it as inevitable and to stop worrying about it.
The US Is Exporting Obesity
CAMBRIDGE – As US President Donald Trump’s administration throws sharp elbows in trade negotiations and systematically rescinds regulations introduced by President Barack Obama, one casualty is likely to be efforts to fight the global obesity epidemic.
Left unchecked, rapidly rising obesity rates could slow or even reverse the dramatic gains in health and life expectancy that much of the world has enjoyed over the past few decades.
And by forcing its food culture on countries like Mexico and Canada, the United States is making the problem worse.
One of the paradoxes of modern global capitalism is that whereas more than 800 million people in the world do not have enough to eat, an estimated 700 million people (including 100 million children) are obese.
Of course, the two are not necessarily directly related. A considerable proportion of world hunger occurs in countries suffering from domestic strife or severe government dysfunction.
The obesity epidemic, however, has a much broader footprint, affecting advanced economies and most emerging markets.
Although there is some connection between obesity and poverty within countries, it is notable that obesity rates in rich countries such as the United States, the United Kingdom, and Canada are among the world’s highest.
Recently, the US Centers for Disease Control estimated that a stunning 40% of all Americans are obese (defined as having a body mass index of 30 or higher), a figure that includes 20.6% of adolescents (12-19 years old).
According to the CDC, the average weight of an American woman today is greater than the average weight of an American man in 1960 (166 pounds, or 75 kilos).
Back in 1960, the average weight of an American woman was 140 pounds, while the average weight of an American man today is 195 pounds. (Over the same period, the average height of Americans increased by only one inch, or 2.5 centimeters.)
This same dynamic is playing out worldwide, with obesity rates soaring in Europe, Latin America, and even in China.
Although it is difficult to gauge the long-run health consequences, there is abundant evidence that obesity contributes significantly to higher rates of type II diabetes, heart attacks, and certain types of cancer.
The health costs are staggering, estimated to be close to $200 billion per year in the US alone.
And with rising childhood obesity rates worldwide portending significantly greater health problems in the future adult population, the costs are likely to rise considerably.
The causes of obesity are manifold and complex.
Nevertheless, a growing body of evidence suggests that a culture emphasizing processed food and a generally sedentary lifestyle lies at the center of the problem.
In emerging markets, rapid urbanization is another important factor, as well as a desire to emulate Western lifestyles.
Many governments have launched initiatives to improve nutrition education.
Unfortunately, industry advertising typically dwarfs these efforts, as do US trade lobbyists’ own efforts to push processed and fast food on the rest of the world.
It is hard to ignore the fact that Mexico’s adult obesity rate has soared since the adoption in 1993 of the North American Free Trade Agreement.
While there are many causes, post-NAFTA direct foreign investment in the processed food industry and a surge in advertising are important contributors.
Mexican consumption of sugary beverages nearly tripled between 1993 and 2014, and a new tax on sugary drinks has muted demand only slightly since then.
The other NAFTA partner, Canada, has similarly experienced a rise in obesity, partly because US imports have led to a sharp decline in the price of fructose.
It is unfortunate that government regulators have been so slow to try to reverse these trends by, for example, helping to educate the public on the science of nutrition.
And, for too long, most government anti-obesity education has focused on mechanically regulating calorie intake, without taking into account that different foods have dramatically different effects on appetite (as David Ludwig, a professor at Harvard Medical School, emphasizes in his excellent new book Always Hungry).
Skeptics may point out that nutrition guidelines always seem to be morphing, with last year’s sin food becoming this year’s superfood, and vice versa.
Though there is some truth to this, the fact is that nutrition research has made significant progress in recent decades.
The government has other tools at its disposal, besides education, for affecting people’s eating habits.
They can and should place greater restrictions on advertising to children, as the UK, France, and several other countries have done; obesity in early years can lead to lifelong problems.
Beyond that, Ludwig, Tufts University’s Dariush Mozaffarian, and I have proposed instituting a tax on processed food, much the same way that tobacco is taxed.
Proceeds from the tax could be used to subsidize healthier alternatives.
It is perhaps fantasy to expect the current US administration to consider any kind of anti-obesity strategy while it is still busy dismantling Obama-era policies.
But that is all the more reason why countries entering new trade agreements with the US (for example, the post-Brexit UK, or post-NAFTA Canada) must be wary of any provisions that tie their hands in the war against obesity.
“America First” Financial Regulation?
LONDON – As US President Trump struggles to staff his administration with sympathizers who will help transpose tweets into policy, the exodus of Obama appointees from the federal government and other agencies continues.
For the financial world, one of the most significant departures was that of Daniel Tarullo, the Federal Reserve governor who has led its work on financial regulation for the last seven years.
It would be a stretch to say that Tarullo has been universally popular in the banking community.
He led the charge in arguing for much higher capital ratios, in the United States and elsewhere.
He was a tough negotiator, with a well-tuned instinct for spotting special pleading by financial firms.
But crocodile tears will be shed in Europe to mark his resignation.
European banks, and even their regulators, were concerned by his enthusiastic advocacy of even tougher standards in Basel 3.5 (or Basel 4, as bankers like to call it), which would, if implemented in the form favored by the US, require further substantial capital increases for Europe’s banks in particular.
In his absence, these proposals’ fate is uncertain.
But Tarullo has also been an enthusiastic promoter of international regulatory cooperation, with the frequent flyer miles to prove it.
For some years, he has chaired the Financial Stability Board’s little-known but important Standing Committee on Supervisory and Regulatory Cooperation.
His commitment to working with colleagues in international bodies like the FSB and the Basel Committee on Banking Supervision, to reach global regulatory agreements enabling banks to compete on a level playing field, has never been in doubt.
Already, some of those who criticized him most vocally in the past are anxious about his departure.
Who will succeed him?
The 2010 Dodd-Frank Act created a vice-chair position on the Federal Reserve Board – which has never been filled – to lead the Fed’s work on regulation.
Will that appointee, whom Trump now needs to select, be as committed as Tarullo to an international approach?
Or will his principal task be to build a regulatory wall, protecting US banks from global rules?
We do not yet know the answers to these questions, but Fed watchers were alarmed by a January 31 letter to Fed Chair Janet Yellen from Representative Patrick McHenry, the vice chairman of the House Committee on Financial Services. McHenry did not pull his punches.
“Despite the clear message delivered by President Donald Trump in prioritizing America’s interest in international negotiations,” McHenry wrote, “it appears that the Federal Reserve continues negotiating international regulatory standards for financial institutions among global bureaucrats in foreign lands without transparency, accountability, or the authority to do so.
This is unacceptable.”
In her reply of February10, Yellen firmly rebutted McHenry’s arguments.
She pointed out that the Fed does indeed have the authority it needs, that the Basel agreements are not binding, and that, in any event, “strong regulatory standards enhance the stability of the US financial system” and promote the competitiveness of financial firms.
But that will not be the end of the story.
The battle lines are now drawn, and McHenry’s letter shows the arguments that will be deployed in Congress by some Republicans close to the president.
There has always been a strand of thinking in Washington that dislikes foreign entanglements, in this and other areas.
While Yellen’s arguments are correct, the Fed’s entitlement to participate in international negotiations does not oblige it to do so, and a new appointee might argue that it should not.
Such a reversal would generate tensions within the Fed, and where it would leave the FSB, or indeed the Basel Committee, is unclear.
In the early days of the Bank for International Settlements (where the Basel Committee’s secretariat is located) in the 1930s, the US government declined to take a board seat, and the US was represented by JP Morgan.
It is a little hard to see that arrangement working well today.
These questions are of more than passing interest in Europe.
European capital adequacy directives typically transpose Basel Accords into EU law.
If the Basel process stalls, transatlantic deals, which are the crucial underpinning of Western capital markets, will be far harder to reach.
There is a further complication arising from Brexit.
Absent any special deal between the EU27 and the United Kingdom, British and EU regulators will come together in Basel, not in the European Banking Authority.
If Basel becomes a talking shop, without the ability to set firm standards, another key link in the chain will be broken, and it will be harder for the UK to argue that if London’s banks meet international standards, they should be granted equal treatment in the EU.
As central bankers bid farewell to the devil they know, financial regulation has entered a period of high uncertainty – and high anxiety for policymakers as they await an announcement from Mar-a-Lago.
No likely Federal Reserve Board candidates have been spotted at poolside, or being interviewed on the golf course, but a decision cannot be far off.
Nothing can be taken for granted.
The financial world is holding its collective breath.
Navigating America’s Economic-Policy Shocks
NEW YORK – With a series of tax and trade moves being considered in the United States this year, emerging-market economies are likely to face devaluation pressure and volatility.
Three sources of US-fueled economic uncertainty, in particular, will rattle emerging markets in 2017.
The first is a border adjustment tax that would give tax breaks to US exporters, but impose a levy – or, equivalently, disallow deductions – on imports to the US.
Both President Donald Trump and the Republican-controlled US Congress have said they favor the scheme, which has a fair chance of being enacted.
Such a tax, or even the anticipation of its adoption, could drive up the US dollar’s exchange rate (which, ironically, would offset, at least partly, the improvement in the US trade imbalance for which the Trump administration may be hoping).
The second source of uncertainty is the possibility of more aggressive action on Chinese exports to the US.
The Trump administration has said many times that it will confront China over what it considers unfair trade practices.
Trump has openly mused about imposing a 45% tariff on Chinese imports.
The introduction of anything close to that would generate downward pressure on the renminbi, given the resulting reduction in demand for Chinese exports.
But such a move would serve to weaken many other currencies as well.
My research with Zhi Wang and Kunfu Zhu reveals that about half of Chinese exports to the US are value-added products manufactured with components from South Korea, Japan, Taiwan, Singapore, and other countries.
Because products from China are often part of integrated global or regional value chains, a US restriction on its imports from China would indirectly, but very quickly, translate into reduced exports of value-added items by other countries in Asia.
This slippage would likely offset any direct increase in these countries’ exports to the US, at least in the short and medium term, because re-organizing production chains is not a trivial matter.
A third US move that could unsettle emerging markets is faster-than-expected monetary tightening by the Federal Reserve.
A large interest-rate hike would translate into US dollar appreciation, and depreciation of developing-economy currencies.
One exception may be the currencies of commodity exporters.
Higher commodity prices, triggered in part by anticipation of increased demand as a result of a boost in US infrastructure spending, could cause these countries’ currencies to strengthen.
Even on that front, though, some commodity exporters – such as Brazil and Russia – may not see much improvement in their exchange rates, given the drag of other forces on their weak economies.
The challenges that US policy changes pose for emerging-market currencies include not only downward pressure, but also greater volatility.
What, then, should emerging-market countries do to enhance their resilience in anticipation of the shockwaves?
One option is to optimize the structure of capital inflows.
A second is to boost the flexibility of exchange rates.
On the former, as my research with Hui Tong shows, countries that rely heavily on borrowing from foreign banks or international capital markets are more vulnerable to capital flight than countries that depend mainly on foreign direct investment.
Therefore, to guard against exchange-rate volatility or US interest-rate changes, emerging markets should work to improve their business environments to attract FDI, which would reduce their reliance on short-term infusions of “hot money” – and thus lower their vulnerability to abrupt capital-flow reversals.
As for the second option, allowing nominal exchange-rate flexibility would enable currency values to align with underlying economic fundamentals more quickly.
Such adjustment is especially important for countries with rigid labor markets.
One danger of fixed exchange rates is the risk of an overvalued or undervalued currency, neither of which is good for economic stability.
The chance of either scenario is elevated when the forces influencing the equilibrium exchange rate become more volatile.
While the shape and timing of future US policies are uncertain, it seems clear that capital-flow management and nominal exchange-rate flexibility amount to good preparation.
To paraphrase Benjamin Franklin, if developing countries fail to prepare, they will have to prepare to fail.
Why Millennials Will Reject Trump
NEW YORK – The key political divide in the United States is not between parties or states; it is between generations.
The millennial generation (those aged 18-35) voted heavily against Donald Trump and will form the backbone of resistance to his policies.
Older Americans are divided, but Trump’s base lies among those above the age of 45.
On issue after issue, younger voters will reject Trump, viewing him as a politician of the past, not the future.
Of course, these are averages, not absolutes.
Yet the numbers confirm the generational divide.
According to exit polls, Trump received 53% of the votes of those 45 and older, 42% of those 30-44, and just 37% of voters 18-29.
In a 2014 survey, 31% of millennials identified as liberals, compared with 21% of baby boomers (aged 50-68 in the survey) and only 18% of the silent generation (69 and above).
The point is not that today’s young liberals will become tomorrow’s older conservatives.
The millennial generation is far more liberal than the baby boomers and silent generation were in their younger years.
They are also decidedly less partisan, and will support politicians who address their values and needs, including third-party aspirants.
There are at least three big differences in the politics of the young and old.
First, the young are more socially liberal than the older generations.
For them, America’s growing racial, religious, and sexual plurality is no big deal.
A diverse society of whites, African-Americans, Hispanics, and Asians, and of the native-born and immigrants, is the country they’ve always known, not some dramatic change from the past.
They accept sexual and gender categories – lesbian, gay, trans, bi, inter, pan, and others – that were essentially taboo for – or unknown to – their grandparents’ (Trump’s) generation.
Second, the young are facing the unprecedented economic challenges of the information revolution.
They are entering the labor market at a time when market returns are rapidly shifting toward capital (robots, artificial intelligence, and smart machines generally) and away from labor.
The elderly rich, by contrast, are enjoying a stock market boom caused by the same technological revolution.
Trump is peddling cuts in corporate taxes and estate taxes that would further benefit the elderly rich (who are amply represented in Trump’s cabinet), at the expense of larger budget deficits that further burden the young.
Indeed, the young need the opposite policy: higher taxes on the wealth of the older generation in order to finance post-secondary education, job training, renewable-energy infrastructure, and other investments in America’s future.
Third, compared to their parents and grandparents, the young are much more aware of climate change and its threats.
While Trump is enticing the older generation with one last fling with fossil fuels, the young will have none of it.
They want clean energy and will fight against the destruction of the Earth that they and their own children will inherit.
Part of the generational divide over global warming is due to the sheer ignorance of many older Americans, including Trump, about climate change and its causes.
Older Americans didn’t learn about climate change in school.
They were never introduced to the basic science of greenhouse gases.
That is why they are ready to put their own short-term financial interests ahead of the dire threats to their grandchildren’s generation.
In a June 2015 survey, 60% of 18-29 year-olds said that human activity was causing global warming, compared with just 31% of those 65 and older.
A survey released in January found that 38% of American survey respondents 65 and older favored fossil-fuel expansion over renewable energy, compared with only 19% of those 18-29.
Trump’s economic policies are geared to this older, whiter, native-born America.
He favors tax cuts for the older rich, which would burden the young with higher debt.
He is indifferent to the $1 trillion overhang of student debt.
He is reprising the 1990s NAFTA debate over free trade, rather than facing the far more important twenty-first-century jobs challenge posed by robotics and artificial intelligence.
And he is obsessed with squeezing a few more years of profit out of America’s coal, oil, and gas reserves at the cost of a future environmental catastrophe.
One might attribute Trump’s backward-looking mindset to his age.
At 70, Trump is the oldest person ever to become president (Ronald Reagan was slightly younger when he took office in 1981).
Yet age is hardly the sole or even the main factor here.
Bernie Sanders, certainly the freshest mind of all the 2016 presidential candidates and the hero of millennial voters, is 75.
The young are enchanted with Pope Francis, 80, because he puts their concerns – whether about poverty, employment difficulties, or vulnerability to global warming – within a moral framework, rather than dismissing them with the crass cynicism of Trump and his ilk.
The main issue here is mindset and political orientation, not chronological age.
Trump has the shortest time horizon (and attention span) of any president in historical memory.
And he is utterly out of touch with the real challenges facing the young generation as they grapple with new technologies, shifting labor markets, and crushing student debt.
A trade war with Mexico and China, or a tragically misconceived ban on Muslim migrants, will hardly meet their real needs.
Trump’s political success is a blip, not a turning point.
Today’s millennials, with their future-oriented perspective, will soon dominate American politics.
America will be multiethnic, socially liberal, climate conscious, and much fairer in sharing the economic benefits of new technology.
Too many observers remain fixated on the traditional party divides in the US Congress, not on the deeper demographic changes that will soon be decisive.
Sanders nearly captured the Democratic nomination (and would likely have triumphed in the general election) with a platform appealing powerfully to the millennials.
Their time is coming, most likely with a president they support in 2020.
What Makes America Great
CAMBRIDGE – Presidential inaugurations and commencement ceremonies are usually very emotional events.
They are rites of passage that mark both an end and a new beginning in the life of a country or an individual.
As a professor at Harvard’s Kennedy School of Government, I attend our commencement ceremony every year.
Despite this regularity, I still become emotional as I see my students complete a phase of their lives and contemplate their future.
One of the highlights of our ceremony is a video in which several professors and public personalities read, line by line, John F. Kennedy’s inaugural address.
It is a text written 56 years ago, in a different world, where the Cold War, the threat of nuclear Armageddon, and the challenges faced by so many newly independent poor states dominated policymakers’ concerns.
And yet, running at under 14 minutes, it never fails to move and inspire everyone in the audience, including that half of the graduates and their families who hail from other countries, near and far.
To understand why, it is useful to recall a few of the most famous passages.
For starters, there was Kennedy’s vow to defend freedom for its friends and from its enemies: “Let every nation know, whether it wishes us well or ill, that we shall pay any price, bear any burden, meet any hardship, support any friend, oppose any foe to assure the survival and the success of liberty.”
There was also his commitment to fight poverty: “To those people in the huts and villages of half the globe struggling to break the bonds of mass misery, we pledge our best efforts to help them help themselves, for whatever period is required – not because the communists may be doing it, not because we seek their votes, but because it is right.
If a free society cannot help the many who are poor, it cannot save the few who are rich.”
And this commitment was part and parcel of hemispheric solidarity: “To our sister republics south of our border, we offer a special pledge – to convert our good words into good deeds – in a new alliance for progress – to assist free men and free governments in casting off the chains of poverty.”
Finally, there was Kennedy’s ethic of service on behalf of the commonwealth: “And so, my fellow Americans: ask not what your country can do for you – ask what you can do for your country.
My fellow citizens of the world: ask not what America will do for you, but what together we can do for the freedom of man.”
These words’ enduring emotional appeal is rooted in their embrace of a potentially difficult course of action, motivated by a pledge to uphold values shared by citizens of America and the world alike.
It was this approach – one founded on a value-based system of rules, not on individual deals – that enabled the US to create and sustain a coalition of countries that could maintain peace and international cooperation.
Fast forward to today.
President-elect Donald Trump’s campaign narrative was based on the assumption that the US has fallen from its former greatness.
Jobs have moved to Mexico and China because weak leaders negotiated bad deals.
Immigrants, mostly illegal, have taken the few jobs that remain, killing and raping in their free time.
It follows that the US needs a president who will put America first and knows how to extract the best deals for it at every opportunity, using the country’s full might to advance its interests.
I doubt that an inaugural address based on these ideas will awe and inspire many audiences at commencement ceremonies, especially where many of those in attendance are citizens of other countries.
Such a speech will encourage no one to “bear any burden” for the sake of any universal principle or challenge, be it human rights or global warming.
It will not exhort us to focus on something bigger than ourselves.
Over the course of history, very few powerful states have developed a sense of themselves as being based not on ethnic heritage, but on a set of values that all citizens can live by.
For the US, it was “life, liberty, and the pursuit of happiness.”
For the Soviet Union, it was international proletarian solidarity – “workers of the world, unite.”
The European Union is based on universal values and principles that are so attractive that 28 countries have opted to join it; and, Brexit notwithstanding, some half-dozen more are trying to get in.
By contrast, a great and powerful Russia or China today – or the Third Reich in its time – may be able to garner the support of its citizens; but such states cannot constitute the basis of an international order that others find appealing, because they are based on a vision of themselves that does not encompass others.
The basis of America’s greatness and ability to lead the world stems from universal values that underpin a set of rules that uphold the others’ rights, not an America that tries to base its greatness on a set of deals aimed at getting the better of others.
Such an America will find its ability to lead the world compromised by a shortage of goodwill and an abundance of distrust.
Other countries will huddle together to protect themselves from the US bully.
If Trump really wants to make America great again, he should ponder how his inaugural address will sound to a global audience 56 years from now.
Will it inspire the Class of 2073 the way Kennedy’s address still inspires graduates today?
America Goes from Teacher to Student
Cambridge -- As the United States’ epic financial crisis continues to unfold, one can only wish that US policymakers were half as good at listening to advice from developing countries as they are at giving it.
Americans don’t seem to realize that their “sub-prime” mortgage meltdown has all too much in common with many previous post-1945 banking crises throughout the world.
The silver lining is that there are many highly distinguished current and former policymakers out there, particularly from emerging market countries, who have seen this movie before.
If US policymakers would only listen, they might get an idea or two about how to deal with financial crises from experts who have lived through them and come out safely on the other side.
Unfortunately, the parallel between today’s US crisis and previous financial crises is not mere hyperbole.
The qualitative parallels are obvious: banks using off-balance loans to finance highly risky ventures, exotic new financial instruments, and excessive exuberance over the promise of new markets.
But there are strong quantitative parallels as well.
Professor Carmen Reinhart of the University of Maryland and I systematically compared the run-up to the US sub-prime crisis with the run-up to the 19 worst financial crises in the industrialized world over the past 60 years.
These include epic crises in the Scandinavian countries, Spain, and Japan, along with lesser events such as the US savings and loan crises of the 1980’s.
Across virtually all the major indicators – including equity and housing price runs-ups, trade balance deficits, surges in government and household indebtedness, and pre-crisis growth trajectories – red lights are blinking for the US.
Simply put, surging capital flows into the US artificially held down interest rates and inflated asset prices, leading to laxity in banking and regulatory standards and, ultimately, to a meltdown.
When Asia and Latin America had their financial meltdowns in the 1990’s and early 2000’s, they took advice not only from the IMF, but also from a number of small panels composed of eminent people representing diverse backgrounds and experiences.
The US should do the same.
The head of the IMF, Frenchman Dominique Strauss-Kahn, could easily select a superb panel from any range of former crisis countries, including Mexico, Brazil, Korea, Turkey, Japan, and Sweden, not to mention Argentina, Russia, Chile, and many others.
Admittedly, the IMF’s panel would have to look past America’s current hypocrisy.
The US Treasury strongly encouraged Asia to tighten fiscal policy during its 1990’s crisis.
But today the US Congress and President are tripping over themselves to adopt an ill-advised giant fiscal stimulus package, whose main effects will be to tie the hands of the next president in simplifying the US tax code and closing the budget deficit.
Americans firmly told Japan that the only way to clean up its economy was to purge insolvent banks and regenerate the financial system through Schumpeterian “creative destruction.”
Today, US authorities appear willing to contemplate any measure, no matter how inflationary, to insure that none of its major banks and investment houses fails.
For years, foreign governments complained about American hedge funds, arguing that their non-transparent behavior posed unacceptable risks to stability.
Now, many US politicians are complaining about the transparency of sovereign wealth funds (big government investors mainly from Asia and the Middle East), which are taking shares in trophy American assets such as Citibank and Merrill Lynch.
In fact, having countries like Russia and China more vested in the well-being of the US economy would not be a bad thing.
Yes, the IMF ought to develop a voluntary code of conduct for SWF’s, but it should not be used as a weapon to enforce financial protectionism.
For years, I, along with many others, have complained that emerging markets need greater representation in global financial governance.
Today, the issue goes far beyond symbolism.
The US economy is in trouble, and the problems it spins off are unlikely to stop at the US border.
Experts from emerging markets and elsewhere have much to say about dealing with financial crises.
America should start to listen before it is too late.
Obamacare and Effective Government
BERKELEY – When historians look back on the United States’ Patient Protection and Affordable Care Act (ACA), President Barack Obama’s controversial 2010 health-care reform, we predict that they will not devote much attention to its regulations, its troubled insurance exchanges, or its website’s flawed launch.
Instead, we think that they will focus on how “Obamacare” encouraged a wave of innovation that gradually tamed the spiraling costs of a dysfunctional system, even as millions of previously excluded Americans gained access to health insurance.
Innovation is probably the least discussed aspect of health-care reform.
Yet it is crucial to “bending” the sector’s cost curve, because it enables the delivery of quality health care in cost-effective ways.
Obamacare has provided powerful new incentives for such innovation.
From 1980 to 2010, US health-care spending grew almost twice as fast as the economy, rising from 9.2% to 17.4% of GDP.
While many factors contributed to this surge, most experts agree that the single most important cause was a fee-for-service system that rewarded health-care providers for billing as many services as possible, rather than for keeping people healthy and treating their illnesses efficiently.
The ACA has been changing that, by establishing myriad new incentives to foster efficiency in health-care delivery – for example, by reducing costly and unnecessary hospital infections and readmissions, and by adopting electronic health records.
Most important, the ACA is providing incentives for the creation of “affordable care organizations,” “bundled payment systems,” and other delivery innovations to encourage better coordination of care, especially for patients with numerous chronic conditions.
Such patients are among the 10% who account for an estimated 64% of overall health care costs.
Around the US, providers, insurers, non-profits, and local governments are responding to the ACA’s incentives.
The Centers for Medicare and Medicaid Services (which provide health insurance to pensioners and the poor) has just announced its second round of grants – $665 million to 28 states, three territories, and the District of Columbia – to encourage innovations in health-care delivery.
Of course, it is still too early to declare victory, but Obamacare seems to be working.
According to a recent analysis by the Council of Economic Advisers (CEA), about ten million people gained health insurance coverage in 2014 as a result of the ACA – the largest increase in coverage in four decades.
But the real surprise is that growth in health-care spending slowed dramatically from 2010 to 2013, to roughly the same pace as GDP growth.
This represented a sharp break from the previous half-century; indeed, this period was characterized by the slowest growth in real per capita health-care spending on record.
To be sure, the ACA is only one factor in this promising trend; growth in health-care spending often slows in the wake of an economic downturn.
But Medicare spending, which is not affected by recessions, has slowed along with private health-care spending.
In a recent study, the CEA concluded that the ACA’s Medicare reforms account for a significant share of the slowdown.
The ACA is an example of how government can promote innovation to address major societal challenges by providing goals, directions, and incentives, rather than dictating solutions.
The government plays a role akin to that of a venture capitalist providing seed money and financial support to foster innovation.
In this scenario, different players – Medicare and Medicaid, state and local governments, private insurers, physicians, and social entrepreneurs – collaborate to hammer out effective solutions that can be scaled with government revenues.
For example, responding to the ACA’s incentives and flexibility, Arkansas and Oregon have launched bold experiments to revamp Medicaid, in part by rewarding health-care providers who deliver better outcomes and keep patients healthier.
In Camden, New Jersey, Jeffrey Brenner, a family doctor, has pioneered strategies to reduce hospital stays by “super-utilizers,” a small share of Medicaid patients who are frequently admitted for expensive acute care.
Brenner mapped “hot spots” around Camden, and sought to find out why people in some areas ran up such huge bills.
The problem was not fraud. It was an absence of coordinated medical care, especially basic primary care, and a lack of attention to people’s underlying risk factors.
The most expensive 1% of patients, those with a tangle of issues, accounted for 30% of Camden’s public health-care spending.
Brenner’s Camden Coalition of Healthcare Providers, founded in 2003, received its first funding from a philanthropy, the Robert Wood Johnson Foundation, and a private insurer, United Health Care.
The remarkable success in Camden has prompted the foundation to fund similar experiments in Boston, Cleveland, Cincinnati, western Michigan, and Humboldt County, California.
Now the government is providing additional support, with grants to similar programs in Maryland, Colorado, Pennsylvania, and North Carolina.
Oregon has entered into a pay-for-success bargain with the federal government.
The state will receive $1.9 billion over five years to revamp its Medicaid services along the lines of Camden’s approach.
Oregon will get the money only if its per-person Medicaid costs climb substantially more slowly than other states’.
At the moment, Oregon is on track.
Arkansas has moved 20 different “episodes” of health-care delivery (including hip and knee replacements, pregnancy, colonoscopies, asthma, and congestive heart failure) from fee-for-service to paying for quality outcomes.
The results so far are promising – not just by reining in costs, but also by better aligning service delivery with best practices.
The government can spur innovation by offering incentives that tap many different players’ strengths.
In health care, that means taking advantage of the purchasing clout of Medicare and Medicaid, the risk-taking of social entrepreneurs and philanthropists, and the dynamism of markets and private business.
And health-care reform is just one example in which government can deliver what the public wants by setting goals, encouraging creativity, and providing the resources to scale up what works.
Twenty-five years from now, we hope that historians look back on the ACA as the start of a new era of public-private collaboration to develop innovative solutions to complex social problems – and thus to restore trust in government itself.
America’s Hidden Debt
WASHINGTON, DC – Former US Secretary of the Treasury Lawrence H. Summers recently quipped that, “Fiscal stimulus is like a drug with tolerance effects; to keep growth constant, deficits have to keep getting larger.”
People like Summers worry about deficits because they doubt that the money the government is borrowing is being spent in ways that will push the long-term growth of GDP above that of the debt.
Unless the mix of spending changes, the debt-to-GDP ratio will continue to grow, foretelling disaster.
Others do not share such concerns.
On the political left, Nobel laureate Paul Krugman, for example, argues that for “a country that looks like the United States, a debt crisis is fundamentally not possible.”
On the right, John Tamny, Forbes’ political economy editor, says, “Ignore the endless talk of doom, budget deficits really don’t matter.”
But while judgments differ about the sustainability of US government debt, they both accept the standard measure of it as accurate.
This is a mistake, and possibly a catastrophic one.
The Congressional Budget Office (CBO) recently reported that the federal budget deficit in the first ten months of this fiscal year was $116 billion higher than it was at the same time last year.
The CBO is now projecting that the annual deficit will reach $1 trillion by 2020.
This is worrying, but it does not reflect the harsh truth. The annual deficit almost certainly surpassed $1 trillion last year.
To understand why, think of America as a home with a leaky roof.
If you wanted to sell that home to a buyer who is financing the purchase with a mortgage, federal real-estate law would require you to get an appraisal, which would show that the roof needs repairs.
In this scenario, your maintenance delays cannot be ignored.
The law requires that you disclose and pay for the hidden costs of repairing the roof. Otherwise, you are stealing from the buyer.
True, unlike the mortgage on your balance sheet, you may not regard roof maintenance as a current liability.
But putting it off doesn’t make it disappear.
It is still a real debt – just one that has gone unaccounted for.
The federal government also has debt that has not been accounted for, and which one doesn’t often hear about.
The debt that has been accounted for is the $15.6 trillion held by the public in the form of US Treasury bonds. The debts that have not been accounted for include the deferred costs of maintenance on roads, water systems, and 54,560 structurally deficient bridges, as well as the yet-to-be-built low-carbon energy systems necessary to mitigate the catastrophic effects of climate change.
And these are just two broad examples.
So, just how much hidden US debt is there?
At this point, we must rely on rough estimates.
For example, according to a 2016 report from the American Society of Civil Engineers (ASCE), upgrading the country’s crumbling infrastructure would cost $5.2 trillion.
And, according to a 2014 International Energy Agency (IEA) report and our own calculations based on the US share of global CO2 emissions, transitioning to a clean-energy system will cost an additional $6.6 trillion.
All told, that is $11.8 trillion in unaccounted-for non-inflation-adjusted liabilities.
To be sure, these debts are not solely federal liabilities.
In the past, state and local governments were responsible for most infrastructure and climate costs.
However, already burdened with more than $3 trillion of municipal debt, state governments are overwhelmed by the scale of their deferred-maintenance liabilities and the only recently documented costs of climate change abatement.
However, because climate change and infrastructure security are national issues, rather than local, the federal government is ultimately responsible for that $11.8 trillion in infrastructure- and environment-related debts.
They are America’s national “leaky roof.”
That figure increases every year, because as bridges continue to weaken, it costs even more to fix them; and as sea levels and temperatures continue to rise, and as forest fires become more severe, it costs more to mitigate the damage.
In fact, between 2012 and 2016, the ASCE increased its estimate of America’s annual infrastructure-investment gap by $221 billion – about $55 billion per year.
And between 2012 and 2014, the IEA increased its estimated cost of moving to a clean-energy system by roughly $270 billion per year.
Together, the unaccounted-for inflation-adjusted deficit amounted to $345 billion – just from delaying needed infrastructure and climate abatement spending.
The 2017 US federal deficit was $665 billion, reflecting the amount by which debt that is actually accounted for increased.
If infrastructure and climate debt that is not accounted for were to be included, the all-in deficit in 2017 would have been over $1 trillion.
Yes, these are back-of-the-envelope calculations, but they point to an urgent question: Why isn’t the US counting its hidden debts?
The short answer is that the law doesn’t require it.
The federal “debt limit” was never a firm construct, and under pressure it became a squishy “ceiling suspension” that allows the government to borrow as much as it wants.
Meanwhile, a congressional rule that was intended to ensure fiscal responsibility by prohibiting deficit increases above $1.5 trillion within a ten-year window has become an accounting trick to escape responsibility for the 11th year and beyond.
But just as we are stealing from the homebuyer if we do not disclose and pay for our leaky roof, we are stealing from future generations of Americans when we ignore the full extent of government liabilities.
Until all debt is counted, we cannot even begin to know whether fiscal policies are having positive or negative effects on future growth.
America’s Second Chance with India
NEW YORK – Indian Prime Minister Narendra Modi’s visit to Washington, DC, in June garnered little public attention outside of India.
Yet diplomats and military professionals in Asia and beyond were certainly watching closely.
For good reason: the rapprochement between the world’s two most populous democracies could shape the world’s future.
It is worth noting that in his address to the US Congress, Modi invoked the word “partner” or “partnership” no fewer than 15 times.
The official joint statement released by the two governments described India as a “Major Defense Partner” of the United States, eligible for advanced technologies with military applications.
The relationship between India and the US has evolved from one of cool distance to strategic proximity in a generation – lightning fast for geopolitics.
The factors underlying this shift merit attention, for many of them are likely to bring the two countries even closer.
The Cold War’s end was a significant part of the bilateral rapprochement, because it eliminated the possibility of India’s continued association with the Soviet Union, as well as its rationale for embracing non-alignment.
A second factor is Pakistan.
For a long time, the US pursued an even-handed policy toward South Asia’s two most strategically important countries.
Nonetheless, during most of the Cold War, Pakistan was seen as a friendly country, whereas its great rival, India, was viewed as difficult.
This view was reinforced when Pakistan became the essential conduit of weapons to Afghans fighting the Soviet occupation of their country.
But the bond between the US and Pakistan weakened when Soviet forces withdrew from Afghanistan in 1989.
Relations suffered further from Pakistan’s development of nuclear weapons, its provision of sanctuary and support to the Taliban, and its willingness to extend hospitality to some of the world’s most dangerous terrorists, including Osama bin Laden.
As a result, US ties to India were no longer constrained by fear of complications in Pakistan.
China is also animating the improvement in India-US ties.
The motivation is far more fundamental than the fact that India and China still have an unresolved border.
China’s rise has created a strong incentive for countries with a stake in Asia to increase their cooperation with the US, as well as with one another, to ensure that they can stand up to China’s political, military, and economic might.
Domestic politics also loom large in the relationship’s development – on both sides.
The decline of India’s Congress party reduced the influence of the political force most associated with maintaining distance from the US.
Meanwhile, there are now more than three million Indian-Americans, and, as with many other immigrant populations, they have become ever more prominent and powerful.
Supporting closer ties with India has become a rare example of bipartisan US foreign policy, and it can be expected to continue regardless of which party controls the White House or Congress after this November’s elections.
The breakthrough in bilateral ties came a decade ago, when the US lifted sanctions introduced in response to India’s nuclear weapons program and then signed an accord paving the way for US involvement in India’s civil nuclear energy program.
India, unlike both Pakistan and North Korea, is seen as a responsible nuclear power, a country the US now supports for membership in various groups designed to stem the further spread of nuclear materials and weapons.
Economic ties are also growing, along with India’s economy.
Bilateral trade has increased to more than $100 billion a year.
High-level visits have become commonplace.
Closer economic ties and large-scale collaboration on clean energy are a high priority.
One can also predict increased cooperation between the two countries’ military and intelligence establishments.
Indeed, joint efforts to keep the Indian Ocean open and safe are already a reality.
The US and India need not be formal allies for their relationship to have the desired effect on Chinese strategic calculations.
Challenges remain, of course.
Bureaucracy, corruption, and poor infrastructure continue to hold back India’s economy.
Indian leaders must also be careful not to do or say things that could alienate the country’s large Muslim minority.
And they must still ensure that close ties with the US are not simply the policy of one prime minister or party.
This means getting the Congress party fully on board and overcoming the resistance of career officials to new ways of thinking and acting.
It is difficult to overlook the irony in much of this.
More than a half-century ago, in the early years of the Cold War, many in Washington saw India as a potential model of non-Communist political and economic development.
For many reasons, things did not work out that way, as India became economically statist, for a time politically authoritarian, and geopolitically closer to the USSR than US officials liked.
Now, however, India is emerging as a successful example of a market-oriented democracy with close ties to the US.
Second chances are rare in life, but both India and the US may be getting just that.
America Keeping Haiti Down
The IDB, the world's largest regional development bank, works in Latin America and the Caribbean purportedly to “contribute to the acceleration of economic and social development.”
Its actions in Haiti, however, have severely undermined those goals.
Roughly $54 million in IDB loans for water infrastructure in Haiti, home to literally the world’s worst water, offered a proven path to preventing deadly water-borne diseases. Designed to assist in fulfilling the right to water in the most impoverished nation in the Western Hemisphere, these loans and the lives they could have saved instead have become pawns in a deliberate political power play.
In 2001, US officials threatened to use their influence to stop previously approved IDB funding unless Haiti’s majority political party submitted to political demands to accept a particular apportionment of seats in a Haitian electoral oversight body.
Soon after, at the behest of the US, instead of disbursing the loans as planned, the IDB and its members took the unprecedented step of implicitly adding conditions to require political action by Haiti before the funds would be released.
These actions violated the IDB’s own charter, which strictly prohibits the Bank and its members from interfering in the internal political affairs of member states.
Internal emails reveal that a US legal counselor inside the IDB proposed to the US Treasury Department that, though the loans faced no legitimate technical obstacles, the US could effectively block them by “slowing” the process.
Indeed, by requesting further review of the loans, Haiti would have to make scheduled payments before the funds were even disbursed.
“While this is not a ‘bullet-proof’ way to stop IDB disbursements,” the counsellor wrote, “it certainly will put a few more large rocks in the road.”
In 2001, then-US Ambassador to Haiti Dean Curran publicly and explicitly linked the withholding of IDB loans to the demand that Haiti’s political parties reach a compromise that America wanted.
These tactics worked.
Deprived of funds that had already been committed and expected, Haiti fell into arrears on money owed for loan repayment, triggering IDB policies that prevented the Bank from releasing loans.
In subsequent years, the US employed additional delaying tactics, working with the IDB to move the goal posts whenever Haiti appeared to be meeting their demands.
The results have been devastating.
The town of Port-de-Paix, slotted ten years ago by the IDB as the first project site due to its particularly deplorable water situation, has yet to see the implementation of any water projects.
A study conducted by Zanmi Lasante, Partners In Health, the Robert F. Kennedy Memorial Center for Human Rights, and New York University’s Center for Human Rights and Global Justice found no functioning public water sources in the city.
Researchers found three-quarters of water sources in the city contained high levels of coliform bacteria, a key indicator of contamination with fecal matter.
A frightening 15% of households reported symptoms likely related to typhoid.
If the US and other member states join the IDB and take on the responsibility to improve conditions in the Americas, they cannot then use their membership to undermine the basic rights of the people they claim to serve simply to advance their own political agenda.
The IDB and the US government must take responsibility for their actions and implement the necessary transparency mechanisms to ensure that such abuses do not recur.  Congressional inquiries and annual reviews of the Treasury Department by the Government Accountability Office could provide the oversight necessary to prevent future political misuse of the IDB and its funds.
The people of Haiti, as well as US taxpayers, deserve a system that makes public the status of IDB loans and projects in Haiti in order to ensure that the US and IDB member states uphold their commitments to development and human rights.
The Myth of Sound Fundamentals
NEW HAVEN – The spin is all too predictable.
With the US stock market clawing its way back from the sharp correction of early February, the mindless mantra of the great bull market has returned.
The recent correction is now being characterized as a fleeting aberration – a volatility shock – in what is still deemed to be a very accommodating investment climate.
After all, the argument goes, economic fundamentals – not just in the United States, but worldwide – haven’t been this good in a long, long time.
But are the fundamentals really that sound?
For a US economy that has a razor-thin cushion of saving, nothing could be further from the truth.
America’s net national saving rate – the sum of saving by businesses, households, and the government sector – stood at just 2.1% of national income in the third quarter of 2017. That is only one-third the 6.3% average that prevailed in the final three decades of the twentieth century.
It is important to think about saving in “net” terms, which excludes the depreciation of obsolete or worn-out capacity in order to assess how much the economy is putting aside to fund the expansion of productive capacity.
Net saving represents today’s investment in the future, and the bottom line for America is that it is saving next to nothing.
Alas, the story doesn’t end there.
To finance consumption and growth, the US borrows surplus saving from abroad to compensate for the domestic shortfall.
All that borrowing implies a large balance-of-payments deficit with the rest of the world, which spawns an equally large trade deficit.
While President Donald Trump’s administration is hardly responsible for this sad state of affairs, its policies are about to make a tough situation far worse.
Under the guise of tax reform, late last year Trump signed legislation that will increase the federal budget deficit by $1.5 trillion over the next decade.
And now the US Congress, in its infinite wisdom, has upped the ante by another $300 billion in the latest deal to avert a government shutdown.
Never mind that deficit spending makes no sense when the economy is nearing full employment: this sharp widening of the federal deficit is enough, by itself, to push the already-low net national saving rate toward zero. And it’s not just the government’s red ink that is so troublesome.
The personal saving rate fell to 2.4% of disposable (after-tax) income in December 2017, the lowest in 12 years and only about a quarter of the 9.3% average that prevailed over the final three decades of the twentieth century.
As domestic saving plunges, the US has two options – a reduction in investment and the economic growth it supports, or increased borrowing of surplus saving from abroad.
Over the past 35 years, America has consistently opted for the latter, running balance-of-payments deficits every year since 1982 (with a minor exception in 1991, reflecting foreign contributions for US military expenses in the Gulf War).
With these deficits, of course, come equally chronic trade deficits with a broad cross-section of America’s foreign partners.
Astonishingly, in 2017, the US ran trade deficits with 102 countries.
The multilateral foreign-trade deficits of a saving-short US economy set the stage for perhaps the most egregious policy blunder being committed by the Trump administration: a shift toward protectionism.
Further compression of an already-weak domestic saving position spells growing current-account and trade deficits – a fundamental axiom of macroeconomics that the US never seems to appreciate.
Attempting to solve a multilateral imbalance with bilateral tariffs directed mainly at China, such as those just imposed on solar panels and washing machines in January, doesn’t add up.
And, given the growing likelihood of additional trade barriers – as suggested by the US Commerce Department’s recent recommendations of high tariffs on aluminum and steel – the combination of protectionism and ever-widening trade imbalances becomes all the more problematic for a US economy set to become even more dependent on foreign capital.
Far from sound, the fundamentals of a saving-short US economy look shakier than ever.
Lacking a cushion of solid support from income generation, the lack of saving also leaves the US far more beholden to fickle asset markets than might otherwise be the case.
That’s especially true of American consumers who have relied on appreciation of equity holdings and home values to support over-extended lifestyles.
It is also the case for the US Federal Reserve, which has turned to unconventional monetary policies to support the real economy via so-called wealth effects.
And, of course, foreign investors are acutely sensitive to relative returns on assets – the US versus other markets – as well as the translation of those returns into their home currencies.
Driven by the momentum of trends in employment, industrial production, consumer sentiment, and corporate earnings, the case for sound fundamentals plays like a broken record during periods of financial market volatility.
But momentum and fundamentals are two very different things.
Momentum can be fleeting, especially for a saving-short US economy that is consuming the seed corn of future prosperity.
With dysfunctional policies pointing to a further compression of saving in the years ahead, the myth of sound US fundamentals has never rung more hollow.
America’s Midterm Elections Turn Menacing
WASHINGTON, DC – With the approach of this year’s midterm elections in the United States, domestic terrorism is starting to dominate the political landscape.
First, barely two weeks before Election Day, an angry supporter of US President Donald Trump began sending 14 bombs to prominent Democrats and others whom Trump has frequently attacked.
(None of the bombs exploded.)
Then things became much worse, with the murder, on a Saturday, of 11 Jews in a Pittsburgh synagogue.
Today, a polarized and anxious American public finds itself with a president totally unsuited to, and not very interested in, comforting the nation, much less trying to lead it away from the hate and deadly partisanship that he has stoked.
Had the 14 crude bombs, which the FBI called “potentially destructive devices,” worked as intended, the bombmaker could have killed or gravely injured a who’s who of Trump adversaries.
The list included two former presidents (Bill Clinton and Barack Obama), Hillary Clinton, former Attorney General Eric Holder; a former CIA director; a former director of National Intelligence; two likely Democratic presidential candidates in 2020; a black congresswoman whom Trump frequently describes as “low IQ” (a common racist charge); two prominent Jewish billionaire philanthropists, one of whom, George Soros, is a frequent target of Trump and the subject of various right-wing conspiracy fantasies; and the actor Robert De Niro (who began his speech at this year’s Tony Awards ceremony by declaring, “Fuck Trump”).
Though Trump had frequently singled out many of the bomber’s targets at his rallies – still attacking Hillary Clinton, his election opponent in 2016, for example, and then smiling as his audience chanted “Lock her up” – Trump’s defenders tried to throw the spotlight elsewhere.
The mail bombs, they claimed, were a “false flag” operation by the left, with some of the Democrats even sending the bombs to themselves in order to blame Trump.
So it was highly inconvenient for true believers when the would-be bomber turned out to be a fanatical Trump supporter who lives in Florida and drives a white van covered in hate-filled depictions of his targets.
US law enforcement agencies – another frequent target of Trump – are extremely good at tracking down miscreants: the suspect was arrested four days after the first bomb was discovered in Soros’s mailbox.
The most disheartening aspect of the entire episode was Trump’s utter incapacity as a national leader.
But that should surprise no one.
How could a president who has thrived politically on dividing the American people, who has been spewing hate, sowing resentment, and at times even encouraging violence at his rallies, suddenly be – or even pretend to be – a healer?
In fact, Trump’s pattern of incitement and routine denunciations of the media as “the enemy of the people” had convinced many that some of his followers might resort to violence against members of the press.
The day after the discovery of the bombs sent to the Clintons and the Obamas, among others, a subdued Trump read a prepared statement at a prescheduled White House ceremony, condemning “acts or threats of political violence” and saying that the nation must unify.
It didn’t last.
By that evening, at a rally in Wisconsin, he was making fun of his “trying to be nice” act and blamed the media for the violence.
And soon he was back to whipping up fear of a caravan of refugees from Honduras.
Though still roughly 1,000 miles from the US border, Trump portrayed the refugees as an imminent national security threat, warning, without evidence, that “Middle Easterners” were among them.
Trump’s rallies are now almost a daily event, and his lies are even more frequent than before.
With the entire House of Representatives and one-third of the Senate to be chosen on November 6, the upcoming midterm election is widely regarded as the most consequential in memory, perhaps ever.
The Republicans’ two-year lock on the entire US government – the House, the Senate, the presidency, and, with the recent addition of Justice Brett Kavanaugh, the Supreme Court – could be broken.
The midterm election following the election of a new president is often considered a verdict on the incumbent, and his party usually loses strength, particularly in the House.
But Trump has made the midterms about himself to an unprecedented degree.
He tells audiences that though he’s not on the ballot, they should vote as if he were (though his approval ratings are in the low forties).
It has long been believed that the Democrats are more likely to win the House than the Senate, because several of the Senate seats in play are held by Democrats in traditionally conservative states.
Trump’s determination, or anxiety, that Republicans maintain control of both chambers is understandable.
Should the Democrats take over the House, newly empowered committee chairmen, armed with subpoenas, will launch investigations of a broad range of administration actions and agencies, where extensive corruption is suspected.
But the real, almost palpable, fear on Trump’s part is that a Democratic-controlled House will focus all manner of investigations on him personally: his acceptance of Constitutionally forbidden “emoluments” from foreign countries; his failure to separate himself sufficiently from the family business; his tax returns; his unauthorized foreign wars in Yemen and Syria; and of course his official and private dealings with Russia.
At least the House is likely to have the conclusions of Special Counsel Robert Mueller to consider.
In other words, no more lapdog Congress.
But if the Republicans maintain control of the Senate, there will be limits on what the Democrats can achieve.
Even if the House were to impeach Trump – no sure thing – convicting him in the Senate would be extremely difficult.
Whether a Democratic House would even proceed in that direction has been the subject of intra-party debate.
The nightmare election possibility for the Democrats is continued Republican control of both chambers.
In that case, Trump will feel vindicated and more liberated than ever.
He might then fire a raft of officials, treat immigrants still more harshly, and try to shut down Mueller’s investigation of his campaign’s possible collusion with the Kremlin and Trump’s probable obstruction of justice.
The conventional wisdom may prevail, with the Democrats winning the House but not the Senate.
But the polls have been fluctuating.
And since Trump’s stunning election victory in 2016, most observers have become more cautious about predicting outcomes.
Alliances for Peace
WASHINGTON, DC – I grew up in the shadow of World War II, and at the dawn of the Cold War.
My father’s work as a Foreign Service officer gave me an opportunity to see history up close in a searing way: I will never forget walking the beaches of Normandy with him and seeing the burned hulks of Higgins’ boats still on those shores, just a few years after so many young men went to their graves so the world could be free.
Likewise, I will never forget the eerie feeling of riding my bike through the Brandenburg Gate from West Berlin into the East, and seeing the contrast between people who were free and those who were trapped behind the Iron Curtain.
What strikes me now, all these years later, is that a generation of leaders won not only a war, but also the peace.
They did it together.
The United States and our partners worked to create alliances that brought prosperity and stability to Western Europe, Japan, and South Korea.
Old enemies became new allies, and together pioneered a new global economic system that made the world more prosperous.
And even as the Cold War raged, leaders found ways to cooperate on arms control and prevent a nuclear Armageddon.
In short, by building effective and indispensable international institutions and strategic partnerships, we did not just avoid another catastrophic world war; we ultimately ended the Cold War and lifted global living standards for hundreds of millions of people.
That is the remarkable story of the twentieth century.
The question now is what story will emerge from the twenty-first century.
Today, the world order faces new challenges.
Russian aggression is rattling allies.
Extremists who hijack religion threaten governments and people everywhere.
Technology is accelerating a shift in the balance of power between governments and governed that offers both opportunities for democratic accountability and obstacles to inclusive politics.
We have gone from a world where power resided in hierarchies to one where it inhabits networks.
Statecraft has yet to adapt.
The international institutions and partnerships that emerged in the postwar years demand both maintenance and modernization.
In the face of all of this turbulence, some suggest that America should turn inward.
That is nothing new.
Some argued the same after WWII.
They argued it again 25 years ago, after the fall of the Berlin Wall.
They were wrong then – and they are wrong now.
The need for leadership has never been greater, and the US has never been more engaged with the world.
Our role in Afghanistan’s first-ever peaceful, democratic transition reminds us all that, having invested so much blood and treasure in helping to give Afghans a chance to succeed in battle, the world has just as much responsibility to help its leaders succeed in governance.
We know that the destruction of 100% of Syria’s declared chemical weapons would not have happened without direct, hands-on diplomacy and perseverance, just as Syria’s immoral and horrifying civil war will not end without an equal commitment.
So, too, in Asia, where President Barack Obama and Chinese President Xi Jinping just announced ambitious commitments to tackle climate change, we are reminded of what countries can accomplish together with real leadership – and of how much additional leadership is required to conclude a successful climate agreement in Paris next year.
The world has changed, and we are changing with it.
Lines on the map no longer contain the gravest threats, and the players are no longer divided neatly into two camps.
In the twenty-first century, next door is everywhere.
That is why the world needs coalition diplomacy.
No country can defeat terrorism on its own.
No country can solve the existential threat of climate change alone.
No country can eradicate extreme poverty, combat potential pandemics, or improve nuclear security by itself.
None of us can live safer, richer lives by turning our back to the world.
We must build on our history of working with allies by forming new coalitions – with governments, with civil society, and, yes, with everyday people.
A good example is the international effort to confront the Islamic State’s malign brutality in Iraq and Syria.
Political, humanitarian, and intelligence tools from more than 60 countries are being used to support unified military action.
Success depends not on what one or even a handful of countries can do alone, but on what all of us are able to achieve by moving forward together against this common threat.
On an equally important front, the US is working with the United Nations to galvanize a global response to the danger posed by the Ebola virus.
I have personally talked with more than 50 foreign leaders, and we all agree that only by coordinating our actions can we stop the devastation in West Africa and halt Ebola’s spread.
We are making progress on both issues, but much work remains.
Bringing together countries with competing interests and varying resources is hard work.
It demands intense diplomatic engagement and calls upon relationships that have been built and maintained over decades, as well as alliances with new partners.
But by overcoming differences and coordinating efforts to defeat the Islamic State and conquer Ebola, we are reinforcing support for a world order grounded in collective solutions to common problems.
Cooperation is equally vital in reinforcing the bedrock economic principles on which America and other countries built their postwar prosperity.
Frustration cannot grow faster than opportunity in any country.
For example, the negotiations on the Trans-Pacific Partnership (TPP) reflect President Obama’s determination to strike an accord with countries that represent one-third of global trade and 40% of global GDP.
The benefits – for both the US and our partners – are enormous.
Estimates are that the TPP could provide $77 billion a year in real income and support 650,000 new jobs in the US alone.
The Transatlantic Trade and Investment Partnership being negotiated with the European Union offers another major step toward increasing trade.
Whether for mutual security or shared prosperity, genuine partnerships are not built overnight.
Patient diplomacy and a collective will are needed to advance common goals. America’s objectives remain the same as they have been for decades – peace, prosperity, and stability for the US and for our partners around the world.
Closing the Investment Gap
BERKELEY – The weakness of private investment in the United States and other advanced economies is a worrisome – and perplexing – feature of the recovery from the 2008 global financial crisis.
Indeed, according to the International Monetary Fund, through 2014, private investment declined by an average of 25% compared to pre-crisis trends.
The shortfall in investment has been deep and broad-based, affecting not only residential investment but also investment in equipment and structures.
Business investment remains significantly below pre-2008 expectations, and has been hit hard again in the US during the last year by the collapse of energy-sector investment in response to the steep drop in oil prices.
Interestingly, the investment shortfall in the US coincides with a strong rebound in returns to capital.
By one measure, returns to private capital are now at a higher point than any time in recent decades.
But extensive empirical research confirms that at the macro level, business investment depends primarily on expected future demand and output growth, not on current returns or retained earnings.
According to the IMF, this “accelerator” theory of investment explains most of the weakness of business investment in the developed economies since the 2008 crisis.
In accordance with this explanation, investment growth in the US has been in line with its usual historical relationship with output growth.
In short, private investment growth has been weak primarily because the pace of recovery has been anemic.
Businesses have marked down their pre-crisis investment plans to reflect a post-crisis “new normal” of slower and more uncertain growth in demand for their output.
Under conditions of weak aggregate demand, stronger public investment encourages more private business investment.
But public investment, too, has fallen below pre-crisis expectations, aggravating rather than ameliorating the slump in private investment.
The accelerator explanation of the shortfall in business investment in the US is consistent with evidence that, where projected demand growth has been relatively strong – for example, in cable, telecommunications, digital platforms, social networking, and, until recently, energy – investment growth has also been relatively strong.
Indeed, telecom and cable companies accounted for the largest share of business capital expenditures during the last three years, with energy production and mining second on the list.
Differences in innovation opportunities across industries are also consistent with the changing composition of business investment.
During the 2009-2015 period, while business investment in equipment slowed in the US, it accelerated in intellectual property products, including research and development, software, and so-called artistic originals (the output of artists, studios, and publishers).
R&D investment usually expands faster than GDP during cyclical expansions, and the current period is in line with historical trends.
Indeed, as a share of the economy, R&D investment is now at its highest level on record, which bodes well for future productivity growth.
As the accelerator theory of investment would predict, much R&D investment is occurring in technology-intensive sectors where current and future expected demand has been strong.
There is also evidence that the distribution of returns to capital is becoming increasingly skewed toward these sectors.
According to a recent McKinsey Global Institute report, the most digitized sectors – ranked by 18 metrics on digital assets, digital usage, and digital workforce – enjoy significantly higher profit margins than traditional sectors.
In a recent letter to the chief executives of the S&P 500 companies and large European corporations, Larry Fink, the CEO of BlackRock, the world’s largest investment management company, expressed concern that many global firms may be sacrificing value-creating investments by distributing dividends and buying back their own shares.
Among US nonfinancial corporations, the proportion of investable funds used for dividends and share buybacks has been trending upward, albeit with cyclical ups and downs, since the 1980s.
After a sharp downturn during the 2008-2009 recession, this proportion has now recovered to nearly 50%, a high point relative to historical averages.
The macro evidence indicates that the primary cause of disappointing business investment in the US and other developed countries in the years following the global financial crisis has been anemic demand, not a lack of investable funds resulting from excessive distributions to shareholders.
Over the longer term, however, the upward trend in dividends and share buybacks as a percentage of corporate investable funds is a symptom of mounting shareholder pressure on corporations to focus on short-term returns at the expense of long-term investments.
In a recent McKinsey survey of 1,000 top executives and corporate directors, 63% reported that shareholder pressure to realize short-term returns has increased over the last several years.
Indeed, some 79% reported pressure to demonstrate strong financial returns in two years or less.
Shareholder pressure tends to be greater in older firms, and in the US over the last few decades, the proportion of older firms has been growing as the startup rate for new businesses has fallen.
In addition, as Fink and others have warned, compensation practices that link top executives’ pay to measures of short-term success like quarterly earnings per share or annual equity performance also encourage “short-termism” in corporate investment decisions.
A sliding capital gains tax, with rates that decline as the holding period for investments increases, would reduce incentives for short-termism among investors.
Among others, Larry Fink, the Center for American Progress, and Hillary Clinton propose this approach.
In his recent CEO letter, Fink also calls on companies to issue annual “strategic frameworks” for long-term value creation, supported by quantifiable financial metrics and linking long-term executive compensation to performance on them.
These frameworks, Fink notes, should cover environmental, social, and governance (ESG) factors that are core determinants of long-term value.
Companies can use the new evidence-based standards developed by the Sustainability Accounting Standards Board to disclose material information about their ESG performance to their investors.
Strategic frameworks, along with ESG disclosure, should encourage both companies and their shareholders to focus more on long-term value and less on short-term financial performance.
But at the macro level, expected growth in demand and associated innovation opportunities will remain the primary drivers of business investment.
Inequality and the American Child
NEW YORK – Children, it has long been recognized, are a special group.
They do not choose their parents, let alone the broader conditions into which they are born.
They do not have the same abilities as adults to protect or care for themselves.
That is why the League of Nations approved the Geneva Declaration on the Rights of the Child in 1924, and why the international community adopted the Convention on the Rights of the Child in 1989.
Sadly, the United States is not living up to its obligations.
In fact, it has not even ratified the Convention on the Rights of the Child.
The US, with its cherished image as a land of opportunity, should be an inspiring example of just and enlightened treatment of children.
Instead, it is a beacon of failure – one that contributes to global sluggishness on children’s rights in the international arena.
Though an average American childhood may not be the worst in the world, the disparity between the country’s wealth and the condition of its children is unparalleled.
About 14.5% of the American population as a whole is poor, but 19.9% of children – some 15 million individuals – live in poverty.
Among developed countries, only Romania has a higher rate of child poverty.
The US rate is two-thirds higher than that in the United Kingdom, and up to four times the rate in the Nordic countries.
For some groups, the situation is much worse: more than 38% of black children, and 30% of Hispanic children, are poor.
None of this is because Americans do not care about their children.
It is because America has embraced a policy agenda in recent decades that has caused its economy to become wildly unequal, leaving the most vulnerable segments of society further and further behind.
The growing concentration of wealth – and a significant reduction in taxes on it – has meant less money to spend on investments for the public good, like education and the protection of children.
As a result, America’s children have become worse off.
Their fate is a painful example of how inequality not only undermines economic growth and stability – as economists and organizations like the International Monetary Fund are finally acknowledging – but also violates our most cherished notions of what a fair society should look like.
Income inequality is correlated with inequalities in health, access to education, and exposure to environmental hazards, all of which burden children more than other segments of the population.
Indeed, nearly one in five poor American children are diagnosed with asthma, a rate 60% higher than non-poor children.
Learning disabilities occur almost twice as frequently among children in households earning less than $35,000 a year than they do in households earning more than $100,000.
And some in the US Congress want to cut food stamps – on which some 23 million American households depend, threatening the poorest children with hunger.
These inequalities in outcomes are closely tied to inequalities in opportunities.
Inevitably, in countries where children have inadequate nutrition, insufficient access to health care and education, and higher exposure to environmental hazards, the children of the poor will have far different life prospects from those of the rich.
And, partly because an American child’s lifetime prospects are more dependent on his or her parents’ income and education than in other advanced countries, the US now has the least equality of opportunity of any advanced country.
At America’s most elite universities, for example, only around 9% of students come from the bottom half of the population, while 74% come from the top quarter.
Most societies recognize a moral obligation to help ensure that young people can live up to their potential.
Some countries even impose a constitutional mandate for equality of educational opportunities.
But in America, more is spent on the education of rich students than on the education of the poor.
As a result, the US is wasting some of its most valuable assets, with some young people – bereft of skills – turning to dysfunctional activities.
American states like California spend about as much on prisons as on higher education – and sometimes more.
Without compensatory measures – including pre-school education, ideally beginning at a very young age – unequal opportunities translate into unequal lifelong outcomes by the time children reach the age of five.
That should be a spur to policy action.
Indeed, while inequality’s harmful effects are wide-reaching, and impose huge costs on our economies and societies, they are largely avoidable.
The extremes of inequality observed in some countries are not the inexorable result of economic forces and laws.
The right policies – stronger social safety nets, progressive taxation, and better regulation (especially of the financial sector), to name a few – can reverse these devastating trends.
To generate the political will that such reforms require, we must confront policymakers’ inertia and inaction with the grim facts of inequality and its devastating effects on our children.
We can reduce childhood deprivation and increase equality of opportunity, thereby laying the groundwork for a more just and prosperous future – one that reflects our own avowed values.
So why don’t we?
Of the harm that inequality inflicts on our economies, politics, and societies, the damage done to children demands special concern.
Whatever responsibility poor adults may bear for their lot in life – they may not have worked hard enough, saved enough, or made good decisions – children’s circumstances are thrust upon them without any sort of choice.
Children, perhaps more than anyone, need the protection that rights afford – and the US should be providing the world with a shining example of what that means.
American Conservatism’s Crisis of Ideas
BERKELEY – On the back left corner of my desk right now are three recent books: Arthur Brooks’ The Battle, Charles Murray’s Coming Apart, and Nicholas Eberstadt’s A Nation of Takers.
Together, they constitute an important intellectual movement, which also happens to be a large part of the reason that American conservatism today has little that is constructive to say about managing the economy – and little purchase on the center of the American electorate.
But let’s back up historically, to the founding of what we might call modern conservatism in early nineteenth-century Britain and France.
There were some – Frédéric Bastiat and Jean-Baptiste Say come to mind – who believed that government should put the unemployed to work building infrastructure when markets or production were temporarily disrupted.
But they were balanced by those like Nassau Senior, who spoke out against even famine relief: Although a million people would die in the Irish Potato Famine, “that would scarcely be enough.”
The main thrust of early conservatism was root-and-branch opposition to every form of social insurance: make the poor richer, and they would become more fertile.
As a result, farm sizes would drop (as land was divided among ever more children), labor productivity would fall, and the poor would become even poorer.
Social insurance was not just pointless; it was counterproductive.
The proper economic policy was to teach people to venerate the throne (so that they would respect property), the paternal hearth (so that they would not marry imprudently young), and the religious altar (so that they would fear pre-marital sex).
Then, perhaps, with women chaste for half or more of their childbearing years, the surplus population would diminish and conditions for the poor would be as good as they could be.
Fast-forward 150 years to post-World War II America, and to the original Chicago School critique of the New Deal version of social insurance – that it created “notches” that perverted economic incentives.
The government, Milton Friedman and others argued, told the poor: make more money and we will take away your free housing, food stamps, and income support.
People are rational, Friedman said, so they will not work for long if they get nothing or next to nothing for it.
The big difference between the Malthusian conservative critics of social insurance in the early nineteenth century and the Chicago critics of the 1970’s is that the Chicago critics had a point: Providing public support to the “worthy” poor, and then removing it when they began to stand on their own feet, poisoned incentives and was unlikely to lead to good outcomes.
And so, from 1970 to 2000, a broad coalition of conservatives (who wanted to see the government stop encouraging immorality), centrists (who wanted government money spent effectively), and leftists (who wanted poverty alleviated) removed the “notches” from the social-insurance system.
Presidents Jimmy Carter, Ronald Reagan, George H. W. Bush, Bill Clinton, and even George W. Bush and their supporters created the current system, in which tax rates and eligibility thresholds are not punitive disincentives to enterprise.
So what is the problem that America’s new generation of conservative critics of social insurance sees?
It is not that raising poor people’s standard of living above bare subsistence produces Malthusian catastrophe, or that taxes and withdrawal of welfare benefits make people work, at the margin, for nothing.
For Eberstadt, the problem is that dependence on government is emasculating, and that too many people are dependent on government.
For Brooks, it is that knowing that public programs make one’s life easier causes one to vote for non-Republican candidates.
For Murray, it is that social insurance means that behaving badly does not lead to catastrophe – and we need bad behavior to lead to catastrophe in order to keep people from behaving badly.
The crucial point is that America’s conservative elites believe Brooks, Eberstadt, and Murray.
To this day, Mitt Romney is convinced that he lost the presidency in 2012 because Barack Obama unfairly gave Latino-Americans subsidized health insurance; gave women free reproductive health coverage (excluding abortion); and gave other groups similar “gifts.”
He could “never convince them that they should take personal responsibility and care for their lives.”
In fact, it would be a tough sell for any candidate to convince Americans who receive government benefits that they are dependent rather than empowered; that it is bad for people to vote for politicians who make their lives better; and that good public policy seeks to create human catastrophe rather than to avert it.
The problem for American conservatives is not their choice of candidates or the tone of their rhetoric. It is that their ideas are not politically sustainable.
An Unhinged Democracy in America
NEW YORK – Alexis de Tocqueville, a liberal French aristocrat, visited the United States in 1831 ostensibly to write a study of its “enlightened” prison system (locking people up in solitary confinement like penitent monks was the latest modern idea).
Out of this trip came de Tocqueville’s masterpiece, Democracy in America, in which he expressed admiration for American civil liberties and compared the world’s first genuine liberal democracy favorably with Old World institutions.
But de Tocqueville had serious reservations, too.
The biggest danger to US democracy, he believed, was the tyranny of the majority, the suffocating intellectual conformity of American life, the stifling of minority opinion and dissent.
He was convinced that any exercise of unlimited power, be it by an individual despot or a political majority, is bound to end in disaster.
Democracy, in the sense of majority rule, needs restraints, just like any other system of government.
That is why the British have mixed the authority of elected politicians with that of aristocratic privilege.
And it is why Americans still cherish their Constitution’s separation of governmental powers.
By contrast, in the French republican system, the state represents the so-called will of the people.
As a result, its authority is less constrained, which may explain the greater frequency in France of street demonstrations and even of mob violence.
Indeed, these upheavals may act as informal checks on official power.
De Tocqueville identified another source of restraint in the US system: the power of religion.
Human greed, as well as the temptation of going to extremes, was tempered by the moderating influence of a shared Christian faith.
Liberty, in the US, was inextricably entwined with religious belief.
The spectacle of American politics today would seem to cast doubt on de Tocqueville’s observation.
Or, rather, the rhetoric of many Republicans aspiring to be President sounds like a perversion of what he saw in 1831.
Religion and liberty are still mentioned in one breath, but often to promote extreme views.
Religious minorities are denounced.
Apocalyptic fears are stoked.
Intolerance is promoted.
All in the name of God.
Of course, the US is not the only country where fringe demagogues are now poisoning mainstream politics.
Religious language is less often heard in Western Europe, but all the more in parts of Eastern Europe, Turkey, and Israel.
And the message of populism is similar everywhere in the democratic world: Liberal elites are to be blamed for all our ills and anxieties, from Europe’s refugee crisis to the inequities of the global economy, from “multiculturalism” to the rise of radical Islam.
Populism is causing considerable alarm, not least because mainstream politicians seem less and less capable of finding a convincing way to stop its rise.
Those who are rightly worried about the politics of fear like to assume that populism is a threat to democracy itself.
Distrust of the elites fosters distrust of the system, and the longing for great leaders who will deliver us from the selfishness of professional politicians will lead to new forms of tyranny.
That may turn out to be true.
But, in fact, it is not really democracy that is presently under siege.
In some ways, many societies are more democratic than they were before.
If nothing else, the Donald Trump phenomenon shows that old party establishments can be skirted by popular outsiders.
Social media also make it possible to bypass the traditional filters of authority, such as serious newspapers or broadcasters, and publish any point of view directly.
The power of private fortunes to sway public opinion, especially in the US, also upsets the traditional order.
Anti-elitism can be fanned by vast individual wealth, because elitism is defined less by financial clout than by education.
Angry people swayed by the populist message are angrier at liberal professors, clever bankers, or skeptical journalists than they are at multi-billionaires.
(It is both President Barack Obama’s elite education and the color of his skin – or, rather, the combination of the two – that has attracted so much rage.)
At the same time, people have more power to elect power-hungry crooks than they did before.
Like the wild and woolly views swirling around the Internet, such figures are no longer kept at bay by traditional party elites.
What is steadily falling away is not democracy, but the restraints that de Tocqueville thought were essential to make liberal politics work.
More and more, populist leaders regard their election by the majority of voters as a license to crush all political and cultural dissent.
De Tocqueville’s nightmare is not yet the reality in the US, but it is close to what we see in Russia, Turkey, Hungary, and perhaps Poland.
Even Israel, which, despite its many obvious problems, has always had a robust democracy, is moving in this direction, with government ministers demanding proof of “state loyalty” from writers, artists, and journalists.
It is hard to see how traditional elites are going to regain any authority.
And yet I think de Tocqueville was right.
Without editors, there can be no serious journalism.
Without parties led by experienced politicians, the borders between show business and politics will disappear.
Without limits placed on the appetites and prejudices of the majority, intolerance will rule.
This is not a question of nostalgia or snobbery.
Nor is it a plea to trust anyone with a plausible air of authority.
Anger at the elites is not always unjust.
Globalization, immigration, and cosmopolitanism have served the interests of a highly educated minority, but sometimes at the expense of less privileged people.
And yet, the problem identified by de Tocqueville in the 1830s is more relevant now than ever.
Liberal democracy cannot be reduced to a popularity contest.
Constraints on majority rule are necessary to protect the rights of minorities, be they ethnic, religious, or intellectual.
When that protection disappears, we will all end up losing the freedoms that democracy was supposed to defend.
The Indispensable American Partner
MADRID – The United States is gearing up for that most intoxicating (and exhausting) of political events: an open-seat race for the presidency.
With US President Barack Obama's eight years in office coming to an end, and Vice President Joe Biden unlikely to run, the race will be without an incumbent.
As a result, the election could be less a referendum on the last eight years than a contest of ideas, with foreign policy emerging as a key topic.
As for the Democrats, former Secretary of State Hillary Clinton's likely nomination (despite recent revelations that she used her personal email account to conduct government business) reinforces foreign policy's centrality to the election.
From my perspective as the group's only European member, the overarching message should be that the US must conceive of itself not as “the indispensable power," as it now does, but as “the indispensable partner."
This is not merely a matter of semantics; such a change will require the US to re-conceive its role in the world.
But the payoff, for both the US and the liberal world order that it created, would be substantial.
The key to success will be America's ability to retain the best – and abandon the worst – of that most American of notions: exceptionalism.
The sense in the US that the country is unique, with a special mission to promote prosperity, security, and freedom worldwide, has long shaped American foreign policy.
In doing so, he planted the seed of the values-based approach that was adopted by the US as it spearheaded the development of the rules and structures that order today's world.
Those rules and structures have delivered unprecedented economic growth, benefiting all (though the US has reaped the greatest rewards).
But, ironically, the notion of American exceptionalism often has led the US to undermine the international system that it nurtured.
Indeed, US history reveals a persistent isolationist streak, in which the “city upon a hill" is not a beacon, but a fortress.
At times, including over the last six years, the belief that the US is better off going it alone has led to withdrawal from the world.
This tendency was not a serious issue before World War II (though the people of Abyssinia and Manchuria may beg to differ).
But today, US withdrawal from the international system that it built has serious ramifications – namely, the kind of chaos and lawlessness exemplified by Russia's invasion of Ukraine.
Yet isolationism is not America's most destructive impulse.
Worse is its “exemptionalism": its penchant for opting out of the rules that it promotes – and often actively enforces – elsewhere.
Beyond the resentment that such an attitude engenders, American exemptionalism directly undermines multilateral institutions' capacity to address challenges that the US is unwilling or unable to resolve on its own.
US President Barack Obama's administration has tried to create the illusion of a change of course in this regard, pushing “soft" deals that allow the US to participate without submitting to binding rules.
But, though such arrangements make for great headlines, they do not provide the stability and predictability necessary for long-term success.
If the US is to serve as the world's “indispensable partner," it must recommit to the rules-based order that has served it – and the world – so well for the last seven decades.
It should begin by strengthening the flagging institutions that have served as the backbone of the liberal international order.
Indispensable partnership is about helping countries help themselves.
It requires vision, commitment, and, most important, leadership.
A frank discussion about America's foreign policy could prove vital to ensuring that this “city upon a hill" remains a beacon of hope – and a catalyst of progress.
American Foreign Policy after Iraq
What comes after Iraq?
If President George W. Bush’s current troop “surge” fails to produce an outcome that can be called “victory,” what lessons will the United States draw for its future foreign policy?
Will it turn inward, as it did after its defeat in Vietnam three decades ago?
Will it turn from promoting democracy to a narrow realist view of its interests?
Even while discussion in Washington is fixated on Iraq, a number of thoughtful foreign observers are asking these longer-term questions.
Analysts and pundits have often been mistaken about America’s position in the world.
For example, two decades ago, the conventional wisdom was that the US was in decline.
A decade later, with the Cold War’s end, the new conventional wisdom was that the world was a unipolar American hegemony.
Some neo-conservative pundits drew the conclusion that the US was so powerful that it could decide what it thought was right, and others would have to follow.
Charles Krauthammer celebrated this view as “the new unilateralism,” and it heavily influenced the Bush administration even before the attacks on September 11, 2001.
But the new unilateralism was based on a profound misunderstanding of the nature of power in world politics.
Power is the ability to get the outcomes one wants.
Whether the possession of resources will produce such outcomes depends upon the context.
For example, a large, modern tank army is a powerful resource if a war is fought in a desert, but not if it is fought in a swamp – as America discovered in Vietnam.
In the past, it was assumed that military power dominated most issues, but in today’s world, the contexts of power differ greatly.
I have likened the distribution of power in politics today as analogous to a three-dimensional chess game.
On the top board – military relations among states – the world is, indeed, unipolar, and likely to remain that way for decades.
But on the middle board of economic relations, the world is already multipolar, and the US cannot obtain the outcomes it wants without the cooperation of Europe, Japan, China, and others.
And, on the bottom board of transnational issues outside the control of governments – including everything from climate change to pandemics to transnational terrorism – power is chaotically distributed, and it makes no sense at all to claim American hegemony.
Yet it is on this bottom board that we find most of the greatest challenges we face today.
The only way to grapple with these problems is through cooperation with others, and that requires the “soft” power of attraction as well as the hard power of coercion. There is no simple military solution that will produce the outcomes we want.
The new unilateralists who dominated Bush’s first administration made the mistake of thinking that the unipolar distribution of power in the military context was sufficient to guide foreign policy.
They were like a young boy with a hammer who thinks that every problem resembles a nail.
The danger of their approach is now obvious.
Whoever plays a three-dimensional game by focusing on only one board is bound to lose in the long run.
Fortunately, the pendulum has begun to swing back toward cooperation.
In Bush’s second term, some of the most extreme unilateralists have departed from the government, and the president has approached difficult problems like North Korea or Iran with a more multilateral approach than during his first term.
Likewise, for all the complaints about the United Nations, the US and others turned to UN peacekeepers to sort out the mess after the Lebanon War last summer.
The Iraq War, in particular, increased public awareness of the mistakes in Bush’s first term, but other issues are changing as well.
Americans now view cooperative action on global climate change more favorably.
Similarly, the threat of pandemics means that Americans may come to recognize the importance of a stronger World Health Organization, just as the problem of nuclear proliferation is increasing awareness of the importance of the International Atomic Energy Agency.
The nature of these problems means that the US does not have the luxury of turning inward no matter what the outcome in Iraq.
These are not problems you can leave overseas.
They follow you home.
It also is unlikely that American foreign policy will return to a narrow realism and drop all emphasis on democracy and human rights.
While the Iraq War discredited the idea of coercive democratization, both Republicans and Democrats have a strong strand of idealism in their foreign policy orientations.
The problem for whoever is elected president in 2008 will be to find appropriate realistic means to advance democratic values and adjust official rhetoric accordingly.
When rhetoric greatly outstrips reality, others view it as hypocrisy.
Americans will need to find ways to assert their narrative of democracy, freedom, and rights in a manner that respects diversity and the views of others.
What Iraq has taught is the importance of developing civil society and the rule of law before trying to hold broad-based elections.
Democracy is more than voting, for it requires large investments in education, institutions, and promotion of non-governmental organizations.
It must be rooted in the indigenous society and bear its characteristics, not be imposed from abroad.
It is highly unlikely that the US will react after Iraq as it did after Vietnam.
The paradox of American power is that the world’s only military superpower cannot protect its citizens by acting alone.
US Foreign Policy After the Midterm Election
WASHINGTON, DC – One thing missing from the recent US midterm election campaigns was a focus on foreign policy.
While much was made of the migrant caravan making its way from Central America through Mexico, issues such as trade with China, Iran, North Korea, and even Russia and cyber subterfuge didn’t get much traction.
With the Democratic Party having regained control of the US House of Representatives, that will change.
A cornered President Donald Trump is likely to turn to a favorite tactic of autocrats everywhere: manufacturing foreign-policy crises to distract the public’s attention from problems at home.
Trump’s determination to control media headlines makes him all the more likely, when it suits him, to call attention to the troubles in the Middle East, rediscover the North Korean nuclear threat, and force the Democrats to make a tough choice between being hard on Russia or getting into an arms race.
Trump may also decide to use Congress as a foreign-policy foil, tossing international challenges back into the lap of lawmakers, who will be hard-pressed to come up with good answers.
After all, in Trump’s zero-sum “I win, you lose” view of the world, congressional failures that he can blame on the Democrats are almost as good as White House successes.
With the US House of Representatives under “new management,” including a record number of Democratic women, Trump has a tempting target.
He has every incentive to show the newcomers up by passing the ball and watching them fail.
In this new contest to pass the blame, Syria is ripe for the picking.
Eliot Engel, the incoming chairman of the House Foreign Affairs Committee, has already said that the Democrats may seek congressional authorization for the use of military force in Syria.
But no one, Democrat or Republican, has a plausible plan either for ending the war in Syria or even for helping Syrian civilians in significant numbers, other than making it risky for Syria’s ruler, Bashar al-Assad, to use chemical weapons too blatantly.
Any move the Democrats make will be unpopular with their own voters and will simply shift attention from Trump’s inability to solve the problem to their own lack of a plan.
Iran presents Trump with another opportunity to inflict political damage on the Democrats.
Trump followed through on his threat in January to withdraw the United States from the 2015 Iran nuclear deal – formally known as the Joint Comprehensive Plan of Action (JCPOA) – if Congress didn’t “fix” it.
Specifically, he wanted the ability to reimpose sanctions on Iran, which he did earlier this month.
Sanctions, Trump has long maintained, would force Iran to negotiate. That has not happened and is unlikely to happen.
To push Iran toward the negotiating table, and, more importantly, assert his authority and save face, Trump might be tempted to heighten tensions, if not provoke Iran into a confrontation.
And here, Engel might be forced to play along.
Engel has said that Iran is the “most dangerous player” in the Middle East, and he was a vocal opponent of the JCPOA.
Though he supported the deal after it was signed and opposed withdrawing from it, Trump could use Engel’s own position on Iran to push him to adopt a more aggressive posture or risk appearing “weak” on national security.
But the payoff is likely to be a foreign-policy crisis that produces no meaningful progress toward a new nuclear deal and plenty of blame to go around.
The Democrats also provide Trump an out on North Korea.
Back in June, Engel introduced the North Korea Nuclear Baseline Act, which would require the White House to report on the status of North Korea’s nuclear program and provide a “baseline” of progress for continued talks.
Engel has already said he will call a hearing on the talks.
Whatever is said in that hearing could provide North Korean leader Kim Jong-un with a ready excuse to renege on his already-vague denuclearization agreement with Trump.
The US president, Kim could argue, can no longer be trusted with a hostile Congress at his back.
Perhaps in anticipation of a Democratic-led House and a subsequent Democratic pile-on regarding Russia, Trump withdrew the US from the Intermediate-Range Nuclear Forces Treaty (INF) in October, citing Russian violations.
Signed in 1987 by Ronald Reagan and Soviet premier Mikhail Gorbachev, the INF required both the US and Russia to eliminate ground-launched ballistic and cruise missiles. The US withdrawal from it signals the start of a new arms race.
Trump has already called for an increase in defense spending and the launch of a “space force”.
As Democrats focus on Russian interference in the 2016 US elections, Trump’s ties to Russia, and the details of Trump’s closed-door conversation with Russian president Vladimir Putin in Helsinki in July, they will be faced with the prospect of signing off on increased defense spending or else appearing dithering and hypocritical on Russia.
Much of the world breathed a sigh of relief at the Democrats’ recapture of the House, because it signaled a vulnerability in Trump’s aggressively anti-liberal “America First” approach to the world order.
But Democrats should resist the urge to try correcting Trump’s perceived wrongs.
The House has just enough power to get into foreign-policy trouble and not enough to get out of it or to adopt and implement a coherent strategy.
The Democrats’ best bet is to let Trump take the lead on global affairs, however unsavory, and actively work to check and balance his actions.
Oversight and the power of the purse will be their most powerful tools.
In the end, Trump will need House Democrats for money, sanctions, or approval of trade agreements.
If they play their cards right, he will have to deal them in. If they don’t, they will find that Trump still holds a much stronger hand.
American Foreign Policy After the Mid-Term Elections
NEW YORK – Few Americans cast their ballot in the recent mid-term elections on the basis of foreign policy.
While it may be difficult for people around the world to comprehend this, given the global reach of the United States, it is an undeniable fact.
Most Americans are, after all, preoccupied with the US economy’s sluggish growth and persistent high unemployment.
The world’s challenges seem far removed from their day-to-day lives.
The Cold War ended a generation ago; the terror attacks of September 11, 2001, are nearly a decade in the past.
Most Americans do not feel the sacrifices associated with the large troop presence and ongoing conflicts in Afghanistan and Iraq.
But the fact that foreign policy did not materially affect the November elections does not mean that the results will not affect US foreign policy.
They will, but in ways that are inconsistent and even surprising.
One relationship sure to be influenced by Republican gains will be that between the US and Russia.
Quick or easy Senate approval of the New START arms-control treaty is highly unlikely, given stated concerns about verification and the protection of US missile-defense programs; instead, we can expect delays and, possibly, attempts to amend what the two governments already agreed upon.
Congress may also prove less willing to remove hurdles to Russia’s admission to the World Trade Organization, given what is widely judged to be its leaders’ anti-democratic behavior.
China, too, will feel the results of the new balance in Congress.
Pressure was already growing to introduce trade sanctions in response to China’s refusal to allow its currency to rise to a natural level against the dollar.
Such pressure will likely grow, given concerns over Chinese behavior both at home and abroad.
Moreover, Congress will resist rolling back any of the long-standing economic sanctions against Cuba.
President Barack Obama has the authority to take some small steps on his own to normalize ties, but substantial change to US policy requires Congress to act – and Congress wants to see fundamental change in Cuba before it does so.
There will be other consequences stemming from the election.
What little chance there was of the US backing any global plan to limit or tax carbon emissions has disappeared.
Improvement in US performance on climate change will have to come from innovation and increased energy efficiency.
One can anticipate the Republicans, now in control of the House of Representatives, exploiting their ability to convene hearings to question and review foreign policy.
Depending on how this power is used (or abused), it can be beneficial (exercising needed oversight and increasing the transparency of policy and policy-making) or destructive (if, for example, hearings degenerate into politically motivated attacks on administration officials and policies).
In many other areas, continuity can be expected to trump change.
This comes as little surprise, as America’s Constitution and political system delegate most of the initiative on foreign policy and defense to the president.
Yes, Congress must declare war, approve spending, agree to most senior appointments, and (in the case of the Senate) ratify treaties, but the president has enormous latitude when it comes to carrying out diplomacy and using military force in situations other than war, which tend to be most situations.
One area of probable continuity is the Middle East, where Obama will continue to try to broker a deal between Israelis and Palestinians and press Iran not to develop nuclear weapons.
(Republicans, however will argue for putting less pressure on Israel to compromise and more pressure on Iran.)  But he can expect considerable backing from Republicans if he wants to maintain a sizeable US military presence in Afghanistan beyond this July, or a modest military presence in Iraq beyond the end of 2011.
Questions abound when it comes to foreign economic policy, however.
Three completed trade agreements (with South Korea, Panama, and Colombia) have been languishing for years, mostly because of deep opposition to free trade from labor unions and the Democratic Party.
Republicans have historically been more supportive of such bilateral free-trade agreements.
But will the new generation of Republicans continue this tradition?
There is a fair chance that one or more of these bilateral accords will be approved (in part because the Obama administration seems finally to have recognized that trade can generate good jobs), but it is far less certain that the president will gain the authority needed to negotiate a new global trade deal.
An even bigger question mark hovers over what might be the greatest national security concern of all: the federal budget deficit.
Failure to address the deficit (and the mounting debt) will create pressures to reduce what the US spends on foreign aid, intelligence, and defense – although Republicans are more likely than Democrats to protect such spending (except for foreign aid).
Mounting debt also leaves the US vulnerable to the decisions of those who lend it money – or to the vagaries of the market.
A dollar crisis could weaken the foundations of American power.
But averting such a crisis requires that the White House and Congress, Democrats and Republicans, agree on a plan for moving the US budget toward balance.
Alas, the election makes such agreement more distant than ever.
America’s Global Balancing Act
With Russia’s invasion of Ukraine and annexation of Crimea, the disintegration of Iraq’s and Syria’s borders, and increasing Chinese assertiveness in the South and East China Seas, the post-Cold War era appears to have ended in 2014.
Is that true?
The post-Cold War era was not really an “era,” but rather a gradual transition from a bilateral Cold War to a more complex international order that still involves, in the final analysis, two world powers.
In brief, the decisive axis of the new order increasingly involves the United States and the People’s Republic of China.
The Sino-American competition involves two significant realities that distinguish it from the Cold War: neither party is excessively ideological in its orientation; and both parties recognize that they really need mutual accommodation.
America’s supposed “pivot to Asia” took a back seat in 2014 to the crises in Ukraine and the Middle East.
To what extent has uncertainty about the US commitment in Asia stoked tension between China and America’s Asian allies?
I disagree with the premises of the question.
I do think America has made it quite clear that it is in the interest both of America and China to avoid situations in which they will be pushed toward a collision.
The recent indications of some initial dialogue between China and India, and between China and Japan, suggest that China also realizes that escalating old grievances is not in its interest.
The more serious problem with the “pivot to Asia” was its actual wording, which implied a military posture designed to “contain” or “isolate” China.
The Chinese have come to realize more clearly that we were not deliberately attempting to isolate them, but that we had a stake in the avoidance of collisions in the Far East that could produce a wider spillover.
Xi Jinping has used his war on corruption to concentrate more power in his hands than any Chinese leader since Deng Xiaoping, 30 years ago.
How do you see Xi’s presidency evolving?
Power in China is somewhat informally defined, and its limits are set more by political realities than by constitutional arrangements.
That makes it difficult to say whether Xi’s power is greater than any Chinese leader’s since Deng.
He certainly has an authoritative personality and without doubt is more active on the international scene than some of his predecessors.
He has also been very decisive in attacking the growing corruption that has become a major source of internal malaise, reaching even the highest levels of government.
In that respect, it may be argued that his power is more wide-ranging than that of his predecessors, but in fairness it must also be noted that the patterns of corruption that his predecessors faced were not as acute and widespread as they have become in recent years.
At the same time, the increasing emphasis in party journals on the proposition that China’s armed forces must be viewed as servants of the Communist Party, and not simply of the nation, seems to suggest concern that the military may be developing its own view of Chinese domestic affairs, in addition to proclaiming with increasing assertiveness its responsibility for national security.
The Party elite, quite understandably, does not find this reassuring.
Can Russian President Vladimir Putin’s regime withstand a prolonged period of low energy prices and Western sanctions?
What risks do you see emerging should Russia’s economy continue to decline, with Putin increasingly unable to reward his political base?
There is, of course, a danger that at some point Putin may choose to lash out and create a truly massive international crisis, and perhaps precipitate some new form of direct East-West warfare.
But to say that, one must also assume that to some extent he himself is unbalanced and has shifted from a kind of guerilla warfare against the West, always with some possibility of retreat, to all-out combat.
The outcome of that would be inherently unpredictable, but probably in any case very destructive for Russian wellbeing.
If Russia’s economy continues to decline, and if the West succeeds in deterring Putin from further use of force, it is still conceivable that some acceptable resolution (a form of which I recommended publicly by talking about the Finland model) may be contrived.
But that depends in turn on the West’s firmness in supporting Ukraine’s efforts to stabilize itself.
Following the withdrawal of US troops from Afghanistan and Iraq, much of the world now perceives the US as being in a period of “retreat,” similar to the post-Vietnam War era.
Is the US embracing a form of neo-isolationism?
Or will America’s apparent inward turn be as brief as it was following Vietnam?
I do not believe that the US is in a “period of retreat.”
The fact of the matter is that the redistribution of global power has produced a situation in which the US is no longer the sole hegemon.
The US has to acknowledge the fact that the world is now much more complex.
The spread of conflict throughout the Middle East is currently precipitated more by the rise of religious sectarianism than by American interventionism.
In these volatile circumstances, greater attention must be given to the national interests of countries such as Turkey, Iran, Saudi Arabia, Egypt, and Israel.
By the same token, the interests of any one of them must not be allowed to become the total interest of the US.
What may surprise the world most in 2015?
Perhaps the gradual reappearance in Russia of a more politically assertive liberal middle class.
That middle class was beginning to play a more significant role in shaping domestic and international Russian policy under Dmitri Medvedev.
With Putin’s return to power and his recent adventurism, it has been pushed aside by deliberately awakened and intensely stimulated national chauvinism.
Waving a chauvinist banner, however, may not be the best solution for dealing with international problems, especially if the West is intelligent and united. The Russian middle class, quite naturally, wishes to live in a society like that of Western Europe.
A Russia that gradually begins to gravitate toward the West will also be a Russia that ceases to disrupt the international system.
America’s Enemy Within
NEW YORK – Barring any unexpected new revelations, there is not much to be learned from the Tsarnaev brothers, better known as “the Boston bombers.”
We can dig into their family histories in strife-torn Dagestan, or examine, once again, the lethal appeal of Islamist radicalism.
But I doubt that this would be enlightening.
The elder brother, Tamerlan, who died in a gun battle with the police, appears to fit perfectly the profile of what the German writer Hans Magnus Enzensberger calls “the radical loser.”
And his younger brother, Dzhokhar, recovering from gunshot wounds in a Boston hospital while waiting to be put on trial for his life, seems to have been a pathetic follower who acted less out of deep conviction than out of fraternal love.
The radical loser is the kind of young man who feels victimized by an unfeeling, uncaring world.
That sour sense of rejection, felt by many confused youths, turns for some into a fierce desire for vengeance.
Like Samson in the temple of Gaza, he wishes to destroy himself in a public act of violence, taking as many people as possible with him.
Anything can trigger this final act: a lover’s rejection, a job application denied.
In the case of Tamerlan, a talented boxer, he was denied the chance to become a champion because he was not yet a United States citizen.
Radical Islamism offered him a ready-made cause to die for.
More interesting, and in a way far more disturbing, has been the reaction in the US to the Boston bombings, which killed three people and injured 264.
Even after Tamerlan had died, and Dzhokhar, already wounded, was the only known fugitive, the Boston authorities decided to close down the entire city.
Public transport was halted, trains to and from the city were stopped, shops and business closed, and citizens were told to stay home.
Until the surviving bomber was found, Boston was reduced to a ghost town.
If two troubled young men with homemade bombs cobbled together from fertilizer and pressure cookers can have this effect on a major American city, one can imagine how tempting their example must now be to other radical losers, not to mention radical groups.
It shows how vulnerable a modern city can be when its leaders lose their nerve.
The authorities’ overblown reaction – and that of much of the press – was all the odder for having occurred just as the US Senate was voting down a bill that would have made it harder for known killers and mentally disturbed people to buy guns, or for private individuals to acquire weapons normally used only in warfare.
It seems as though Americans can tolerate a society in which schoolchildren and other innocents are regularly murdered by deranged men with weapons bought on the open market, but erupt in collective hysteria when the killings are committed by people labeled as “terrorists.”
This may reflect what people are accustomed to.
The Spanish had grown so inured to acts of violence from Basque separatists that the murder of 191 people in Madrid by Islamist extremists in 2004 was met with remarkable sang-froid. When 52 people were killed in a suicide bombing on the London Underground the following year, the British, too, reacted with relative calm, having lived through years of Irish terrorist violence in the 1970’s.
Like the Spanish, they were used to it.
Americans, despite the attacks of September 11, 2001, are not.
Worse than that, a number of Republican senators, including such luminaries as John McCain, called for stripping Dzhokhar Tsarnaev, who is a US citizen, of his legal rights and placing him before a military tribunal as an “enemy combatant,” as though the 19-year-old college student were a soldier in a war against America.
Exaggerated fear of outside enemies has always been part of the American political landscape.
The “nation of immigrants” was traditionally regarded as a refuge from danger.
The evil outside world should not be able to touch the Land of the Free.
When it does – Pearl Harbor, September 2001 – all hell breaks loose.
Another factor may be the need for a common enemy in a country whose citizens come from so many different cultures and traditions.
Besieged by Communists or Islamists, people feel a sense of belonging.
Defense of the nation against dangerous outsiders – and their domestic agents, whether real or imagined – provides a powerful bond.
Such bonds can be useful, even necessary, in times of war.
But the politics of fear poses a danger to the US itself.
The aim of political terrorist groups, such as Al Qaeda, is to provoke retaliation and maximize publicity for their cause.
As common criminals, such groups’ members would not achieve this goal.
But by claiming to be soldiers at war with the world’s biggest military power, they gain sympathy, as well as recruits, among the radical losers and the disaffected.
Former President George W. Bush once explained terrorism as the expression of hatred for American freedom.
But when terrorism results in torture of prisoners, ever more police surveillance, and official threats to US citizens’ legal rights – or, for that matter, when a crime committed by two young immigrants causes an entire city to be shut down – Americans’ government is harming their freedom more than any terrorist could ever hope to do.
American Hegemony or American Primacy?
CAMBRIDGE – No country in modern history has possessed as much global military power as the United States.
Yet some analysts now argue that the US is following in the footsteps of the United Kingdom, the last global hegemon to decline.
This historical analogy, though increasingly popular, is misleading.
Britain was never as dominant as the US is today.
To be sure, it maintained a navy equal in size to the next two fleets combined, and its empire, on which the sun never set, ruled over a quarter of humankind.
But there were major differences in the relative power resources of imperial Britain and contemporary America.
By the outbreak of World War I, Britain ranked only fourth among the great powers in terms of military personnel, fourth in terms of GDP, and third in military spending.
The British Empire was ruled in large part through reliance on local troops.
Of the 8.6 million British forces in WWI, nearly a third came from the overseas empire.
That made it increasingly difficult for the government in London to declare war on behalf of the empire when nationalist sentiments began to intensify.
By World War II, protecting the empire had become more of a burden than an asset.
The fact that the UK was situated so close to powers like Germany and Russia made matters even more challenging.
For all the loose talk of an “American empire,” the fact is that the US does not have colonies that it must administer, and thus has more freedom to maneuver than the UK did.
And, surrounded by unthreatening countries and two oceans, it finds it far easier to protect itself.
That brings us to another problem with the global hegemon analogy: the confusion over what “hegemony” actually means.
Some observers conflate the concept with imperialism; but the US is clear evidence that a hegemon does not have to have a formal empire.
Others define hegemony as the ability to set the rules of the international system; but precisely how much influence over this process a hegemon must have, relative to other powers, remains unclear.
Still others consider hegemony to be synonymous with control of the most power resources.
But, by this definition, nineteenth-century Britain – which at the height of its power in 1870 ranked third (behind the US and Russia) in GDP and third (behind Russia and France) in military expenditures – could not be considered hegemonic, despite its naval dominance.
Similarly, those who speak of American hegemony after 1945 fail to note that the Soviet Union balanced US military power for more than four decades.
Though the US had disproportionate economic clout, its room for political and military maneuver was constrained by Soviet power.
Some analysts describe the post-1945 period as a US-led hierarchical order with liberal characteristics, in which the US provided public goods while operating within a loose system of multilateral rules and institutions that gave weaker states a say.
They point out that it may be rational for many countries to preserve this institutional framework, even if American power resources decline.
In this sense, the US-led international order could outlive America’s primacy in power resources, though many others argue that the emergence of new powers portends this order’s demise.
But, when it comes to the era of supposed US hegemony, there has always been a lot of fiction mixed in with the facts.
It was less a global order than a group of like-minded countries, largely in the Americas and Western Europe, which comprised less than half of the world.
And its effects on non-members – including significant powers like China, India, Indonesia, and the Soviet bloc – were not always benign.
Given this, the US position in the world could more accurately be called a “half-hegemony.”
Of course, America did maintain economic dominance after 1945: the devastation of WWII in so many countries meant that the US produced nearly half of global GDP. That position lasted until 1970, when the US share of global GDP fell to its pre-war level of one-quarter.
But, from a political or military standpoint, the world was bipolar, with the Soviet Union balancing America’s power.
Indeed, during this period, the US often could not defend its interests: the Soviet Union acquired nuclear weapons; communist takeovers occurred in China, Cuba, and half of Vietnam; the Korean War ended in a stalemate; and revolts in Hungary and Czechoslovakia were repressed.
Against this background, “primacy” seems like a more accurate description of a country’s disproportionate (and measurable) share of all three kinds of power resources: military, economic, and soft.
The question now is whether the era of US primacy is coming to an end.
Given the unpredictability of global developments, it is, of course, impossible to answer this question definitively.
The rise of transnational forces and non-state actors, not to mention emerging powers like China, suggests that there are big changes on the horizon.
But there is still reason to believe that, at least in the first half of this century, the US will retain its primacy in power resources and continue to play the central role in the global balance of power.
In short, while the era of US primacy is not over, it is set to change in important ways.
Whether or not these changes will bolster global security and prosperity remains to be seen.
What I Tell My Non-American Friends
CAMBRIDGE – I frequently travel overseas, and invariably my foreign friends ask, with varying degrees of bewilderment: What in the world is going on in your country?
Here is what I say.
First, do not misinterpret the 2016 election.
Contrary to some commentary, the American political system has not been swept away by a wave of populism.
True, we have a long history of rebelling against elites.
Donald Trump tapped into a tradition associated with leaders like Andrew Jackson and William Jennings Bryan in the nineteenth century and Huey Long and George Wallace in the twentieth century.
And yet Trump lost the popular vote by nearly three million.
He won the election by appealing to populist resentment in three Rust Belt states – Michigan, Pennsylvania, and Wisconsin – that had previously voted Democratic.
If a hundred thousand votes had been cast differently in those states, Trump would have lost the Electoral College and the presidency.
That said, Trump’s victory points to a real problem of growing social and regional inequality in the United States.
J.D. Vance’s recent best-selling book Hillbilly Elegy compellingly describes the vast difference between California and Appalachia.
Research by the Princeton economists Anne Case and Angus Deaton shows that the demographic trends among lower-income whites without a college degree are worse than those for African-Americans, who historically anchored the lower extremes of inequality.
In 1999, mortality rates among whites with no college were around 30% lower than those of African-Americans; by 2015, they were 30% higher.
Moreover, manufacturing employment, once a prime source of high-paying jobs for working-class whites, has fallen sharply over the last generation, to just 12% of the workforce.
These previously Democratic voters were attracted by Trump’s promises to shake things up and bring back manufacturing jobs.
Ironically, Trump’s efforts to repeal President Barack Obama’s health-care legislation would make their lives worse.
The second thing I tell my foreign friends is not to underestimate Trump’s communications skills.
Many are offended by his tweet storms and outrageous disregard for facts.
But Trump is a veteran of reality television, where he learned that the key to success is to monopolize viewers’ attention, and that the way to do that is with extreme statements, not careful regard for the truth.
Twitter helps him to set the agenda and distract his critics.
What offends commentators in the media and academia does not bother his supporters.
But as he turns from his permanent self-centered campaigning to trying to govern, Twitter becomes a two-edged sword that deters needed allies.
Third, I tell my friends not to expect normal behavior.
Normally, a president who loses the popular vote moves to the political center to attract additional support.
This is what George W. Bush did successfully in 2001.
Trump, by contrasts, proclaims that he won the popular vote and, acting as though he really did, appeals to his base voters.
While Trump has made solid centrist appointments to the Departments of Defense, State, and Homeland Security, his picks for the Environmental Protection Agency and the Department of Health and Human Services are from the extremes of the Republican Party.
His White House staff is divided between pragmatists and ideologues, and he caters to both.
Fourth, no one should underestimate US institutions.
Sometimes my friends talk as though the sky is falling and ask if Trump is as dangerous a narcissist as Mussolini.
I tell them not to panic.
The US, for all its problems, is not Italy in 1922.
Our national political elites are often polarized; but so were America’s founders.
In designing the US Constitution, the founders’ goal was not to ensure harmonious government, but to constrain political power with a system of checks and balances that made it difficult to exercise.
The joke goes that the founders created a political system that made it impossible for King George to rule over us – or for anyone to ever do so.
Inefficiency was placed in the service of liberty.
It is still early in the Trump presidency, and we cannot be sure what might happen after, say, a major terrorist attack.
So far, however, the courts, the Congress, and the states have checked and balanced the administration, as Madison intended.
And the permanent civil servants in the executive departments add ballast.
Finally, my friends ask what all of this means for American foreign policy and the liberal international order led by the US since 1945.
Frankly, I don’t know, but I worry less about the rise of China than the rise of Trump.
While American leaders, including Obama, have complained about free riders, the US has long taken the lead in providing key global public goods: security, a stable international reserve currency, relatively open markets, and stewardship of the Earth’s commons.
Despite the US-led international order’s problems, the world has prospered and poverty has been reduced under it.
But one cannot be sure it will continue.
The US will need to cooperate with China, Europe, Japan, and others to manage transnational problems.
During the 2016 campaign, Trump was the first major party candidate in 70 years to call the American alliance system into question.
Since taking office in January, statements by Trump and his appointees suggest that it is likely to persist.
American hard and soft power, after all, stems largely from the fact that the US has 60 allies (while China has only a few).
But the stability of the multilateral institutions that help manage the world economy and global commons is more uncertain.
Trump’s budget director speaks of a hard-power budget, with funds cut from the State Department and the United Nations system.
Other officials advocate replacing multilateral trade deals with “fair and balanced” bilateral arrangements.
And Trump is repudiating Obama’s efforts to address climate change.
I tell my friends I wish I could reassure them on these issues.
But I cannot.
Reclaiming American Internationalism
DENVER – To watch the debate play out in America’s news media, it would seem that the opposite of “America First” is American interventionism: a chronic penchant for leaping, to no apparent end, into wars of choice and demonstrating America’s unrivaled military power.
But interventionism is not the same thing as internationalism.
Conflating the two collapses the distinction between quick and decisive use of force and thoughtful engagement with the world and its problems.
In America’s “get ’er done” transactional Weltanschauung, international disputes tend to be viewed as military challenges that are merely masquerading as political issues.
In fact, they are usually the opposite, which is why the world’s most complex conflicts are rarely resolved by intervention.
Geopolitical conflicts have long, sordid histories, and violence is more often a symptom of their intractability than an inherent trait.
They often have something to do with identity, and with claims of collective ownership of the land beneath the feet of a particular “nation.”
The basis of political membership is more often ethnic than civil, which is contrary to Americans’ understanding of nationhood.
Moreover, contemporary problems can be the products of flawed arrangements that were made decades or even centuries ago.
Two examples that immediately come to mind are the 1916 Sykes-Picot agreement between Britain and France, which carved up the Middle East, and the 1919 Treaty of Versailles, which established national borders in the Balkans.
In both cases, creating new states may have seemed like a straightforward solution, but doing so turned out to be a prescription for more war.
For the United States, international conflicts are often an occasion to demonstrate “toughness” and “resolve.”
The US airstrikes in Bosnia were meant to lend momentum to a political process that already had the support of the European Union and Russia.
The air campaign was a last resort, an effort to punish those who did not support the peace process.
For many American pundits and politicians, then, the lesson of Bosnia was merely that the bad guys should have been bombed sooner.
Few took the opportunity to study the region’s complex history so that judicious inter-entity boundaries could be drawn up.
If they had, the final arrangement might have done more to preserve external borders and nurture a constitutional structure that would allow the new state to be integrated into the European map.
Kosovo, too, supplied more historical complexity than many were willing to grapple with.
On-the-ground diplomacy to achieve sovereign autonomy for Kosovo while respecting Serbs’ emotional connection to it was derided.
The implication was that military means should be the first – rather than the last – option for securing Kosovo’s independence.
Never mind that many European countries objected to the creation of an independent state, and had called for multilateral diplomacy to be attempted before any discussion of air strikes.
Interventionism, with internationalism as an afterthought, continued after the turn of the century, but on a much bigger stage.
After the attacks of September 11, 2001, the US led an invasion and subsequent occupation of Afghanistan to root out al-Qaeda.
But after 17 years with troops on the ground in that country, Americans have lost patience, with many embracing US President Donald Trump’s “America First” isolationism.
In Iraq, where the connection to terrorism was more dubious, the US mounted a major military effort with goals that were perplexing and shifting, insofar as they were ever clearly articulated at all.
American interventionism has often been accompanied by criticism of friends and allies, who are depicted as weak and vacillating in the face of global challenges such as Russian President Vladimir Putin’s annexation of Crimea or China’s increasing assertiveness in the South China Sea.
When things went wrong in Afghanistan and Iraq, the US blamed those countries’ political leaders, denouncing them as corrupt and deserving of regime change.
The Europeans, too, were denounced, not just for fecklessness in the face of evil, but for living fat and happy lives without shouldering their proper burden.
With these narratives deeply etched into American public consciousness, it is no wonder that Trump’s dystopian vision has prevailed over internationalism, which has become a byword for the endless use of force and condescension toward allies.
American internationalism will be back at some point.
But those who claim to support it could hasten its revival by acting in accordance with its original meaning.
Traditional internationalists show respect for the opinions of others, and a willingness to accept – and even champion – multilateral structures.
What internationalism needs now is a renewed American commitment to cooperation, even when other governments require more time to secure a mandate for action from their respective constituencies.
At the end of the day, US international leadership must rest on American values, and on a broad perception of adherence to the unalienable principles underlying liberal democracy.
In other words, America must lead by example.
Its failure to do so in recent times – not least on the refugee issue – has undermined the influence on which its power ultimately rests.
Renewing American Leadership
MADRID – December always provides an opportunity to pause and reflect on what was and what will be.
This year, one of the conclusions that such reflection yields is that the United States remains firmly at the center of the liberal world order.
Another is that the US needs to do more to lead in the way that its international standing demands.
Doubts about America’s continued global leadership have been proliferating for years.
But, though the much-discussed multi-polar world order may well be in the cards, the reality is that, for now, efforts to address global challenges – from climate change to conflict in the Middle East – demand US engagement.
Unfortunately, the narrative of American decline has gained so much traction in recent years that even US officials seem to have started to believe it, pursuing weak and piecemeal policies (or, in some cases, doing nothing at all).
President Barack Obama’s restrained foreign-policy approach appears to be fueling, not reducing, global instability.
The reasons for this lack of strong action are disputed.
Some blame Obama’s own fears about repeating his predecessors’ mistakes; others blame a hostile Congress for tying his hands.
In fact, both factors may be at work.
It may well be true that Obama would rather exercise caution – even when bold action is called for – than act impulsively and potentially cause more damage.
But the negative impact of an obstructionist, highly partisan US Congress should not be underestimated.
For example, by blocking reforms to International Monetary Fund governance that were agreed in 2010, Congress has damaged, perhaps irreparably, the legitimacy and relevance of the Bretton Woods institutions.
Likewise, by refusing to ratify the United Nations Convention on the Law of the Sea, the US Congress has undermined America’s credibility as it attempts to reaffirm international law in the South China Sea, where China is acting with increasing audacity.
And, by opposing the inclusion of legally binding climate commitments, it weakened the global climate agreement that was reached this month in Paris, leaving compliance and implementation uncertain.
Stalemate has become the name of the game in US politics in recent years.
That is why next year’s presidential election is so crucial.
It offers an opportunity for a fresh start, a new approach that produces the type of policy actions that the world needs.
The key is engagement – among branches of the US government, between the US government and the public, and between the US and the rest of the world.
For starters, to avoid the kind of obstructionism that prevailed in the last eight years, the next president must engage Congress directly and actively.
And, in fact, two of the Obama administration’s recent wins – the passage of so-called trade promotion authority (fast-track negotiating authority to conclude the Trans-Pacific Partnership) and the reauthorization of the small but vital Export-Import Bank – were the result of dedicated outreach, education, and, yes, cajoling of lawmakers.
The Iran nuclear agreement, one of Obama’s hallmark achievements, involved similar efforts to engage Congress, from protracted trips to Capitol Hill by Obama administration officials to a creative approach that allowed legislators to display their displeasure for the deal, without blocking its progress.
Even in America’s highly divisive political atmosphere, it seems, where there is a will, there is a way.
America’s next president must also improve engagement with citizens, whose widespread disaffection constrains – or allows – US leaders to pursue a weak foreign policy.
Like many Europeans today, most Americans do not seem to understand – or care to understand – that the crumbling of the liberal world order would have dire consequences for all of them.
It was not always this way.
Immediately after World War II, the memory of war, together with the enduring threat posed by the Soviet Union, made plain the importance of building and maintaining a liberal world order.
Today, though the need for such an order is just as great, the argument is not nearly as comprehensible or emotionally powerful.
Discussion of rules and institutions comes across as bloodless.
It is up to political leaders – and especially the president – to figure out how to make a compelling case about what is at stake.